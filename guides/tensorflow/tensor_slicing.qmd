---
title: Tensor Slicing
description: > 
  Advanced guide for working with sub-sections (slices) of Tensors.
---

```{r}
# Copyright 2020 The TensorFlow Authors.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
```

# Introduction to tensor slicing

When working on ML applications such as object detection and NLP, it is
sometimes necessary to work with sub-sections (slices) of tensors. For
example, if your model architecture includes routing, where one layer
might control which training example gets routed to the next layer. In
this case, you could use tensor slicing ops to split the tensors up and
put them back together in the right order.

In NLP applications, you can use tensor slicing to perform word masking
while training. For example, you can generate training data from a list
of sentences by choosing a word index to mask in each sentence, taking
the word out as a label, and then replacing the chosen word with a mask
token.

In this guide, you will learn how to use the TensorFlow APIs to:

-   Extract slices from a tensor
-   Insert data at specific indices in a tensor

This guide assumes familiarity with tensor indexing. Read the indexing
sections of the
[Tensor](https://www.tensorflow.org/guide/tensor#indexing) and
[TensorFlow NumPy](https://www.tensorflow.org/guide/tf_numpy#indexing)
guides before getting started with this guide.

## Setup

```{r}
library(tensorflow)
```

## Extract tensor slices

Perform slicing using the `[` operator:

```{r}
t1 <- as_tensor(c(1, 2, 3, 4, 5, 6, 7))
t1[1:3]
```

![](images/tf_slicing/slice_1d_1.png)

::: callout-note
Unlike base R's `[` operator, TensorFlow's `[` uses negative indexes for
selecting starting from the end.

`NULL` can be used instead of the last dimension or first, depending if
it appears before or after the `:`.
:::

```{r}
t1[-3:NULL]
```

![](images/tf_slicing/slice_1d_2.png)

For 2-dimensional tensors,you can use something like:

```{r}
t2 <- as_tensor(rbind(c(0, 1, 2, 3, 4),
                      c(5, 6, 7, 8, 9),
                      c(10, 11, 12, 13, 14),
                      c(15, 16, 17, 18, 19)))

t2[NULL:-1, 2:3]
```

![](images/tf_slicing/slice_2d_1.png)

::: callout-note
`tf$slice` can be used instead of the `[` operator. However, not that
when using functions directly from the `tf` module, dimensions and
indexes will start from 0, unlike in R.

You also need to make sure that indexes are passed to TensorFlow with
the integer type, for example using the `L` suffix notation.
:::

You can use `tf$slice` on higher dimensional tensors as well.

```{r}
t3 <- as_tensor(array(seq(from=1, to = 31, by = 2), dim = c(2,2,4)))
tf$slice(
  t3,
  begin = list(1L, 1L, 0L),
  size = list(1L, 1L, 2L)
)
```

You can also use `tf$strided_slice` to extract slices of tensors by
'striding' over the tensor dimensions.

Use `tf$gather` to extract specific indices from a single axis of a
tensor.

```{r}
tf$gather(t1, indices = c(0L, 3L, 6L))
```

![](images/tf_slicing/slice_1d_3.png)

`tf$gather` does not require indices to be evenly spaced.

```{r}
alphabet <- as_tensor(strsplit("abcdefghijklmnopqrstuvwxyz", "")[[1]])
tf$gather(alphabet, indices = c(2L, 0L, 19L, 18L))
```

![](images/tf_slicing/gather_1.png)

To extract slices from multiple axes of a tensor, use `tf$gather_nd`.
This is useful when you want to gather the elements of a matrix as
opposed to just its rows or columns.

```{r}
t4 <- as_tensor(rbind(c(0, 5),
                      c(1, 6),
                      c(2, 7),
                      c(3, 8),
                      c(4, 9)))

tf$gather_nd(t4, indices = list(list(2L), list(3L), list(0L)))
```

![](images/tf_slicing/gather_2.png)

```{r}
t5 <- array(1:18, dim = c(2,3,3))
tf$gather_nd(t5, indices = list(c(0L, 0L, 0L), c(1L, 2L, 1L)))
```

```{r}
# Return a list of two matrices
tf$gather_nd(
  t5,
  indices = list(
    list(c(0L, 0L), c(0L, 2L)), 
    list(c(1L, 0L), c(1L, 2L)))
)
```

```{r}
# Return one matrix
tf$gather_nd(
  t5,
  indices = list(c(0L, 0L), c(0L, 2L), c(1L, 0L), c(1L, 2L))
)
```

## Insert data into tensors

Use `tf$scatter_nd` to insert data at specific slices/indices of a
tensor. Note that the tensor into which you insert values is
zero-initialized.

```{r}
t6 <- as_tensor(list(10L))
indices <- as_tensor(list(list(1L), list(3L), list(5L), list(7L), list(9L)))
data <- as_tensor(c(2, 4, 6, 8, 10))

tf$scatter_nd(
  indices = indices,
  updates = data,
  shape = t6
)
```

Methods like `tf$scatter_nd` which require zero-initialized tensors are
similar to sparse tensor initializers. You can use `tf$gather_nd` and
`tf$scatter_nd` to mimic the behavior of sparse tensor ops.

Consider an example where you construct a sparse tensor using these two
methods in conjunction.

```{r}
# Gather values from one tensor by specifying indices
new_indices <- as_tensor(rbind(c(0L, 2L), c(2L, 1L), c(3L, 3L)))
t7 <- tf$gather_nd(t2, indices = new_indices)
```

![](images/tf_slicing/gather_nd_sparse.png)

```{r}
# Add these values into a new tensor
t8 <- tf$scatter_nd(
  indices = new_indices, 
  updates = t7, 
  shape = as_tensor(c(4L, 5L))
)
t8
```

This is similar to:

```{r}
t9 <- tf$SparseTensor(
  indices = list(c(0L, 2L), c(2L, 1L), c(3L, 3L)),
  values = c(2, 11, 18),
  dense_shape = c(4L, 5L)
)
t9
```

```{r}
# Convert the sparse tensor into a dense tensor
t10 <- tf$sparse$to_dense(t9)
t10
```

To insert data into a tensor with pre-existing values, use
`tf$tensor_scatter_nd_add`.

```{r}
t11 <- as_tensor(rbind(c(2, 7, 0),
                       c(9, 0, 1),
                       c(0, 3, 8)))

# Convert the tensor into a magic square by inserting numbers at appropriate indices
t12 <- tf$tensor_scatter_nd_add(
  t11,
  indices = list(c(0L, 2L), c(1L, 1L), c(2L, 0L)),
  updates = c(6, 5, 4)
)
t12
```

Similarly, use `tf$tensor_scatter_nd_sub` to subtract values from a
tensor with pre-existing values.

```{r}
# Convert the tensor into an identity matrix
t13 <- tf$tensor_scatter_nd_sub(
  t11,
  indices = list(c(0L, 0L), c(0L, 1L), c(1L, 0L), c(1L, 1L), c(1L, 2L), c(2L, 1L), c(2L, 2L)),
  updates = c(1, 7, 9, -1, 1, 3, 7)
)

print(t13)
```

Use `tf$tensor_scatter_nd_min` to copy element-wise minimum values from
one tensor to another.

```{r}
t14 <- as_tensor(rbind(c(-2, -7, 0),
                       c(-9, 0, 1),
                       c(0, -3, -8)))

t15 <- tf$tensor_scatter_nd_min(
  t14,
  indices = list(c(0L, 2L), c(1L, 1L), c(2L, 0L)),
  updates = c(-6, -5, -4)
)
t15
```

Similarly, use `tf$tensor_scatter_nd_max` to copy element-wise maximum
values from one tensor to another.

```{r}
t16 <- tf$tensor_scatter_nd_max(
  t14,
  indices = list(c(0L, 2L), c(1L, 1L), c(2L, 0L)),
  updates = c(6, 5, 4)
)
t16
```

## Further reading and resources

In this guide, you learned how to use the tensor slicing ops available
with TensorFlow to exert finer control over the elements in your
tensors.

-   Check out the slicing ops available with TensorFlow NumPy such as
    `tf$experimental$numpy$take_along_axis` and
    `tf$experimental$numpy$take`.

-   Also check out the [Tensor
    guide](https://www.tensorflow.org/guide/tensor) and the [Variable
    guide](https://www.tensorflow.org/guide/variable).

{{< include ../../_environment.qmd >}}
