---
format:
  html:
    css: /reference/assets/reference.css
---

| <button class="button"> ![](/reference/assets/GitHub-Mark-32px.png){width="20"} [View source on GitHub](https://github.com/rstudio/keras//blob/main/R/layers-activations.R#L84) </button> |
|:------------------------------:|:--------------------------------------:|

# layer_activation_parametric_relu

## Parametric Rectified Linear Unit.

## Description
It follows: `f(x) = alpha * x`` for `x < 0`, `f(x) = x`for`x >= 0`, where alpha is a learned array with the same shape as x. 


## Usage
```r
layer_activation_parametric_relu( 
  object, 
  alpha_initializer = "zeros", 
  alpha_regularizer = NULL, 
  alpha_constraint = NULL, 
  shared_axes = NULL, 
  input_shape = NULL, 
  batch_input_shape = NULL, 
  batch_size = NULL, 
  dtype = NULL, 
  name = NULL, 
  trainable = NULL, 
  weights = NULL 
) 
```

## Arguments
|Arguments|Description|
|---|---|
| object | What to compose the new `Layer` instance with. Typically a Sequential model or a Tensor (e.g., as returned by `layer_input()`). The return value depends on `object`. If `object` is: <br>- missing or `NULL`, the `Layer` instance is returned. <br>- a `Sequential` model, the model with an additional layer is returned. <br>- a Tensor, the output tensor from `layer_instance(object)` is returned.  |
| alpha_initializer | Initializer function for the weights. |
| alpha_regularizer | Regularizer for the weights. |
| alpha_constraint | Constraint for the weights. |
| shared_axes | The axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set shared_axes=c(1, 2). |
| input_shape | Input shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model. |
| batch_input_shape | Shapes, including the batch size. For instance, `batch_input_shape=c(10, 32)` indicates that the expected input will be batches of 10 32-dimensional vectors. `batch_input_shape=list(NULL, 32)`<br>indicates batches of an arbitrary number of 32-dimensional vectors. |
| batch_size | Fixed batch size for layer |
| dtype | The data type expected by the input, as a string (`float32`, `float64`, `int32`...) |
| name | An optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn't provided. |
| trainable | Whether the layer weights will be updated during training. |
| weights | Initial weights for layer. |






## See Also

[Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852). 

Other activation layers:  `layer_activation_elu()`, `layer_activation_leaky_relu()`, `layer_activation_relu()`, `layer_activation_selu()`, `layer_activation_softmax()`, `layer_activation_thresholded_relu()`, `layer_activation()`

