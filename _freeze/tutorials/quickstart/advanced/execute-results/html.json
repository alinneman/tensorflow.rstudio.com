{
  "hash": "2396b3e1813e60cc8d026c0d9c9b53d9",
  "result": {
    "markdown": "---\ntitle: Advanced\n---\n\n\n##### Copyright 2019 The TensorFlow Authors.\n\n\n\n::: {.cell cellView='form'}\n\n```{.r .cell-code}\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n\n# you may not use this file except in compliance with the License.\n\n# You may obtain a copy of the License at\n\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n\n#\n# Unless required by applicable law or agreed to in writing, software\n\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\n# See the License for the specific language governing permissions and\n\n# limitations under the License.\n```\n:::\n\n\n# TensorFlow 2 quickstart for experts\n\n\n<table class = \"tfo-notebook-buttons\" align = \"left\">\n  <td>\n    <a target = \"_blank\" href = \"https://www.tensorflow.org/tutorials/quickstart/advanced\"><img src = \"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n  </td>\n  <td>\n    <a target = \"_blank\" href = \"https://colab$research$google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced$ipynb\"><img src = \"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n  </td>\n  <td>\n    <a target = \"_blank\" href = \"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced$ipynb\"><img src = \"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n  </td>\n  <td>\n    <a href = \"https://storage$googleapis.com/tensorflow_docs/docs/site/en/tutorials/quickstart/advanced$ipynb\"><img src = \"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n  </td>\n</table>\n\nThis is a [Google Colaboratory](https://colab$research$google.com/notebooks/welcome.qmd) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n\n1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n2. Run all the notebook code cells: Select *Runtime* > *Run all*.\n\nDownload and install TensorFlow 2. Import TensorFlow into your program:\n\nNote: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details.\n\nImport TensorFlow into your program:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\nprint(\"TensorFlow version:\", tf$__version__)\n\nfrom tensorflow$keras$layers import Dense, Flatten, Conv2D\nfrom tensorflow$keras import Model\n```\n:::\n\n\nLoad and prepare the [MNIST dataset](http://yann$lecun.com/exdb/mnist/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmnist <- tf$keras$datasets$mnist\n\n(x_train, y_train), (x_test, y_test) = mnist$load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Add a channels dimension\n\nx_train <- x_train[..., tf$newaxis].astype(\"float32\")\nx_test <- x_test[..., tf$newaxis].astype(\"float32\")\n```\n:::\n\n\nUse `tf$data` to batch and shuffle the dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_ds <- tf$data$Dataset$from_tensor_slices(\n    (x_train, y_train)).shuffle(10000).batch(32)\n\ntest_ds <- tf$data$Dataset$from_tensor_slices((x_test, y_test)).batch(32)\n```\n:::\n\n\nBuild the `tf$keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass MyModel(Model):\n  initialize <- function() {    }\n    super$initialize()\n    self$conv1 <- Conv2D(32, 3, activation = 'relu')\n    self$flatten <- Flatten()\n    self$d1 <- Dense(128, activation = 'relu')\n    self$d2 <- Dense(10)\n\n  call <- function(x) {    }\n    x <- self$conv1(x)\n    x <- self$flatten(x)\n    x <- self$d1(x)\n    return self$d2(x)\n\n# Create an instance of the model\n\nmodel <- MyModel()\n```\n:::\n\n\nChoose an optimizer and loss function for training: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nloss_object <- tf$keras$losses$SparseCategoricalCrossentropy(from_logits = TRUE)\n\noptimizer <- tf$keras$optimizers$Adam()\n```\n:::\n\n\nSelect metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_loss <- tf$keras$metrics$Mean(name = 'train_loss')\ntrain_accuracy <- tf$keras$metrics$SparseCategoricalAccuracy(name = 'train_accuracy')\n\ntest_loss <- tf$keras$metrics$Mean(name = 'test_loss')\ntest_accuracy <- tf$keras$metrics$SparseCategoricalAccuracy(name = 'test_accuracy')\n```\n:::\n\n\nUse `tf$GradientTape` to train the model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n@tf_function\ntrain_step <- function(images, labels) {    }\n  with(tf$GradientTape() %as% tape, {    })\n    # training = TRUE is only needed if there are layers with different\n    # behavior during training versus inference (e.g. Dropout).\n    predictions <- model(images, training = TRUE)\n    loss <- loss_object(labels, predictions)\n  gradients <- tape$gradient(loss, model$trainable_variables)\n  optimizer$apply_gradients(zip_lists(gradients, model$trainable_variables))\n\n  train_loss(loss)\n  train_accuracy(labels, predictions)\n```\n:::\n\n\nTest the model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n@tf_function\ntest_step <- function(images, labels) {    }\n  # training = FALSE is only needed if there are layers with different\n  # behavior during training versus inference (e.g. Dropout).\n  predictions <- model(images, training = FALSE)\n  t_loss <- loss_object(labels, predictions)\n\n  test_loss(t_loss)\n  test_accuracy(labels, predictions)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nEPOCHS <- 5\n\nfor epoch in range(EPOCHS):\n  # Reset the metrics at the start of the next epoch\n  train_loss$reset_states()\n  train_accuracy$reset_states()\n  test_loss$reset_states()\n  test_accuracy$reset_states()\n\n  for images, labels in train_ds:\n    train_step(images, labels)\n\n  for test_images, test_labels in test_ds:\n    test_step(test_images, test_labels)\n\n  print(\n    f'Epoch list(epoch + 1), '\n    f'Loss: list(train_loss$result()), '\n    f'Accuracy: list(train_accuracy$result() * 100), '\n    f'Test Loss: list(test_loss$result()), '\n    f'Test Accuracy: list(test_accuracy$result() * 100)'\n  )\n```\n:::\n\n\nThe image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}