{
  "hash": "1a26b56706ce85e87f586231ebbb9ae9",
  "result": {
    "markdown": "---\nformat:\n  html:\n    css: /reference/assets/reference.css\n---\n\n\n| <button class=\"button\"> ![](/reference/assets/GitHub-Mark-32px.png){width=\"20\"} [View source on GitHub](https://github.com/rstudio/keras//blob/main/R/Layer.R#L64) </button> |\n|:------------------------------:|:--------------------------------------:|\n\n# Layer\n\n## (Deprecated) Create a custom Layer\n\n## Description\nThis function is maintained but deprecated. Please use `new_layer_class()` or `%py_class%` to define custom layers. \n\n\n## Usage\n```r\nLayer( \n  classname, \n  initialize, \n  build = NULL, \n  call = NULL, \n  compute_output_shape = NULL, \n  ..., \n  inherit = keras::keras$layers$Layer \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| classname | the name of the custom Layer. |\n| initialize | a function. This is where you define the arguments used to further build your layer. For example, a dense layer would take the `units` argument. You should always call `super()$`__init__()`` to initialize the base inherited layer. |\n| build | a function that takes `input_shape` as argument. This is where you will define your weights. Note that if your layer doesn't define trainable weights then you need not implement this method. |\n| call | This is where the layer's logic lives. Unless you want your layer to support masking, you only have to care about the first argument passed to `call`<br>(the input tensor). |\n| compute_output_shape | a function that takes `input_shape` as an argument. In case your layer modifies the shape of its input, you should specify here the shape transformation logic. This allows Keras to do automatic shape inference. If you don't modify the shape of the input then you need not implement this method. |\n| ... | Any other methods and/or attributes can be specified using named arguments. They will be added to the layer class. |\n| inherit | the Keras layer to inherit from. |\n\n\n\n## Value\nA function that wraps `create_layer`, similar to `keras::layer_dense`. \n\n\n## Examples\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\nlayer_dense2 <- Layer( \n  \"Dense2\", \n  initialize = function(units) { \n    super()$`__init__`() \n    self$units <- as.integer(units) \n  }, \n  build = function(input_shape) { \n    print(class(input_shape)) \n    self$kernel <- self$add_weight( \n      name = \"kernel\", \n      shape = list(input_shape[[2]], self$units), \n      initializer = \"uniform\", \n      trainable = TRUE \n    ) \n  }, \n  call = function(x) { \n    tensorflow::tf$matmul(x, self$kernel) \n  }, \n  compute_output_shape = function(input_shape) { \n    list(input_shape[[1]], self$units) \n  } \n) \nl <- layer_dense2(units = 10) \nl(matrix(runif(10), ncol = 1)) \n```\n:::\n",
    "supporting": [
      "layer_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}