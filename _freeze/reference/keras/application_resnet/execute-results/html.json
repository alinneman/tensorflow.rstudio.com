{
  "hash": "8f8339f84fecb72a31f0399edf8621b5",
  "result": {
    "markdown": "---\nformat:\n  html:\n    css: /reference/assets/reference.css\n---\n\n\n| <button class=\"button\"> ![](/reference/assets/GitHub-Mark-32px.png){width=\"20\"} [View source on GitHub](https://github.com/rstudio/keras//blob/main/R/applications.R) </button> | <button class=\"button\"> ![](/reference/assets/GitHub-Mark-32px.png){width=\"20\"} [Suggest edits on GitHub](https://github.com/rstudio/keras//edit/main/R/applications.R) </button> |\n|:------------------------------:|:--------------------------------------:|\n\n*R/applications.R*\n\n# application_resnet\n\n## Instantiates the ResNet architecture\n\n## Description\nInstantiates the ResNet architecture \n\n\n## Usage\n```r\napplication_resnet50( \n  include_top = TRUE, \n  weights = \"imagenet\", \n  input_tensor = NULL, \n  input_shape = NULL, \n  pooling = NULL, \n  classes = 1000, \n  ... \n) \napplication_resnet101( \n  include_top = TRUE, \n  weights = \"imagenet\", \n  input_tensor = NULL, \n  input_shape = NULL, \n  pooling = NULL, \n  classes = 1000, \n  ... \n) \napplication_resnet152( \n  include_top = TRUE, \n  weights = \"imagenet\", \n  input_tensor = NULL, \n  input_shape = NULL, \n  pooling = NULL, \n  classes = 1000, \n  ... \n) \napplication_resnet50_v2( \n  include_top = TRUE, \n  weights = \"imagenet\", \n  input_tensor = NULL, \n  input_shape = NULL, \n  pooling = NULL, \n  classes = 1000, \n  classifier_activation = \"softmax\", \n  ... \n) \napplication_resnet101_v2( \n  include_top = TRUE, \n  weights = \"imagenet\", \n  input_tensor = NULL, \n  input_shape = NULL, \n  pooling = NULL, \n  classes = 1000, \n  classifier_activation = \"softmax\", \n  ... \n) \napplication_resnet152_v2( \n  include_top = TRUE, \n  weights = \"imagenet\", \n  input_tensor = NULL, \n  input_shape = NULL, \n  pooling = NULL, \n  classes = 1000, \n  classifier_activation = \"softmax\", \n  ... \n) \nresnet_preprocess_input(x) \nresnet_v2_preprocess_input(x) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| include_top | Whether to include the fully-connected layer at the top of the network. Defaults to `TRUE`. |\n| weights | One of `NULL` (random initialization), `'imagenet'` (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to `'imagenet'`. |\n| input_tensor | Optional Keras tensor (i.e. output of `layer_input()`) to use as image input for the model. |\n| input_shape | optional shape list, only to be specified if `include_top` is FALSE (otherwise the input shape has to be `c(224, 224, 3)` (with `'channels_last'` data format) or `c(3, 224, 224)` (with `'channels_first'` data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. `c(200, 200, 3)` would be one valid value. |\n| pooling | Optional pooling mode for feature extraction when `include_top` is `FALSE`. Defaults to `NULL`. <br>- `NULL` means that the output of the model will be the 4D tensor output of the last convolutional layer. <br>- `'avg'` means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. <br>- `'max'` means that global max pooling will be applied.  |\n| classes | Optional number of classes to classify images into, only to be specified if `include_top` is TRUE, and if no `weights` argument is specified. Defaults to 1000 (number of ImageNet classes). |\n| ... | For backwards and forwards compatibility |\n| classifier_activation | A string or callable. The activation function to use on the \"top\" layer. Ignored unless `include_top = TRUE`. Set `classifier_activation = NULL` to return the logits of the \"top\" layer. Defaults to `'softmax'`. When loading pretrained weights, `classifier_activation` can only be `NULL` or `\"softmax\"`. |\n| x | `preprocess_input()` takes an array or floating point tensor, 3D or 4D with 3 color channels, with values in the range `[0, 255]`. |\n\n## Details\n\nReference: \n\n- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) (CVPR 2015) \n\nFor image classification use cases, see [this page for detailed examples](https://keras.io/api/applications/#usage-examples-for-image-classification-models). \n\nFor transfer learning use cases, make sure to read the [guide to transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/). \n\nNote: each Keras Application expects a specific kind of input preprocessing. For ResNet, call `tf.keras.applications.resnet.preprocess_input` on your inputs before passing them to the model. `resnet.preprocess_input` will convert the input images from RGB to BGR, then will zero-center each color channel with respect to the ImageNet dataset, without scaling. \n\n\n\n\n## Examples\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras) \n# instantiate the model \nmodel <- application_resnet50(weights = 'imagenet') \n# load the image \nimg_path <- \"elephant.jpg\" \nimg <- image_load(img_path, target_size = c(224,224)) \nx <- image_to_array(img) \n# ensure we have a 4d tensor with single element in the batch dimension, \n# the preprocess the input for prediction using resnet50 \nx <- array_reshape(x, c(1, dim(x))) \nx <- imagenet_preprocess_input(x) \n# make predictions then decode and print them \npreds <- model %>% predict(x) \nimagenet_decode_predictions(preds, top = 3)[[1]] \n```\n:::\n\n\n## See Also\n\n- [https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50)\n\n- [https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet101](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet101)\n\n- [https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet152](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet152)\n\n- [https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2)\n\n- [https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet101V2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet101V2)\n\n- [https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet152V2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet152V2)\n\n- [https://keras.io/api/applications/](https://keras.io/api/applications/)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}