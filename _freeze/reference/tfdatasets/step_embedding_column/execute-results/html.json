{
  "hash": "4018653a5bc30083dac6911c32da3d49",
  "result": {
    "markdown": "---\nexecute:\n  freeze: true\n---\n\n\n[R/feature_spec.R](https://github.com/rstudio/tfdatasets//blob/main/R/feature_spec.R#L1549) \n\n# step_embedding_column\n\n## Creates embeddings columns\n\n## Description\n Use this step to create ambeddings columns from categorical columns. \n\n\n## Usage\n```r\n \nstep_embedding_column( \n  spec, \n  ..., \n  dimension = function(x) { \n     as.integer(x^0.25) \n }, \n  combiner = \"mean\", \n  initializer = NULL, \n  ckpt_to_load_from = NULL, \n  tensor_name_in_ckpt = NULL, \n  max_norm = NULL, \n  trainable = TRUE \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| spec | A feature specification created with `feature_spec()`. |\n| ... | Comma separated list of variable names to apply the step. selectors can also be used. |\n| dimension | An integer specifying dimension of the embedding, must be > 0. Can also be a function of the size of the vocabulary. |\n| combiner | A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see `tf.embedding_lookup_sparse`. |\n| initializer | A variable initializer function to be used in embedding variable initialization. If not specified, defaults to `tf.truncated_normal_initializer` with mean `0.0` and standard deviation `1/sqrt(dimension)`. |\n| ckpt_to_load_from | String representing checkpoint name/pattern from which to restore column weights. Required if `tensor_name_in_ckpt` is not `NULL`. |\n| tensor_name_in_ckpt | Name of the Tensor in ckpt_to_load_from from which to restore the column weights. Required if `ckpt_to_load_from` is not `NULL`. |\n| max_norm | If not `NULL`, embedding values are l2-normalized to this value. |\n| trainable | Whether or not the embedding is trainable. Default is `TRUE`. |\n\n\n\n## Value\n a `FeatureSpec` object. \n\n\n## Examples\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tfdatasets) \ndata(hearts) \nfile <- tempfile() \nwriteLines(unique(hearts$thal), file) \nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32) \n \n# use the formula interface \nspec <- feature_spec(hearts, target ~ thal) %>% \n  step_categorical_column_with_vocabulary_list(thal) %>% \n  step_embedding_column(thal, dimension = 3) \nspec_fit <- fit(spec) \nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit) \n```\n:::\n\n\n## See Also\n steps for a complete list of allowed steps.  Other Feature Spec Functions:  `dataset_use_spec()`, `feature_spec()`, `fit.FeatureSpec()`, `step_bucketized_column()`, `step_categorical_column_with_hash_bucket()`, `step_categorical_column_with_identity()`, `step_categorical_column_with_vocabulary_file()`, `step_categorical_column_with_vocabulary_list()`, `step_crossed_column()`, `step_indicator_column()`, `step_numeric_column()`, `step_remove_column()`, `step_shared_embeddings_column()`, `steps` \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}