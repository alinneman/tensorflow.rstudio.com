{
  "hash": "dbff62095ee471458d01e37e9555d4e9",
  "result": {
    "markdown": "---\ntitle: deep_dream\ndescription: Deep Dreams in Keras.\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\n\n\n# Utility functions -------------------------------------------------------\n\n# Util function to open, resize, and format pictures into tensors that Inception V3 can process\npreprocess_image <- function(image_path) {\n  image_load(image_path) %>%\n    image_to_array() %>%\n    array_reshape(dim = c(1, dim(.))) %>%\n    inception_v3_preprocess_input()\n}\n\n# Util function to convert a tensor into a valid image\ndeprocess_image <- function(img) {\n  img <- array_reshape(img, dim = c(dim(img)[[2]], dim(img)[[3]], 3))\n  # Undoes preprocessing that was performed by `imagenet_preprocess_input`\n  img <- img / 2\n  img <- img + 0.5\n  img <- img * 255\n  \n  dims <- dim(img)\n  img <- pmax(0, pmin(img, 255))\n  dim(img) <- dims\n  img\n}\n\nresize_img <- function(img, size) {\n  image_array_resize(img, size[[1]], size[[2]])\n}\n\nsave_img <- function(img, fname) {\n  img <- deprocess_image(img)\n  image_array_save(img, fname)\n}\n\n\n# Model  ----------------------------------------------\n\n# You won't be training the model, so this command disables all training-specific operations.\nk_set_learning_phase(0)\n\n# Builds the Inception V3 network, without its convolutional base. The model will be loaded with pretrained ImageNet weights.\nmodel <- application_inception_v3(weights = \"imagenet\",\n                                  include_top = FALSE)\n\n# Named list mapping layer names to a coefficient quantifying how much the layer's activation contributes to the loss you'll seek to maximize. Note that the layer names are hardcoded in the built-in Inception V3 application. You can list all layer names using `summary(model)`.\nlayer_contributions <- list(\n  mixed2 = 0.2,\n  mixed3 = 3,\n  mixed4 = 2,\n  mixed5 = 1.5\n)\n\n# You'll define the loss by adding layer contributions to this scalar variable\nloss <- k_variable(0)\nfor (layer_name in names(layer_contributions)) {\n  coeff <- layer_contributions[[layer_name]]\n  # Retrieves the layer's output\n  activation <- get_layer(model, layer_name)$output\n  scaling <- k_prod(k_cast(k_shape(activation), \"float32\"))\n  # Retrieves the layer's output\n  loss <- loss + (coeff * k_sum(k_square(activation)) / scaling)\n}\n\n# Retrieves the layer's output\ndream <- model$input\n\n# Computes the gradients of the dream with regard to the loss\ngrads <- k_gradients(loss, dream)[[1]]\n\n# Normalizes the gradients (important trick)\ngrads <- grads / k_maximum(k_mean(k_abs(grads)), 1e-7)\n\noutputs <- list(loss, grads)\n\n# Sets up a Keras function to retrieve the value of the loss and gradients, given an input image\nfetch_loss_and_grads <- k_function(list(dream), outputs)\n\neval_loss_and_grads <- function(x) {\n  outs <- fetch_loss_and_grads(list(x))\n  loss_value <- outs[[1]]\n  grad_values <- outs[[2]]\n  list(loss_value, grad_values)\n}\n\n\n# Run gradient ascent -----------------------------------------------------\n\n# This function runs gradient ascent for a number of iterations.\ngradient_ascent <-\n  function(x, iterations, step, max_loss = NULL) {\n    for (i in 1:iterations) {\n      c(loss_value, grad_values) %<-% eval_loss_and_grads(x)\n      if (!is.null(max_loss) && loss_value > max_loss)\n        break\n      cat(\"...Loss value at\", i, \":\", loss_value, \"\\n\")\n      x <- x + (step * grad_values)\n    }\n    x\n  }\n\n# Playing with these hyperparameters will let you achieve new effects.\n# Gradient ascent step size\nstep <- 0.01\n# Number of scales at which to run gradient ascent\nnum_octave <- 3\n# Size ratio between scales\noctave_scale <- 1.4\n# Number of ascent steps to run at each scale\niterations <- 20\n# If the loss grows larger than 10, we will interrupt the gradient-ascent process to avoid ugly artifacts.\nmax_loss <- 10\n\n# Fill this with the path to the image you want to use.\nbase_image_path <- \"/tmp/mypic.jpg\"\n\n# Loads the base image into an array\nimg <-\n  preprocess_image(base_image_path)\n\n# Prepares a list of shape tuples defining the different scales at which to run gradient ascent\noriginal_shape <- dim(img)[-1]\nsuccessive_shapes <-\n  list(original_shape)\nfor (i in 1:num_octave) {\n  shape <- as.integer(original_shape / (octave_scale ^ i))\n  successive_shapes[[length(successive_shapes) + 1]] <-\n    shape\n}\n# Reverses the list of shapes so they're in increasing order\nsuccessive_shapes <-\n  rev(successive_shapes)\n\noriginal_img <- img\n#  Resizes the array of the image to the smallest scale\nshrunk_original_img <-\n  resize_img(img, successive_shapes[[1]])\n\nfor (shape in successive_shapes) {\n  cat(\"Processing image shape\", shape, \"\\n\")\n  # Scales up the dream image\n  img <- resize_img(img, shape)\n  # Runs gradient ascent, altering the dream\n  img <- gradient_ascent(img,\n                         iterations = iterations,\n                         step = step,\n                         max_loss = max_loss)\n  # Scales up the smaller version of the original image: it will be pixellated\n  upscaled_shrunk_original_img <-\n    resize_img(shrunk_original_img, shape)\n  # Computes the high-quality version of the original image at this size\n  same_size_original <-\n    resize_img(original_img, shape)\n  # The difference between the two is the detail that was lost when scaling up\n  lost_detail <-\n    same_size_original - upscaled_shrunk_original_img\n  # Reinjects lost detail into the dream\n  img <- img + lost_detail\n  shrunk_original_img <-\n    resize_img(original_img, shape)\n  save_img(img, fname = sprintf(\"dream_at_scale_%s.png\",\n                                paste(shape, collapse = \"x\")))\n}\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}