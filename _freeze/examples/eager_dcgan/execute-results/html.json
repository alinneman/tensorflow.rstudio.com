{
  "hash": "7b72a8e872b5d0ebdf2fd31c0266deb0",
  "result": {
    "markdown": "---\ntitle: eager_dcgan\ndescription: Generating digits with generative adversarial networks and eager execution.\n---\n\nThis is the companion code to the post\n\"Generating digits with Keras and TensorFlow eager execution\"\non the TensorFlow for R blog.\n\nhttps://blogs.rstudio.com/tensorflow/posts/2018-08-26-eager-dcgan/\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\nuse_implementation(\"tensorflow\")\nuse_session_with_seed(7777, disable_gpu = FALSE, disable_parallel_cpu = FALSE)\nlibrary(tensorflow)\ntfe_enable_eager_execution(device_policy = \"silent\")\n\nlibrary(tfdatasets)\n\n\nmnist <- dataset_mnist()\nc(train_images, train_labels) %<-% mnist$train\n\ntrain_images <- train_images %>%\n  k_expand_dims() %>%\n  k_cast(dtype = \"float32\")\n\ntrain_images <- (train_images - 127.5) / 127.5\n\nbuffer_size <- 60000\nbatch_size <- 256\nbatches_per_epoch <- (buffer_size / batch_size) %>% round()\n\ntrain_dataset <- tensor_slices_dataset(train_images) %>%\n  dataset_shuffle(buffer_size) %>%\n  dataset_batch(batch_size)\n\ngenerator <-\n  function(name = NULL) {\n    keras_model_custom(name = name, function(self) {\n      self$fc1 <- layer_dense(units = 7 * 7 * 64, use_bias = FALSE)\n      self$batchnorm1 <- layer_batch_normalization()\n      self$leaky_relu1 <- layer_activation_leaky_relu()\n      \n      self$conv1 <-\n        layer_conv_2d_transpose(\n          filters = 64,\n          kernel_size = c(5, 5),\n          strides = c(1, 1),\n          padding = \"same\",\n          use_bias = FALSE\n        )\n      self$batchnorm2 <- layer_batch_normalization()\n      self$leaky_relu2 <- layer_activation_leaky_relu()\n      \n      self$conv2 <-\n        layer_conv_2d_transpose(\n          filters = 32,\n          kernel_size = c(5, 5),\n          strides = c(2, 2),\n          padding = \"same\",\n          use_bias = FALSE\n        )\n      self$batchnorm3 <- layer_batch_normalization()\n      self$leaky_relu3 <- layer_activation_leaky_relu()\n      \n      self$conv3 <-\n        layer_conv_2d_transpose(\n          filters = 1,\n          kernel_size = c(5, 5),\n          strides = c(2, 2),\n          padding = \"same\",\n          use_bias = FALSE,\n          activation = \"tanh\"\n        )\n      \n      function(inputs,\n               mask = NULL,\n               training = TRUE) {\n        self$fc1(inputs) %>%\n          self$batchnorm1(training = training) %>%\n          self$leaky_relu1() %>%\n          k_reshape(shape = c(-1, 7, 7, 64)) %>%\n          \n          self$conv1() %>%\n          self$batchnorm2(training = training) %>%\n          self$leaky_relu2() %>%\n          \n          self$conv2() %>%\n          self$batchnorm3(training = training) %>%\n          self$leaky_relu3() %>%\n          \n          self$conv3()\n      }\n    })\n  }\n\ndiscriminator <-\n  function(name = NULL) {\n    keras_model_custom(name = name, function(self) {\n      self$conv1 <- layer_conv_2d(\n        filters = 64,\n        kernel_size = c(5, 5),\n        strides = c(2, 2),\n        padding = \"same\"\n      )\n      self$leaky_relu1 <- layer_activation_leaky_relu()\n      self$dropout <- layer_dropout(rate = 0.3)\n      \n      self$conv2 <-\n        layer_conv_2d(\n          filters = 128,\n          kernel_size = c(5, 5),\n          strides = c(2, 2),\n          padding = \"same\"\n        )\n      self$leaky_relu2 <- layer_activation_leaky_relu()\n      self$flatten <- layer_flatten()\n      self$fc1 <- layer_dense(units = 1)\n      \n      function(inputs,\n               mask = NULL,\n               training = TRUE) {\n        inputs %>% self$conv1() %>%\n          self$leaky_relu1() %>%\n          self$dropout(training = training) %>%\n          self$conv2() %>%\n          self$leaky_relu2() %>%\n          self$flatten() %>%\n          self$fc1()\n        \n      }\n    })\n  }\n\ngenerator <- generator()\ndiscriminator <- discriminator()\n\ngenerator$call = tf$contrib$eager$defun(generator$call)\ndiscriminator$call = tf$contrib$eager$defun(discriminator$call)\n\ndiscriminator_loss <- function(real_output, generated_output) {\n  real_loss <-\n    tf$losses$sigmoid_cross_entropy(multi_class_labels = k_ones_like(real_output),\n                                    logits = real_output)\n  generated_loss <-\n    tf$losses$sigmoid_cross_entropy(multi_class_labels = k_zeros_like(generated_output),\n                                    logits = generated_output)\n  real_loss + generated_loss\n}\n\ngenerator_loss <- function(generated_output) {\n  tf$losses$sigmoid_cross_entropy(tf$ones_like(generated_output), generated_output)\n}\n\ndiscriminator_optimizer <- tf$train$AdamOptimizer(1e-4)\ngenerator_optimizer <- tf$train$AdamOptimizer(1e-4)\n\nnum_epochs <- 150\nnoise_dim <- 100\nnum_examples_to_generate <- 25L\n\nrandom_vector_for_generation <-\n  k_random_normal(c(num_examples_to_generate,\n                    noise_dim))\n\ngenerate_and_save_images <- function(model, epoch, test_input) {\n  predictions <- model(test_input, training = FALSE)\n  png(paste0(\"images_epoch_\", epoch, \".png\"))\n  par(mfcol = c(5, 5))\n  par(mar = c(0.5, 0.5, 0.5, 0.5),\n      xaxs = 'i',\n      yaxs = 'i')\n  for (i in 1:25) {\n    img <- predictions[i, , , 1]\n    img <- t(apply(img, 2, rev))\n    image(\n      1:28,\n      1:28,\n      img * 127.5 + 127.5,\n      col = gray((0:255) / 255),\n      xaxt = 'n',\n      yaxt = 'n'\n    )\n  }\n  dev.off()\n}\n\ntrain <- function(dataset, epochs, noise_dim) {\n  for (epoch in seq_len(num_epochs)) {\n    start <- Sys.time()\n    total_loss_gen <- 0\n    total_loss_disc <- 0\n    iter <- make_iterator_one_shot(train_dataset)\n    \n    until_out_of_range({\n      batch <- iterator_get_next(iter)\n      noise <- k_random_normal(c(batch_size, noise_dim))\n      with(tf$GradientTape() %as% gen_tape, {\n        with(tf$GradientTape() %as% disc_tape, {\n          generated_images <- generator(noise)\n          disc_real_output <- discriminator(batch, training = TRUE)\n          disc_generated_output <-\n            discriminator(generated_images, training = TRUE)\n          gen_loss <- generator_loss(disc_generated_output)\n          disc_loss <-\n            discriminator_loss(disc_real_output, disc_generated_output)\n        })\n      })\n      \n      gradients_of_generator <-\n        gen_tape$gradient(gen_loss, generator$variables)\n      gradients_of_discriminator <-\n        disc_tape$gradient(disc_loss, discriminator$variables)\n      \n      generator_optimizer$apply_gradients(purrr::transpose(list(\n        gradients_of_generator, generator$variables\n      )))\n      discriminator_optimizer$apply_gradients(purrr::transpose(\n        list(gradients_of_discriminator, discriminator$variables)\n      ))\n      \n      total_loss_gen <- total_loss_gen + gen_loss\n      total_loss_disc <- total_loss_disc + disc_loss\n      \n    })\n    \n    cat(\"Time for epoch \", epoch, \": \", Sys.time() - start, \"\\n\")\n    cat(\"Generator loss: \",\n        total_loss_gen$numpy() / batches_per_epoch,\n        \"\\n\")\n    cat(\"Discriminator loss: \",\n        total_loss_disc$numpy() / batches_per_epoch,\n        \"\\n\\n\")\n    if (epoch %% 10 == 0)\n      generate_and_save_images(generator,\n                               epoch,\n                               random_vector_for_generation)\n    \n  }\n}\n\ntrain(train_dataset, num_epochs, noise_dim)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}