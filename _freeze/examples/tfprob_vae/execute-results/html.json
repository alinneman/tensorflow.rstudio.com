{
  "hash": "f2cda50526d9c81682db71e521aff755",
  "result": {
    "markdown": "---\ntitle: tfprob_vae\ndescription: A variational autoencoder using TensorFlow Probability on Kuzushiji-MNIST.\n---\n\nThis is the companion code to the post\n\"Getting started with TensorFlow Probability from R\"\non the TensorFlow for R blog.\n\nhttps://blogs.rstudio.com/tensorflow/posts/2019-01-08-getting-started-with-tf-probability/\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\nuse_implementation(\"tensorflow\")\nlibrary(tensorflow)\ntfe_enable_eager_execution(device_policy = \"silent\")\n\ntfp <- import(\"tensorflow_probability\")\ntfd <- tfp$distributions\n\nlibrary(tfdatasets)\nlibrary(dplyr)\nlibrary(glue)\n\n\n# Utilities --------------------------------------------------------\n\nnum_examples_to_generate <- 64L\n\ngenerate_random <- function(epoch) {\n  decoder_likelihood <-\n    decoder(latent_prior$sample(num_examples_to_generate))\n  predictions <- decoder_likelihood$mean()\n  # change path according to your preferences\n  png(file.path(\"/tmp\", paste0(\"random_epoch_\", epoch, \".png\")))\n  par(mfcol = c(8, 8))\n  par(mar = c(0.5, 0.5, 0.5, 0.5),\n      xaxs = 'i',\n      yaxs = 'i')\n  for (i in 1:64) {\n    img <- predictions[i, , , 1]\n    img <- t(apply(img, 2, rev))\n    image(\n      1:28,\n      1:28,\n      img * 127.5 + 127.5,\n      col = gray((0:255) / 255),\n      xaxt = 'n',\n      yaxt = 'n'\n    )\n  }\n  dev.off()\n}\n\nshow_grid <- function(epoch) {\n  # change path according to your preferences\n  png(file.path(\"/tmp\", paste0(\"grid_epoch_\", epoch, \".png\")))\n  par(mar = c(0.5, 0.5, 0.5, 0.5),\n      xaxs = 'i',\n      yaxs = 'i')\n  n <- 16\n  img_size <- 28\n  grid_x <- seq(-4, 4, length.out = n)\n  grid_y <- seq(-4, 4, length.out = n)\n  rows <- NULL\n  for (i in 1:length(grid_x)) {\n    column <- NULL\n    for (j in 1:length(grid_y)) {\n      z_sample <- matrix(c(grid_x[i], grid_y[j]), ncol = 2)\n      decoder_likelihood <- decoder(k_cast(z_sample, k_floatx()))\n      column <-\n        rbind(column,\n              (decoder_likelihood$mean() %>% as.numeric()) %>% matrix(ncol = img_size))\n    }\n    rows <- cbind(rows, column)\n  }\n  rows %>% as.raster() %>% plot()\n  dev.off()\n}\n\n\n# Setup and preprocessing -------------------------------------------------\n\nnp <- import(\"numpy\")\n\n# assume data have been downloaded from https://github.com/rois-codh/kmnist\n# and stored in /tmp\nkuzushiji <- np$load(\"/tmp/kmnist-train-imgs.npz\")\nkuzushiji <- kuzushiji$get(\"arr_0\")\n\ntrain_images <- kuzushiji %>%\n  k_expand_dims() %>%\n  k_cast(dtype = \"float32\")\ntrain_images <- train_images %>% `/`(255)\n\nbuffer_size <- 60000\nbatch_size <- 256\nbatches_per_epoch <- buffer_size / batch_size\n\ntrain_dataset <- tensor_slices_dataset(train_images) %>%\n  dataset_shuffle(buffer_size) %>%\n  dataset_batch(batch_size)\n\n\n# Params ------------------------------------------------------------------\n\nlatent_dim <- 2\nmixture_components <- 16\n\n\n# Model -------------------------------------------------------------------\n\n# Encoder ------------------------------------------------------------------\n\nencoder_model <- function(name = NULL) {\n  \n  keras_model_custom(name = name, function(self) {\n    self$conv1 <-\n      layer_conv_2d(\n        filters = 32,\n        kernel_size = 3,\n        strides = 2,\n        activation = \"relu\"\n      )\n    self$conv2 <-\n      layer_conv_2d(\n        filters = 64,\n        kernel_size = 3,\n        strides = 2,\n        activation = \"relu\"\n      )\n    self$flatten <- layer_flatten()\n    self$dense <- layer_dense(units = 2 * latent_dim)\n    \n    function (x, mask = NULL) {\n      x <- x %>%\n        self$conv1() %>%\n        self$conv2() %>%\n        self$flatten() %>%\n        self$dense()\n      tfd$MultivariateNormalDiag(loc = x[, 1:latent_dim],\n                                 scale_diag = tf$nn$softplus(x[, (latent_dim + 1):(2 * latent_dim)] + 1e-5))\n    }\n  })\n}\n\n\n# Decoder ------------------------------------------------------------------\n\ndecoder_model <- function(name = NULL) {\n  \n  keras_model_custom(name = name, function(self) {\n    self$dense <- layer_dense(units = 7 * 7 * 32, activation = \"relu\")\n    self$reshape <- layer_reshape(target_shape = c(7, 7, 32))\n    self$deconv1 <-\n      layer_conv_2d_transpose(\n        filters = 64,\n        kernel_size = 3,\n        strides = 2,\n        padding = \"same\",\n        activation = \"relu\"\n      )\n    self$deconv2 <-\n      layer_conv_2d_transpose(\n        filters = 32,\n        kernel_size = 3,\n        strides = 2,\n        padding = \"same\",\n        activation = \"relu\"\n      )\n    self$deconv3 <-\n      layer_conv_2d_transpose(\n        filters = 1,\n        kernel_size = 3,\n        strides = 1,\n        padding = \"same\"\n      )\n    \n    function (x, mask = NULL) {\n      x <- x %>%\n        self$dense() %>%\n        self$reshape() %>%\n        self$deconv1() %>%\n        self$deconv2() %>%\n        self$deconv3()\n      \n      tfd$Independent(tfd$Bernoulli(logits = x),\n                      reinterpreted_batch_ndims = 3L)\n      \n    }\n  })\n}\n\n# Learnable Prior -------------------------------------------------------------------\n\nlearnable_prior_model <-\n  function(name = NULL, latent_dim, mixture_components) {\n    \n    keras_model_custom(name = name, function(self) {\n      self$loc <-\n        tf$get_variable(\n          name = \"loc\",\n          shape = list(mixture_components, latent_dim),\n          dtype = tf$float32\n        )\n      self$raw_scale_diag <- tf$get_variable(\n        name = \"raw_scale_diag\",\n        shape = c(mixture_components, latent_dim),\n        dtype = tf$float32\n      )\n      self$mixture_logits <-\n        tf$get_variable(\n          name = \"mixture_logits\",\n          shape = c(mixture_components),\n          dtype = tf$float32\n        )\n      \n      function (x, mask = NULL) {\n        tfd$MixtureSameFamily(\n          components_distribution = tfd$MultivariateNormalDiag(\n            loc = self$loc,\n            scale_diag = tf$nn$softplus(self$raw_scale_diag)\n          ),\n          mixture_distribution = tfd$Categorical(logits = self$mixture_logits)\n        )\n      }\n    })\n  }\n\n\n# Loss and optimizer ------------------------------------------------------\n\ncompute_kl_loss <-\n  function(latent_prior,\n           approx_posterior,\n           approx_posterior_sample) {\n    kl_div <- approx_posterior$log_prob(approx_posterior_sample) - latent_prior$log_prob(approx_posterior_sample)\n    avg_kl_div <- tf$reduce_mean(kl_div)\n    avg_kl_div\n  }\n\n\nglobal_step <- tf$train$get_or_create_global_step()\noptimizer <- tf$train$AdamOptimizer(1e-4)\n\n\n# Training loop -----------------------------------------------------------\n\nnum_epochs <- 50\n\nencoder <- encoder_model()\ndecoder <- decoder_model()\nlatent_prior_model <-\n  learnable_prior_model(latent_dim = latent_dim, mixture_components = mixture_components)\n\n# change this according to your preferences\ncheckpoint_dir <- \"/tmp/checkpoints\"\ncheckpoint_prefix <- file.path(checkpoint_dir, \"ckpt\")\ncheckpoint <-\n  tf$train$Checkpoint(\n    optimizer = optimizer,\n    global_step = global_step,\n    encoder = encoder,\n    decoder = decoder,\n    latent_prior_model = latent_prior_model\n  )\n\nfor (epoch in seq_len(num_epochs)) {\n  iter <- make_iterator_one_shot(train_dataset)\n  \n  total_loss <- 0\n  total_loss_nll <- 0\n  total_loss_kl <- 0\n  \n  until_out_of_range({\n    x <-  iterator_get_next(iter)\n    \n    with(tf$GradientTape(persistent = TRUE) %as% tape, {\n      approx_posterior <- encoder(x)\n      \n      approx_posterior_sample <- approx_posterior$sample()\n      decoder_likelihood <- decoder(approx_posterior_sample)\n      \n      nll <- -decoder_likelihood$log_prob(x)\n      avg_nll <- tf$reduce_mean(nll)\n      \n      latent_prior <- latent_prior_model(NULL)\n      \n      kl_loss <-\n        compute_kl_loss(latent_prior,\n                        approx_posterior,\n                        approx_posterior_sample)\n\n      loss <- kl_loss + avg_nll\n    })\n    \n    total_loss <- total_loss + loss\n    total_loss_nll <- total_loss_nll + avg_nll\n    total_loss_kl <- total_loss_kl + kl_loss\n    \n    encoder_gradients <- tape$gradient(loss, encoder$variables)\n    decoder_gradients <- tape$gradient(loss, decoder$variables)\n    prior_gradients <-\n      tape$gradient(loss, latent_prior_model$variables)\n    \n    optimizer$apply_gradients(purrr::transpose(list(\n      encoder_gradients, encoder$variables\n    )),\n    global_step = tf$train$get_or_create_global_step())\n    optimizer$apply_gradients(purrr::transpose(list(\n      decoder_gradients, decoder$variables\n    )),\n    global_step = tf$train$get_or_create_global_step())\n    optimizer$apply_gradients(purrr::transpose(list(\n      prior_gradients, latent_prior_model$variables\n    )),\n    global_step = tf$train$get_or_create_global_step())\n    \n})\n  \n  checkpoint$save(file_prefix = checkpoint_prefix)\n  \n  cat(\n    glue(\n      \"Losses (epoch): {epoch}:\",\n      \"  {(as.numeric(total_loss_nll)/batches_per_epoch) %>% round(4)} nll\",\n      \"  {(as.numeric(total_loss_kl)/batches_per_epoch) %>% round(4)} kl\",\n      \"  {(as.numeric(total_loss)/batches_per_epoch) %>% round(4)} total\"\n    ),\n    \"\\n\"\n  )\n  \n  if (TRUE) {\n    generate_random(epoch)\n    show_grid(epoch)\n  }\n}\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}