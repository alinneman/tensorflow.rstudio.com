{
  "hash": "bdc87e280398025f16eab7ec13a17ddf",
  "result": {
    "markdown": "---\ntitle: The Sequential model\nAuthor: \"[fchollet](https://twitter.com/fchollet), Tomasz Kalinowski\"\ndate-created: 2020/04/12\ndate-last-modified: 2020/04/12\ndescription: Complete guide to the Sequential model.\n---\n\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nError in reticulate::use_virtualenv(\"r-tensorflow-site\", required = TRUE) : \n  Directory ~/.virtualenvs/r-tensorflow-site is not a Python virtualenv\n```\n:::\n\n```{.r .cell-code}\nlibrary(keras)\n```\n:::\n\n\n## When to use a Sequential model\n\nA `Sequential` model is appropriate for **a plain stack of layers**\nwhere each layer has **exactly one input tensor and one output tensor**.\n\nSchematically, the following `Sequential` model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define Sequential model with 3 layers\nmodel <- keras_model_sequential() %>% \n  layer_dense(2, activation = \"relu\", name = \"layer1\") %>% \n  layer_dense(3, activation = \"relu\", name = \"layer2\") %>% \n  layer_dense(4, name = \"layer3\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoaded Tensorflow version 2.9.1\n```\n:::\n\n```{.r .cell-code}\n# Call model on a test input\nx <- tf$ones(shape(3, 3))\ny <- model(x)\n```\n:::\n\n\nis equivalent to this function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 3 layers\nlayer1 <- layer_dense(units = 2, activation = \"relu\", name = \"layer1\")\nlayer2 <- layer_dense(units = 3, activation = \"relu\", name = \"layer2\")\nlayer3 <- layer_dense(units = 4, name = \"layer3\")\n\n# Call layers on a test input\nx <- tf$ones(shape(3, 3))\ny <- layer3(layer2(layer1(x)))\n```\n:::\n\n\nA Sequential model is **not appropriate** when:\n\n-   Your model has multiple inputs or multiple outputs\n-   Any of your layers has multiple inputs or multiple outputs\n-   You need to do layer sharing\n-   You want non-linear topology (e.g. a residual connection, a\n    multi-branch model)\n\n## Creating a Sequential model\n\nYou can create a Sequential model by piping a model through a series\nlayers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential() %>%\n  layer_dense(2, activation = \"relu\") %>%\n  layer_dense(3, activation = \"relu\") %>%\n  layer_dense(4)\n```\n:::\n\n\nIts layers are accessible via the `layers` attribute:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel$layers\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n<keras.layers.core.dense.Dense object at 0x7f9d0df43820>\n\n[[2]]\n<keras.layers.core.dense.Dense object at 0x7f9d0ded8d00>\n\n[[3]]\n<keras.layers.core.dense.Dense object at 0x7f9d0df11a90>\n```\n:::\n:::\n\n\nYou can also create a Sequential model incrementally:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential()\nmodel %>% layer_dense(2, activation = \"relu\")\nmodel %>% layer_dense(3, activation = \"relu\")\nmodel %>% layer_dense(4)\n```\n:::\n\n\nNote that there's also a corresponding `pop()` method to remove layers:\na Sequential model behaves very much like a stack of layers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>% pop_layer()\nlength(model$layers)  # 2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\n\nAlso note that the Sequential constructor accepts a `name` argument,\njust like any layer or model in Keras. This is useful to annotate\nTensorBoard graphs with semantically meaningful names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential(name = \"my_sequential\")\nmodel %>% layer_dense(2, activation = \"relu\", name = \"layer1\")\nmodel %>% layer_dense(3, activation = \"relu\", name = \"layer2\")\nmodel %>% layer_dense(4, name = \"layer3\")\n```\n:::\n\n\n## Specifying the input shape in advance\n\nGenerally, all layers in Keras need to know the shape of their inputs in\norder to be able to create their weights. So when you create a layer\nlike this, initially, it has no weights:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlayer <- layer_dense(units = 3)\nlayer$weights  # Empty\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlist()\n```\n:::\n:::\n\n\nIt creates its weights the first time it is called on an input, since\nthe shape of the weights depends on the shape of the inputs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Call layer on a test input\nx <- tf$ones(shape(1, 4))\ny <- layer(x)\nlayer$weights  # Now it has weights, of shape (4, 3) and (3,)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n<tf.Variable 'dense_6/kernel:0' shape=(4, 3) dtype=float32, numpy=\narray([[ 0.5611099 ,  0.28887486,  0.16154385],\n       [ 0.6592573 , -0.09965378,  0.7208358 ],\n       [-0.3989585 , -0.8135034 , -0.9171356 ],\n       [-0.77588034, -0.01154035,  0.01568812]], dtype=float32)>\n\n[[2]]\n<tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n```\n:::\n:::\n\n\nNaturally, this also applies to Sequential models. When you instantiate\na Sequential model without an input shape, it isn't \"built\": it has no\nweights (and calling `model$weights` results in an error stating just\nthis). The weights are created when the model first sees some input\ndata:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential() %>% \n        layer_dense(2, activation = \"relu\") %>% \n        layer_dense(3, activation = \"relu\") %>% \n        layer_dense(4)\n\n# No weights at this stage!\n# At this point, you can't do this:\n\ntry(model$weights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nError in py_get_attr_impl(x, name, silent) : \n  ValueError: Weights for model sequential_3 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.\n```\n:::\n\n```{.r .cell-code}\n# The model summary is also not available:\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: <no summary available, model was not built>\n```\n:::\n\n```{.r .cell-code}\n# Call the model on a test input\nx <- tf$ones(shape(1, 4))\ny <- model(x)\ncat(\"Number of weights after calling the model:\", length(model$weights), \"\\n\")  # 6\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of weights after calling the model: 6 \n```\n:::\n:::\n\n\nOnce a model is \"built\", you can call its `summary()` method to display\nits contents (the `summary()` method is also called by the default\n`print()` method:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_3\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_9 (Dense)                  (1, 2)                        10          \n dense_8 (Dense)                  (1, 3)                        9           \n dense_7 (Dense)                  (1, 4)                        16          \n============================================================================\nTotal params: 35\nTrainable params: 35\nNon-trainable params: 0\n____________________________________________________________________________\n```\n:::\n:::\n\n\nHowever, it can be very useful when building a Sequential model\nincrementally to be able to display the summary of the model so far,\nincluding the current output shape. In this case, you should start your\nmodel by passing an `input_shape` argument to your model, so that it\nknows its input shape from the start:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential(input_shape = c(4))\nmodel %>% layer_dense(2, activation = \"relu\")\n\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_4\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_10 (Dense)                 (None, 2)                     10          \n============================================================================\nTotal params: 10\nTrainable params: 10\nNon-trainable params: 0\n____________________________________________________________________________\n```\n:::\n:::\n\n\nModels built with a predefined input shape like this always have weights\n(even before seeing any data) and always have a defined output shape.\n\nIn general, it's a recommended best practice to always specify the input\nshape of a Sequential model in advance if you know what it is.\n\n## A common debugging workflow: `%>%` + `summary()`\n\nWhen building a new Sequential architecture, it's useful to\nincrementally stack layers and print model summaries. For instance, this\nenables you to monitor how a stack of `Conv2D` and `MaxPooling2D` layers\nis downsampling image feature maps:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential(input_shape = c(250, 250, 3)) # 250x250 RGB images\n  \nmodel %>% \n  layer_conv_2d(32, 5, strides = 2, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(3) \n\n# Can you guess what the current output shape is at this point? Probably not.\n# Let's just print it:\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_5\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n conv2d_1 (Conv2D)                (None, 123, 123, 32)          2432        \n conv2d (Conv2D)                  (None, 121, 121, 32)          9248        \n max_pooling2d (MaxPooling2D)     (None, 40, 40, 32)            0           \n============================================================================\nTotal params: 11,680\nTrainable params: 11,680\nNon-trainable params: 0\n____________________________________________________________________________\n```\n:::\n\n```{.r .cell-code}\n# The answer was: (40, 40, 32), so we can keep downsampling...\nmodel %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(3) %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(2) \n\n# And now?\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_5\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n conv2d_1 (Conv2D)                (None, 123, 123, 32)          2432        \n conv2d (Conv2D)                  (None, 121, 121, 32)          9248        \n max_pooling2d (MaxPooling2D)     (None, 40, 40, 32)            0           \n conv2d_5 (Conv2D)                (None, 38, 38, 32)            9248        \n conv2d_4 (Conv2D)                (None, 36, 36, 32)            9248        \n max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 32)            0           \n conv2d_3 (Conv2D)                (None, 10, 10, 32)            9248        \n conv2d_2 (Conv2D)                (None, 8, 8, 32)              9248        \n max_pooling2d_1 (MaxPooling2D)   (None, 4, 4, 32)              0           \n============================================================================\nTotal params: 48,672\nTrainable params: 48,672\nNon-trainable params: 0\n____________________________________________________________________________\n```\n:::\n\n```{.r .cell-code}\n# Now that we have 4x4 feature maps, time to apply global max pooling.\nmodel %>% layer_global_max_pooling_2d()\n\n# Finally, we add a classification layer.\nmodel %>% layer_dense(10)\n```\n:::\n\n\nVery practical, right?\n\n## What to do once you have a model\n\nOnce your model architecture is ready, you will want to:\n\n-   Train your model, evaluate it, and run inference. See our [guide to\n    training & evaluation with the built-in\n    loops](/guides/training_with_built_in_methods/)\n-   Save your model to disk and restore it. See our [guide to\n    serialization & saving](/guides/serialization_and_saving/).\n-   Speed up model training by leveraging multiple GPUs. See our [guide\n    to multi-GPU and distributed\n    training](https://keras.io/guides/distributed_training/).\n\n## Feature extraction with a Sequential model\n\nOnce a Sequential model has been built, it behaves like a [Functional\nAPI model](/guides/functional_api/). This means that every layer has an\n`input` and `output` attribute. These attributes can be used to do neat\nthings, like quickly creating a model that extracts the outputs of all\nintermediate layers in a Sequential model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninitial_model <-\n  keras_model_sequential(input_shape = c(250, 250, 3)) %>%\n  layer_conv_2d(32, 5, strides = 2, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\")\n\nfeature_extractor <- keras_model(\n  inputs = initial_model$inputs,\n  outputs = lapply(initial_model$layers, \\(layer) layer$output)\n)\n\n# Call feature extractor on test input.\n\nx <- tf$ones(shape(1, 250, 250, 3))\nfeatures <- feature_extractor(x)\n```\n:::\n\n\nHere's a similar example that only extract features from one layer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninitial_model <-\n  keras_model_sequential(input_shape = c(250, 250, 3)) %>%\n  layer_conv_2d(32, 5, strides = 2, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\", name = \"my_intermediate_layer\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\")\n\nfeature_extractor <- keras_model(\n  inputs = initial_model$inputs,\n  outputs =  get_layer(initial_model, name = \"my_intermediate_layer\")$output\n)\n\n# Call feature extractor on test input.\nx <- tf$ones(shape(1, 250, 250, 3))\nfeatures <- feature_extractor(x)\n```\n:::\n\n\n## Transfer learning with a Sequential model\n\nTransfer learning consists of freezing the bottom layers in a model and\nonly training the top layers. If you aren't familiar with it, make sure\nto read our [guide to transfer learning](/guides/transfer_learning/).\n\nHere are two common transfer learning blueprint involving Sequential\nmodels.\n\nFirst, let's say that you have a Sequential model, and you want to\nfreeze all layers except the last one. In this case, you would simply\niterate over `model$layers` and set `layer$trainable = FALSE` on each\nlayer, except the last one. Like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential(input_shape = c(784)) %>%\n  layer_dense(32, activation = 'relu') %>%\n  layer_dense(32, activation = 'relu') %>%\n  layer_dense(32, activation = 'relu') %>%\n  layer_dense(10)\n\n\n# Presumably you would want to first load pre-trained weights.\nmodel$load_weights(...)\n\n# Freeze all layers except the last one.\nfor (layer in head(model$layers, -1))\n  layer$trainable <- FALSE\n\n# can also just call: freeze_weights(model, to = -2)\n\n# Recompile and train (this will only update the weights of the last layer).\nmodel %>% compile(...)\nmodel %>% fit(...)\n```\n:::\n\n\nAnother common blueprint is to use a Sequential model to stack a\npre-trained model and some freshly initialized classification layers.\nLike this:\n\n# Load a convolutional base with pre-trained weights\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_model <- application_xception(\n    weights = 'imagenet',\n    include_top = FALSE,\n    pooling = 'avg')\n\n# Freeze the base model\nbase_model$trainable <- FALSE\n\n# Use a Sequential model to add a trainable classifier on top\nmodel <- keras_model_sequential() %>%\n  base_model() %>%\n  layer_dense(1000)\n\n# Compile & train\nmodel %>% compile(...)\nmodel %>% fit(...)\n```\n:::\n\n\nIf you do transfer learning, you will probably find yourself frequently\nusing these two patterns.\n\nThat's about all you need to know about Sequential models!\n\nTo find out more about building models in Keras, see:\n\n-   [Guide to the Functional API](/guides/functional_api/)\n-   [Guide to making new Layers & Models via\n    subclassing](/guides/making_new_layers_and_models_via_subclassing/)\n\n\n---\nformat: html\n---\n\n## Environment Details \n\n::: {.callout-note appearance=\"simple\"  collapse=\"true\"}\n\n### Tensorflow Version\n\n::: {.cell}\n\n```{.r .cell-code}\ntensorflow::tf_version()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] '2.9'\n```\n:::\n:::\n\n\n:::\n\n::: {.callout-note appearance=\"simple\"  collapse=\"true\"}\n\n### R Environment Information\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.1.0 Patched (2021-05-18 r80324)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] keras_2.9.0.9000      tensorflow_2.9.0.9000\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.9        rstudioapi_0.13   knitr_1.39        whisker_0.4      \n [5] magrittr_2.0.3    lattice_0.20-44   R6_2.5.1          rlang_1.0.4      \n [9] fastmap_1.1.0     stringr_1.4.0     tools_4.1.0       grid_4.1.0       \n[13] xfun_0.31         png_0.1-7         cli_3.3.0         htmltools_0.5.2  \n[17] tfruns_1.5.0      yaml_2.3.5        digest_0.6.29     Matrix_1.3-3     \n[21] base64enc_0.1-3   htmlwidgets_1.5.3 zeallot_0.1.0     evaluate_0.15    \n[25] rmarkdown_2.14    stringi_1.7.8     compiler_4.1.0    generics_0.1.2   \n[29] reticulate_1.25   jsonlite_1.8.0   \n```\n:::\n:::\n\n::: {.callout-note appearance=\"simple\"  collapse=\"true\"}\n\n### Python Environment Information\n\n::: {.cell}\n\n```{.r .cell-code}\nreticulate::py_config()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npython:         /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/bin/python\nlibpython:      /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/lib/libpython3.8.dylib\npythonhome:     /Users/dfalbel/Library/r-miniconda/envs/r-reticulate:/Users/dfalbel/Library/r-miniconda/envs/r-reticulate\nversion:        3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:47)  [Clang 12.0.1 ]\nnumpy:          /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/numpy\nnumpy_version:  1.22.4\ntensorflow:     /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/tensorflow\n\nNOTE: Python version was forced by RETICULATE_PYTHON\n```\n:::\n\n```{.r .cell-code}\nreticulate:::pip_freeze(reticulate::py_exe())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          package\n1                         absl-py\n2                        appnope \n3                      asttokens \n4                      astunparse\n5                       backcall \n6  backports.functools-lru-cache \n7                      cachetools\n8                         certifi\n9              charset-normalizer\n10                       debugpy \n11                     decorator \n12                           dill\n13                   entrypoints \n14                          etils\n15                     executing \n16                    flatbuffers\n17                           gast\n18                    google-auth\n19           google-auth-oauthlib\n20                   google-pasta\n21       googleapis-common-protos\n22                         grpcio\n23                           h5py\n24                           idna\n25             importlib-metadata\n26            importlib-resources\n27                     ipykernel \n28                       ipython \n29                          jedi \n30                jupyter-client \n31                  jupyter-core \n32                          keras\n33            Keras-Preprocessing\n34                       libclang\n35                       Markdown\n36             matplotlib-inline \n37                  nest-asyncio \n38                         numpy \n39                       oauthlib\n40                     opt-einsum\n41                     packaging \n42                         parso \n43                       pexpect \n44                   pickleshare \n45                         Pillow\n46                        promise\n47                prompt-toolkit \n48                       protobuf\n49                        psutil \n50                    ptyprocess \n51                     pure-eval \n52                         pyasn1\n53                 pyasn1-modules\n54                         pydot \n55                      Pygments \n56                     pyparsing \n57               python-dateutil \n58                         pyzmq \n59                       requests\n60              requests-oauthlib\n61                            rsa\n62                         scipy \n63                           six \n64                    stack-data \n65                    tensorboard\n66        tensorboard-data-server\n67         tensorboard-plugin-wit\n68                     tensorflow\n69            tensorflow-datasets\n70           tensorflow-estimator\n71                 tensorflow-hub\n72   tensorflow-io-gcs-filesystem\n73            tensorflow-metadata\n74                      termcolor\n75                           toml\n76                       tornado \n77                           tqdm\n78                     traitlets \n79              typing_extensions\n80                        urllib3\n81                       wcwidth \n82                       Werkzeug\n83                          wrapt\n84                           zipp\n                                                                                                                       version\n1                                                                                                                        1.1.0\n2                                                 file:///home/conda/feedstock_root/build_artifacts/appnope_1649077682618/work\n3                                               file:///home/conda/feedstock_root/build_artifacts/asttokens_1618968359944/work\n4                                                                                                                        1.6.3\n5                                                file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n6                           file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n7                                                                                                                        5.2.0\n8                                                                                                                  2022.5.18.1\n9                                                                                                                       2.0.12\n10                                                        file:///Users/runner/miniforge3/conda-bld/debugpy_1649586603968/work\n11                                              file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\n12                                                                                                                     0.3.5.1\n13                                            file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\n14                                                                                                                       0.6.0\n15                                              file:///home/conda/feedstock_root/build_artifacts/executing_1646044401614/work\n16                                                                                                                        1.12\n17                                                                                                                       0.4.0\n18                                                                                                                       2.7.0\n19                                                                                                                       0.4.6\n20                                                                                                                       0.2.0\n21                                                                                                                      1.56.2\n22                                                                                                                      1.46.3\n23                                                                                                                       3.7.0\n24                                                                                                                         3.3\n25                                                                                                                      4.11.4\n26                                                                                                                       5.7.1\n27                                                      file:///Users/runner/miniforge3/conda-bld/ipykernel_1654565231778/work\n28                                                        file:///Users/runner/miniforge3/conda-bld/ipython_1653755011383/work\n29                                                           file:///Users/runner/miniforge3/conda-bld/jedi_1649067146773/work\n30                                         file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1654730843242/work\n31                                                   file:///Users/runner/miniforge3/conda-bld/jupyter_core_1652365306989/work\n32                                                                                                                       2.9.0\n33                                                                                                                       1.1.2\n34                                                                                                                      14.0.1\n35                                                                                                                       3.3.7\n36                                      file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\n37                                           file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1648959695634/work\n38                                                          file:///Users/runner/miniforge3/conda-bld/numpy_1653325830837/work\n39                                                                                                                       3.2.0\n40                                                                                                                       3.3.0\n41                                              file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\n42                                                  file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\n43                                                file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\n44                                            file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n45                                                                                                                       9.1.1\n46                                                                                                                         2.3\n47                                         file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1649130487073/work\n48                                                                                                                      3.19.4\n49                                                         file:///Users/runner/miniforge3/conda-bld/psutil_1653089386834/work\n50  file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n51                                              file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\n52                                                                                                                       0.4.8\n53                                                                                                                       0.2.8\n54                                                          file:///Users/runner/miniforge3/conda-bld/pydot_1636047909408/work\n55                                               file:///home/conda/feedstock_root/build_artifacts/pygments_1650904496387/work\n56                                              file:///home/conda/feedstock_root/build_artifacts/pyparsing_1652235407899/work\n57                                        file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\n58                                                          file:///Users/runner/miniforge3/conda-bld/pyzmq_1654181479158/work\n59                                                                                                                      2.28.0\n60                                                                                                                       1.3.1\n61                                                                                                                         4.8\n62                                                          file:///Users/runner/miniforge3/conda-bld/scipy_1653074091860/work\n63                                                    file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\n64                                             file:///home/conda/feedstock_root/build_artifacts/stack_data_1644872665635/work\n65                                                                                                                       2.9.1\n66                                                                                                                       0.6.1\n67                                                                                                                       1.8.1\n68                                                                                                                       2.9.1\n69                                                                                                                       4.6.0\n70                                                                                                                       2.9.0\n71                                                                                                                      0.12.0\n72                                                                                                                      0.26.0\n73                                                                                                                       1.8.0\n74                                                                                                                       1.1.0\n75                                                                                                                      0.10.2\n76                                                        file:///Users/runner/miniforge3/conda-bld/tornado_1648827543297/work\n77                                                                                                                      4.64.0\n78                                              file:///home/conda/feedstock_root/build_artifacts/traitlets_1654067514780/work\n79                                                                                                                       4.2.0\n80                                                                                                                      1.26.9\n81                                                file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\n82                                                                                                                       2.1.2\n83                                                                                                                      1.14.1\n84                                                                                                                       3.8.0\n                                                                                                                               requirement\n1                                                                                                                           absl-py==1.1.0\n2                                                   appnope @ file:///home/conda/feedstock_root/build_artifacts/appnope_1649077682618/work\n3                                               asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1618968359944/work\n4                                                                                                                        astunparse==1.6.3\n5                                                 backcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n6       backports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n7                                                                                                                        cachetools==5.2.0\n8                                                                                                                     certifi==2022.5.18.1\n9                                                                                                               charset-normalizer==2.0.12\n10                                                          debugpy @ file:///Users/runner/miniforge3/conda-bld/debugpy_1649586603968/work\n11                                              decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\n12                                                                                                                           dill==0.3.5.1\n13                                          entrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\n14                                                                                                                            etils==0.6.0\n15                                              executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1646044401614/work\n16                                                                                                                       flatbuffers==1.12\n17                                                                                                                             gast==0.4.0\n18                                                                                                                      google-auth==2.7.0\n19                                                                                                             google-auth-oauthlib==0.4.6\n20                                                                                                                     google-pasta==0.2.0\n21                                                                                                        googleapis-common-protos==1.56.2\n22                                                                                                                          grpcio==1.46.3\n23                                                                                                                             h5py==3.7.0\n24                                                                                                                               idna==3.3\n25                                                                                                              importlib-metadata==4.11.4\n26                                                                                                              importlib-resources==5.7.1\n27                                                      ipykernel @ file:///Users/runner/miniforge3/conda-bld/ipykernel_1654565231778/work\n28                                                          ipython @ file:///Users/runner/miniforge3/conda-bld/ipython_1653755011383/work\n29                                                                jedi @ file:///Users/runner/miniforge3/conda-bld/jedi_1649067146773/work\n30                                    jupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1654730843242/work\n31                                                jupyter-core @ file:///Users/runner/miniforge3/conda-bld/jupyter_core_1652365306989/work\n32                                                                                                                            keras==2.9.0\n33                                                                                                              Keras-Preprocessing==1.1.2\n34                                                                                                                        libclang==14.0.1\n35                                                                                                                         Markdown==3.3.7\n36                              matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\n37                                        nest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1648959695634/work\n38                                                              numpy @ file:///Users/runner/miniforge3/conda-bld/numpy_1653325830837/work\n39                                                                                                                         oauthlib==3.2.0\n40                                                                                                                       opt-einsum==3.3.0\n41                                              packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\n42                                                      parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\n43                                                  pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\n44                                          pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n45                                                                                                                           Pillow==9.1.1\n46                                                                                                                            promise==2.3\n47                                    prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1649130487073/work\n48                                                                                                                        protobuf==3.19.4\n49                                                            psutil @ file:///Users/runner/miniforge3/conda-bld/psutil_1653089386834/work\n50 ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n51                                              pure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\n52                                                                                                                           pyasn1==0.4.8\n53                                                                                                                   pyasn1-modules==0.2.8\n54                                                              pydot @ file:///Users/runner/miniforge3/conda-bld/pydot_1636047909408/work\n55                                                Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1650904496387/work\n56                                              pyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1652235407899/work\n57                                  python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\n58                                                              pyzmq @ file:///Users/runner/miniforge3/conda-bld/pyzmq_1654181479158/work\n59                                                                                                                        requests==2.28.0\n60                                                                                                                requests-oauthlib==1.3.1\n61                                                                                                                                rsa==4.8\n62                                                              scipy @ file:///Users/runner/miniforge3/conda-bld/scipy_1653074091860/work\n63                                                          six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\n64                                            stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1644872665635/work\n65                                                                                                                      tensorboard==2.9.1\n66                                                                                                          tensorboard-data-server==0.6.1\n67                                                                                                           tensorboard-plugin-wit==1.8.1\n68                                                                                                                       tensorflow==2.9.1\n69                                                                                                              tensorflow-datasets==4.6.0\n70                                                                                                             tensorflow-estimator==2.9.0\n71                                                                                                                  tensorflow-hub==0.12.0\n72                                                                                                    tensorflow-io-gcs-filesystem==0.26.0\n73                                                                                                              tensorflow-metadata==1.8.0\n74                                                                                                                        termcolor==1.1.0\n75                                                                                                                            toml==0.10.2\n76                                                          tornado @ file:///Users/runner/miniforge3/conda-bld/tornado_1648827543297/work\n77                                                                                                                            tqdm==4.64.0\n78                                              traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1654067514780/work\n79                                                                                                                typing_extensions==4.2.0\n80                                                                                                                         urllib3==1.26.9\n81                                                  wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\n82                                                                                                                         Werkzeug==2.1.2\n83                                                                                                                           wrapt==1.14.1\n84                                                                                                                             zipp==3.8.0\n```\n:::\n:::\n\n### System Information\n\n\n```\nWarning in system(\"nvidia-smi\"): error in running command\n```\n\nTF Devices:  - :PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\nCPU cores: 8 \nPage render time:  and 9 seconds\n\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}