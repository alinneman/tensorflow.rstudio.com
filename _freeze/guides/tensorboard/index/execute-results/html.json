{
  "hash": "0e971f9c6ef81cd0113f3a0046687bcb",
  "result": {
    "markdown": "---\ntitle: TensorBoard\naliases:\n  - /tools/tensorboard.html\n  - /tools/tensorboard/\nexecute:\n  eval: false\n---\n\n\n## Overview\n\nThe computations you’ll use TensorFlow for - like training a massive deep neural network - can be complex and confusing. To make it easier to understand, debug, and optimize TensorFlow programs, a suite of visualization tools called TensorBoard is available. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it.\n\nFor example, here’s a TensorBoard display for Keras accuracy and loss metrics:\n\n![](../tensorboard.png){.screenshot}\n\n## Recording Data\n\nThe method for recording events for visualization by TensorBoard varies depending upon which TensorFlow interface you are working with:\n\n|  |  |\n|---------------|---------------------------------------------------------------|\n| [Keras](../keras/index.html)  | When using Keras, include the `callback_tensorboard()` when invoking the `fit()` function to train a model. See the [Keras documentation](http://127.0.0.1:4321/keras/articles/training_visualization.html#recording-data) for additional details. |\n| [Core API](training_flags.html) | When using the core API, you need to attach `tf$summary$scalar` operations to the graph for the metrics you want to record for viewing in TensorBoard. See the [core documentation](http://127.0.0.1:4321/tensorflow/articles/howto_summaries_and_tensorboard.html) for additional details. |\n\nNote that in all cases it's important that you use a unique directory to record training events (otherwise events from multiple training runs will be aggregated together).\n\nYou can remove and recreate event log directories between runs, or alternatively use the [tfruns package](tfruns/articles/overview.html) to do training, which will automatically create a new directory for each training run.\n\n## Viewing Data\n\nTo view TensorBoard data for a given set of runs you use the `tensorboard()` function, pointing it to to a directory which contains TensorBoard logs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntensorboard(\"logs/run_a\")\n```\n:::\n\n\nIt's often useful to run TensorBoard while you are training a model. To do this, simply launch tensorboard within the training directory right before you begin training:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# launch TensorBoard (data won't show up until after the first epoch)\ntensorboard(\"logs/run_a\")\n\n# fit the model with the TensorBoard callback\nhistory <- model %>% fit(\n  x_train, y_train,\n  batch_size = batch_size,\n  epochs = epochs,\n  verbose = 1,\n  callbacks = callback_tensorboard(\"logs/run_a\"),\n  validation_split = 0.2\n)\n```\n:::\n\n\nKeras writes TensorBoard data at the end of each epoch so you won't see any data in TensorBoard until 10-20 seconds after the end of the first epoch (TensorBoard automatically refreshes it's display every 30 seconds during training).\n\n\n### tfruns\n\nIf you are using the [tfruns package](tfruns/articles/overview.html) to track and manage training runs then there are some shortcuts available for the `tensorboard()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntensorboard()                                # views the latest run by default\ntensorboard(latest_run())                    # view the latest run\ntensorboard(ls_runs(order = eval_acc)[1,])   # view the run with the best eval_acc\n```\n:::\n\n\n\n## Comparing Runs\n\nTensorBoard will automatically include all runs logged within the sub-directories of the specified `log_dir`, for example, if you logged another run using:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncallback_tensorboard(log_dir = \"logs/run_b\")\n```\n:::\n\n\nThen called tensorboard as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntensorboard(\"logs\")\n```\n:::\n\n\nThe TensorBoard visualization would look like this:\n\n![](../tensorboard_compare.png){width=700 height=540 .screenshot}\n\nYou can also pass multiple log directories. For example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntensorboard(c(\"logs/run_a\", \"logs/run_b\"))\n```\n:::\n\n\n### tfruns\n\nIf you are using the [tfruns package](tfruns/articles/overview.html) to track and manage training runs then you easily pass multiple runs that match a criteria using the `ls_runs()` function. For example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntensorboard(ls_runs(latest_n = 2))         # last 2 runs\ntensorboard(ls_runs(eval_acc > 0.98))      # all runs with > 0.98 eval accuracy\ntensorboard(ls_runs(order = eval_acc))[5,] # top 5 runs w/r/t eval accuracy\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}