{
  "hash": "2b58b3f891eacbe8ab4e47f67db8c298",
  "result": {
    "markdown": "---\ntitle: \"Overview\"\naliases:\n  - /tools/gpu.html\n---\n\n\n\n\nIt's highly recommended, although not strictly necessary, that you run\ndeep-learning code on a modern NVIDIA GPU. Some applications -- in\nparticular, image processing with convolutional networks and sequence\nprocessing with recurrent neural networks -- will be excruciatingly slow\non CPU, even a fast multicore CPU. And even for applications that can\nrealistically be run on CPU, you'll generally see speed increase by a\nfactor or 5 or 10 by using a modern GPU.\n\nIf your local workstation doesn't already have a GPU that you can use\nfor deep learning (a recent, high-end NVIDIA GPU), then running deep\nlearning experiments in the cloud is a simple, low-cost way for you to\nget started without having to buy any additional hardware. See the\ndocumentation below for details on using both local and cloud GPUs.\n\n|                                                                                                                                                   |                                                                                                                                                                                                                                                                               |\n|---------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| <a href=\"/installation/gpu/local_gpu\">Local GPU<br/><img src=\"images/local-gpu-illustration.png\" class=\"nav-image\" width=\"64/\"/></a>              | For systems that have a recent, high-end NVIDIAÂ® GPU, TensorFlow is available in a GPU version that takes advantage of the CUDA and cuDNN libraries to accelerate training performance. Similarly, Arm Macs can take advantage of the GPU.                                    |\n| <a href=\"/tools/cloudml/getting_started\">CloudML<br/><img src=\"images/cloud-ml-illustration.png\" class=\"nav-image\" width=\"64/\"/></a>              | Google CloudML is a managed service that provides on-demand access to training on GPUs, including the new Tesla P100 GPUs from NVIDIA. CloudML also provides hyperparameter tuning to optmize key attributes of model architectures in order to maximize predictive accuracy. |\n| <a href=\"/installation/gpu/cloud_server_gpu\">Cloud Server<br/><img src=\"images/cloud-server-illustration.png\" class=\"nav-image\" width=\"64/\"/></a> | Cloud server instances with GPUs are available from services like Amazon EC2 and Google Compute Engine. You can use RStudio Server on these instances, making the development experience nearly identical to working locally.                                                 |\n\n                                                                                                                                                      |\n\n<!-- Paperspace image needs to be updated -->\n\n<!-- | <a href=\"/installation/gpu/cloud_desktop_gpu\">Cloud Desktop<br/><img src=\"images/cloud-desktop-illustration.png\" class=\"nav-image\" width=\"64/\"/></a> | Virtual cloud desktops with GPUs are available from Paperspace. This provides an Ubuntu 16.04 desktop environment that you can access entirely within a web browser (note that this requires a reasonably fast internet connection to be usable).                                                                                                                                                 | -->\n",
    "supporting": [
      "gpu_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}