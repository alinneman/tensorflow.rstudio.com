<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-0.9.183">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>tf-site-title - Writing Layer and Model objects from scratch.</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>

  <script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
  <script src="../../site_libs/clipboard/clipboard.min.js"></script>
  <meta name="quarto:offset" content="../../">
  <script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
  <script src="../../site_libs/quarto-search/fuse.min.js"></script>
  <script src="../../site_libs/quarto-search/quarto-search.js"></script>
  <script src="../../site_libs/quarto-html/quarto.js"></script>
  <script src="../../site_libs/quarto-html/popper.min.js"></script>
  <script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
  <script src="../../site_libs/quarto-html/anchor.min.js"></script>
  <link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
  <link id="quarto-text-highlighting-styles" href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
  <script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
  <link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
  <link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
  <script id="quarto-search-options" type="application/json">{
    "location": "sidebar",
    "copy-button": false,
    "collapse-after": 3,
    "panel-placement": "start",
    "type": "textbox",
    "limit": 20,
    "language": {
      "search-no-results-text": "No results",
      "search-matching-documents-text": "matching documents",
      "search-copy-link-title": "Copy link to search",
      "search-hide-matches-text": "Hide additional matches",
      "search-more-match-text": "more match in this document",
      "search-more-matches-text": "more matches in this document",
      "search-clear-button-title": "Clear",
      "search-detached-cancel-button-title": "Cancel",
      "search-submit-button-title": "Submit"
    }
  }</script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
<h2 id="toc-title">On this page</h2>
<ul>
<li><a href="#setup" id="toc-setup" class="nav-link active" data-scroll-target="#setup">Setup</a></li>
<li><a href="#the-layer-class-a-combination-of-state-weights-and-some-computation" id="toc-the-layer-class-a-combination-of-state-weights-and-some-computation" class="nav-link" data-scroll-target="#the-layer-class-a-combination-of-state-weights-and-some-computation">The <code>Layer</code> class: a combination of state (weights) and some computation</a></li>
<li><a href="#layers-can-have-non-trainable-weights" id="toc-layers-can-have-non-trainable-weights" class="nav-link" data-scroll-target="#layers-can-have-non-trainable-weights">Layers can have non-trainable weights</a></li>
<li><a href="#best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known" id="toc-best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known" class="nav-link" data-scroll-target="#best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known">Best practice: deferring weight creation until the shape of the inputs is known</a></li>
<li><a href="#layers-are-recursively-composable" id="toc-layers-are-recursively-composable" class="nav-link" data-scroll-target="#layers-are-recursively-composable">Layers are recursively composable</a></li>
<li><a href="#the-add_loss-method" id="toc-the-add_loss-method" class="nav-link" data-scroll-target="#the-add_loss-method">The <code>add_loss()</code> method</a></li>
<li><a href="#the-add_metric-method" id="toc-the-add_metric-method" class="nav-link" data-scroll-target="#the-add_metric-method">The <code>add_metric()</code> method</a></li>
<li><a href="#you-can-optionally-enable-serialization-on-your-layers" id="toc-you-can-optionally-enable-serialization-on-your-layers" class="nav-link" data-scroll-target="#you-can-optionally-enable-serialization-on-your-layers">You can optionally enable serialization on your layers</a></li>
<li><a href="#privileged-training-argument-in-the-call-method" id="toc-privileged-training-argument-in-the-call-method" class="nav-link" data-scroll-target="#privileged-training-argument-in-the-call-method">Privileged <code>training</code> argument in the <code>call()</code> method</a></li>
<li><a href="#privileged-mask-argument-in-the-call-method" id="toc-privileged-mask-argument-in-the-call-method" class="nav-link" data-scroll-target="#privileged-mask-argument-in-the-call-method">Privileged <code>mask</code> argument in the <code>call()</code> method</a></li>
<li><a href="#the-model-class" id="toc-the-model-class" class="nav-link" data-scroll-target="#the-model-class">The <code>Model</code> class</a></li>
<li><a href="#putting-it-all-together-an-end-to-end-example" id="toc-putting-it-all-together-an-end-to-end-example" class="nav-link" data-scroll-target="#putting-it-all-together-an-end-to-end-example">Putting it all together: an end-to-end example</a></li>
<li><a href="#beyond-object-oriented-development-the-functional-api" id="toc-beyond-object-oriented-development-the-functional-api" class="nav-link" data-scroll-target="#beyond-object-oriented-development-the-functional-api">Beyond object-oriented development: the Functional API</a></li>
<li><a href="#defining-custom-layers-and-models-in-an-r-package" id="toc-defining-custom-layers-and-models-in-an-r-package" class="nav-link" data-scroll-target="#defining-custom-layers-and-models-in-an-r-package">Defining custom layers and models in an R package</a></li>
<li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
</ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header id="title-block-header" class="quarto-title-block default">

<div class="quarto-title"><h1 class="title display-7">Writing <code>Layer</code> and <code>Model</code> objects from scratch.</h1></div></header>

<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<div class="cell">

</div>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tfdatasets)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tf_version</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stderr">
<pre><code>Loaded Tensorflow version 2.8.0</code></pre>
</div>
<div class="cell-output-stdout">
<pre><code>[1] '2.8'</code></pre>
</div>
</div>
</section>
<section id="the-layer-class-a-combination-of-state-weights-and-some-computation" class="level2">
<h2 class="anchored" data-anchor-id="the-layer-class-a-combination-of-state-weights-and-some-computation">The <code>Layer</code> class: a combination of state (weights) and some computation</h2>
<p>One of the central abstractions in Keras is the <code>Layer</code> class. A layer encapsulates both a state (the layer’s “weights”) and a transformation from inputs to outputs (a “call”, the layer’s forward pass).</p>
<p>Here’s a densely-connected layer. It has a state: the variables <code>w</code> and <code>b</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Linear</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">input_dim =</span> <span class="dv">32</span>) {</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    w_init <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">random_normal_initializer</span>()</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>w <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">Variable</span>(</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">initial_value =</span> <span class="fu">w_init</span>(</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">shape =</span> <span class="fu">shape</span>(input_dim, units),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">dtype =</span> <span class="st">"float32"</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    b_init <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">zeros_initializer</span>()</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>b <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">Variable</span>(</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">initial_value =</span> <span class="fu">b_init</span>(<span class="at">shape =</span> <span class="fu">shape</span>(units), <span class="at">dtype =</span> <span class="st">"float32"</span>),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You would use a layer by calling it on some tensor input(s), much like a regular function.</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">ones</span>(<span class="fu">shape</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>linear_layer <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">linear_layer</span>(x)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>tf.Tensor(
[[0.11195514 0.06101172 0.05288789 0.03446084]
 [0.11195514 0.06101172 0.05288789 0.03446084]], shape=(2, 4), dtype=float32)</code></pre>
</div>
</div>
<p><code>Linear</code> behaves similarly to a layer present in the Python interface to keras (e.g., <code>keras$layers$Dense</code>).</p>
<p>However, one additional step is needed to make it behave like the builtin layers present in the keras R package (e.g., <code>layer_dense()</code>).</p>
<p>Keras layers in R are designed to compose nicely with the pipe operator (<code>%&gt;%</code>), so that the layer instance is conveniently created on demand when an existing model or tensor is piped in. In order to make a custom layer similarly compose nicely with the pipe, you can call <code>create_layer_wrapper()</code> on the layer class constructor.</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>layer_linear <span class="ot">&lt;-</span> <span class="fu">create_layer_wrapper</span>(Linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now <code>layer_linear</code> is a layer constructor that composes nicely with <code>%&gt;%</code>, just like the built-in layers:</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_linear</span>(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">model</span>(<span class="fu">k_ones</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>tf.Tensor(
[[ 0.09593566 -0.0239684  -0.08020082 -0.20181108]
 [ 0.09593566 -0.0239684  -0.08020082 -0.20181108]], shape=(2, 4), dtype=float32)</code></pre>
</div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>Model: "sequential"
____________________________________________________________________________
 Layer (type)                     Output Shape                  Param #     
============================================================================
 linear_1 (Linear)                (2, 4)                        12          
============================================================================
Total params: 12
Trainable params: 12
Non-trainable params: 0
____________________________________________________________________________</code></pre>
</div>
</div>
<p>Because the pattern above is so common, there is a convenience function that combines the steps of subclassing <code>keras$layers$Layer</code> and calling <code>create_layer_wrapper</code> on the output: the <code>Layer</code> function. The <code>layer_linear</code> defined below is identical to the <code>layer_linear</code> defined above.</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>layer_linear <span class="ot">&lt;-</span> <span class="fu">Layer</span>(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Linear"</span>,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span>  <span class="cf">function</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">input_dim =</span> <span class="dv">32</span>) {</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    w_init <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">random_normal_initializer</span>()</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>w <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="at">initial_value =</span> <span class="fu">w_init</span>(<span class="at">shape =</span> <span class="fu">shape</span>(input_dim, units),</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>                                                 <span class="at">dtype =</span> <span class="st">"float32"</span>),</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">trainable =</span> <span class="cn">TRUE</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    b_init <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">zeros_initializer</span>()</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>b <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="at">initial_value =</span> <span class="fu">b_init</span>(<span class="at">shape =</span> <span class="fu">shape</span>(units),</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>                                                 <span class="at">dtype =</span> <span class="st">"float32"</span>),</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>                          <span class="at">trainable =</span> <span class="cn">TRUE</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">call =</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the remainder of this vignette we’ll be using the <code>%py_class%</code> constructor. However, in your own code feel free to use <code>create_layer_wrapper</code> and/or <code>Layer</code> if you prefer.</p>
<p>Note that the weights <code>w</code> and <code>b</code> are automatically tracked by the layer upon being set as layer attributes:</p>
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">all.equal</span>(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  linear_layer<span class="sc">$</span>weights,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(linear_layer<span class="sc">$</span>w, linear_layer<span class="sc">$</span>b)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You also have access to a quicker shortcut for adding a weight to a layer: the <code>add_weight()</code> method:</p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Linear</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">input_dim =</span> <span class="dv">32</span>) {</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    w_init <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">random_normal_initializer</span>()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>w <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(input_dim, units),</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>b <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(units),</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"zeros"</span>,</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">ones</span>(<span class="fu">shape</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>linear_layer <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">linear_layer</span>(x)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>tf.Tensor(
[[-0.10461128  0.03076715  0.03548232 -0.02009123]
 [-0.10461128  0.03076715  0.03548232 -0.02009123]], shape=(2, 4), dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="layers-can-have-non-trainable-weights" class="level2">
<h2 class="anchored" data-anchor-id="layers-can-have-non-trainable-weights">Layers can have non-trainable weights</h2>
<p>Besides trainable weights, you can add non-trainable weights to a layer as well. Such weights are meant not to be taken into account during backpropagation, when you are training the layer.</p>
<p>Here’s how to add and use a non-trainable weight:</p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ComputeSum</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(input_dim) {</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>total <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">Variable</span>(</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">initial_value =</span> tf<span class="sc">$</span><span class="fu">zeros</span>(<span class="fu">shape</span>(input_dim)),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">FALSE</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>total<span class="sc">$</span><span class="fu">assign_add</span>(tf<span class="sc">$</span><span class="fu">reduce_sum</span>(inputs, <span class="at">axis =</span> 0L))</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>total</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">ones</span>(<span class="fu">shape</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>my_sum <span class="ot">&lt;-</span> <span class="fu">ComputeSum</span>(<span class="dv">2</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">my_sum</span>(x)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">as.numeric</span>(y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>[1] 2 2</code></pre>
</div>
<div class="sourceCode" id="cb18"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">my_sum</span>(x)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">as.numeric</span>(y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>[1] 4 4</code></pre>
</div>
</div>
<p>It’s part of <code>layer$weights</code>, but it gets categorized as a non-trainable weight:</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"weights:"</span>, <span class="fu">length</span>(my_sum<span class="sc">$</span>weights), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>weights: 1 </code></pre>
</div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"non-trainable weights:"</span>, <span class="fu">length</span>(my_sum<span class="sc">$</span>non_trainable_weights), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>non-trainable weights: 1 </code></pre>
</div>
<div class="sourceCode" id="cb24"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># It's not included in the trainable weights:</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"trainable_weights:"</span>, my_sum<span class="sc">$</span>trainable_weights, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>trainable_weights:  </code></pre>
</div>
</div>
</section>
<section id="best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known" class="level2">
<h2 class="anchored" data-anchor-id="best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known">Best practice: deferring weight creation until the shape of the inputs is known</h2>
<p>Our <code>Linear</code> layer above took an <code>input_dim</code>argument that was used to compute the shape of the weights <code>w</code> and <code>b</code> in <code>initialize()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Linear</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">input_dim =</span> <span class="dv">32</span>) {</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>w <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(input_dim, units),</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>b <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(units),</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"zeros"</span>,</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In many cases, you may not know in advance the size of your inputs, and you would like to lazily create weights when that value becomes known, some time after instantiating the layer.</p>
<p>In the Keras API, we recommend creating layer weights in the <code>build(self, inputs_shape)</code> method of your layer. Like this:</p>
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Linear</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">units =</span> <span class="dv">32</span>) {</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>units <span class="ot">&lt;-</span> units</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  build <span class="ot">&lt;-</span> <span class="cf">function</span>(input_shape) {</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>w <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(<span class="fu">tail</span>(input_shape, <span class="dv">1</span>), self<span class="sc">$</span>units),</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>b <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(self<span class="sc">$</span>units),</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>build()</code> method of your layer will automatically run the first time your layer instance is called. You now have a layer that can handle an arbitrary number of input features:</p>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># At instantiation, we don't know on what inputs this is going to get called</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>linear_layer <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">32</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The layer's weights are created dynamically the first time the layer is called</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">linear_layer</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stderr">
<pre><code>Warning in is.na(d): is.na() applied to non-(list or vector) of type
'environment'</code></pre>
</div>
</div>
<p>Implementing <code>build()</code> separately as shown above nicely separates creating weights only once from using weights in every call. However, for some advanced custom layers, it can become impractical to separate the state creation and computation. Layer implementers are allowed to defer weight creation to the first <code>call()</code>, but need to take care that later calls use the same weights. In addition, since <code>call()</code> is likely to be executed for the first time inside a <code>tf_function()</code>, any variable creation that takes place in <code>call()</code> should be wrapped in a <code>tf$init_scope()</code>.</p>
</section>
<section id="layers-are-recursively-composable" class="level2">
<h2 class="anchored" data-anchor-id="layers-are-recursively-composable">Layers are recursively composable</h2>
<p>If you assign a Layer instance as an attribute of another Layer, the outer layer will start tracking the weights created by the inner layer.</p>
<p>We recommend creating such sublayers in the <code>initialize()</code> method and leave it to the first <code>call()</code> to trigger building their weights.</p>
<div class="cell">
<div class="sourceCode" id="cb30"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's assume we are reusing the Linear class</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># with a `build` method that we defined above.</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="fu">MLPBlock</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>linear_1 <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">32</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>linear_2 <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">32</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>linear_3 <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">1</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">linear_1</span>(inputs)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> tf<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">relu</span>(x)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">linear_2</span>(x)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> tf<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">relu</span>(x)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">linear_3</span>(x)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>mlp <span class="ot">&lt;-</span> <span class="fu">MLPBlock</span>()</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">mlp</span>(tf<span class="sc">$</span><span class="fu">ones</span>(<span class="at">shape =</span> <span class="fu">shape</span>(<span class="dv">3</span>, <span class="dv">64</span>))) <span class="co"># The first call to the `mlp` will create the weights</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stderr">
<pre><code>Warning in is.na(d): is.na() applied to non-(list or vector) of type
'environment'

Warning in is.na(d): is.na() applied to non-(list or vector) of type
'environment'

Warning in is.na(d): is.na() applied to non-(list or vector) of type
'environment'</code></pre>
</div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"weights:"</span>, <span class="fu">length</span>(mlp<span class="sc">$</span>weights), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>weights: 6 </code></pre>
</div>
<div class="sourceCode" id="cb34"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"trainable weights:"</span>, <span class="fu">length</span>(mlp<span class="sc">$</span>trainable_weights), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>trainable weights: 6 </code></pre>
</div>
</div>
</section>
<section id="the-add_loss-method" class="level2">
<h2 class="anchored" data-anchor-id="the-add_loss-method">The <code>add_loss()</code> method</h2>
<p>When writing the <code>call()</code> method of a layer, you can create loss tensors that you will want to use later, when writing your training loop. This is doable by calling <code>self$add_loss(value)</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb36"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A layer that creates an activity regularization loss</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ActivityRegularizationLayer</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">rate =</span> <span class="fl">1e-2</span>) {</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>rate <span class="ot">&lt;-</span> rate</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">add_loss</span>(self<span class="sc">$</span>rate <span class="sc">*</span> tf<span class="sc">$</span><span class="fu">reduce_sum</span>(inputs))</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    inputs</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These losses (including those created by any inner layer) can be retrieved via <code>layer$losses</code>. This property is reset at the start of every <code>call()</code> to the top-level layer, so that <code>layer$losses</code> always contains the loss values created during the last forward pass.</p>
<div class="cell">
<div class="sourceCode" id="cb37"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">OuterLayer</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>activity_reg <span class="ot">&lt;-</span> <span class="fu">ActivityRegularizationLayer</span>(<span class="fl">1e-2</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">activity_reg</span>(inputs)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>layer <span class="ot">&lt;-</span> <span class="fu">OuterLayer</span>()</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">length</span>(layer<span class="sc">$</span>losses) <span class="sc">==</span> <span class="dv">0</span>) <span class="co"># No losses yet since the layer has never been called</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="fu">layer</span>(tf<span class="sc">$</span><span class="fu">zeros</span>(<span class="fu">shape</span>(<span class="dv">1</span>, <span class="dv">1</span>))) <span class="sc">|&gt;</span> <span class="fu">invisible</span>()</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">length</span>(layer<span class="sc">$</span>losses) <span class="sc">==</span> <span class="dv">1</span>) <span class="co"># We created one loss value</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="co"># `layer$losses` gets reset at the start of each call()</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="fu">layer</span>(tf<span class="sc">$</span><span class="fu">zeros</span>(<span class="fu">shape</span>(<span class="dv">1</span>, <span class="dv">1</span>))) <span class="sc">|&gt;</span> <span class="fu">invisible</span>()</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">length</span>(layer<span class="sc">$</span>losses) <span class="sc">==</span> <span class="dv">1</span>) <span class="co"># This is the loss created during the call above</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In addition, the <code>loss</code> property also contains regularization losses created for the weights of any inner layer:</p>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">OuterLayerWithKernelRegularizer</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dense <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="fl">1e-3</span>))</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">dense</span>(inputs)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>layer <span class="ot">&lt;-</span> <span class="fu">OuterLayerWithKernelRegularizer</span>()</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="fu">layer</span>(tf<span class="sc">$</span><span class="fu">zeros</span>(<span class="fu">shape</span>(<span class="dv">1</span>, <span class="dv">1</span>))) <span class="sc">|&gt;</span> <span class="fu">invisible</span>()</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co"># This is `1e-3 * sum(layer$dense$kernel ** 2)`,</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co"># created by the `kernel_regularizer` above.</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(layer<span class="sc">$</span>losses)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>[[1]]
tf.Tensor(0.0018123012, shape=(), dtype=float32)</code></pre>
</div>
</div>
<p>These losses are meant to be taken into account when writing training loops, like this:</p>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate an optimizer.</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">&lt;-</span> <span class="fu">optimizer_sgd</span>(<span class="at">learning_rate =</span> <span class="fl">1e-3</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="ot">&lt;-</span> <span class="fu">loss_sparse_categorical_crossentropy</span>(<span class="at">from_logits =</span> <span class="cn">TRUE</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate over the batches of a dataset.</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>dataset_iterator <span class="ot">&lt;-</span> reticulate<span class="sc">::</span><span class="fu">as_iterator</span>(train_dataset)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(<span class="sc">!</span><span class="fu">is.null</span>(batch <span class="ot">&lt;-</span> <span class="fu">iter_next</span>(dataset_iterator))) {</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(x_batch_train, y_batch_train) <span class="sc">%&lt;-%</span> batch</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape, {</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    logits <span class="ot">&lt;-</span> <span class="fu">layer</span>(x_batch_train) <span class="co"># Logits for this minibatch</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loss value for this minibatch</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    loss_value <span class="ot">&lt;-</span> <span class="fu">loss_fn</span>(y_batch_train, logits)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add extra losses created during this forward pass:</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    loss_value <span class="ot">&lt;-</span> loss_value <span class="sc">+</span> <span class="fu">sum</span>(model<span class="sc">$</span>losses)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>  grads <span class="ot">&lt;-</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss_value, model<span class="sc">$</span>trainable_weights)</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>    purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(grads, model<span class="sc">$</span>trainable_weights)))</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For a detailed guide about writing training loops, see the <a href="../../guides/writing_a_training_loop_from_scratch/">guide to writing a training loop from scratch</a>.</p>
<p>These losses also work seamlessly with <code>fit()</code> (they get automatically summed and added to the main loss, if any):</p>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>input <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="fu">shape</span>(<span class="dv">3</span>))</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> input <span class="sc">%&gt;%</span> <span class="fu">layer_activity_regularization</span>()</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># output &lt;- ActivityRegularizationLayer()(input)</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(input, output)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co"># If there is a loss passed in `compile`, the regularization</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># losses get added to it</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(<span class="at">optimizer =</span> <span class="st">"adam"</span>, <span class="at">loss =</span> <span class="st">"mse"</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(<span class="fu">k_random_uniform</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)),</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">k_random_uniform</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)),</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">1</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co"># It's also possible not to pass any loss in `compile`,</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co"># since the model already has a loss to minimize, via the `add_loss`</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="co"># call during the forward pass!</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(<span class="at">optimizer =</span> <span class="st">"adam"</span>)</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(<span class="fu">k_random_uniform</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)),</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">k_random_uniform</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)),</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">1</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="the-add_metric-method" class="level2">
<h2 class="anchored" data-anchor-id="the-add_metric-method">The <code>add_metric()</code> method</h2>
<p>Similarly to <code>add_loss()</code>, layers also have an <code>add_metric()</code> method for tracking the moving average of a quantity during training.</p>
<p>Consider the following layer: a “logistic endpoint” layer. It takes as inputs predictions and targets, it computes a loss which it tracks via <code>add_loss()</code>, and it computes an accuracy scalar, which it tracks via <code>add_metric()</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb42"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">LogisticEndpoint</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">name =</span> <span class="cn">NULL</span>) {</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>(<span class="at">name =</span> name)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>loss_fn <span class="ot">&lt;-</span> <span class="fu">loss_binary_crossentropy</span>(<span class="at">from_logits =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>accuracy_fn <span class="ot">&lt;-</span> <span class="fu">metric_binary_accuracy</span>()</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(targets, logits, <span class="at">sample_weights =</span> <span class="cn">NULL</span>) {</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the training-time loss value and add it</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to the layer using `self$add_loss()`.</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">loss_fn</span>(targets, logits, sample_weights)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">add_loss</span>(loss)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log accuracy as a metric and add it</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to the layer using `self.add_metric()`.</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    acc <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">accuracy_fn</span>(targets, logits, sample_weights)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">add_metric</span>(acc, <span class="at">name =</span> <span class="st">"accuracy"</span>)</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the inference-time prediction tensor (for `.predict()`).</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">softmax</span>(logits)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Metrics tracked in this way are accessible via <code>layer$metrics</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>layer <span class="ot">&lt;-</span> <span class="fu">LogisticEndpoint</span>()</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>targets <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">ones</span>(<span class="fu">shape</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>logits <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">ones</span>(<span class="fu">shape</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">layer</span>(targets, logits)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"layer$metrics: "</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>layer$metrics: </code></pre>
</div>
<div class="sourceCode" id="cb45"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(layer<span class="sc">$</span>metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>List of 1
 $ :BinaryAccuracy(name=binary_accuracy,dtype=float32,threshold=0.5)</code></pre>
</div>
<div class="sourceCode" id="cb47"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"current accuracy value:"</span>, <span class="fu">as.numeric</span>(layer<span class="sc">$</span>metrics[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">result</span>()), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>current accuracy value: 1 </code></pre>
</div>
</div>
<p>Just like for <code>add_loss()</code>, these metrics are tracked by <code>fit()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>inputs <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="fu">shape</span>(<span class="dv">3</span>), <span class="at">name =</span> <span class="st">"inputs"</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>targets <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="fu">shape</span>(<span class="dv">10</span>), <span class="at">name =</span> <span class="st">"targets"</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>logits <span class="ot">&lt;-</span> inputs <span class="sc">%&gt;%</span> <span class="fu">layer_dense</span>(<span class="dv">10</span>)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">LogisticEndpoint</span>(<span class="at">name =</span> <span class="st">"predictions"</span>)(logits, targets)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> <span class="fu">list</span>(inputs, targets), <span class="at">outputs =</span> predictions)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(<span class="at">optimizer =</span> <span class="st">"adam"</span>)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">inputs =</span> <span class="fu">k_random_uniform</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>)),</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">targets =</span> <span class="fu">k_random_uniform</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">10</span>))</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(data, <span class="at">epochs =</span> <span class="dv">1</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="you-can-optionally-enable-serialization-on-your-layers" class="level2">
<h2 class="anchored" data-anchor-id="you-can-optionally-enable-serialization-on-your-layers">You can optionally enable serialization on your layers</h2>
<p>If you need your custom layers to be serializable as part of a <a href="../../guides/functional_api/">Functional model</a>, you can optionally implement a <code>get_config()</code> method:</p>
<div class="cell">
<div class="sourceCode" id="cb50"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Linear</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">units =</span> <span class="dv">32</span>) {</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>units <span class="ot">&lt;-</span> units</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>  build <span class="ot">&lt;-</span> <span class="cf">function</span>(input_shape) {</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>w <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(<span class="fu">tail</span>(input_shape, <span class="dv">1</span>), self<span class="sc">$</span>units),</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>b <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(self<span class="sc">$</span>units),</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a>  get_config <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">units =</span> self<span class="sc">$</span>units)</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can recreate the layer from its config:</span></span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a>layer <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">64</span>)</span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a>config <span class="ot">&lt;-</span> layer<span class="sc">$</span><span class="fu">get_config</span>()</span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>$units
[1] 64</code></pre>
</div>
<div class="sourceCode" id="cb52"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>new_layer <span class="ot">&lt;-</span> Linear<span class="sc">$</span><span class="fu">from_config</span>(config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that the <code>initialize()</code> method of the base <code>Layer</code> class takes some additional named arguments, in particular a <code>name</code> and a <code>dtype</code>. It’s good practice to pass these arguments to the parent class in <code>initialize()</code> and to include them in the layer config:</p>
<div class="cell">
<div class="sourceCode" id="cb53"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Linear</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">units =</span> <span class="dv">32</span>, ...) {</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>(...)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>units <span class="ot">&lt;-</span> units</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>  build <span class="ot">&lt;-</span> <span class="cf">function</span>(input_shape) {</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>w <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(<span class="fu">tail</span>(input_shape, <span class="dv">1</span>), self<span class="sc">$</span>units),</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>b <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> <span class="fu">shape</span>(self<span class="sc">$</span>units),</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">initializer =</span> <span class="st">"random_normal"</span>,</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>  get_config <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a>    config <span class="ot">&lt;-</span> super<span class="sc">$</span><span class="fu">get_config</span>()</span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a>    config<span class="sc">$</span>units <span class="ot">&lt;-</span> self<span class="sc">$</span>units</span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a>    config</span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a>layer <span class="ot">&lt;-</span> <span class="fu">Linear</span>(<span class="dv">64</span>)</span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>config <span class="ot">&lt;-</span> layer<span class="sc">$</span><span class="fu">get_config</span>()</span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>List of 4
 $ name     : chr "linear_9"
 $ trainable: logi TRUE
 $ dtype    : chr "float32"
 $ units    : num 64</code></pre>
</div>
<div class="sourceCode" id="cb55"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>new_layer <span class="ot">&lt;-</span> Linear<span class="sc">$</span><span class="fu">from_config</span>(config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If you need more flexibility when deserializing the layer from its config, you can also override the <code>from_config()</code> class method. This is the base implementation of <code>from_config()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb56"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>from_config <span class="ot">&lt;-</span> <span class="cf">function</span>(cls, config) <span class="fu">do.call</span>(cls, config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To learn more about serialization and saving, see the complete <a href="../../guides/serialization_and_saving/">guide to saving and serializing models</a>.</p>
</section>
<section id="privileged-training-argument-in-the-call-method" class="level2">
<h2 class="anchored" data-anchor-id="privileged-training-argument-in-the-call-method">Privileged <code>training</code> argument in the <code>call()</code> method</h2>
<p>Some layers, in particular the <code>BatchNormalization</code> layer and the <code>Dropout</code> layer, have different behaviors during training and inference. For such layers, it is standard practice to expose a <code>training</code> (boolean) argument in the <code>call()</code> method.</p>
<p>By exposing this argument in <code>call()</code>, you enable the built-in training and evaluation loops (e.g.&nbsp;<code>fit()</code>) to correctly use the layer in training and inference. Note, the default of <code>NULL</code> means that the training parameter will be inferred by keras from the training context (e.g., it will be <code>TRUE</code> if called from <code>fit()</code>, <code>FALSE</code> if called from <code>predict()</code>)</p>
<div class="cell">
<div class="sourceCode" id="cb57"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">CustomDropout</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(rate, ...) {</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>(...)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>rate <span class="ot">&lt;-</span> rate</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs, <span class="at">training =</span> <span class="cn">NULL</span>) {</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">isTRUE</span>(training)) {</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(tf<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">dropout</span>(inputs, <span class="at">rate =</span> self<span class="sc">$</span>rate))</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    inputs</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="privileged-mask-argument-in-the-call-method" class="level2">
<h2 class="anchored" data-anchor-id="privileged-mask-argument-in-the-call-method">Privileged <code>mask</code> argument in the <code>call()</code> method</h2>
<p>The other privileged argument supported by <code>call()</code> is the <code>mask</code> argument.</p>
<p>You will find it in all Keras RNN layers. A mask is a boolean tensor (one boolean value per timestep in the input) used to skip certain input timesteps when processing timeseries data.</p>
<p>Keras will automatically pass the correct <code>mask</code> argument to <code>call()</code> for layers that support it, when a mask is generated by a prior layer. Mask-generating layers are the <code>Embedding</code> layer configured with <code>mask_zero=True</code>, and the <code>Masking</code> layer.</p>
<p>To learn more about masking and how to write masking-enabled layers, please check out the guide <a href="../../guides/understanding_masking_and_padding/">“understanding padding and masking”</a>.</p>
</section>
<section id="the-model-class" class="level2">
<h2 class="anchored" data-anchor-id="the-model-class">The <code>Model</code> class</h2>
<p>In general, you will use the <code>Layer</code> class to define inner computation blocks, and will use the <code>Model</code> class to define the outer model – the object you will train.</p>
<p>For instance, in a ResNet50 model, you would have several ResNet blocks subclassing <code>Layer</code>, and a single <code>Model</code> encompassing the entire ResNet50 network.</p>
<p>The <code>Model</code> class has the same API as <code>Layer</code>, with the following differences:</p>
<ul>
<li>It has support for built-in training, evaluation, and prediction methods (<code>fit()</code>, <code>evaluate()</code>, <code>predict()</code>).</li>
<li>It exposes the list of its inner layers, via the <code>model$layers</code> property.</li>
<li>It exposes saving and serialization APIs (<code>save_model_tf()</code>, <code>save_model_weights_tf()</code>, …)</li>
</ul>
<p>Effectively, the <code>Layer</code> class corresponds to what we refer to in the literature as a “layer” (as in “convolution layer” or “recurrent layer”) or as a “block” (as in “ResNet block” or “Inception block”).</p>
<p>Meanwhile, the <code>Model</code> class corresponds to what is referred to in the literature as a “model” (as in “deep learning model”) or as a “network” (as in “deep neural network”).</p>
<p>So if you’re wondering, “should I use the <code>Layer</code> class or the <code>Model</code> class?”, ask yourself: will I need to call <code>fit()</code> on it? Will I need to call <code>save()</code> on it? If so, go with <code>Model</code>. If not (either because your class is just a block in a bigger system, or because you are writing training &amp; saving code yourself), use <code>Layer</code>.</p>
<p>For instance, we could take our mini-resnet example above, and use it to build a <code>Model</code> that we could train with <code>fit()</code>, and that we could save with <code>save_model_weights_tf()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb58"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ResNet</span>(keras<span class="sc">$</span>Model) <span class="sc">%py_class%</span> {</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">num_classes =</span> <span class="dv">1000</span>) {</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>()</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>block_1 <span class="ot">&lt;-</span> <span class="fu">ResNetBlock</span>()</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>block_2 <span class="ot">&lt;-</span> <span class="fu">ResNetBlock</span>()</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>global_pool <span class="ot">&lt;-</span> <span class="fu">layer_global_average_pooling_2d</span>()</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>classifier <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> num_classes)</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">block_1</span>(inputs)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">block_2</span>(x)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">global_pool</span>(x)</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">classifier</span>(x)</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>resnet <span class="ot">&lt;-</span> <span class="fu">ResNet</span>()</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>dataset <span class="ot">&lt;-</span> ...</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>resnet <span class="sc">%&gt;%</span> <span class="fu">fit</span>(dataset, <span class="at">epochs =</span> <span class="dv">10</span>)</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>resnet <span class="sc">%&gt;%</span> <span class="fu">save_model_tf</span>(filepath)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="putting-it-all-together-an-end-to-end-example" class="level2">
<h2 class="anchored" data-anchor-id="putting-it-all-together-an-end-to-end-example">Putting it all together: an end-to-end example</h2>
<p>Here’s what you’ve learned so far:</p>
<ul>
<li>A <code>Layer</code> encapsulates a state (created in <code>initialize()</code> or <code>build()</code>), and some computation (defined in <code>call()</code>).</li>
<li>Layers can be recursively nested to create new, bigger computation blocks.</li>
<li>Layers can create and track losses (typically regularization losses) as well as metrics, via <code>add_loss()</code> and <code>add_metric()</code></li>
<li>The outer container, the thing you want to train, is a <code>Model</code>. A <code>Model</code> is just like a <code>Layer</code>, but with added training and serialization utilities.</li>
</ul>
<p>Let’s put all of these things together into an end-to-end example: we’re going to implement a Variational AutoEncoder (VAE). We’ll train it on MNIST digits.</p>
<p>Our VAE will be a subclass of <code>Model</code>, built as a nested composition of layers that subclass <code>Layer</code>. It will feature a regularization loss (KL divergence).</p>
<div class="cell">
<div class="sourceCode" id="cb59"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Sampling</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(z_mean, z_log_var) <span class="sc">%&lt;-%</span> inputs</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    batch <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">shape</span>(z_mean)[<span class="dv">1</span>]</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    dim <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">shape</span>(z_mean)[<span class="dv">2</span>]</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="ot">&lt;-</span> <span class="fu">k_random_normal</span>(<span class="at">shape =</span> <span class="fu">c</span>(batch, dim))</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    z_mean <span class="sc">+</span> <span class="fu">exp</span>(<span class="fl">0.5</span> <span class="sc">*</span> z_log_var) <span class="sc">*</span> epsilon</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="fu">Encoder</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Maps MNIST digits to a triplet (z_mean, z_log_var, z)."</span></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">latent_dim =</span> <span class="dv">32</span>, <span class="at">intermediate_dim =</span> <span class="dv">64</span>, <span class="at">name =</span> <span class="st">"encoder"</span>, ...) {</span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>(<span class="at">name =</span> name, ...)</span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dense_proj <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> intermediate_dim, <span class="at">activation =</span> <span class="st">"relu"</span>)</span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dense_mean <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> latent_dim)</span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dense_log_var <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> latent_dim)</span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>sampling <span class="ot">&lt;-</span> <span class="fu">Sampling</span>()</span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">dense_proj</span>(inputs)</span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a>    z_mean <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">dense_mean</span>(x)</span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a>    z_log_var <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">dense_log_var</span>(x)</span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">sampling</span>(<span class="fu">c</span>(z_mean, z_log_var))</span>
<span id="cb59-28"><a href="#cb59-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(z_mean, z_log_var, z)</span>
<span id="cb59-29"><a href="#cb59-29" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb59-30"><a href="#cb59-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb59-31"><a href="#cb59-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-32"><a href="#cb59-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-33"><a href="#cb59-33" aria-hidden="true" tabindex="-1"></a><span class="fu">Decoder</span>(keras<span class="sc">$</span>layers<span class="sc">$</span>Layer) <span class="sc">%py_class%</span> {</span>
<span id="cb59-34"><a href="#cb59-34" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Converts z, the encoded digit vector, back into a readable digit."</span></span>
<span id="cb59-35"><a href="#cb59-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-36"><a href="#cb59-36" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(original_dim, <span class="at">intermediate_dim =</span> <span class="dv">64</span>, <span class="at">name =</span> <span class="st">"decoder"</span>, ...) {</span>
<span id="cb59-37"><a href="#cb59-37" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>(<span class="at">name =</span> name, ...)</span>
<span id="cb59-38"><a href="#cb59-38" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dense_proj <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> intermediate_dim, <span class="at">activation =</span> <span class="st">"relu"</span>)</span>
<span id="cb59-39"><a href="#cb59-39" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dense_output <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> original_dim, <span class="at">activation =</span> <span class="st">"sigmoid"</span>)</span>
<span id="cb59-40"><a href="#cb59-40" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb59-41"><a href="#cb59-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-42"><a href="#cb59-42" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb59-43"><a href="#cb59-43" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">dense_proj</span>(inputs)</span>
<span id="cb59-44"><a href="#cb59-44" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">dense_output</span>(x)</span>
<span id="cb59-45"><a href="#cb59-45" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb59-46"><a href="#cb59-46" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb59-47"><a href="#cb59-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-48"><a href="#cb59-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-49"><a href="#cb59-49" aria-hidden="true" tabindex="-1"></a><span class="fu">VariationalAutoEncoder</span>(keras<span class="sc">$</span>Model) <span class="sc">%py_class%</span> {</span>
<span id="cb59-50"><a href="#cb59-50" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Combines the encoder and decoder into an end-to-end model for training."</span></span>
<span id="cb59-51"><a href="#cb59-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-52"><a href="#cb59-52" aria-hidden="true" tabindex="-1"></a>  initialize <span class="ot">&lt;-</span> <span class="cf">function</span>(original_dim, <span class="at">intermediate_dim =</span> <span class="dv">64</span>, <span class="at">latent_dim =</span> <span class="dv">32</span>,</span>
<span id="cb59-53"><a href="#cb59-53" aria-hidden="true" tabindex="-1"></a>                         <span class="at">name =</span> <span class="st">"autoencoder"</span>, ...) {</span>
<span id="cb59-54"><a href="#cb59-54" aria-hidden="true" tabindex="-1"></a>    super<span class="sc">$</span><span class="fu">initialize</span>(<span class="at">name =</span> name, ...)</span>
<span id="cb59-55"><a href="#cb59-55" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>original_dim <span class="ot">&lt;-</span> original_dim</span>
<span id="cb59-56"><a href="#cb59-56" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>encoder <span class="ot">&lt;-</span> <span class="fu">Encoder</span>(</span>
<span id="cb59-57"><a href="#cb59-57" aria-hidden="true" tabindex="-1"></a>      <span class="at">latent_dim =</span> latent_dim,</span>
<span id="cb59-58"><a href="#cb59-58" aria-hidden="true" tabindex="-1"></a>      <span class="at">intermediate_dim =</span> intermediate_dim</span>
<span id="cb59-59"><a href="#cb59-59" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb59-60"><a href="#cb59-60" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>decoder <span class="ot">&lt;-</span> <span class="fu">Decoder</span>(original_dim, <span class="at">intermediate_dim =</span> intermediate_dim)</span>
<span id="cb59-61"><a href="#cb59-61" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb59-62"><a href="#cb59-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-63"><a href="#cb59-63" aria-hidden="true" tabindex="-1"></a>  call <span class="ot">&lt;-</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb59-64"><a href="#cb59-64" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(z_mean, z_log_var, z) <span class="sc">%&lt;-%</span> self<span class="sc">$</span><span class="fu">encoder</span>(inputs)</span>
<span id="cb59-65"><a href="#cb59-65" aria-hidden="true" tabindex="-1"></a>    reconstructed <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">decoder</span>(z)</span>
<span id="cb59-66"><a href="#cb59-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add KL divergence regularization loss.</span></span>
<span id="cb59-67"><a href="#cb59-67" aria-hidden="true" tabindex="-1"></a>    kl_loss <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(z_log_var <span class="sc">-</span> tf<span class="sc">$</span><span class="fu">square</span>(z_mean) <span class="sc">-</span> tf<span class="sc">$</span><span class="fu">exp</span>(z_log_var) <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb59-68"><a href="#cb59-68" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span><span class="fu">add_loss</span>(kl_loss)</span>
<span id="cb59-69"><a href="#cb59-69" aria-hidden="true" tabindex="-1"></a>    reconstructed</span>
<span id="cb59-70"><a href="#cb59-70" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb59-71"><a href="#cb59-71" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s write a simple training loop on MNIST:</p>
<div class="cell">
<div class="sourceCode" id="cb60"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tfautograph)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tfdatasets)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>original_dim <span class="ot">&lt;-</span> <span class="dv">784</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>vae <span class="ot">&lt;-</span> <span class="fu">VariationalAutoEncoder</span>(original_dim, <span class="dv">64</span>, <span class="dv">32</span>)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">&lt;-</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> <span class="fl">1e-3</span>)</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>mse_loss_fn <span class="ot">&lt;-</span> <span class="fu">loss_mean_squared_error</span>()</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>loss_metric <span class="ot">&lt;-</span> <span class="fu">metric_mean</span>()</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">dataset_mnist</span>()<span class="sc">$</span>train<span class="sc">$</span>x <span class="sc">%&gt;%</span></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">array_reshape</span>(<span class="fu">c</span>(<span class="dv">60000</span>, <span class="dv">784</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">/</span><span class="st">`</span>(<span class="dv">255</span>)</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="ot">&lt;-</span> <span class="fu">tensor_slices_dataset</span>(x_train) <span class="sc">%&gt;%</span></span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataset_shuffle</span>(<span class="at">buffer_size =</span> <span class="dv">1024</span>) <span class="sc">%&gt;%</span></span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataset_batch</span>(<span class="dv">64</span>)</span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate over epochs.</span></span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (epoch <span class="cf">in</span> <span class="fu">seq</span>(epochs)) {</span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Start of epoch %d</span><span class="sc">\n</span><span class="st">"</span>, epoch))</span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-27"><a href="#cb60-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Iterate over the batches of the dataset.</span></span>
<span id="cb60-28"><a href="#cb60-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># autograph lets you use tfdatasets in `for` and `while`</span></span>
<span id="cb60-29"><a href="#cb60-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autograph</span>({</span>
<span id="cb60-30"><a href="#cb60-30" aria-hidden="true" tabindex="-1"></a>    step <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb60-31"><a href="#cb60-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (x_batch_train <span class="cf">in</span> train_dataset) {</span>
<span id="cb60-32"><a href="#cb60-32" aria-hidden="true" tabindex="-1"></a>      <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape, {</span>
<span id="cb60-33"><a href="#cb60-33" aria-hidden="true" tabindex="-1"></a>        <span class="do">## Note: we're four opaque contexts deep here (for, autograph, for,</span></span>
<span id="cb60-34"><a href="#cb60-34" aria-hidden="true" tabindex="-1"></a>        <span class="do">## with), When in doubt about the objects or methods that are available</span></span>
<span id="cb60-35"><a href="#cb60-35" aria-hidden="true" tabindex="-1"></a>        <span class="do">## (e.g., what is `tape` here?), remember you can always drop into a</span></span>
<span id="cb60-36"><a href="#cb60-36" aria-hidden="true" tabindex="-1"></a>        <span class="do">## debugger right here:</span></span>
<span id="cb60-37"><a href="#cb60-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># browser()</span></span>
<span id="cb60-38"><a href="#cb60-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-39"><a href="#cb60-39" aria-hidden="true" tabindex="-1"></a>        reconstructed <span class="ot">&lt;-</span> <span class="fu">vae</span>(x_batch_train)</span>
<span id="cb60-40"><a href="#cb60-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute reconstruction loss</span></span>
<span id="cb60-41"><a href="#cb60-41" aria-hidden="true" tabindex="-1"></a>        loss <span class="ot">&lt;-</span> <span class="fu">mse_loss_fn</span>(x_batch_train, reconstructed)</span>
<span id="cb60-42"><a href="#cb60-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-43"><a href="#cb60-43" aria-hidden="true" tabindex="-1"></a>        loss <span class="sc">%&lt;&gt;%</span> <span class="fu">add</span>(vae<span class="sc">$</span>losses[[<span class="dv">1</span>]]) <span class="co"># Add KLD regularization loss</span></span>
<span id="cb60-44"><a href="#cb60-44" aria-hidden="true" tabindex="-1"></a>      })</span>
<span id="cb60-45"><a href="#cb60-45" aria-hidden="true" tabindex="-1"></a>      grads <span class="ot">&lt;-</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, vae<span class="sc">$</span>trainable_weights)</span>
<span id="cb60-46"><a href="#cb60-46" aria-hidden="true" tabindex="-1"></a>      optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(</span>
<span id="cb60-47"><a href="#cb60-47" aria-hidden="true" tabindex="-1"></a>        purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(grads, vae<span class="sc">$</span>trainable_weights)))</span>
<span id="cb60-48"><a href="#cb60-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-49"><a href="#cb60-49" aria-hidden="true" tabindex="-1"></a>      <span class="fu">loss_metric</span>(loss)</span>
<span id="cb60-50"><a href="#cb60-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-51"><a href="#cb60-51" aria-hidden="true" tabindex="-1"></a>      step <span class="sc">%&lt;&gt;%</span> <span class="fu">add</span>(<span class="dv">1</span>)</span>
<span id="cb60-52"><a href="#cb60-52" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (step <span class="sc">%%</span> <span class="dv">100</span> <span class="sc">==</span> <span class="dv">0</span>) {</span>
<span id="cb60-53"><a href="#cb60-53" aria-hidden="true" tabindex="-1"></a>        <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"step %d: mean loss = %.4f</span><span class="sc">\n</span><span class="st">"</span>, step, loss_metric<span class="sc">$</span><span class="fu">result</span>()))</span>
<span id="cb60-54"><a href="#cb60-54" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb60-55"><a href="#cb60-55" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb60-56"><a href="#cb60-56" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb60-57"><a href="#cb60-57" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-stdout">
<pre><code>Start of epoch 1
step 100: mean loss = 0.1247
step 200: mean loss = 0.0987
step 300: mean loss = 0.0888
step 400: mean loss = 0.0839
step 500: mean loss = 0.0806
step 600: mean loss = 0.0785
step 700: mean loss = 0.0770
step 800: mean loss = 0.0759
step 900: mean loss = 0.0749
Start of epoch 2
step 100: mean loss = 0.0739
step 200: mean loss = 0.0734
step 300: mean loss = 0.0729
step 400: mean loss = 0.0726
step 500: mean loss = 0.0722
step 600: mean loss = 0.0719
step 700: mean loss = 0.0716
step 800: mean loss = 0.0714
step 900: mean loss = 0.0711</code></pre>
</div>
</div>
<p>Note that since the VAE is subclassing <code>Model</code>, it features built-in training loops. So you could also have trained it like this:</p>
<div class="cell">
<div class="sourceCode" id="cb62"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>vae <span class="ot">&lt;-</span> <span class="fu">VariationalAutoEncoder</span>(<span class="dv">784</span>, <span class="dv">64</span>, <span class="dv">32</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">&lt;-</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> <span class="fl">1e-3</span>)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>vae <span class="sc">%&gt;%</span> <span class="fu">compile</span>(optimizer, <span class="at">loss =</span> <span class="fu">loss_mean_squared_error</span>())</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>vae <span class="sc">%&gt;%</span> <span class="fu">fit</span>(x_train, x_train, <span class="at">epochs =</span> <span class="dv">2</span>, <span class="at">batch_size =</span> <span class="dv">64</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="beyond-object-oriented-development-the-functional-api" class="level2">
<h2 class="anchored" data-anchor-id="beyond-object-oriented-development-the-functional-api">Beyond object-oriented development: the Functional API</h2>
<p>If you prefer a less object-oriented way of programming, you can also build models using the <a href="../../guides/functional_api/">Functional API</a>. Importantly, choosing one style or another does not prevent you from leveraging components written in the other style: you can always mix-and-match.</p>
<p>For instance, the Functional API example below reuses the same <code>Sampling</code> layer we defined in the example above:</p>
<div class="cell">
<div class="sourceCode" id="cb63"><pre class="sourceCode r cell-code code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>original_dim <span class="ot">&lt;-</span> <span class="dv">784</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>intermediate_dim <span class="ot">&lt;-</span> <span class="dv">64</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>latent_dim <span class="ot">&lt;-</span> <span class="dv">32</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define encoder model.</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>original_inputs <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> original_dim, <span class="at">name =</span> <span class="st">"encoder_input"</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> intermediate_dim, <span class="at">activation =</span> <span class="st">"relu"</span>)(original_inputs)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>z_mean <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> latent_dim, <span class="at">name =</span> <span class="st">"z_mean"</span>)(x)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>z_log_var <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> latent_dim, <span class="at">name =</span> <span class="st">"z_log_var"</span>)(x)</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">Sampling</span>()(<span class="fu">list</span>(z_mean, z_log_var))</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>encoder <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> original_inputs, <span class="at">outputs =</span> z, <span class="at">name =</span> <span class="st">"encoder"</span>)</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define decoder model.</span></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>latent_inputs <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> latent_dim, <span class="at">name =</span> <span class="st">"z_sampling"</span>)</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> intermediate_dim, <span class="at">activation =</span> <span class="st">"relu"</span>)(latent_inputs)</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>outputs <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> original_dim, <span class="at">activation =</span> <span class="st">"sigmoid"</span>)(x)</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>decoder <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> latent_inputs, <span class="at">outputs =</span> outputs, <span class="at">name =</span> <span class="st">"decoder"</span>)</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Define VAE model.</span></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>outputs <span class="ot">&lt;-</span> <span class="fu">decoder</span>(z)</span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a>vae <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> original_inputs, <span class="at">outputs =</span> outputs, <span class="at">name =</span> <span class="st">"vae"</span>)</span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Add KL divergence regularization loss.</span></span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a>kl_loss <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(z_log_var <span class="sc">-</span> tf<span class="sc">$</span><span class="fu">square</span>(z_mean) <span class="sc">-</span> tf<span class="sc">$</span><span class="fu">exp</span>(z_log_var) <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a>vae<span class="sc">$</span><span class="fu">add_loss</span>(kl_loss)</span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Train.</span></span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">&lt;-</span> keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adam</span>(<span class="at">learning_rate =</span> <span class="fl">1e-3</span>)</span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a>vae <span class="sc">%&gt;%</span> <span class="fu">compile</span>(optimizer, <span class="at">loss =</span> <span class="fu">loss_mean_squared_error</span>())</span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a>vae <span class="sc">%&gt;%</span> <span class="fu">fit</span>(x_train, x_train, <span class="at">epochs =</span> <span class="dv">3</span>, <span class="at">batch_size =</span> <span class="dv">64</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For more information, make sure to read the <a href="../../guides/functional_api/">Functional API guide</a>.</p>
</section>
<section id="defining-custom-layers-and-models-in-an-r-package" class="level2">
<h2 class="anchored" data-anchor-id="defining-custom-layers-and-models-in-an-r-package">Defining custom layers and models in an R package</h2>
<p>Unfortunately you can’t use anything that creates references to Python objects, at the top-level of an R package.</p>
<p>Here is why: when you build an R package, all the R files in the <code>R/</code> directory get sourced in an R environment (the package namespace), and then that environment is saved as part of the package bundle. Loading the package means restoring the saved R environment. This means that the R code only gets sourced once, at build time. If you create references to external objects (e.g., Python objects) at package build time, they will be NULL pointers when the package is loaded, because the external objects they pointed to at build time no longer exist at load time.</p>
<p>The solution is to delay creating references to Python objects until run time. Fortunately, <code>%py_class%</code>, <code>Layer()</code>, and <code>create_layer_wrapper(R6Class(...))</code> are all lazy about initializing the Python reference, so they are safe to define and export in an R package.</p>
<p>If you’re writing an R package that uses keras and reticulate, <a href="https://rstudio.github.io/reticulate/articles/package.html">this article</a> might be helpful to read over.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>In this guide you learned about creating custom layers and models in keras.</p>
<ul>
<li>The constructors available: <code>new_layer_class()</code>, <code>%py_class%</code>, <code>create_layer_wrapper()</code>, <code>R6Class()</code>, <code>Layer()</code>.</li>
<li>What methods to you might want to define to your model: <code>initialize()</code>, <code>build()</code>, <code>call()</code>, and <code>get_config()</code>.</li>
<li>What convenience methods are available when you subclass <code>keras$layers$Layer</code>: <code>add_weight()</code>, <code>add_loss()</code>, and <code>add_metric()</code></li>
</ul>



</section>
</main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->


</body></html>