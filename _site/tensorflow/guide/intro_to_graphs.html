<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-99.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>TensorFlow for R - Intro To_graphs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../keras/guides/sequential_model.html" rel="next">
<link href="../../tensorflow/guide/autodiff.html" rel="prev">
<link href="../../images/favicon/icon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <img src="../../images/favicon/icon.png" alt="">
    <span class="navbar-title">TensorFlow for R</span>
  </a>
          <div class="quarto-toggle-container ms-auto">
              <a href="" class="quarto-reader-toggle nav-link" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
          </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Intro To_graphs</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Tensorflow Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tensorflow/guide/basics.html" class="sidebar-item-text sidebar-link">Overview</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tensorflow/guide/tensor.html" class="sidebar-item-text sidebar-link">Tensors</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tensorflow/guide/variable.html" class="sidebar-item-text sidebar-link">Variables</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tensorflow/guide/autodiff.html" class="sidebar-item-text sidebar-link">Automatic differentiation</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tensorflow/guide/intro_to_graphs.html" class="sidebar-item-text sidebar-link active">Graphs and functions</a>
  </div>
</li>
    </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Keras</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/sequential_model.html" class="sidebar-item-text sidebar-link">The Sequential model</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/functional_api.html" class="sidebar-item-text sidebar-link">The Functional API</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/making_new_layers_and_models_via_subclassing.html" class="sidebar-item-text sidebar-link">Writing <code>Layer</code> and <code>Model</code> objects from scratch.</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/customizing_what_happens_in_fit.html" class="sidebar-item-text sidebar-link">Customizing what happens in <code>fit()</code></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/preprocessing_layers.html" class="sidebar-item-text sidebar-link">Working with preprocessing layers</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/transfer_learning.html" class="sidebar-item-text sidebar-link">Transfer learning and fine-tuning</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/working_with_rnns.html" class="sidebar-item-text sidebar-link">Working with RNNs</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../keras/guides/writing_your_own_callbacks.html" class="sidebar-item-text sidebar-link">Writing your own callbacks</a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-graphs-and-tf_function" id="toc-introduction-to-graphs-and-tf_function" class="nav-link active" data-scroll-target="#introduction-to-graphs-and-tf_function">Introduction to graphs and tf_function</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a>
  <ul class="collapse">
  <li><a href="#what-are-graphs" id="toc-what-are-graphs" class="nav-link" data-scroll-target="#what-are-graphs">What are graphs?</a></li>
  <li><a href="#the-benefits-of-graphs" id="toc-the-benefits-of-graphs" class="nav-link" data-scroll-target="#the-benefits-of-graphs">The benefits of graphs</a></li>
  </ul></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#taking-advantage-of-graphs" id="toc-taking-advantage-of-graphs" class="nav-link" data-scroll-target="#taking-advantage-of-graphs">Taking advantage of graphs</a>
  <ul class="collapse">
  <li><a href="#converting-python-functions-to-graphs" id="toc-converting-python-functions-to-graphs" class="nav-link" data-scroll-target="#converting-python-functions-to-graphs">Converting Python functions to graphs</a></li>
  <li><a href="#polymorphism-one-function-many-graphs" id="toc-polymorphism-one-function-many-graphs" class="nav-link" data-scroll-target="#polymorphism-one-function-many-graphs">Polymorphism: one <code>Function</code>, many graphs</a></li>
  </ul></li>
  <li><a href="#using-tf_function" id="toc-using-tf_function" class="nav-link" data-scroll-target="#using-tf_function">Using <code>tf_function()</code></a>
  <ul class="collapse">
  <li><a href="#graph-execution-vs.-eager-execution" id="toc-graph-execution-vs.-eager-execution" class="nav-link" data-scroll-target="#graph-execution-vs.-eager-execution">Graph execution vs.&nbsp;eager execution</a></li>
  <li><a href="#non-strict-execution" id="toc-non-strict-execution" class="nav-link" data-scroll-target="#non-strict-execution">Non-strict execution</a></li>
  <li><a href="#tf_function-best-practices" id="toc-tf_function-best-practices" class="nav-link" data-scroll-target="#tf_function-best-practices"><code>tf_function()</code> best practices</a></li>
  </ul></li>
  <li><a href="#seeing-the-speed-up" id="toc-seeing-the-speed-up" class="nav-link" data-scroll-target="#seeing-the-speed-up">Seeing the speed-up</a>
  <ul class="collapse">
  <li><a href="#performance-and-trade-offs" id="toc-performance-and-trade-offs" class="nav-link" data-scroll-target="#performance-and-trade-offs">Performance and trade-offs</a></li>
  </ul></li>
  <li><a href="#when-is-a-function-tracing" id="toc-when-is-a-function-tracing" class="nav-link" data-scroll-target="#when-is-a-function-tracing">When is a <code>Function</code> tracing?</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next steps</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Intro To_graphs</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="copyright-2020-the-tensorflow-authors." class="level5">
<h5 class="anchored" data-anchor-id="copyright-2020-the-tensorflow-authors.">Copyright 2020 The TensorFlow Authors.</h5>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#@title Licensed under the Apache License, Version 2.0 (the "License");</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># you may not use this file except in compliance with the License.</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># You may obtain a copy of the License at</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.apache.org/licenses/LICENSE-2.0</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Unless required by applicable law or agreed to in writing, software</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># distributed under the License is distributed on an "AS IS" BASIS,</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># See the License for the specific language governing permissions and</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># limitations under the License.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="introduction-to-graphs-and-tf_function" class="level1">
<h1>Introduction to graphs and tf_function</h1>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This guide goes beneath the surface of TensorFlow and Keras to demonstrate how TensorFlow works. If you instead want to immediately get started with Keras, check out the <a href="https://www.tensorflow.org/guide/keras/">collection of Keras guides</a>.</p>
<p>In this guide, you’ll learn how TensorFlow allows you to make simple changes to your code to get graphs, how graphs are stored and represented, and how you can use them to accelerate your models.</p>
<p>Note: For those of you who are only familiar with TensorFlow 1.x, this guide demonstrates a very different view of graphs.</p>
<p><strong>This is a big-picture overview that covers how <code>tf_function()</code> allows you to switch from eager execution to graph execution.</strong> For a more complete specification of <code>tf_function()</code>, go to the <a href="function.qmd"><code>tf_function()</code> guide</a>.</p>
<section id="what-are-graphs" class="level3">
<h3 class="anchored" data-anchor-id="what-are-graphs">What are graphs?</h3>
<p>In the previous three guides, you ran TensorFlow <strong>eagerly</strong>. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.</p>
<p>While eager execution has several unique advantages, graph execution enables portability outside Python and tends to offer better performance. <strong>Graph execution</strong> means that tensor computations are executed as a <em>TensorFlow graph</em>, sometimes referred to as a <code>tf$Graph</code> or simply a “graph.”</p>
<p><strong>Graphs are data structures that contain a set of <code>tf$Operation</code> objects, which represent units of computation; and <code>tf$Tensor</code> objects, which represent the units of data that flow between operations.</strong> They are defined in a <code>tf$Graph</code> context. Since these graphs are data structures, they can be saved, run, and restored all without the original R code.</p>
<p>This is what a TensorFlow graph representing a two-layer neural network looks like when visualized in TensorBoard.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">A simple TensorFlow g</figcaption><p></p>
</figure>
</div>
</section>
<section id="the-benefits-of-graphs" class="level3">
<h3 class="anchored" data-anchor-id="the-benefits-of-graphs">The benefits of graphs</h3>
<p>With a graph, you have a great deal of flexibility. You can use your TensorFlow graph in environments that don’t have an R interpreter, like mobile applications, embedded devices, and backend servers. TensorFlow uses graphs as the format for <a href="saved_model">saved models</a> when it exports them from R.</p>
<p>Graphs are also easily optimized, allowing the compiler to do transformations like:</p>
<ul>
<li>Statically infer the value of tensors by folding constant nodes in your computation <em>(“constant folding”)</em>.</li>
<li>Separate sub-parts of a computation that are independent and split them between threads or devices.</li>
<li>Simplify arithmetic operations by eliminating common subexpressions.</li>
</ul>
<p>There is an entire optimization system, <a href="./graph_optimization.qmd">Grappler</a>, to perform this and other speedups.</p>
<p>In short, graphs are extremely useful and let your TensorFlow run <strong>fast</strong>, run <strong>in parallel</strong>, and run efficiently <strong>on multiple devices</strong>.</p>
<p>However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them.</p>
</section>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr, <span class="at">include.only =</span> <span class="st">"%&gt;%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="taking-advantage-of-graphs" class="level2">
<h2 class="anchored" data-anchor-id="taking-advantage-of-graphs">Taking advantage of graphs</h2>
<p>You create and run a graph in TensorFlow by using <code>tf_function()</code>, either as a direct call or as a decorator. <code>tf_function()</code> takes a regular function as input and returns a <code>Function</code>. <strong>A <code>Function</code> is a callable that builds TensorFlow graphs from the R function. You use a <code>Function</code> in the same way as its R equivalent.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define an R function.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>a_regular_function <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y, b) {</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  x <span class="sc">%&gt;%</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(y) <span class="sc">%&gt;%</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    { . <span class="sc">+</span> b }</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># `a_function_that_uses_a_graph` is a TensorFlow `Function`.</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>a_function_that_uses_a_graph <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(a_regular_function)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loaded Tensorflow version 2.9.1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make some tensors.</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">as_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="st">"float64"</span>, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">as_tensor</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>, <span class="st">"float64"</span>, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="fu">as_tensor</span>(<span class="dv">4</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>orig_value <span class="ot">&lt;-</span> <span class="fu">as.array</span>(<span class="fu">a_regular_function</span>(x1, y1, b1))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Call a `Function` like a Python function.</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>tf_function_value <span class="ot">&lt;-</span> <span class="fu">as.array</span>(<span class="fu">a_function_that_uses_a_graph</span>(x1, y1, b1))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(orig_value <span class="sc">==</span> tf_function_value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>On the outside, a <code>Function</code> looks like a regular function you write using TensorFlow operations. <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py">Underneath</a>, however, it is <em>very different</em>. A <code>Function</code> <strong>encapsulates <a href="#polymorphism_one_function_many_graphs">several <code>tf$Graph</code>s behind one API</a>.</strong> That is how <code>Function</code> is able to give you the <a href="#the_benefits_of_graphs">benefits of graph execution</a>, like speed and deployability.</p>
<p><code>tf_function</code> applies to a function <em>and all other functions it calls</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>inner_function <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y, b) {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  tf<span class="sc">$</span><span class="fu">matmul</span>(x, y) <span class="sc">+</span> b</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>outer_function <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(<span class="cf">function</span>(x) {</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">as_tensor</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>, <span class="st">"float64"</span>, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  b <span class="ot">&lt;-</span> <span class="fu">as_tensor</span>(<span class="fl">4.0</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inner_function</span>(x, y, b)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that the callable will create a graph that</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># includes `inner_function` as well as `outer_function`.</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="fu">outer_function</span>(<span class="fu">as_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="st">"float64"</span>, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))) <span class="co">#%&gt;% as.array()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([[12.]], shape=(1, 1), dtype=float64)</code></pre>
</div>
</div>
<p>If you have used TensorFlow 1.x, you will notice that at no time did you need to define a <code>Placeholder</code> or <code>tf$Session()</code>.</p>
<section id="converting-python-functions-to-graphs" class="level3">
<h3 class="anchored" data-anchor-id="converting-python-functions-to-graphs">Converting Python functions to graphs</h3>
<p>Any function you write with TensorFlow will contain a mixture of built-in TF operations and R control-flow logic, such as <code>if-then</code> clauses, loops, <code>break</code>, <code>return</code>, <code>next</code>, and more. While TensorFlow operations are easily captured by a <code>tf$Graph</code>, R-specific logic needs to undergo an extra step in order to become part of the graph. <code>tf_function()</code> uses a library called {tfautograph} to evaluate the R code in a special way so that it generates a graph.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>simple_relu <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (tf<span class="sc">$</span><span class="fu">greater</span>(x, <span class="dv">0</span>))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    x</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tensor</span>(<span class="dv">0</span>, x<span class="sc">$</span>dtype)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>tf_simple_relu <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(simple_relu)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">"First branch, with graph: "</span>, <span class="fu">format</span>(<span class="fu">tf_simple_relu</span>(<span class="fu">as_tensor</span>(<span class="dv">1</span>))), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Second branch, with graph: "</span>, <span class="fu">format</span>(<span class="fu">tf_simple_relu</span>(<span class="fu">as_tensor</span>(<span class="sc">-</span><span class="dv">1</span>))), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>,</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">sep =</span> <span class="st">""</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>First branch, with graph: tf.Tensor(1.0, shape=(), dtype=float64)
Second branch, with graph: tf.Tensor(0.0, shape=(), dtype=float64)</code></pre>
</div>
</div>
<p>Though it is unlikely that you will need to view graphs directly, you can inspect the outputs to check the exact results. These are not easy to read, so no need to look too carefully!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This is the graph itself.</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>tf_simple_relu<span class="sc">$</span><span class="fu">get_concrete_function</span>(<span class="fu">as_tensor</span>(<span class="dv">1</span>))<span class="sc">$</span>graph<span class="sc">$</span><span class="fu">as_graph_def</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Most of the time, <code>tf_function()</code> will work without special considerations. However, there are some caveats, and the <a href="./function.qmd">tf_function guide</a> can help here, as well as the <a href="https://t-kalinowski.github.io/tfautograph/articles/tfautograph.html">tfautograph Getting Started vignette</a></p>
</section>
<section id="polymorphism-one-function-many-graphs" class="level3">
<h3 class="anchored" data-anchor-id="polymorphism-one-function-many-graphs">Polymorphism: one <code>Function</code>, many graphs</h3>
<p>A <code>tf$Graph</code> is specialized to a specific type of inputs (for example, tensors with a specific <a href="https://www.tensorflow.org/api_docs/python/tf/dtypes/DType"><code>dtype</code></a> or objects with the same <a href="https://docs.python.org/3/library/functions.html#id%5D"><code>id()</code></a>) (i.e, the same memory address).</p>
<p>Each time you invoke a <code>Function</code> with a set of arguments that can’t be handled by any of its existing graphs (such as arguments with new <code>dtypes</code> or incompatible shapes), <code>Function</code> creates a new <code>tf$Graph</code> specialized to those new arguments. The type specification of a <code>tf$Graph</code>’s inputs is known as its <strong>input signature</strong> or just a <strong>signature</strong>. For more information regarding when a new <code>tf$Graph</code> is generated and how that can be controlled, see the <a href="https://www.tensorflow.org/guide/function#rules_of_tracing">rules of retracing</a>.</p>
<p>The <code>Function</code> stores the <code>tf$Graph</code> corresponding to that signature in a <code>ConcreteFunction</code>. <strong>A <code>ConcreteFunction</code> is a wrapper around a <code>tf$Graph</code>.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>my_relu <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(<span class="cf">function</span>(x) {</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">message</span>(<span class="st">"Tracing my_relu(x) with: "</span>, x)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  tf<span class="sc">$</span><span class="fu">maximum</span>(<span class="fu">as_tensor</span>(<span class="dv">0</span>), x)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># `my_relu` creates new graphs as it observes more signatures.</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="fu">my_relu</span>(<span class="fu">as_tensor</span>(<span class="fl">5.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Tracing my_relu(x) with: Tensor("x:0", shape=(), dtype=float64)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(5.5, shape=(), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">my_relu</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Tracing my_relu(x) with: 1-1</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([1. 0.], shape=(2), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">my_relu</span>(<span class="fu">as_tensor</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="sc">-</span><span class="dv">3</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Tracing my_relu(x) with: Tensor("x:0", shape=(2,), dtype=float64)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([3. 0.], shape=(2), dtype=float64)</code></pre>
</div>
</div>
<p>If the <code>Function</code> has already been called with that signature, <code>Function</code> does not create a new <code>tf$Graph</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># These two calls do *not* create new graphs.</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">my_relu</span>(<span class="fu">as_tensor</span>(<span class="sc">-</span><span class="fl">2.5</span>)) <span class="co"># Signature matches `as_tensor(5.5)`.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(0.0, shape=(), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">my_relu</span>(<span class="fu">as_tensor</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.</span>, <span class="fl">1.</span>))) <span class="co"># Signature matches `as_tensor(c(3., -3.))`.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([0. 1.], shape=(2), dtype=float64)</code></pre>
</div>
</div>
<p>Because it’s backed by multiple graphs, a <code>Function</code> is <sup>polymorphic</sup>. That enables it to support more input types than a single <code>tf$Graph</code> could represent, as well as to optimize each <code>tf$Graph</code> for better performance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># There are three `ConcreteFunction`s (one for each graph) in `my_relu`.</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># The `ConcreteFunction` also knows the return type and shape!</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(my_relu<span class="sc">$</span><span class="fu">pretty_printed_concrete_signatures</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>fn(x)
  Args:
    x: float64 Tensor, shape=()
  Returns:
    float64 Tensor, shape=()

fn(x=[1.0, -1.0])
  Returns:
    float64 Tensor, shape=(2,)

fn(x)
  Args:
    x: float64 Tensor, shape=(2,)
  Returns:
    float64 Tensor, shape=(2,)</code></pre>
</div>
</div>
</section>
</section>
<section id="using-tf_function" class="level2">
<h2 class="anchored" data-anchor-id="using-tf_function">Using <code>tf_function()</code></h2>
<p>So far, you’ve learned how to convert a Python function into a graph simply by using <code>tf_function()</code> as function wrapper. But in practice, getting <code>tf_function</code> to work correctly can be tricky! In the following sections, you’ll learn how you can make your code work as expected with <code>tf_function()</code>.</p>
<section id="graph-execution-vs.-eager-execution" class="level3">
<h3 class="anchored" data-anchor-id="graph-execution-vs.-eager-execution">Graph execution vs.&nbsp;eager execution</h3>
<p>The code in a <code>Function</code> can be executed both eagerly and as a graph. By default, <code>Function</code> executes its code as a graph:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>get_MSE <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(<span class="cf">function</span>(y_true, y_pred) {</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># if y_true and y_pred are tensors, the R generics mean`, `^`, and `-`</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># dispatch to tf$reduce_mean(), tf$math$pow(), and tf$math$subtract()</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>((y_true <span class="sc">-</span> y_pred) <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>(y_true <span class="ot">&lt;-</span> tf<span class="sc">$</span>random<span class="sc">$</span><span class="fu">uniform</span>(<span class="fu">shape</span>(<span class="dv">5</span>), <span class="at">maxval =</span> 10L, <span class="at">dtype =</span> tf<span class="sc">$</span>int32))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([5 3 4 7 6], shape=(5), dtype=int32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>(y_pred <span class="ot">&lt;-</span> tf<span class="sc">$</span>random<span class="sc">$</span><span class="fu">uniform</span>(<span class="fu">shape</span>(<span class="dv">5</span>), <span class="at">maxval =</span> 10L, <span class="at">dtype =</span> tf<span class="sc">$</span>int32))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([9 4 6 3 7], shape=(5), dtype=int32)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">get_MSE</span>(y_true, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(7, shape=(), dtype=int32)</code></pre>
</div>
</div>
<p>To verify that your <code>Function</code>’s graph is doing the same computation as its equivalent Python function, you can make it execute eagerly with <code>tf$config$run_functions_eagerly(TRUE)</code>. This is a switch that <strong>turns off <code>Function</code>’s ability to create and run graphs</strong>, instead executing the code normally.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>config<span class="sc">$</span><span class="fu">run_functions_eagerly</span>(<span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">get_MSE</span>(y_true, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(7, shape=(), dtype=int32)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Don't forget to set it back when you are done.</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>config<span class="sc">$</span><span class="fu">run_functions_eagerly</span>(<span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>However, <code>Function</code> can behave differently under graph and eager execution. The R <code>print()</code> function is one example of how these two modes differ. Let’s check out what happens when you insert a <code>print</code> statement to your function and call it repeatedly.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>get_MSE <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(<span class="cf">function</span>(y_true, y_pred) {</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">"Calculating MSE!"</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>((y_true <span class="sc">-</span> y_pred) <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  })</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Observe what is printed:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">get_MSE</span>(y_true, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Calculating MSE!"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">get_MSE</span>(y_true, y_pred)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">get_MSE</span>(y_true, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Is the output surprising? <strong><code>get_MSE</code> only printed once even though it was called <em>three</em> times.</strong></p>
<p>To explain, the <code>print</code> statement is executed when <code>Function</code> runs the original code in order to create the graph in a process known as <a href="function.qmd#tracing">“tracing”</a>. <strong>Tracing captures the TensorFlow operations into a graph, and <code>print()</code> is not captured in the graph.</strong> That graph is then executed for all three calls <strong>without ever running the R code again</strong>.</p>
<p>As a sanity check, let’s turn off graph execution to compare:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, globally set everything to run eagerly to force eager execution.</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>config<span class="sc">$</span><span class="fu">run_functions_eagerly</span>(<span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Observe what is printed below.</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">get_MSE</span>(y_true, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Calculating MSE!"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">get_MSE</span>(y_true, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Calculating MSE!"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">get_MSE</span>(y_true, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Calculating MSE!"</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>config<span class="sc">$</span><span class="fu">run_functions_eagerly</span>(<span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>print</code> is an <em>R side effect</em>, and there are other differences that you should be aware of when converting a function into a <code>Function</code>. Learn more in the <em>Limitations</em> section of the <a href="./function.qmd#limitations">Better performance with tf_function</a> guide.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note: If you would like to print values in both eager and graph execution, use <code>tf$print()</code> instead.</p>
</div>
</div>
</section>
<section id="non-strict-execution" class="level3">
<h3 class="anchored" data-anchor-id="non-strict-execution">Non-strict execution</h3>
<p>Graph execution only executes the operations necessary to produce the observable effects, which includes:</p>
<ul>
<li>The return value of the function</li>
<li>Documented well-known side-effects such as:
<ul>
<li>Input/output operations, like <code>tf$print()</code></li>
<li>Debugging operations, such as the assert functions in <code>tf$debugging()</code> (also, <code>stopifnot()</code>)</li>
<li>Mutations of <code>tf$Variable()</code></li>
</ul></li>
</ul>
<p>This behavior is usually known as “Non-strict execution”, and differs from eager execution, which steps through all of the program operations, needed or not.</p>
<p>In particular, runtime error checking does not count as an observable effect. If an operation is skipped because it is unnecessary, it cannot raise any runtime errors.</p>
<p>In the following example, the “unnecessary” operation <code>tf$gather()</code> is skipped during graph execution, so the runtime error <code>InvalidArgumentError</code> is not raised as it would be in eager execution. Do not rely on an error being raised while executing a graph.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>unused_return_eager <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># tf$gather() will fail on a CPU device if the index is out of bounds</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">device</span>(<span class="st">"CPU"</span>),</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>       tf<span class="sc">$</span><span class="fu">gather</span>(x, <span class="fu">list</span>(2L))) <span class="co"># unused</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>  x</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="fu">try</span>(<span class="fu">unused_return_eager</span>(<span class="fu">as_tensor</span>(<span class="dv">0</span>, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">1</span>))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Error in py_call_impl(callable, dots$args, dots$keywords) : 
  tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 2 is not in [0, 1) [Op:GatherV2]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># All operations are run during eager execution so an error is raised.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>unused_return_graph <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(<span class="cf">function</span>(x) {</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">device</span>(<span class="st">"CPU"</span>),</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>       tf<span class="sc">$</span><span class="fu">gather</span>(x, <span class="fu">list</span>(2L))) <span class="co"># unused</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>  x</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Only needed operations are run during graph exection. The error is not raised.</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="fu">unused_return_graph</span>(<span class="fu">as_tensor</span>(<span class="dv">0</span>, <span class="at">shape =</span> <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([0.], shape=(1), dtype=float64)</code></pre>
</div>
</div>
</section>
<section id="tf_function-best-practices" class="level3">
<h3 class="anchored" data-anchor-id="tf_function-best-practices"><code>tf_function()</code> best practices</h3>
<p>It may take some time to get used to the behavior of <code>Function</code>. To get started quickly, first-time users should play around with wrapping toy functions with <code>tf_function()</code> to get experience with going from eager to graph execution.</p>
<p><em>Designing for <code>tf_function</code></em> may be your best bet for writing graph-compatible TensorFlow programs. Here are some tips:</p>
<ul>
<li><p>Toggle between eager and graph execution early and often with <code>tf$config$run_functions_eagerly()</code> to pinpoint if/when the two modes diverge.</p></li>
<li><p>Create <code>tf$Variable</code>s outside the Python function and modify them on the inside. The same goes for objects that use <code>tf$Variable</code>, like <code>keras$layers</code>, <code>keras$Model</code>s and <code>tf$optimizers</code>.</p></li>
<li><p>Avoid writing functions that <a href="function#depending_on_python_global_and_free_variables">depend on outer Python variables</a>, excluding <code>tf$Variable</code>s and Keras objects.</p></li>
<li><p>Prefer to write functions which take tensors and other TensorFlow types as input. You can pass in other object types but <a href="function#depending_on_python_objects">be careful</a>!</p></li>
<li><p>Include as much computation as possible under a <code>tf_function</code> to maximize the performance gain. For example, wrap a whole training step or the entire training loop.</p></li>
</ul>
</section>
</section>
<section id="seeing-the-speed-up" class="level2">
<h2 class="anchored" data-anchor-id="seeing-the-speed-up">Seeing the speed-up</h2>
<p><code>tf_function</code> usually improves the performance of your code, but the amount of speed-up depends on the kind of computation you run. Small computations can be dominated by the overhead of calling a graph. You can measure the difference in performance like so:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> tf<span class="sc">$</span>random<span class="sc">$</span><span class="fu">uniform</span>(<span class="fu">shape</span>(<span class="dv">10</span>, <span class="dv">10</span>),</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">minval =</span> <span class="sc">-</span>1L, <span class="at">maxval =</span> 2L,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">dtype =</span> tf<span class="sc">$</span>dtypes<span class="sc">$</span>int32)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) {</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">eye</span>(10L, <span class="at">dtype =</span> tf<span class="sc">$</span>dtypes<span class="sc">$</span>int32)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (. <span class="cf">in</span> <span class="fu">seq_len</span>(y))</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>    result <span class="ot">&lt;-</span> tf<span class="sc">$</span><span class="fu">matmul</span>(x, result)</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>  result</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>power_as_graph <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(power)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bench<span class="sc">::</span><span class="fu">mark</span>(</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Eager execution"</span> <span class="ot">=</span> <span class="fu">power</span>(x, <span class="dv">100</span>),</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Graph execution"</span> <span class="ot">=</span> <span class="fu">power_as_graph</span>(x, <span class="dv">100</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required namespace: tidyr</code></pre>
</div>
<div class="cell-output-display">
<p><img src="intro_to_graphs_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><code>tf_function</code> is commonly used to speed up training loops, and you can learn more about it in <a href="https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch#speeding-up_your_training_step_with_tffunction">Writing a training loop from scratch</a> with Keras.</p>
<p>Note: You can also try <a href="https://www.tensorflow.org/xla#explicit_compilation_with_tffunctionjit_compiletrue"><code>tf_function(jit_compile = TRUE)</code></a> for a more significant performance boost, especially if your code is heavy on TF control flow and uses many small tensors.</p>
<section id="performance-and-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="performance-and-trade-offs">Performance and trade-offs</h3>
<p>Graphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. <strong>This investment is usually quickly paid back with the performance boost of subsequent executions, but it’s important to be aware that the first few steps of any large model training can be slower due to tracing.</strong></p>
<p>No matter how large your model, you want to avoid tracing frequently. The <code>tf_function()</code> guide discusses <a href="function#controlling_retracing">how to set input specifications and use tensor arguments</a> to avoid retracing. If you find you are getting unusually poor performance, it’s a good idea to check if you are retracing accidentally.</p>
</section>
</section>
<section id="when-is-a-function-tracing" class="level2">
<h2 class="anchored" data-anchor-id="when-is-a-function-tracing">When is a <code>Function</code> tracing?</h2>
<p>To figure out when your <code>Function</code> is tracing, add a <code>print</code> or <code>message()</code> statement to its code. As a rule of thumb, <code>Function</code> will execute the <code>message</code> statement every time it traces.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>a_function_with_r_side_effect <span class="ot">&lt;-</span> <span class="fu">tf_function</span>(<span class="cf">function</span>(x) {</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">message</span>(<span class="st">"Tracing!"</span>) <span class="co"># An eager-only side effect.</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>  (x <span class="sc">*</span> x) <span class="sc">+</span> <span class="dv">2</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co"># This is traced the first time.</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="fu">a_function_with_r_side_effect</span>(<span class="fu">as_tensor</span>(<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Tracing!</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(6.0, shape=(), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The second time through, you won't see the side effect.</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">a_function_with_r_side_effect</span>(<span class="fu">as_tensor</span>(<span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(11.0, shape=(), dtype=float64)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This retraces each time the Python argument changes,</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="co"># as a Python argument could be an epoch count or other</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co"># hyperparameter.</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="fu">a_function_with_r_side_effect</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Tracing!</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(6.0, shape=(), dtype=float32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">a_function_with_r_side_effect</span>(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Tracing!</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(11.0, shape=(), dtype=float32)</code></pre>
</div>
</div>
<p>New (non-tensor) R arguments always trigger the creation of a new graph, hence the extra tracing.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps</h2>
<p>You can learn more about <code>tf_function()</code> on the API reference page and by following the <a href="function.qmd">Better performance with <code>tf_function</code></a> guide.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../tensorflow/guide/autodiff.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Automatic differentiation</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../keras/guides/sequential_model.html" class="pagination-link">
        <span class="nav-page-text">The Sequential model</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>