[
  {
    "objectID": "deploy/docker.html",
    "href": "deploy/docker.html",
    "title": "Deploying a TensorFlow model using TensorFlow serving",
    "section": "",
    "text": "In this tutorial you will learn how to deploy a TensorFlow model using TensorFlow serving.\nWe will use the Docker container provided by the TensorFlow organization to deploy a model that classifies images of handwritten digits.\nUsing the Docker container is a an easy way to test the API locally and then deploy it to any cloud provider."
  },
  {
    "objectID": "deploy/docker.html#building-the-model",
    "href": "deploy/docker.html#building-the-model",
    "title": "Deploying a TensorFlow model using TensorFlow serving",
    "section": "Building the model",
    "text": "Building the model\nThe first thing we are going to do is to build our model. We will use the Keras API to build this model.\nWe will use the MNIST dataset to build our model.\n\nlibrary(keras)\n\nWarning: package 'keras' was built under R version 4.1.2\n\nlibrary(tensorflow)\n\nWarning: package 'tensorflow' was built under R version 4.1.2\n\nmnist <- dataset_mnist()\n\nLoaded Tensorflow version 2.9.1\n\nmnist$train$x <- (mnist$train$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nmnist$test$x <- (mnist$test$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nNow, we are going to define our Keras model, it will be a simple convolutional neural network.\n\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nmodel %>% \n  compile(\n    loss = \"sparse_categorical_crossentropy\",\n    optimizer = \"adam\",\n    metrics = \"accuracy\"\n  )\n\nNext, we fit the model using the MNIST dataset:\n\nmodel %>% \n  fit(\n    x = mnist$train$x, y = mnist$train$y,\n    batch_size = 32,\n    epochs = 5,\n    validation_sample = 0.2,\n    verbose = 2\n  )\n\nWhen we are happy with our model accuracy in the validation dataset we can evaluate the results on the test dataset with:\n\nmodel %>% evaluate(x = mnist$test$x, y = mnist$test$y)\n\n      loss   accuracy \n0.03585155 0.98879999 \n\n\nOK, we have 99% accuracy on the test dataset and we want to deploy that model. First, let’s save the model in the SavedModel format using:\n\nsave_model_tf(model, \"cnn-mnist\")\n\nWith the model built and saved we can now start building our plumber API file."
  },
  {
    "objectID": "deploy/docker.html#running-locally",
    "href": "deploy/docker.html#running-locally",
    "title": "Deploying a TensorFlow model using TensorFlow serving",
    "section": "Running locally",
    "text": "Running locally\nYou can run the tensorflow/serving Docker image locally using the great stevedore package. For example:\n\ndocker <- stevedore::docker_client()\ncontainer <- docker$container$run(\n  image = \"tensorflow/serving\", # name of the image\n  \n  # host port and docker port - if you set 4000:8501, the API \n  # will be accecible in localhost:4000\n  port = \"8501:8501\", \n  \n  # a string path/to/the/saved/model/locally:models/modelname/version\n  # you must put the model file in the /models/ folder.\n  volume = paste0(normalizePath(\"cnn-mnist\"), \":/models/model/1\"), \n  \n  # the name of the model - it's the name of the folder inside `/models`\n  # above.\n  env = c(\"MODEL_NAME\" = \"model\"),\n  \n  # to run the container detached\n  detach = TRUE\n)\n\nNow we have initialized the container serving the model. You can see the container logs with:\n\ncontainer$logs()\n\nNow you can make POST requests no the following endpoint : http://localhost:8501/v1/models/model/versions/1:predict. The input data must be passed in a special format 0 - see the format definition here, which may seem unnatural for R users. Here is an example:\n\ninstances <- purrr::array_tree(mnist$test$x[1:5,,,,drop=FALSE]) %>% \n  purrr::map(~list(input_1 = .x))\ninstances <- list(instances = instances)\n\nreq <- httr::POST(\n  \"http://localhost:8501/v1/models/model/versions/1:predict\", \n  body = instances, \n  encode = \"json\"\n)\nhttr::content(req)\n\nThis is how you can serve TensorFlow models with TF serving locally. Additionaly, we can deploy this to multiple clouds. In the next section we will show how it can be deployed to Google Cloud.\nWhen done, you can stop the container with:\n\ncontainer$stop()"
  },
  {
    "objectID": "deploy/docker.html#deploying-to-google-cloud-run",
    "href": "deploy/docker.html#deploying-to-google-cloud-run",
    "title": "Deploying a TensorFlow model using TensorFlow serving",
    "section": "Deploying to Google Cloud Run",
    "text": "Deploying to Google Cloud Run\nTHe first thing you need to do is to follow the section Before you begin in this page.\nNow let’s create a Dockerfile that will copy the SavedModel to the container image. We assume in this section some experience with Docker.\nHere’s an example - create a file called Dockerfile in the same root folder as your SavedModel and paste the following:\nFROM tensorflow/serving\nCOPY cnn-mnist /models/model/1\nENTRYPOINT [\"/usr/bin/tf_serving_entrypoint.sh\", \"--rest_api_port=8080\"]\nWe need to run the rest service in the 8080 port. The only that is open by Google Cloud Run. Now you can build this image and send it to gcr.io. Run the following in your terminal:\ndocker build -t gcr.io/PROJECT-ID/cnn-mnist .\ndocker push gcr.io/PROJECT-ID/cnn-mnist\nYou can get your PROJECT-ID by running:\ngcloud config get-value project\nNext, we can create the service in Google Cloud Run using:\ngcloud run deploy --image gcr.io/rstudio-162821/cnn-mnist --platform managed\nYou will be prompted to select a region, a name for the service and wether you allow unauthorized requests. If everything works correctly you will get a url like https://cnn-mnist-ld4lzfalyq-ue.a.run.app which you can now use to make requests to your model. For example:\n\nreq <- httr::POST(\n  \"https://cnn-mnist-ld4lzfalyq-ue.a.run.app/v1/models/model/versions/1:predict\", \n  body = instances, \n  encode = \"json\"\n)\nhttr::content(req)\n\nNote that in this case, all pre-processing must be done in R before sending the data to the API."
  },
  {
    "objectID": "deploy/index.html",
    "href": "deploy/index.html",
    "title": "Overview",
    "section": "",
    "text": "Plumber API: Create a REST API using Plumber to deploy your TensorFlow model. With Plumber you will still depend on having an R runtime which be useful when you want to make the data pre-processing in R.\nShiny: Create a Shiny app that uses a TensorFlow model to generate outputs.\nTensorFlow Serving: This is the most performant way of deploying TensorFlow models since it’s based only inn the TensorFlow serving C++ server. With TF serving you don’t depend on an R runtime, so all pre-processing must be done in the TensorFlow graph.\nRStudio Connect: RStudio Connect makes it easy to deploy TensorFlow models and uses TensorFlow serving in the backend.\n\nThere are many other options to deploy TensorFlow models built with R that are not covered in this section. For example:\n\nDeploy it using a Python runtime.\nDeploy using a JavaScript runtime.\nDeploy to a mobile phone app using TensorFlow Lite.\nDeploy to a iOS app using Apple’s Core ML tool.\nUse plumber and Docker to deploy your TensorFlow model (by T-Mobile)."
  },
  {
    "objectID": "deploy/plumber.html",
    "href": "deploy/plumber.html",
    "title": "Deploying a TensorFlow API with Plumber",
    "section": "",
    "text": "In this tutorial you will learn how to deploy a TensorFlow model using a plumber API.\nIn this example we will build an endpoint that takes POST requests sending images containing handwritten digits and returning the predicted number."
  },
  {
    "objectID": "deploy/plumber.html#building-the-model",
    "href": "deploy/plumber.html#building-the-model",
    "title": "Deploying a TensorFlow API with Plumber",
    "section": "Building the model",
    "text": "Building the model\nThe first thing we are going to do is to build our model. W We will use the Keras API to build this model.\nWe will use the MNIST dataset to build our model.\n\nlibrary(keras)\n\nWarning: package 'keras' was built under R version 4.1.2\n\nlibrary(tensorflow)\n\nWarning: package 'tensorflow' was built under R version 4.1.2\n\nmnist <- dataset_mnist()\n\nLoaded Tensorflow version 2.9.1\n\nmnist$train$x <- (mnist$train$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nmnist$test$x <- (mnist$test$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nNow, we are going to define our Keras model, it will be a simple convolutional neural network.\n\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nmodel %>% \n  compile(\n    loss = \"sparse_categorical_crossentropy\",\n    optimizer = \"adam\",\n    metrics = \"accuracy\"\n  )\n\nNext, we fit the model using the MNIST dataset:\n\nmodel %>% \n  fit(\n    x = mnist$train$x, y = mnist$train$y,\n    batch_size = 32,\n    epochs = 5,\n    validation_sample = 0.2,\n    verbose = 2\n  )\n\nWhen we are happy with our model accuracy in the validation dataset we can evaluate the results on the test dataset with:\n\nmodel %>% evaluate(x = mnist$test$x, y = mnist$test$y)\n\n      loss   accuracy \n0.02827194 0.99059999 \n\n\nOK, we have 99% accuracy on the test dataset and we want to deploy that model. First, let’s save the model in the SavedModel format using:\n\nsave_model_tf(model, \"cnn-mnist\")\n\nWith the model built and saved we can now start building our plumber API file."
  },
  {
    "objectID": "deploy/plumber.html#plumber-api",
    "href": "deploy/plumber.html#plumber-api",
    "title": "Deploying a TensorFlow API with Plumber",
    "section": "Plumber API",
    "text": "Plumber API\nA plumber API is defined by a .R file with a few annotations. Here’s is how we can write our api.R file:\n\nlibrary(keras)\n\nmodel <- load_model_tf(\"cnn-mnist/\")\n\n#* Predicts the number in an image\n#* @param enc a base64  encoded 28x28 image\n#* @post /cnn-mnist\nfunction(enc) {\n  # decode and read the jpeg image\n  img <- jpeg::readJPEG(source = base64enc::base64decode(enc))\n  \n  # reshape\n  img <- img %>% \n    array_reshape(., dim = c(1, dim(.), 1))\n  \n  # make the prediction\n  predict_classes(model, img)\n}\n\nMake sure to have the your SavedModel in the same folder as api.R and call:\n\np <- plumber::plumb(\"api.R\")\np$run(port = 8000)\n\nYou can now make requests to the http://lcoalhost:8000/cnn-minist/ endpoint. For example, let’s verify we can make a POST request to the API sending the first image from the test set:\n\nimg <- mnist$test$x[1,,,]\nmnist$test$y[1]\n\n[1] 7\n\n\nFirst let’s encode the image:\n\nencoded_img <- img %>% \n  jpeg::writeJPEG() %>% \n  base64enc::base64encode()\nencoded_img\n\n[1] \"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APHIYJbmZYYInllc4VEUszH2A6064tbi0k8q5glgcfwyIVP5GoqKsWGoXel3sd7YXD29zESUljOGXIwf0JrpLf4o+MLeNUbVftAU5BuIUlPTplhn/wDVXQ+PNcvk8D6bpmtPbz6vqDi9lCwqhtocYRRtHU8k9+orzKius8CeHrS/nutd1pWGiaQnm3GBnznyNsQ+p/w4zWL4h1u48Ra7d6rcDa1w+VQdEUcKo+gAFZtFbsfjDVIPB7+FoRBHYyymWVlT95JyDgknGMgdADx1rCor/9k=\"\n\n\n\nreq <- httr::POST(\"http://localhost:8000/cnn-mnist\",\n           body = list(enc = encoded_img), \n           encode = \"json\")\nhttr::content(req)\n\n[[1]]\n[1] 7\nYou can also access the Swagger interface by accessing http://127.0.0.1:8000/swagger/ and paste the encoded string in the UI to visualize the result."
  },
  {
    "objectID": "deploy/plumber.html#more-advanced-models",
    "href": "deploy/plumber.html#more-advanced-models",
    "title": "Deploying a TensorFlow API with Plumber",
    "section": "More advanced models",
    "text": "More advanced models\nWhen building more advanced models you may not be able to save the entire model using the save_model_tf function. In this case you can use the save_model_weights_tf function.\nFor example:\n\nsave_model_weights_tf(model, \" cnn-model-weights\")\n\nThen, in the api.R file whenn loading the model you will need to rebuild the model using the exact same code that you used when training and saving and then use load_model_weights_tf to load the model weights.\n\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nload_model_weights_tf(model, \"cnn-model-weights\")"
  },
  {
    "objectID": "deploy/plumber.html#hosting-the-plumber-api",
    "href": "deploy/plumber.html#hosting-the-plumber-api",
    "title": "Deploying a TensorFlow API with Plumber",
    "section": "Hosting the plumber API",
    "text": "Hosting the plumber API\nPlumber is very flexible and allows multiple hosting options. See the plumber Hostinng documentation for more information."
  },
  {
    "objectID": "deploy/rsconnect.html",
    "href": "deploy/rsconnect.html",
    "title": "Deploying a TensorFlow Model to RStudio Connect",
    "section": "",
    "text": "In this tutorial you will learn how to deploy a TensorFlow model to RStudio Connect. RStudio Connect uses TensorFlow Serving for performance but makes it much easier for R users to manage their deployment."
  },
  {
    "objectID": "deploy/rsconnect.html#building-the-model",
    "href": "deploy/rsconnect.html#building-the-model",
    "title": "Deploying a TensorFlow Model to RStudio Connect",
    "section": "Building the model",
    "text": "Building the model\nThe first thing we are going to do is to build our model. We will use the Keras API to build this model.\nWe will use the MNIST dataset to build our model.\n\nlibrary(keras)\n\nWarning: package 'keras' was built under R version 4.1.2\n\nlibrary(tensorflow)\n\nWarning: package 'tensorflow' was built under R version 4.1.2\n\nmnist <- dataset_mnist()\n\nLoaded Tensorflow version 2.9.1\n\nmnist$train$x <- (mnist$train$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nmnist$test$x <- (mnist$test$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nNow, we are going to define our Keras model, it will be a simple convolutional neural network.\n\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nmodel %>% \n  compile(\n    loss = \"sparse_categorical_crossentropy\",\n    optimizer = \"adam\",\n    metrics = \"accuracy\"\n  )\n\nNext, we fit the model using the MNIST dataset:\n\nmodel %>% \n  fit(\n    x = mnist$train$x, y = mnist$train$y,\n    batch_size = 32,\n    epochs = 5,\n    validation_sample = 0.2,\n    verbose = 2\n  )\n\nWhen we are happy with our model accuracy in the validation dataset we can evaluate the results on the test dataset with:\n\nmodel %>% evaluate(x = mnist$test$x, y = mnist$test$y, verbose = 0)\n\n      loss   accuracy \n0.03402501 0.98860002 \n\n\nOK, we have 99% accuracy on the test dataset and we want to deploy that model. First, let’s save the model in the SavedModel format using:\n\nsave_model_tf(model, \"cnn-mnist\")\n\nWith the model built and saved we can now start building our plumber API file."
  },
  {
    "objectID": "deploy/rsconnect.html#deployiong-to-rstudio-connect",
    "href": "deploy/rsconnect.html#deployiong-to-rstudio-connect",
    "title": "Deploying a TensorFlow Model to RStudio Connect",
    "section": "Deployiong to RStudio Connect",
    "text": "Deployiong to RStudio Connect\nOnce the model is saved to the SavedModel format, the model can be deployed with a single line of code:\n\nrsconnect::deployTFModel(\"cnn-mnist/\")\n\nWhen the deployment is complete you will be redirected to your browser with some instructions on how to call the REST endpoint:"
  },
  {
    "objectID": "deploy/shiny.html",
    "href": "deploy/shiny.html",
    "title": "Deploying a Shiny app with a TensorFlow model",
    "section": "",
    "text": "In this tutorial you will learn how to deploy a TensorFlow model inside a Shiny app. We will build a model that can classify handwritten digits in images, then we will build a Shiny app that let’s you upload an image and get predictions from this model."
  },
  {
    "objectID": "deploy/shiny.html#building-the-model",
    "href": "deploy/shiny.html#building-the-model",
    "title": "Deploying a Shiny app with a TensorFlow model",
    "section": "Building the model",
    "text": "Building the model\nThe first thing we are going to do is to build our model. We will use the Keras API to build this model.\nWe will use the MNIST dataset to build our model.\n\nlibrary(keras)\n\nWarning: package 'keras' was built under R version 4.1.2\n\nlibrary(tensorflow)\n\nWarning: package 'tensorflow' was built under R version 4.1.2\n\nmnist <- dataset_mnist()\n\nLoaded Tensorflow version 2.9.1\n\nmnist$train$x <- (mnist$train$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nmnist$test$x <- (mnist$test$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nNow, we are going to define our Keras model, it will be a simple convolutional neural network.\n\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nmodel %>% \n  compile(\n    loss = \"sparse_categorical_crossentropy\",\n    optimizer = \"adam\",\n    metrics = \"accuracy\"\n  )\n\nNext, we fit the model using the MNIST dataset:\n\nmodel %>% \n  fit(\n    x = mnist$train$x, y = mnist$train$y,\n    batch_size = 32,\n    epochs = 5,\n    validation_sample = 0.2,\n    verbose = 2\n  )\n\nWhen we are happy with our model accuracy in the validation dataset we can evaluate the results on the test dataset with:\n\nmodel %>% evaluate(x = mnist$test$x, y = mnist$test$y)\n\n      loss   accuracy \n0.03422958 0.98920000 \n\n\nOK, we have 99% accuracy on the test dataset and we want to deploy that model. First, let’s save the model in the SavedModel format using:\n\nsave_model_tf(model, \"cnn-mnist\")\n\nWith the model built and saved we can now start building our plumber API file."
  },
  {
    "objectID": "deploy/shiny.html#shiny-app",
    "href": "deploy/shiny.html#shiny-app",
    "title": "Deploying a Shiny app with a TensorFlow model",
    "section": "Shiny app",
    "text": "Shiny app\nA simple shiny app can be define in an app.R file with a few conventions. Here’s how we can structure our Shiny app.\n\nlibrary(shiny)\nlibrary(keras)\n\n# Load the model\nmodel <- load_model_tf(\"cnn-mnist/\")\n\n# Define the UI\nui <- fluidPage(\n  # App title ----\n  titlePanel(\"Hello TensorFlow!\"),\n  # Sidebar layout with input and output definitions ----\n  sidebarLayout(\n    # Sidebar panel for inputs ----\n    sidebarPanel(\n      # Input: File upload\n      fileInput(\"image_path\", label = \"Input a JPEG image\")\n    ),\n    # Main panel for displaying outputs ----\n    mainPanel(\n      # Output: Histogram ----\n      textOutput(outputId = \"prediction\"),\n      plotOutput(outputId = \"image\")\n    )\n  )\n)\n\n# Define server logic required to draw a histogram ----\nserver <- function(input, output) {\n  \n  image <- reactive({\n    req(input$image_path)\n    jpeg::readJPEG(input$image_path$datapath)\n  })\n  \n  output$prediction <- renderText({\n    \n    img <- image() %>% \n      array_reshape(., dim = c(1, dim(.), 1))\n    \n    paste0(\"The predicted class number is \", predict_classes(model, img))\n  })\n  \n  output$image <- renderPlot({\n    plot(as.raster(image()))\n  })\n  \n}\n\nshinyApp(ui, server)\n\nThis app can be used locally or deployed using any Shiny deployment option. If you are deploying to RStudio Connect or Shinnyapps.io, don’t forget to set the RETICULATE_PYTHON environment variable so rsconnect can detect what python packages are required to reproduce your local environment. See the F.A.Q. for more information.\n\nYou can see a live version of this app here. Note that to keep the code simple, it will only accept JPEG images with 28x28 pixels. You can download this file if you want to try the app."
  },
  {
    "objectID": "deploy/shiny.html#more-advanced-models",
    "href": "deploy/shiny.html#more-advanced-models",
    "title": "Deploying a Shiny app with a TensorFlow model",
    "section": "More advanced models",
    "text": "More advanced models\nWhen building more advanced models you may not be able to save the entire model using the save_model_tf function. In this case you can use the save_model_weights_tf function.\nFor example:\n\nsave_model_weights_tf(model, \" cnn-model-weights\")\n\nThen, in the api.R file whenn loading the model you will need to rebuild the model using the exact same code that you used when training and saving and then use load_model_weights_tf to load the model weights.\n\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nload_model_weights_tf(model, \"cnn-model-weights\")"
  },
  {
    "objectID": "deploy/shiny.html#hosting-the-shiny-app",
    "href": "deploy/shiny.html#hosting-the-shiny-app",
    "title": "Deploying a Shiny app with a TensorFlow model",
    "section": "Hosting the shiny app",
    "text": "Hosting the shiny app\nThis Shiny app can be hosted in any server using the Shiny Server. If you are managing the complete infrastructure, make sure that you have Python and all required Python packages installed in the server.\nIf you are using Shinyapps.io or RStudio Connect the dependencies will be infered when deploying the app. In this case, don’t forget to set the RETICULATE_PYTHON environment variable.\nYou can find more examples of using reticulate in RStudio products here and learn more about Python in RStudio Connect best practices here."
  },
  {
    "objectID": "examples/addition_rnn.html",
    "href": "examples/addition_rnn.html",
    "title": "Sequence to sequence learning for performing number addition",
    "section": "",
    "text": "Input: “535+61”\nOutput: “596”\nPadding is handled by using a repeated sentinel character (space)\nInput may optionally be reversed, shown to increase performance in many tasks in: “Learning to Execute” http://arxiv.org/abs/1410.4615 and “Sequence to Sequence Learning with Neural Networks” http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf Theoretically it introduces shorter term dependencies between source and target.\nTwo digits reversed: One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\nThree digits reversed: One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\nFour digits reversed: One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\nFive digits reversed: One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n\nlibrary(keras)\nlibrary(stringi)\n\n# Function Definitions ----------------------------------------------------\n\n# Creates the char table and sorts them.\nlearn_encoding <- function(chars){\n  sort(chars)\n}\n\n# Encode from a character sequence to a one hot integer representation.\n# > encode(\"22+22\", char_table)\n# [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n# 2    0    0    0    0    1    0    0    0    0     0     0     0\n# 2    0    0    0    0    1    0    0    0    0     0     0     0\n# +    0    1    0    0    0    0    0    0    0     0     0     0\n# 2    0    0    0    0    1    0    0    0    0     0     0     0\n# 2    0    0    0    0    1    0    0    0    0     0     0     0\nencode <- function(char, char_table){\n  strsplit(char, \"\") %>%\n    unlist() %>%\n    sapply(function(x){\n      as.numeric(x == char_table)\n    }) %>% \n    t()\n}\n\n# Decode the one hot representation/probabilities representation\n# to their character output.\ndecode <- function(x, char_table){\n  apply(x,1, function(y){\n    char_table[which.max(y)]\n  }) %>% paste0(collapse = \"\")\n}\n\n# Returns a list of questions and expected answers.\ngenerate_data <- function(size, digits, invert = TRUE){\n  \n  max_num <- as.integer(paste0(rep(9, digits), collapse = \"\"))\n  \n  # generate integers for both sides of question\n  x <- sample(1:max_num, size = size, replace = TRUE)\n  y <- sample(1:max_num, size = size, replace = TRUE)\n  \n  # make left side always smaller than right side\n  left_side <- ifelse(x <= y, x, y)\n  right_side <- ifelse(x >= y, x, y)\n  \n  results <- left_side + right_side\n  \n  # pad with spaces on the right\n  questions <- paste0(left_side, \"+\", right_side)\n  questions <- stri_pad(questions, width = 2*digits+1, \n                        side = \"right\", pad = \" \")\n  if(invert){\n    questions <- stri_reverse(questions)\n  }\n  # pad with spaces on the left\n  results <- stri_pad(results, width = digits + 1, \n                      side = \"left\", pad = \" \")\n  \n  list(\n    questions = questions,\n    results = results\n  )\n}\n\n# Parameters --------------------------------------------------------------\n\n# Parameters for the model and dataset\nTRAINING_SIZE <- 50000\nDIGITS <- 2\n\n# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n# int is DIGITS\nMAXLEN <- DIGITS + 1 + DIGITS\n\n# All the numbers, plus sign and space for padding\ncharset <- c(0:9, \"+\", \" \")\nchar_table <- learn_encoding(charset)\n\n\n# Data Preparation --------------------------------------------------------\n\n# Generate Data\nexamples <- generate_data(size = TRAINING_SIZE, digits = DIGITS)\n\n# Vectorization\nx <- array(0, dim = c(length(examples$questions), MAXLEN, length(char_table)))\ny <- array(0, dim = c(length(examples$questions), DIGITS + 1, length(char_table)))\n\nfor(i in 1:TRAINING_SIZE){\n  x[i,,] <- encode(examples$questions[i], char_table)\n  y[i,,] <- encode(examples$results[i], char_table)\n}\n\n# Shuffle\nindices <- sample(1:TRAINING_SIZE, size = TRAINING_SIZE)\nx <- x[indices,,]\ny <- y[indices,,]\n\n\n# Explicitly set apart 10% for validation data that we never train over\nsplit_at <- trunc(TRAINING_SIZE/10)\nx_val <- x[1:split_at,,]\ny_val <- y[1:split_at,,]\nx_train <- x[(split_at + 1):TRAINING_SIZE,,]\ny_train <- y[(split_at + 1):TRAINING_SIZE,,]\n\nprint('Training Data:')\n\n[1] \"Training Data:\"\n\nprint(dim(x_train))\n\n[1] 45000     5    12\n\nprint(dim(y_train))\n\n[1] 45000     3    12\n\nprint('Validation Data:')\n\n[1] \"Validation Data:\"\n\nprint(dim(x_val))\n\n[1] 5000    5   12\n\nprint(dim(y_val))\n\n[1] 5000    3   12\n\n# Training ----------------------------------------------------------------\n\nHIDDEN_SIZE <- 128\nBATCH_SIZE <- 128\nLAYERS <- 1\n\n# Initialize sequential model\nmodel <- keras_model_sequential() \n\nLoaded Tensorflow version 2.9.1\n\nmodel %>%\n  # \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n  # Note: In a situation where your input sequences have a variable length,\n  # use input_shape=(None, num_feature).\n  layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%\n  # As the decoder RNN's input, repeatedly provide with the last hidden state of\n  # RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n  # length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n  layer_repeat_vector(DIGITS + 1)\n\n# The decoder RNN could be multiple layers stacked or a single layer.\n# By setting return_sequences to True, return not only the last output but\n# all the outputs so far in the form of (num_samples, timesteps,\n# output_dim). This is necessary as TimeDistributed in the below expects\n# the first dimension to be the timesteps.\nfor(i in 1:LAYERS)\n  model %>% layer_lstm(HIDDEN_SIZE, return_sequences = TRUE)\n\nmodel %>% \n  # Apply a dense layer to the every temporal slice of an input. For each of step\n  # of the output sequence, decide which character should be chosen.\n  time_distributed(layer_dense(units = length(char_table))) %>%\n  layer_activation(\"softmax\")\n\n# Compiling the model\nmodel %>% compile(\n  loss = \"categorical_crossentropy\", \n  optimizer = \"adam\", \n  metrics = \"accuracy\"\n)\n\n# Get the model summary\nsummary(model)\n\nModel: \"sequential\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n lstm (LSTM)                      (None, 128)                   72192       \n repeat_vector (RepeatVector)     (None, 3, 128)                0           \n lstm_1 (LSTM)                    (None, 3, 128)                131584      \n time_distributed (TimeDistribute  (None, 3, 12)                1548        \n d)                                                                         \n activation (Activation)          (None, 3, 12)                 0           \n============================================================================\nTotal params: 205,324\nTrainable params: 205,324\nNon-trainable params: 0\n____________________________________________________________________________\n\n# Fitting loop\nmodel %>% fit( \n  x = x_train, \n  y = y_train, \n  batch_size = BATCH_SIZE, \n  epochs = 70,\n  validation_data = list(x_val, y_val)\n)\n\n# Predict for a new observation\nnew_obs <- encode(\"55+22\", char_table) %>%\n  array(dim = c(1,5,12))\nresult <- predict(model, new_obs)\nresult <- result[1,,]\ndecode(result, char_table)\n\n[1] \" 77\""
  },
  {
    "objectID": "examples/babi_memnn.html",
    "href": "examples/babi_memnn.html",
    "title": "Trains a memory network on the bAbI dataset",
    "section": "",
    "text": "References:\n\nJason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush, “Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks”, http://arxiv.org/abs/1502.05698\nSainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus, “End-To-End Memory Networks”, http://arxiv.org/abs/1503.08895\n\nReaches 98.6% accuracy on task ‘single_supporting_fact_10k’ after 120 epochs. Time per epoch: 3s on CPU (core i7).\n\nlibrary(keras)\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.1.2\n\nlibrary(stringr)\nlibrary(purrr)\nlibrary(tibble)\n\nWarning: package 'tibble' was built under R version 4.1.2\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Function definition -----------------------------------------------------\n\ntokenize_words <- function(x){\n  x <- x %>% \n    str_replace_all('([[:punct:]]+)', ' \\\\1') %>% \n    str_split(' ') %>%\n    unlist()\n  x[x != \"\"]\n}\n\nparse_stories <- function(lines, only_supporting = FALSE){\n  lines <- lines %>% \n    str_split(\" \", n = 2) %>%\n    map_dfr(~tibble(nid = as.integer(.x[[1]]), line = .x[[2]]))\n  \n  lines <- lines %>%\n    mutate(\n      split = map(line, ~str_split(.x, \"\\t\")[[1]]),\n      q = map_chr(split, ~.x[1]),\n      a = map_chr(split, ~.x[2]),\n      supporting = map(split, ~.x[3] %>% str_split(\" \") %>% unlist() %>% as.integer()),\n      story_id = c(0, cumsum(nid[-nrow(.)] > nid[-1]))\n    ) %>%\n    select(-split)\n  \n  stories <- lines %>%\n    filter(is.na(a)) %>%\n    select(nid_story = nid, story_id, story = q)\n  \n  questions <- lines %>%\n    filter(!is.na(a)) %>%\n    select(-line) %>%\n    left_join(stories, by = \"story_id\") %>%\n    filter(nid_story < nid)\n  \n  if(only_supporting){\n    questions <- questions %>%\n      filter(map2_lgl(nid_story, supporting, ~.x %in% .y))\n  }\n  \n  questions %>%\n    group_by(story_id, nid, question = q, answer = a) %>%\n    summarise(story = paste(story, collapse = \" \")) %>%\n    ungroup() %>% \n    mutate(\n      question = map(question, ~tokenize_words(.x)),\n      story = map(story, ~tokenize_words(.x)),\n      id = row_number()\n    ) %>%\n    select(id, question, answer, story)\n}\n\nvectorize_stories <- function(data, vocab, story_maxlen, query_maxlen){\n  \n  questions <- map(data$question, function(x){\n    map_int(x, ~which(.x == vocab))\n  })\n  \n  stories <- map(data$story, function(x){\n    map_int(x, ~which(.x == vocab))\n  })\n  \n  # \"\" represents padding\n  answers <- sapply(c(\"\", vocab), function(x){\n    as.integer(x == data$answer)\n  })\n  \n  list(\n    questions = pad_sequences(questions, maxlen = query_maxlen),\n    stories   = pad_sequences(stories, maxlen = story_maxlen),\n    answers   = answers\n  )\n}\n\n\n# Parameters --------------------------------------------------------------\n\nchallenges <- list(\n  # QA1 with 10,000 samples\n  single_supporting_fact_10k = \"%stasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_%s.txt\",\n  # QA2 with 10,000 samples\n  two_supporting_facts_10k = \"%stasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_%s.txt\"\n)\n\nchallenge_type <- \"single_supporting_fact_10k\"\nchallenge <- challenges[[challenge_type]]\nmax_length <- 999999\n\n\n# Data Preparation --------------------------------------------------------\n\n# Download data\npath <- get_file(\n  fname = \"babi-tasks-v1-2.tar.gz\",\n  origin = \"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\"\n)\n\nLoaded Tensorflow version 2.9.1\n\nuntar(path, exdir = str_replace(path, fixed(\".tar.gz\"), \"/\"))\npath <- str_replace(path, fixed(\".tar.gz\"), \"/\")\n\n# Reading training and test data\ntrain <- read_lines(sprintf(challenge, path, \"train\")) %>%\n  parse_stories() %>%\n  filter(map_int(story, ~length(.x)) <= max_length)\n\n`summarise()` has grouped output by 'story_id', 'nid', 'question'. You can\noverride using the `.groups` argument.\n\ntest <- read_lines(sprintf(challenge, path, \"test\")) %>%\n  parse_stories() %>%\n  filter(map_int(story, ~length(.x)) <= max_length)\n\n`summarise()` has grouped output by 'story_id', 'nid', 'question'. You can\noverride using the `.groups` argument.\n\n# Extract the vocabulary\nall_data <- bind_rows(train, test)\nvocab <- c(unlist(all_data$question), all_data$answer, \n           unlist(all_data$story)) %>%\n  unique() %>%\n  sort()\n\n# Reserve 0 for masking via pad_sequences\nvocab_size <- length(vocab) + 1\nstory_maxlen <- map_int(all_data$story, ~length(.x)) %>% max()\nquery_maxlen <- map_int(all_data$question, ~length(.x)) %>% max()\n\n# Vectorized versions of training and test sets\ntrain_vec <- vectorize_stories(train, vocab, story_maxlen, query_maxlen)\ntest_vec <- vectorize_stories(test, vocab, story_maxlen, query_maxlen)\n\n\n# Defining the model ------------------------------------------------------\n\n# Placeholders\nsequence <- layer_input(shape = c(story_maxlen))\nquestion <- layer_input(shape = c(query_maxlen))\n\n# Encoders\n# Embed the input sequence into a sequence of vectors\nsequence_encoder_m <- keras_model_sequential()\nsequence_encoder_m %>%\n  layer_embedding(input_dim = vocab_size, output_dim = 64) %>%\n  layer_dropout(rate = 0.3)\n# output: (samples, story_maxlen, embedding_dim)\n\n# Embed the input into a sequence of vectors of size query_maxlen\nsequence_encoder_c <- keras_model_sequential()\nsequence_encoder_c %>%\n  layer_embedding(input_dim = vocab_size, output_dim = query_maxlen) %>%\n  layer_dropout(rate = 0.3)\n# output: (samples, story_maxlen, query_maxlen)\n\n# Embed the question into a sequence of vectors\nquestion_encoder <- keras_model_sequential()\nquestion_encoder %>%\n  layer_embedding(input_dim = vocab_size, output_dim = 64, \n                  input_length = query_maxlen) %>%\n  layer_dropout(rate = 0.3)\n# output: (samples, query_maxlen, embedding_dim)\n\n# Encode input sequence and questions (which are indices)\n# to sequences of dense vectors\nsequence_encoded_m <- sequence_encoder_m(sequence)\nsequence_encoded_c <- sequence_encoder_c(sequence)\nquestion_encoded <- question_encoder(question)\n\n# Compute a 'match' between the first input vector sequence\n# and the question vector sequence\n# shape: `(samples, story_maxlen, query_maxlen)`\ndot <- layer_dot(axes = c(2,2))\nmatch <- list(sequence_encoded_m, question_encoded) %>%\n  dot() %>%\n  layer_activation(\"softmax\")\n\n# Add the match matrix with the second input vector sequence\nresponse <- list(match, sequence_encoded_c) %>%\n  layer_add() %>%\n  layer_permute(c(2,1))\n\n# Concatenate the match matrix with the question vector sequence\nanswer <- list(response, question_encoded) %>%\n  layer_concatenate() %>%\n  # The original paper uses a matrix multiplication for this reduction step.\n  # We choose to use an RNN instead.\n  layer_lstm(32) %>%\n  # One regularization layer -- more would probably be needed.\n  layer_dropout(rate = 0.3) %>%\n  layer_dense(vocab_size) %>%\n  # We output a probability distribution over the vocabulary\n  layer_activation(\"softmax\")\n\n# Build the final model\nmodel <- keras_model(inputs = list(sequence, question), answer)\nmodel %>% compile(\n  optimizer = \"rmsprop\",\n  loss = \"categorical_crossentropy\",\n  metrics = \"accuracy\"\n)\n\n\n# Training ----------------------------------------------------------------\n\nmodel %>% fit(\n  x = list(train_vec$stories, train_vec$questions),\n  y = train_vec$answers,\n  batch_size = 32,\n  epochs = 120,\n  validation_data = list(list(test_vec$stories, test_vec$questions), test_vec$answers)\n)"
  },
  {
    "objectID": "examples/babi_rnn.html",
    "href": "examples/babi_rnn.html",
    "title": "Trains a two-branch recurrent network on the bAbI dataset",
    "section": "",
    "text": "The results are comparable to those for an LSTM model provided in Weston et al.: “Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks” http://arxiv.org/abs/1502.05698\n\n\n\nTask Number\nFB LSTM Baseline\nKeras QA\n\n\n\n\nQA1 - Single Supporting Fact\n50\n100.0\n\n\nQA2 - Two Supporting Facts\n20\n50.0\n\n\nQA3 - Three Supporting Facts\n20\n20.5\n\n\nQA4 - Two Arg. Relations\n61\n62.9\n\n\nQA5 - Three Arg. Relations\n70\n61.9\n\n\nQA6 - yes/No Questions\n48\n50.7\n\n\nQA7 - Counting\n49\n78.9\n\n\nQA8 - Lists/Sets\n45\n77.2\n\n\nQA9 - Simple Negation\n64\n64.0\n\n\nQA10 - Indefinite Knowledge\n44\n47.7\n\n\nQA11 - Basic Coreference\n72\n74.9\n\n\nQA12 - Conjunction\n74\n76.4\n\n\nQA13 - Compound Coreference\n94\n94.4\n\n\nQA14 - Time Reasoning\n27\n34.8\n\n\nQA15 - Basic Deduction\n21\n32.4\n\n\nQA16 - Basic Induction\n23\n50.6\n\n\nQA17 - Positional Reasoning\n51\n49.1\n\n\nQA18 - Size Reasoning\n52\n90.8\n\n\nQA19 - Path Finding\n8\n9.0\n\n\nQA20 - Agent’s Motivations\n91\n90.7\n\n\n\nFor the resources related to the bAbI project, refer to: https://research.facebook.com/researchers/1543934539189348\nNotes:\n\nWith default word, sentence, and query vector sizes, the GRU model achieves:\n100% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n50% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU) In comparison, the Facebook paper achieves 50% and 20% for the LSTM baseline.\nThe task does not traditionally parse the question separately. This likely improves accuracy and is a good example of merging two RNNs.\nThe word vector embeddings are not shared between the story and question RNNs.\nSee how the accuracy changes given 10,000 training samples (en-10k) instead of only 1000. 1000 was used in order to be comparable to the original paper.\nExperiment with GRU, LSTM, and JZS1-3 as they give subtly different results.\nThe length and noise (i.e. ‘useless’ story components) impact the ability for LSTMs / GRUs to provide the correct answer. Given only the supporting facts, these RNNs can achieve 100% accuracy on many tasks. Memory networks and neural networks that use attentional processes can efficiently search through this noise to find the relevant statements, improving performance substantially. This becomes especially obvious on QA2 and QA3, both far longer than QA1.\n\n\nlibrary(keras)\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.1.2\n\nlibrary(stringr)\nlibrary(purrr)\nlibrary(tibble)\n\nWarning: package 'tibble' was built under R version 4.1.2\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Function definition -----------------------------------------------------\n\ntokenize_words <- function(x){\n  x <- x %>% \n    str_replace_all('([[:punct:]]+)', ' \\\\1') %>% \n    str_split(' ') %>%\n    unlist()\n  x[x != \"\"]\n}\n\nparse_stories <- function(lines, only_supporting = FALSE){\n  lines <- lines %>% \n    str_split(\" \", n = 2) %>%\n    map_dfr(~tibble(nid = as.integer(.x[[1]]), line = .x[[2]]))\n  \n  lines <- lines %>%\n    mutate(\n      split = map(line, ~str_split(.x, \"\\t\")[[1]]),\n      q = map_chr(split, ~.x[1]),\n      a = map_chr(split, ~.x[2]),\n      supporting = map(split, ~.x[3] %>% str_split(\" \") %>% unlist() %>% as.integer()),\n      story_id = c(0, cumsum(nid[-nrow(.)] > nid[-1]))\n    ) %>%\n    select(-split)\n  \n  stories <- lines %>%\n    filter(is.na(a)) %>%\n    select(nid_story = nid, story_id, story = q)\n  \n  questions <- lines %>%\n    filter(!is.na(a)) %>%\n    select(-line) %>%\n    left_join(stories, by = \"story_id\") %>%\n    filter(nid_story < nid)\n\n  if(only_supporting){\n    questions <- questions %>%\n      filter(map2_lgl(nid_story, supporting, ~.x %in% .y))\n  }\n    \n  questions %>%\n    group_by(story_id, nid, question = q, answer = a) %>%\n    summarise(story = paste(story, collapse = \" \"), .groups = \"keep\") %>%\n    ungroup() %>% \n    mutate(\n      question = map(question, ~tokenize_words(.x)),\n      story = map(story, ~tokenize_words(.x)),\n      id = row_number()\n    ) %>%\n    select(id, question, answer, story)\n}\n\nvectorize_stories <- function(data, vocab, story_maxlen, query_maxlen){\n  \n  questions <- map(data$question, function(x){\n    map_int(x, ~which(.x == vocab))\n  })\n  \n  stories <- map(data$story, function(x){\n    map_int(x, ~which(.x == vocab))\n  })\n  \n  # \"\" represents padding\n  answers <- sapply(c(\"\", vocab), function(x){\n    as.integer(x == data$answer)\n  })\n  \n\n  list(\n    questions = pad_sequences(questions, maxlen = query_maxlen),\n    stories   = pad_sequences(stories, maxlen = story_maxlen),\n    answers   = answers\n  )\n}\n\n# Parameters --------------------------------------------------------------\n\nmax_length <- 99999\nembed_hidden_size <- 50\nbatch_size <- 32\nepochs <- 40\n\n# Data Preparation --------------------------------------------------------\n\npath <- get_file(\n  fname = \"babi-tasks-v1-2.tar.gz\",\n  origin = \"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\"\n)\n\nLoaded Tensorflow version 2.9.1\n\nuntar(path, exdir = str_replace(path, fixed(\".tar.gz\"), \"/\"))\npath <- str_replace(path, fixed(\".tar.gz\"), \"/\")\n\n# Default QA1 with 1000 samples\n# challenge = '%stasks_1-20_v1-2/en/qa1_single-supporting-fact_%s.txt'\n# QA1 with 10,000 samples\nchallenge = '%stasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_%s.txt'\n# QA2 with 1000 samples\n# challenge <- \"%stasks_1-20_v1-2/en/qa2_two-supporting-facts_%s.txt\"\n# QA2 with 10,000 samples\n# challenge = '%stasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_%s.txt'\n\ntrain <- read_lines(sprintf(challenge, path, \"train\")) %>%\n  parse_stories() %>%\n  filter(map_int(story, ~length(.x)) <= max_length)\n\ntest <- read_lines(sprintf(challenge, path, \"test\")) %>%\n  parse_stories() %>%\n  filter(map_int(story, ~length(.x)) <= max_length)\n\n# extract the vocabulary\nall_data <- bind_rows(train, test)\nvocab <- c(unlist(all_data$question), all_data$answer, \n           unlist(all_data$story)) %>%\n  unique() %>%\n  sort()\n\n# Reserve 0 for masking via pad_sequences\nvocab_size <- length(vocab) + 1\nstory_maxlen <- map_int(all_data$story, ~length(.x)) %>% max()\nquery_maxlen <- map_int(all_data$question, ~length(.x)) %>% max()\n\n# vectorized versions of training and test sets\ntrain_vec <- vectorize_stories(train, vocab, story_maxlen, query_maxlen)\ntest_vec <- vectorize_stories(test, vocab, story_maxlen, query_maxlen)\n\n# Defining the model ------------------------------------------------------\n\nsentence <- layer_input(shape = c(story_maxlen), dtype = \"int32\")\nencoded_sentence <- sentence %>% \n  layer_embedding(input_dim = vocab_size, output_dim = embed_hidden_size) %>%\n  layer_dropout(rate = 0.3)\n\nquestion <- layer_input(shape = c(query_maxlen), dtype = \"int32\")\nencoded_question <- question %>%\n  layer_embedding(input_dim = vocab_size, output_dim = embed_hidden_size) %>%\n  layer_dropout(rate = 0.3) %>%\n  layer_lstm(units = embed_hidden_size) %>%\n  layer_repeat_vector(n = story_maxlen)\n\nmerged <- list(encoded_sentence, encoded_question) %>%\n  layer_add() %>%\n  layer_lstm(units = embed_hidden_size) %>%\n  layer_dropout(rate = 0.3)\n\npreds <- merged %>%\n  layer_dense(units = vocab_size, activation = \"softmax\")\n\nmodel <- keras_model(inputs = list(sentence, question), outputs = preds)\nmodel %>% compile(\n  optimizer = \"adam\",\n  loss = \"categorical_crossentropy\",\n  metrics = \"accuracy\"\n)\n\nmodel\n\nModel: \"model\"\n____________________________________________________________________________\n Layer (type)            Output Shape    Param #  Connected to              \n============================================================================\n input_2 (InputLayer)    [(None, 4)]     0        []                        \n embedding_1 (Embedding)  (None, 4, 50)  1100     ['input_2[0][0]']         \n input_1 (InputLayer)    [(None, 68)]    0        []                        \n dropout_1 (Dropout)     (None, 4, 50)   0        ['embedding_1[0][0]']     \n embedding (Embedding)   (None, 68, 50)  1100     ['input_1[0][0]']         \n lstm (LSTM)             (None, 50)      20200    ['dropout_1[0][0]']       \n dropout (Dropout)       (None, 68, 50)  0        ['embedding[0][0]']       \n repeat_vector (RepeatVe  (None, 68, 50)  0       ['lstm[0][0]']            \n ctor)                                                                      \n add (Add)               (None, 68, 50)  0        ['dropout[0][0]',         \n                                                   'repeat_vector[0][0]']   \n lstm_1 (LSTM)           (None, 50)      20200    ['add[0][0]']             \n dropout_2 (Dropout)     (None, 50)      0        ['lstm_1[0][0]']          \n dense (Dense)           (None, 22)      1122     ['dropout_2[0][0]']       \n============================================================================\nTotal params: 43,722\nTrainable params: 43,722\nNon-trainable params: 0\n____________________________________________________________________________\n\n# Training ----------------------------------------------------------------\n\nmodel %>% fit(\n  x = list(train_vec$stories, train_vec$questions),\n  y = train_vec$answers,\n  batch_size = batch_size,\n  epochs = epochs,\n  validation_split=0.05\n)\n\nevaluation <- model %>% evaluate(\n  x = list(test_vec$stories, test_vec$questions),\n  y = test_vec$answers,\n  batch_size = batch_size\n)\n\nevaluation\n\n       loss    accuracy \n0.001482824 1.000000000"
  },
  {
    "objectID": "examples/cifar10_cnn.html",
    "href": "examples/cifar10_cnn.html",
    "title": "Simple CNN on CIFAR10 dataset",
    "section": "",
    "text": "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs, though it is still underfitting at that point.\nIf doing data augmentation you may try increasing the number of filters in convolutions and in dense layers.\n\nlibrary(keras)\n\n# Parameters --------------------------------------------------------------\n\nbatch_size <- 32\nepochs <- 50\ndata_augmentation <- FALSE\n\n\n# Data Preparation --------------------------------------------------------\n\n# See ?dataset_cifar10 for more info\ncifar10 <- dataset_cifar10()\n\nLoaded Tensorflow version 2.9.1\n\n# Feature scale RGB values in test and train inputs  \nx_train <- cifar10$train$x/255\nx_test <- cifar10$test$x/255\ny_train <- cifar10$train$y\ny_test <- cifar10$test$y\n\n\n# Defining Model ----------------------------------------------------------\n\n# Initialize sequential model\nmodel <- keras_model_sequential()\n\n\nif (data_augmentation) {\n  data_augmentation = keras_model_sequential() %>% \n    layer_random_flip(\"horizontal\") %>% \n    layer_random_rotation(0.2)\n  \n  model <- model %>% \n    data_augmentation()\n}\n\nmodel <- model %>%\n  # Start with hidden 2D convolutional layer being fed 32x32 pixel images\n  layer_conv_2d(\n    filter = 16, kernel_size = c(3,3), padding = \"same\", \n    input_shape = c(32, 32, 3)\n  ) %>%\n  layer_activation_leaky_relu(0.1) %>% \n\n  # Second hidden layer\n  layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%\n  layer_activation_leaky_relu(0.1) %>% \n\n  # Use max pooling\n  layer_max_pooling_2d(pool_size = c(2,2)) %>%\n  layer_dropout(0.25) %>%\n  \n  # 2 additional hidden 2D convolutional layers\n  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = \"same\") %>%\n  layer_activation_leaky_relu(0.1) %>% \n  layer_conv_2d(filter = 64, kernel_size = c(3,3)) %>%\n  layer_activation_leaky_relu(0.1) %>% \n\n  # Use max pooling once more\n  layer_max_pooling_2d(pool_size = c(2,2)) %>%\n  layer_dropout(0.25) %>%\n  \n  # Flatten max filtered output into feature vector \n  # and feed into dense layer\n  layer_flatten() %>%\n  layer_dense(256) %>%\n  layer_activation_leaky_relu(0.1) %>% \n  layer_dropout(0.5) %>%\n\n  # Outputs from dense layer are projected onto 10 unit output layer\n  layer_dense(10)\n\nopt <- optimizer_adamax(learning_rate = learning_rate_schedule_exponential_decay(\n  initial_learning_rate = 5e-3, \n  decay_rate = 0.96, \n  decay_steps = 1500, \n  staircase = TRUE\n))\n\nmodel %>% compile(\n  loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),\n  optimizer = opt,\n  metrics = \"accuracy\"\n)\n\n\n# Training ----------------------------------------------------------------\nmodel %>% fit(\n  x_train, y_train,\n  batch_size = batch_size,\n  epochs = epochs,\n  validation_data = list(x_test, y_test),\n  shuffle = TRUE\n)\n\nmodel %>% evaluate(x_test, y_test)\n\n     loss  accuracy \n0.5960141 0.8206000"
  },
  {
    "objectID": "examples/conv_lstm.html",
    "href": "examples/conv_lstm.html",
    "title": "Convolutional LSTM network",
    "section": "",
    "text": "animation"
  },
  {
    "objectID": "examples/dcgan_overriding_train_step.html",
    "href": "examples/dcgan_overriding_train_step.html",
    "title": "DCGAN to generate face images",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "examples/dcgan_overriding_train_step.html#prepare-celeba-data",
    "href": "examples/dcgan_overriding_train_step.html#prepare-celeba-data",
    "title": "DCGAN to generate face images",
    "section": "Prepare CelebA data",
    "text": "Prepare CelebA data\nWe’ll use face images from the CelebA dataset, resized to 64x64.\n\noutput <- \"celeba_gan/data.zip\"\nif (!fs::dir_exists(\"celeba_gan\")) {\n  fs::dir_create(\"celeba_gan\")\n  url <- \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n  reticulate::import(\"gdown\")$download(url, output, quiet=TRUE)\n  unzip(output, exdir = fs::path_dir(output))\n}\n\ndataset_path <- fs::path(fs::path_dir(output), \"img_align_celeba\")\n\nCreate a dataset from our folder:\n\ndataset <- image_dataset_from_directory(\n  dataset_path, \n  image_size = c(64, 64),\n  label_mode = NULL, \n  batch_size = 32\n)\n\nLoaded Tensorflow version 2.9.1\n\ndataset <- dataset$apply(tf$data$experimental$ignore_errors(\n    log_warning=FALSE\n))\n\nLet’s display a sample image:\n\ndataset %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next() %>% \n  as.array() %>% \n  {.[1,,,]} %>% \n  as.raster(max = 255) %>% \n  plot()"
  },
  {
    "objectID": "examples/dcgan_overriding_train_step.html#create-the-discriminator",
    "href": "examples/dcgan_overriding_train_step.html#create-the-discriminator",
    "title": "DCGAN to generate face images",
    "section": "Create the discriminator",
    "text": "Create the discriminator\nIt maps a 64x64 image to a binary classification score.\n\ndiscriminator <- keras_model_sequential(name = \"discriminator\", input_shape = shape(64, 64, 3)) %>% \n  layer_conv_2d(64, kernel_size = 4, strides = 2, padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d(128, kernel_size = 4, strides = 2, padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d(128, kernel_size = 4, strides = 2, padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_flatten() %>% \n  layer_dropout(0.2) %>% \n  layer_dense(1, activation = \"sigmoid\")\nsummary(discriminator)\n\nModel: \"discriminator\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_2 (Conv2D)                  (None, 32, 32, 64)              3136        \n leaky_re_lu_2 (LeakyReLU)          (None, 32, 32, 64)              0           \n conv2d_1 (Conv2D)                  (None, 16, 16, 128)             131200      \n leaky_re_lu_1 (LeakyReLU)          (None, 16, 16, 128)             0           \n conv2d (Conv2D)                    (None, 8, 8, 128)               262272      \n leaky_re_lu (LeakyReLU)            (None, 8, 8, 128)               0           \n flatten (Flatten)                  (None, 8192)                    0           \n dropout (Dropout)                  (None, 8192)                    0           \n dense (Dense)                      (None, 1)                       8193        \n================================================================================\nTotal params: 404,801\nTrainable params: 404,801\nNon-trainable params: 0\n________________________________________________________________________________"
  },
  {
    "objectID": "examples/dcgan_overriding_train_step.html#create-the-generator",
    "href": "examples/dcgan_overriding_train_step.html#create-the-generator",
    "title": "DCGAN to generate face images",
    "section": "Create the generator",
    "text": "Create the generator\nIt mirrors the discriminator, replacing conv_2d layers with conv_2d_transpose layers.\n\nlatent_dim <- 128L\n\ngenerator <- keras_model_sequential(input_shape = shape(latent_dim), name = \"generator\") %>% \n  layer_dense(8 * 8 * 128) %>% \n  layer_reshape(shape(8, 8, 128)) %>% \n  layer_conv_2d_transpose(128, kernel_size = 4, strides = 2, padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d_transpose(256, kernel_size = 4, strides = 2, padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d_transpose(512, kernel_size = 4, strides = 2, padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d(3, kernel_size = 5, padding = \"same\", activation = \"sigmoid\")\n\nsummary(generator)\n\nModel: \"generator\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_1 (Dense)                    (None, 8192)                    1056768     \n reshape (Reshape)                  (None, 8, 8, 128)               0           \n conv2d_transpose_2 (Conv2DTranspos  (None, 16, 16, 128)            262272      \n e)                                                                             \n leaky_re_lu_5 (LeakyReLU)          (None, 16, 16, 128)             0           \n conv2d_transpose_1 (Conv2DTranspos  (None, 32, 32, 256)            524544      \n e)                                                                             \n leaky_re_lu_4 (LeakyReLU)          (None, 32, 32, 256)             0           \n conv2d_transpose (Conv2DTranspose)  (None, 64, 64, 512)            2097664     \n leaky_re_lu_3 (LeakyReLU)          (None, 64, 64, 512)             0           \n conv2d_3 (Conv2D)                  (None, 64, 64, 3)               38403       \n================================================================================\nTotal params: 3,979,651\nTrainable params: 3,979,651\nNon-trainable params: 0\n________________________________________________________________________________"
  },
  {
    "objectID": "examples/dcgan_overriding_train_step.html#override-train_step",
    "href": "examples/dcgan_overriding_train_step.html#override-train_step",
    "title": "DCGAN to generate face images",
    "section": "Override train_step",
    "text": "Override train_step\n\ngan <- new_model_class(\n  \"gan\",\n  initialize = function(discriminator, generator, latent_dim) {\n    super()$`__init__`()\n    self$discriminator <- discriminator\n    self$generator <- generator\n    self$latent_dim <- latent_dim\n    self$rescale <- layer_rescaling(scale = 1/255)\n  },\n  compile = function(d_optimizer, g_optimizer, loss_fn) {\n    super()$compile()\n    self$d_optimizer <- d_optimizer\n    self$g_optimizer <- g_optimizer\n    self$loss_fn <- loss_fn\n    self$d_loss_metric <- tf$keras$metrics$Mean(name = \"d_loss\")\n    self$g_loss_metric <- keras$metrics$Mean(name = \"g_loss\")\n  },\n  metrics = mark_active(function() {\n    list(self$d_loss_metric, self$g_loss_metric)\n  }),\n  train_step = function(real_images) {\n    real_images <- self$rescale(real_images)\n    \n    # Sample random points in the latent space\n    batch_size <- tf$shape(real_images)[1]\n    random_latent_vectors <- tf$random$normal(\n      shape = reticulate::tuple(batch_size, self$latent_dim)\n    )\n    \n    # Decode them to fake images\n    generated_images <- self$generator(random_latent_vectors)\n    \n    # Combine them with real images\n    combined_images <- tf$concat(list(generated_images, real_images), axis = 0L)\n    \n    # Assemble labels discriminating real from fake images\n    labels <- tf$concat(\n      list(\n        tf$ones(reticulate::tuple(batch_size, 1L)), \n        tf$zeros(reticulate::tuple(batch_size, 1L))\n      ), \n      axis = 0L\n    )\n    # Add random noise to the labels - important trick!\n    labels <- labels + 0.05 * tf$random$uniform(tf$shape(labels))\n    \n    # Train the discriminator\n    with(tf$GradientTape() %as% tape, {   \n      predictions <- self$discriminator(combined_images)\n      d_loss <- self$loss_fn(labels, predictions)\n    })\n    \n    grads <- tape$gradient(d_loss, self$discriminator$trainable_weights)\n    self$d_optimizer$apply_gradients(\n      zip_lists(grads, self$discriminator$trainable_weights)\n    )\n    \n    # Sample random points in the latent space\n    random_latent_vectors <- tf$random$normal(\n      shape = reticulate::tuple(batch_size, self$latent_dim)\n    )\n    \n    # Assemble labels that say \"all real images\"\n    misleading_labels <- tf$zeros(reticulate::tuple(batch_size, 1L))\n    \n    # Train the generator (note that we should *not* update the weights\n    # of the discriminator)!\n    with(tf$GradientTape() %as% tape, {   \n      predictions <- self$discriminator(self$generator(random_latent_vectors))\n      g_loss <- self$loss_fn(misleading_labels, predictions)\n    })\n    grads <- tape$gradient(g_loss, self$generator$trainable_weights)\n    self$g_optimizer$apply_gradients(zip_lists(grads, self$generator$trainable_weights))\n    \n    # Update metrics\n    self$d_loss_metric$update_state(d_loss)\n    self$g_loss_metric$update_state(g_loss)\n    list(\n      \"d_loss\" = self$d_loss_metric$result(),\n      \"g_loss\" = self$g_loss_metric$result()\n    )\n  }\n)"
  },
  {
    "objectID": "examples/dcgan_overriding_train_step.html#create-a-callback-that-periodically-saves-generated-images",
    "href": "examples/dcgan_overriding_train_step.html#create-a-callback-that-periodically-saves-generated-images",
    "title": "DCGAN to generate face images",
    "section": "Create a callback that periodically saves generated images",
    "text": "Create a callback that periodically saves generated images\n\ngan_monitor <- new_callback_class(\n  \"gan_monitor\",\n  initialize = function(num_img = 3, latent_dim = 128L) {\n    self$num_img <- num_img\n    self$latent_dim <- as.integer(latent_dim)\n    if (!fs::dir_exists(\"dcgan\")) fs::dir_create(\"dcgan\")\n  },\n  on_epoch_end = function(epoch, logs) {\n    random_latent_vectors <- tf$random$normal(shape = shape(self$num_img, self$latent_dim))\n    generated_images <- self$model$generator(random_latent_vectors)\n    generated_images <- tf$clip_by_value(generated_images * 255, 0, 255)\n    generated_images <- as.array(generated_images)\n    for (i in seq_len(self$num_img)) {\n      image_array_save(\n        generated_images[i,,,], \n        sprintf(\"dcgan/generated_img_%03d_%d.png\", epoch, i),\n        scale = FALSE\n      )\n    }\n  }\n)"
  },
  {
    "objectID": "examples/dcgan_overriding_train_step.html#train-the-end-to-end-model",
    "href": "examples/dcgan_overriding_train_step.html#train-the-end-to-end-model",
    "title": "DCGAN to generate face images",
    "section": "Train the end-to-end model",
    "text": "Train the end-to-end model\n\nepochs <- 15  # In practice, use ~100 epochs\n\ngan <- gan(discriminator = discriminator, generator = generator, latent_dim = latent_dim)\ngan %>% compile(\n  d_optimizer = optimizer_adam(learning_rate = 1e-4),\n  g_optimizer = optimizer_adam(learning_rate = 1e-4),\n  loss_fn = loss_binary_crossentropy(),\n)\n\ngan %>% fit(\n  dataset, \n  epochs = epochs, \n  callbacks = list(\n    gan_monitor(num_img = 10, latent_dim = latent_dim)\n  )\n)\n\nSome of the last generated images around epoch 15 - each row is an epoch. (results keep improving after that):\n\ngrid <- expand.grid(1:10, 0:14)\nknitr::include_graphics(sprintf(\"dcgan/generated_img_%03d_%d.png\", grid[[2]], grid[[1]]))"
  },
  {
    "objectID": "examples/deep_dream.html",
    "href": "examples/deep_dream.html",
    "title": "Deep Dream",
    "section": "",
    "text": "“Deep dream” is an image-filtering technique which consists of taking an image classification model, and running gradient ascent over an input image to try to maximize the activations of specific layers (and sometimes, specific units in specific layers) for this input. It produces hallucination-like visuals.\nIt was first introduced by Alexander Mordvintsev from Google in July 2015.\nProcess:\n\nLoad the original image.\nDefine a number of processing scales (“octaves”), from smallest to largest.\nResize the original image to the smallest scale.\nFor every scale, starting with(the smallest (i$e. current one), { })\n\nRun gradient ascent\nUpscale image to the next scale\nReinject the detail that was lost at upscaling time\n\nStop when we are back to the original size. To obtain the detail lost during upscaling, we simply take the original image, shrink it down, upscale it, and compare the result to the (resized) original image."
  },
  {
    "objectID": "examples/deep_dream.html#setup",
    "href": "examples/deep_dream.html#setup",
    "title": "Deep Dream",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)\nlibrary(keras)\n\nbase_image_path <- get_file(\"sky.jpg\", \"https://i.imgur.com/aGBdQyK.jpg\")\n\nLoaded Tensorflow version 2.9.1\n\nresult_prefix <- \"sky_dream\"\n\n# These are the names of the layers\n# for which we try to maximize activation,\n# as well as their weight in the final loss\n# we try to maximize.\n# You can tweak these setting to obtain new visual effects.\nlayer_settings <- list(\n  \"mixed4\" = 1.0,\n  \"mixed5\" = 1.5,\n  \"mixed6\" = 2.0,\n  \"mixed7\" = 2.5\n)\n\n# Playing with these hyperparameters will also allow you to achieve new effects\n\nstep <- 0.01  # Gradient ascent step size\nnum_octave <- 3  # Number of scales at which to run gradient ascent\noctave_scale <- 1.4  # Size ratio between scales\niterations <- 20  # Number of ascent steps per scale\nmax_loss <- 15.0\n\nThis is our base image:\n\nplot_image <- function(img) {\n  img %>%   \n    as.raster(max = 255) %>% \n    plot()\n}\n\nbase_image_path %>% \n  image_load() %>% \n  image_to_array() %>% \n  plot_image()\n\n\n\n\nLet’s set up some image preprocessing/deprocessing utilities:\n\npreprocess_image <- function(image_path) {\n  # Util function to open, resize and format pictures\n  # into appropriate arrays.\n  img <- image_path %>% \n    image_load() %>% \n    image_to_array()\n  dim(img) <- c(1, dim(img))\n  inception_v3_preprocess_input(img)\n}\n\ndeprocess_image <- function(x) {\n  dim(x) <- dim(x)[-1]\n  # Undo inception v3 preprocessing\n  x <- x/2.0\n  x <- x + 0.5\n  x <- x*255.0\n  x[] <- raster::clamp(as.numeric(x), 0, 255)\n  x\n}"
  },
  {
    "objectID": "examples/deep_dream.html#compute-the-deep-dream-loss",
    "href": "examples/deep_dream.html#compute-the-deep-dream-loss",
    "title": "Deep Dream",
    "section": "Compute the Deep Dream loss",
    "text": "Compute the Deep Dream loss\nFirst, build a feature extraction model to retrieve the activations of our target layers given an input image.\n\n# Build an InceptionV3 model loaded with pre-trained ImageNet weights\nmodel <- application_inception_v3(weights = \"imagenet\", include_top = FALSE)\n\n# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\noutputs_dict <- purrr::imap(layer_settings, function(v, name) {\n  layer <- get_layer(model, name)\n  layer$output\n})\n\n# Set up a model that returns the activation values for every target layer\n# (as a dict)\n\nfeature_extractor <- keras_model(inputs = model$inputs, outputs = outputs_dict)\n\nThe actual loss computation is very simple:\n\ncompute_loss <- function(input_image) {\n  features <- feature_extractor(input_image)\n  # Initialize the loss\n  loss <- tf$zeros(shape = shape())\n  \n  layer_settings %>% \n    purrr::imap(function(coeff, name) {\n      activation <- features[[name]]\n      scaling <- tf$reduce_prod(tf$cast(tf$shape(activation), \"float32\"))\n      # We avoid border artifacts by only involving non-border pixels in the loss.\n      coeff * tf$reduce_sum(tf$square(activation[, 3:-2, 3:-2, ])) / scaling\n    }) %>% \n    purrr::reduce(tf$add)\n}"
  },
  {
    "objectID": "examples/deep_dream.html#set-up-the-gradient-ascent-loop-for-one-octave",
    "href": "examples/deep_dream.html#set-up-the-gradient-ascent-loop-for-one-octave",
    "title": "Deep Dream",
    "section": "Set up the gradient ascent loop for one octave",
    "text": "Set up the gradient ascent loop for one octave\n\ngradient_ascent_step <- tf_function(function(img, learning_rate) {\n  with(tf$GradientTape() %as% tape, {    \n    tape$watch(img)\n    loss <- compute_loss(img)\n  })\n  \n  # Compute gradients.\n  grads <- tape$gradient(loss, img)\n  # Normalize gradients.\n  grads <- grads/tf$maximum(tf$reduce_mean(tf$abs(grads)), 1e-6)\n  img <- img + learning_rate * grads\n  list(loss, img)\n})\n\n\ngradient_ascent_loop <- function(img, iterations, learning_rate, max_loss = NULL) {\n  for (i in seq_len(iterations)) {\n    c(loss, img) %<-% gradient_ascent_step(img, learning_rate)\n    if (!is.null(max_loss) && as.logical(loss > max_loss)) {\n      break\n    }\n    cat(\"... Loss value at step \", i, \": \", as.numeric(loss), \"\\n\")\n  }\n  img\n}"
  },
  {
    "objectID": "examples/deep_dream.html#run-the-training-loop-iterating-over-different-octaves",
    "href": "examples/deep_dream.html#run-the-training-loop-iterating-over-different-octaves",
    "title": "Deep Dream",
    "section": "Run the training loop, iterating over different octaves",
    "text": "Run the training loop, iterating over different octaves\n\noriginal_img <- preprocess_image(base_image_path)\noriginal_shape <- dim(original_img)[2:3]\n\nsuccessive_shapes <- list(original_shape)\nfor (i in seq_len(num_octave - 1)) {\n  shape <- as.integer(original_shape / octave_scale^i)\n  successive_shapes[[i+1]] <- shape\n}\nsuccessive_shapes <- rev(successive_shapes)\n\nshrunk_original_img <- tf$image$resize(original_img, successive_shapes[[1]])\nimg <- tf$identity(original_img)  # Make a copy\nfor (i in seq_along(successive_shapes)) {\n  shape <- successive_shapes[[i]]\n  \n  cat(\"Processing octave \", i, \"with shape:\", shape, \"\\n\")\n  \n  img <- tf$image$resize(img, shape)\n  img <- gradient_ascent_loop(\n    img, iterations = iterations, learning_rate = step, max_loss = max_loss\n  )\n  upscaled_shrunk_original_img <- tf$image$resize(shrunk_original_img, shape)\n  same_size_original <- tf$image$resize(original_img, shape)\n  lost_detail <- same_size_original - upscaled_shrunk_original_img\n  \n  img <- img + lost_detail\n  shrunk_original_img <- tf$image$resize(original_img, shape)\n}\n\nProcessing octave  1 with shape: 326 489 \n\n\nWarning: Negative numbers are interpreted python-style when subsetting tensorflow tensors.\nSee: ?`[.tensorflow.tensor` for details.\nTo turn off this warning, set `options(tensorflow.extract.warn_negatives_pythonic = FALSE)`\n\n\n... Loss value at step  1 :  0.5014445 \n... Loss value at step  2 :  0.7033256 \n... Loss value at step  3 :  0.9973832 \n... Loss value at step  4 :  1.341042 \n... Loss value at step  5 :  1.693359 \n... Loss value at step  6 :  2.03979 \n... Loss value at step  7 :  2.387946 \n... Loss value at step  8 :  2.715209 \n... Loss value at step  9 :  3.03404 \n... Loss value at step  10 :  3.378432 \n... Loss value at step  11 :  3.713022 \n... Loss value at step  12 :  4.024627 \n... Loss value at step  13 :  4.329374 \n... Loss value at step  14 :  4.628398 \n... Loss value at step  15 :  4.914916 \n... Loss value at step  16 :  5.191645 \n... Loss value at step  17 :  5.453531 \n... Loss value at step  18 :  5.751193 \n... Loss value at step  19 :  6.031643 \n... Loss value at step  20 :  6.28981 \nProcessing octave  2 with shape: 457 685 \n... Loss value at step  1 :  1.214938 \n... Loss value at step  2 :  1.944987 \n... Loss value at step  3 :  2.545274 \n... Loss value at step  4 :  3.015953 \n... Loss value at step  5 :  3.477545 \n... Loss value at step  6 :  3.915648 \n... Loss value at step  7 :  4.317786 \n... Loss value at step  8 :  4.721938 \n... Loss value at step  9 :  5.106613 \n... Loss value at step  10 :  5.479532 \n... Loss value at step  11 :  5.876842 \n... Loss value at step  12 :  6.188484 \n... Loss value at step  13 :  6.564732 \n... Loss value at step  14 :  6.862813 \n... Loss value at step  15 :  7.20891 \n... Loss value at step  16 :  7.54597 \n... Loss value at step  17 :  7.828108 \n... Loss value at step  18 :  8.182717 \n... Loss value at step  19 :  8.480966 \n... Loss value at step  20 :  8.817674 \nProcessing octave  3 with shape: 640 960 \n... Loss value at step  1 :  1.346328 \n... Loss value at step  2 :  2.127061 \n... Loss value at step  3 :  2.76038 \n... Loss value at step  4 :  3.279132 \n... Loss value at step  5 :  3.785562 \n... Loss value at step  6 :  4.262078 \n... Loss value at step  7 :  4.723996 \n... Loss value at step  8 :  5.128141 \n... Loss value at step  9 :  5.526906 \n... Loss value at step  10 :  5.915565 \n... Loss value at step  11 :  6.307329 \n... Loss value at step  12 :  6.672551 \n... Loss value at step  13 :  7.040999 \n... Loss value at step  14 :  7.306005 \n... Loss value at step  15 :  7.659632 \n... Loss value at step  16 :  7.972069 \n... Loss value at step  17 :  8.320035 \n... Loss value at step  18 :  8.578279 \n... Loss value at step  19 :  8.917708 \n... Loss value at step  20 :  9.189703 \n\n\nDisplay the result.\n\nimg %>% \n  as.array() %>% \n  deprocess_image() %>% \n  plot_image()"
  },
  {
    "objectID": "examples/image_captioning.html",
    "href": "examples/image_captioning.html",
    "title": "Image Captioning",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)\nlibrary(tfdatasets)"
  },
  {
    "objectID": "examples/image_captioning.html#download-the-dataset",
    "href": "examples/image_captioning.html#download-the-dataset",
    "title": "Image Captioning",
    "section": "Download the dataset",
    "text": "Download the dataset\nWe will be using the Flickr8K dataset for this tutorial. This dataset comprises over 8,000 images, that are each paired with five different captions.\n\nflickr_images <- get_file(\n  \"fickr8k.zip\",\n  \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\"\n)\n\nLoaded Tensorflow version 2.9.1\n\nflickr_text <- get_file(\n  \"flickr9k_text.zip\",\n  \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\"\n)\n\n\nif (!fs::dir_exists(fs::path(fs::path_dir(flickr_text), \"Flicker8k_Dataset\"))) {\n  unzip(flickr_images, exdir = fs::path_dir(flickr_images))\n  unzip(flickr_text, exdir = fs::path_dir(flickr_text))  \n}\n\n\n# Path to the images\nIMAGES_PATH <- \"Flicker8k_Dataset\"\n\n# Desired image dimensions\nIMAGE_SIZE <- shape(299, 299)\n\n# Vocabulary size\nVOCAB_SIZE <- 10000\n\n# Fixed length allowed for any sequence\nSEQ_LENGTH <- 25\n\n# Dimension for the image embeddings and token embeddings\nEMBED_DIM <- 512\n\n# Per-layer units in the feed-forward network\nFF_DIM <- 512\n\n# Other training parameters\n\nBATCH_SIZE <- 64\nEPOCHS <- 30\nAUTOTUNE <- tf$data$AUTOTUNE"
  },
  {
    "objectID": "examples/image_captioning.html#preparing-the-dataset",
    "href": "examples/image_captioning.html#preparing-the-dataset",
    "title": "Image Captioning",
    "section": "Preparing the dataset",
    "text": "Preparing the dataset\n\ncaptions <- fs::path(fs::path_dir(flickr_text), \"Flickr8k.token.txt\") %>% \n  readr::read_delim(\n    col_names = c(\"img\", \"caption\"),\n    delim = \"\\t\"\n  ) %>% \n  tidyr::separate(img, into = c(\"img\", \"caption_id\"), sep = \"#\") %>% \n  dplyr::select(img, caption) %>% \n  dplyr::group_by(img) %>% \n  dplyr::summarise(caption = list(caption)) %>% \n  dplyr::mutate(img = fs::path(fs::path_dir(flickr_text), \"Flicker8k_Dataset\", img))\n\nRows: 40460 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (2): img, caption\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntrain <- fs::path(fs::path_dir(flickr_text), \"Flickr_8k.trainImages.txt\") %>% \n  readr::read_lines() \n  \nvalid <- fs::path(fs::path_dir(flickr_text), \"Flickr_8k.devImages.txt\") %>% \n  readr::read_lines()\n\ntest <- fs::path(fs::path_dir(flickr_text), \"Flickr_8k.testImages.txt\") %>% \n  readr::read_lines()\n\n\ntrain_data <- captions %>% \n  dplyr::filter(fs::path_file(img) %in% train)\n\nvalid_data <- captions %>% \n  dplyr::filter(fs::path_file(img) %in% test)\n\ndplyr::n_distinct(train_data$img)\n\n[1] 6000\n\ndplyr::n_distinct(valid_data$img)\n\n[1] 1000"
  },
  {
    "objectID": "examples/image_captioning.html#vectorizing-the-text-data",
    "href": "examples/image_captioning.html#vectorizing-the-text-data",
    "title": "Image Captioning",
    "section": "Vectorizing the text data",
    "text": "Vectorizing the text data\nWe’ll use the text_vectorization layer to vectorize the text data, that is to say, to turn the original strings into integer sequences where each integer represents the index of a word in a vocabulary. We will use a custom string standardization scheme (strip punctuation characters except < and >) and the default splitting scheme (split on whitespace).\n\npunctuation <- c(\"!\", \"\\\\\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", \"(\", \")\", \"*\", \n\"+\", \",\", \"-\", \".\", \"/\", \":\", \";\", \"=\", \"?\", \"@\", \"[\", \n\"\\\\\", \"\\\\\", \"]\", \"^\", \"_\", \"`\", \"{\", \"|\", \"}\", \"~\")\nre <- reticulate::import(\"re\")\npunctuation_group <- punctuation %>% \n  sapply(re$escape) %>% \n  paste0(collapse = \"\") %>% \n  sprintf(\"[%s]\", .)\n\ncustom_standardization <- function(input_string) {\n  lowercase <- tf$strings$lower(input_string)\n  tf$strings$regex_replace(lowercase, punctuation_group, \"\")\n}\n\nvectorization <- layer_text_vectorization(\n    max_tokens = VOCAB_SIZE,\n    output_mode = \"int\",\n    output_sequence_length = SEQ_LENGTH,\n    standardize = custom_standardization,\n)\nvectorization %>% adapt(unlist(train_data$caption))\n\n# Data augmentation for image data\n\nimage_augmentation <- keras_model_sequential() %>% \n  layer_random_flip(\"horizontal\") %>% \n  layer_random_rotation(0.2) %>% \n  layer_random_contrast(0.3)"
  },
  {
    "objectID": "examples/image_captioning.html#building-a-tensorflow-dataset-pipeline-for-training",
    "href": "examples/image_captioning.html#building-a-tensorflow-dataset-pipeline-for-training",
    "title": "Image Captioning",
    "section": "Building a TensorFlow dataset pipeline for training",
    "text": "Building a TensorFlow dataset pipeline for training\nWe will generate pairs of images and corresponding captions using a tf$data$Dataset object. The pipeline consists of two steps:\n\nRead the image from the disk\nTokenize all the five captions corresponding to the image\n\n\ndecode_and_resize <- function(img_path) {\n  img_path %>% \n    tf$io$read_file() %>% \n    tf$image$decode_jpeg(channels = 3) %>% \n    tf$image$resize(IMAGE_SIZE) %>% \n    tf$image$convert_image_dtype(tf$float32)\n}\n\n\nprocess_input <- function(img_path, captions) {\n  reticulate::tuple(\n    decode_and_resize(img_path), \n    vectorization(captions)\n  )\n}\n\nmake_dataset <- function(data) {\n  data %>% unname() %>% \n    tensor_slices_dataset() %>% \n    dataset_shuffle(nrow(data)) %>% \n    dataset_map(process_input, num_parallel_calls = AUTOTUNE) %>% \n    dataset_batch(BATCH_SIZE) %>% \n    dataset_prefetch(AUTOTUNE)\n}\n\n\n# Pass the list of images and the list of corresponding captions\ntrain_dataset <- make_dataset(train_data)\nvalid_dataset <- make_dataset(valid_data)"
  },
  {
    "objectID": "examples/image_captioning.html#building-the-model",
    "href": "examples/image_captioning.html#building-the-model",
    "title": "Image Captioning",
    "section": "Building the model",
    "text": "Building the model\nOur image captioning architecture consists of three models:\n\nA CNN: used to extract the image features\nA TransformerEncoder: The extracted image features are then passed to a Transformer based encoder that generates a new representation of the inputs\nA TransformerDecoder: This model takes the encoder output and the text data (sequences) as inputs and tries to learn to generate the caption.\n\n\nget_cnn_model <- function() {\n  base_model <- application_efficientnet_b0(\n    input_shape = c(IMAGE_SIZE, 3),\n    include_top = FALSE,\n    weights = \"imagenet\"\n  )\n  # We freeze our feature extractor\n  base_model$trainable <- FALSE\n  base_model_out <- base_model$output %>% \n    layer_reshape(target_shape = c(-1, tail(dim(base_model$output), 1)))\n  keras_model(base_model$input, base_model_out)\n}\n\n\ntransformer_encoder_block <- new_layer_class(\n  \"transformer_encoder_block\", \n  initialize = function(embed_dim, dense_dim, num_heads, ...) {\n    super()$`__init__`(...)\n    self$embed_dim <- embed_dim\n    self$dense_dim <- dense_dim\n    self$num_heads <- num_heads\n    self$attention_1 <- layer_multi_head_attention(\n      num_heads = num_heads, key_dim = embed_dim, dropout = 0.0\n    )\n    self$layernorm_1 <- layer_normalization()\n    self$layernorm_2 <- layer_normalization()\n    self$dense_1 <- layer_dense(units = embed_dim, activation = \"relu\")\n  },\n  call = function(inputs, training, mask = NULL) {\n    inputs <- self$layernorm_1(inputs)\n    inputs <- self$dense_1(inputs)\n    \n    attention_output_1 <- self$attention_1(\n      query = inputs,\n      value = inputs,\n      key = inputs,\n      attention_mask = NULL,\n      training = training,\n    )\n    out_1 <- self$layernorm_2(inputs + attention_output_1)\n  \n    out_1\n  }\n)\n\npositional_embedding <- new_layer_class(\n  \"positional_embedding\",\n  initialize = function(sequence_length, vocab_size, embed_dim, ...) {\n    super()$`__init__`(...)\n    self$token_embeddings <- layer_embedding(\n      input_dim = vocab_size, output_dim = embed_dim\n    )\n    self$position_embeddings <- layer_embedding(\n      input_dim = sequence_length, output_dim = embed_dim\n    )\n    self$sequence_length <- sequence_length\n    self$vocab_size <- vocab_size\n    self$embed_dim <- embed_dim\n    self$embed_scale <- tf$math$sqrt(tf$cast(embed_dim, tf$float32))\n  },\n  call = function(inputs) {\n    length <- tail(dim(inputs), 1)\n    positions <- tf$range(start = 0L, limit = length, delta = 1L)\n    embedded_tokens <- self$token_embeddings(inputs)\n    embedded_tokens <- embedded_tokens * self$embed_scale\n    embedded_positions <- self$position_embeddings(positions)\n    embedded_tokens + embedded_positions\n  },\n  compute_mask = function(inputs, mask) {\n    tf$math$not_equal(inputs, 0L)\n  }\n)\n\ntransformer_decoder_block <- new_layer_class(\n  \"transformer_decoder_block\",\n  initialize = function(embed_dim, ff_dim, num_heads, ...) {\n    super()$`__init__`(...)\n    self$embed_dim <- embed_dim\n    self$ff_dim <- ff_dim\n    self$num_heads <- num_heads\n    self$attention_1 <- layer_multi_head_attention(\n      num_heads = num_heads, key_dim = embed_dim, dropout = 0.1\n    )\n    self$attention_2 <- layer_multi_head_attention(\n      num_heads = num_heads, key_dim = embed_dim, dropout = 0.1\n    )\n    self$ffn_layer_1 <- layer_dense(units = ff_dim, activation = \"relu\")\n    self$ffn_layer_2 <- layer_dense(units = embed_dim)\n    \n    self$layernorm_1 <- layer_normalization()\n    self$layernorm_2 <- layer_normalization()\n    self$layernorm_3 <- layer_normalization()\n    \n    self$embedding <- positional_embedding(\n      embed_dim = EMBED_DIM, sequence_length = SEQ_LENGTH, vocab_size = VOCAB_SIZE\n    )\n    self$out <- layer_dense(units = VOCAB_SIZE, activation = \"softmax\")\n    \n    self$dropout_1 <- layer_dropout(rate = 0.3)\n    self$dropout_2 <- layer_dropout(rate = 0.5)\n    self$supports_masking <- TRUE\n  },\n  call = function(inputs, encoder_outputs, training, mask = NULL) {\n    inputs <- self$embedding(inputs)\n    causal_mask <- self$get_causal_attention_mask(inputs)\n    \n    if(!is.null(mask)) {\n      padding_mask <- tf$cast(mask[, , tf$newaxis], dtype = tf$int32)\n      combined_mask <- tf$cast(mask[, tf$newaxis, ], dtype = tf$int32)\n      combined_mask <- tf$minimum(combined_mask, causal_mask)\n    }\n    \n    attention_output_1 <- self$attention_1(\n      query = inputs,\n      value = inputs,\n      key = inputs,\n      attention_mask = combined_mask,\n      training = training,\n    )\n    out_1 <- self$layernorm_1(inputs + attention_output_1)\n    \n    attention_output_2 <- self$attention_2(\n      query = out_1,\n      value = encoder_outputs,\n      key = encoder_outputs,\n      attention_mask = padding_mask,\n      training = training,\n    )\n    out_2 <- self$layernorm_2(out_1 + attention_output_2)\n    \n    ffn_out <- self$ffn_layer_1(out_2)\n    ffn_out <- self$dropout_1(ffn_out, training = training)\n    ffn_out <- self$ffn_layer_2(ffn_out)\n    \n    ffn_out <- self$layernorm_3(ffn_out + out_2, training = training)\n    ffn_out <- self$dropout_2(ffn_out, training = training)\n    preds <- self$out(ffn_out)\n    preds\n  },\n  get_causal_attention_mask = function(inputs) {\n    input_shape <- tf$shape(inputs)\n    batch_size <- input_shape[1]\n    sequence_length <- input_shape[2]\n    i <- tf$range(sequence_length)[, tf$newaxis]\n    j <- tf$range(sequence_length)\n    mask <- tf$cast(i >= j, dtype = \"int32\")\n    mask <- tf$reshape(mask, list(1L, input_shape[2], input_shape[2]))\n    mult <- tf$concat(list(\n      tf$expand_dims(batch_size, -1L), \n      as_tensor(c(1L, 1L), dtype = tf$int32)\n    ), axis = 0L)\n    tf$tile(mask, mult)\n  }\n)\n\nimage_captioning_model <- new_model_class(\n  \"image_captioning_model\",\n  initialize = function(cnn_model, encoder, decoder, num_captions_per_image = 5,\n                        image_aug = NULL) {\n    super()$`__init__`()\n    self$cnn_model <- cnn_model\n    self$encoder <- encoder\n    self$decoder <- decoder\n    self$loss_tracker <- metric_mean(name = \"loss\")\n    self$acc_tracker <- metric_mean(name = \"accuracy\")\n    self$num_captions_per_image <- num_captions_per_image\n    self$image_aug <- image_aug\n  },\n  calculate_loss = function(y_true, y_pred, mask) {\n    loss <- self$loss(y_true, y_pred)\n    mask <- tf$cast(mask, dtype = loss$dtype)\n    loss <- loss* mask\n    tf$reduce_sum(loss) / tf$reduce_sum(mask)\n  },\n  calculate_accuracy = function(y_true, y_pred, mask) {\n    accuracy <- tf$equal(y_true, tf$argmax(y_pred, axis = 2L))\n    accuracy <- tf$math$logical_and(mask, accuracy)\n    accuracy <- tf$cast(accuracy, dtype = tf$float32)\n    mask <- tf$cast(mask, dtype = tf$float32)\n    tf$reduce_sum(accuracy) / tf$reduce_sum(mask)\n  },\n  .compute_caption_loss_and_acc = function(img_embed, batch_seq, training = TRUE) {\n    encoder_out <- self$encoder(img_embed, training = training)\n    batch_seq_inp <- batch_seq[, NULL:-2]\n    batch_seq_true <- batch_seq[, 2:NULL]\n    mask <- tf$math$not_equal(batch_seq_true, 0L)\n    batch_seq_pred <- self$decoder(\n      batch_seq_inp, encoder_out, training = training, mask = mask\n    )\n    loss <- self$calculate_loss(batch_seq_true, batch_seq_pred, mask)\n    acc <- self$calculate_accuracy(batch_seq_true, batch_seq_pred, mask)\n    list(loss, acc)\n  },\n  train_step = function(batch_data) {\n    batch_img <- batch_data[[1]] \n    batch_seq <- batch_data[[2]]\n    batch_loss <- 0\n    batch_acc <- 0\n    \n    if (!is.null(self$image_aug)){\n      batch_img <- self$image_aug(batch_img)\n    }\n    \n    \n    # 1. Get image embeddings\n    img_embed <- self$cnn_model(batch_img)\n    \n    # 2. Pass each of the five captions one by one to the decoder\n    # along with the encoder outputs and compute the loss as well as accuracy\n    # for each caption.\n    for (i in seq_len(self$num_captions_per_image)) {\n      with(tf$GradientTape() %as% tape, {    \n        c(loss, acc) %<-% self$.compute_caption_loss_and_acc(\n          img_embed, batch_seq[, i, ], training = TRUE\n        )\n        \n        # 3. Update loss and accuracy\n        batch_loss <- batch_loss + loss \n        batch_acc <- batch_acc + acc    \n      })\n      \n      # 4. Get the list of all the trainable weights\n      train_vars <- c(self$encoder$trainable_variables,\n                      self$decoder$trainable_variables)\n      \n      # 5. Get the gradients\n      grads <- tape$gradient(loss, train_vars)\n      \n      # 6. Update the trainable weights\n      self$optimizer$apply_gradients(zip_lists(grads, train_vars))\n    }\n    \n    # 7. Update the trackers\n    batch_acc <- batch_acc/self$num_captions_per_image\n    self$loss_tracker$update_state(batch_loss)\n    self$acc_tracker$update_state(batch_acc)\n    \n    # 8. Return the loss and accuracy values\n    list(\n      loss = self$loss_tracker$result(), \n      acc = self$acc_tracker$result()\n    )\n  },\n  test_step = function(batch_data) {\n    batch_img <- batch_data[[1]] \n    batch_seq <- batch_data[[2]]\n    batch_loss <- 0\n    batch_acc <- 0\n\n    # 1. Get image embeddings\n    img_embed <- self$cnn_model(batch_img)\n    \n    # 2. Pass each of the five captions one by one to the decoder\n    # along with the encoder outputs and compute the loss as well as accuracy\n    # for each caption.\n    for (i in seq_len(self$num_captions_per_image)) {\n      with(tf$GradientTape() %as% tape, {    \n        c(loss, acc) %<-% self$.compute_caption_loss_and_acc(\n          img_embed, batch_seq[, i, ], training = TRUE\n        )\n        \n        # 3. Update loss and accuracy\n        batch_loss <- batch_loss + loss \n        batch_acc <- batch_acc + acc    \n      })\n    }\n    \n    batch_acc <- batch_acc / self$num_captions_per_image\n    \n    # 4. Update the trackers\n    self$loss_tracker$update_state(batch_loss)\n    self$acc_tracker$update_state(batch_acc)\n    \n    # 5. Return the loss and accuracy values\n    list(\n      \"loss\" = self$loss_tracker$result(), \n      \"acc\" = self$acc_tracker$result()\n    )\n  },\n  metrics = mark_active(function() {\n    # We need to list our metrics here so the `reset_states()` can be\n    # called automatically.\n    list(self$loss_tracker, self$acc_tracker)\n  })\n)\n\n\ncnn_model <- get_cnn_model()\nencoder <- transformer_encoder_block(embed_dim = EMBED_DIM, dense_dim = FF_DIM, num_heads = 1)\ndecoder <- transformer_decoder_block(embed_dim = EMBED_DIM, ff_dim = FF_DIM, num_heads = 2)\ncaption_model <- image_captioning_model(\n  cnn_model = cnn_model,\n  encoder = encoder,\n  decoder = decoder,\n  image_aug = image_augmentation\n)"
  },
  {
    "objectID": "examples/image_captioning.html#model-training",
    "href": "examples/image_captioning.html#model-training",
    "title": "Image Captioning",
    "section": "Model training",
    "text": "Model training\n\n# Define the loss function\ncross_entropy <- loss_sparse_categorical_crossentropy(\n    from_logits = FALSE, reduction = \"none\"\n)\n\n# EarlyStopping criteria\nearly_stopping <- callback_early_stopping(patience = 3, restore_best_weights = TRUE)\n\n\n# Learning Rate Scheduler for the optimizer\nlr_schedule <- new_learning_rate_schedule_class(\n  \"lr_schedule\",\n  initialize = function(post_warmup_learning_rate, warmup_steps) {\n    super()$`__init__`()\n    self$post_warmup_learning_rate <- post_warmup_learning_rate\n    self$warmup_steps <- warmup_steps\n  },\n  call = function(step) {\n    global_step <- tf$cast(step, tf$float32)\n    warmup_steps <- tf$cast(self$warmup_steps, tf$float32)\n    warmup_progress <- global_step / warmup_steps\n    warmup_learning_rate <- self$post_warmup_learning_rate * warmup_progress\n    tf$cond(\n      global_step < warmup_steps,\n      function() warmup_learning_rate,\n      function() self$post_warmup_learning_rate\n    )\n  }\n)\n\n\n\n# Create a learning rate schedule\nnum_train_steps <- length(train_dataset) * EPOCHS\nnum_warmup_steps <- num_train_steps %/% 15\nlr <- lr_schedule(post_warmup_learning_rate = 1e-4, warmup_steps = num_warmup_steps)\n\n# Compile the model\ncaption_model %>% compile(\n  optimizer = optimizer_adam(learning_rate = lr), \n  loss = cross_entropy\n)\n\n# Fit the model\ncaption_model %>% fit(\n  train_dataset,\n  epochs = EPOCHS,\n  validation_data = valid_dataset,\n  callbacks = list(early_stopping)\n)\n\nWarning: Negative numbers are interpreted python-style when subsetting tensorflow tensors.\nSee: ?`[.tensorflow.tensor` for details.\nTo turn off this warning, set `options(tensorflow.extract.warn_negatives_pythonic = FALSE)`"
  },
  {
    "objectID": "examples/image_captioning.html#check-sample-predictions",
    "href": "examples/image_captioning.html#check-sample-predictions",
    "title": "Image Captioning",
    "section": "Check sample predictions",
    "text": "Check sample predictions\n\nvocab <- get_vocabulary(vectorization)\nmax_decoded_sentence_length <- SEQ_LENGTH - 1\nvalid_images <- valid_data$img\n\n\ngenerate_caption <- function() {\n  # Select a random image from the validation dataset\n  sample_img <- sample(valid_images, 1)\n  \n  # Read the image from the disk\n  sample_img <- decode_and_resize(sample_img)\n  img <- as.array(tf$clip_by_value(sample_img, 0, 255))\n  img %>% as.raster(max = 255) %>% plot()\n  \n  # Pass the image to the CNN\n  img <- tf$expand_dims(sample_img, 0L)\n  img <- caption_model$cnn_model(img)\n  \n  # Pass the image features to the Transformer encoder\n  encoded_img <- caption_model$encoder(img, training = FALSE)\n  \n  # Generate the caption using the Transformer decoder\n  decoded_caption <- \"<start> \"\n  for (i in seq_len(max_decoded_sentence_length)) {\n    tokenized_caption <- vectorization(list(decoded_caption))\n    mask <- tf$math$not_equal(tokenized_caption, 0L)\n    predictions <- caption_model$decoder(\n      tokenized_caption, encoded_img, training = FALSE, mask = mask\n    )\n    sampled_token_index <- tf$argmax(predictions[1, i, ])\n    sampled_token <- vocab[as.integer(sampled_token_index) + 1]\n    \n    if (sampled_token == \" <end>\") {\n      break\n    }\n\n    decoded_caption <- paste(decoded_caption, sampled_token, sep = \" \")\n  }\n    \n  cat(\"Predicted Caption: \", decoded_caption)\n}\n\n# Check predictions for a few samples\n\ngenerate_caption()\n\n\n\n\nPredicted Caption:  <start>  skier is doing a jump in the air on a snowboard in the air on a snowy field of snow covered ground in the\n\ngenerate_caption()\n\n\n\n\nPredicted Caption:  <start>  dog running on the beach with a dog with a ball in the background and a sandy area with a sandy area with a\n\ngenerate_caption()\n\n\n\n\nPredicted Caption:  <start>  boy is standing in a river with a stick in the water and a lake and a lake and a lake in the background"
  },
  {
    "objectID": "examples/image_captioning.html#end-notes",
    "href": "examples/image_captioning.html#end-notes",
    "title": "Image Captioning",
    "section": "End Notes",
    "text": "End Notes\nWe saw that the model starts to generate reasonable captions after a few epochs. To keep this example easily runnable, we have trained it with a few constraints, like a minimal number of attention heads. To improve the predictions, you can try changing these training settings and find a good model for your use case."
  },
  {
    "objectID": "examples/index.html",
    "href": "examples/index.html",
    "title": "Examples",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nConvolutional LSTM network\n\n\nDemonstrates the use of a convolutional LSTM network.\n\n\n\n\nDCGAN to generate face images\n\n\nA simple DCGAN trained using fit() by overriding train_step on CelebA images.\n\n\n\n\nDeep Dream\n\n\nGenerating Deep Dreams with Keras.\n\n\n\n\nImage Captioning\n\n\nImplement an image captioning model using a CNN and a Transformer.\n\n\n\n\nSequence to sequence learning for performing number addition\n\n\nImplementation of sequence to sequence learning for performing addition of two numbers (as strings).\n\n\n\n\nSimple CNN on CIFAR10 dataset\n\n\nTrains a simple deep CNN on the CIFAR10 small images dataset.\n\n\n\n\nTrains a memory network on the bAbI dataset\n\n\nTrains a memory network on the bAbI dataset for reading comprehension.\n\n\n\n\nTrains a two-branch recurrent network on the bAbI dataset\n\n\nTrains a two-branch recurrent network on the bAbI dataset for reading comprehension.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "guides/data/data.html",
    "href": "guides/data/data.html",
    "title": "Build TensorFlow input pipelines",
    "section": "",
    "text": "The tfdatasets API enables you to build complex input pipelines from simple, reusable pieces. For example, the pipeline for an image model might aggregate data from files in a distributed file system, apply random perturbations to each image, and merge randomly selected images into a batch for training. The pipeline for a text model might involve extracting symbols from raw text data, converting them to embedding identifiers with a lookup table, and batching together sequences of different lengths. The tf$data API makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations.\nThe tfdatasets API introduces a TensorFlow Dataset abstraction that represents a sequence of elements, in which each element consists of one or more components. For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label.\nThere are two distinct ways to create a dataset:"
  },
  {
    "objectID": "guides/data/data.html#basic-mechanics",
    "href": "guides/data/data.html#basic-mechanics",
    "title": "Build TensorFlow input pipelines",
    "section": "Basic mechanics",
    "text": "Basic mechanics\nTo create an input pipeline, you must start with a data source. For example, to construct a Dataset from data in memory, you can use tensors_dataset() or tensor_slices_dataset(). Alternatively, if your input data is stored in a file in the recommended TFRecord format, you can use tfrecord_dataset().\nOnce you have a Dataset object, you can transform it into a new Dataset by chaining method calls on the Dataset object. For example, you can apply per-element transformations such as dataset_map(), and multi-element transformations such as dataset_batch(). See the documentation for tfdatasets for a complete list of transformations.\nThe Dataset object is a iterable. This makes it possible to consume its elements using a the coro::loop:\n\ndataset <- tensor_slices_dataset(c(8, 3, 0, 8, 2, 1))\n\nLoaded Tensorflow version 2.9.1\n\ndataset\n\n<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.float32, name=None)>\n\n\n\ncoro::loop(for(elem in dataset) {\n  print(as.numeric(elem))\n})\n\n[1] 8\n[1] 3\n[1] 0\n[1] 8\n[1] 2\n[1] 1\n\n\nOr by explicitly creating a Python iterator using iter and consuming its elements using next:\n\nit <- reticulate::as_iterator(dataset)\nprint(reticulate::iter_next(it))\n\ntf.Tensor(8.0, shape=(), dtype=float32)\n\n\nAlternatively, dataset elements can be consumed using the reduce transformation, which reduces all elements to produce a single result. The following example illustrates how to use the reduce transformation to compute the sum of a dataset of integers.\n\ndataset %>% \n  dataset_reduce(0, function(state, value) state + value)\n\ntf.Tensor(22.0, shape=(), dtype=float32)\n\n\n\nDataset structure\nA dataset produces a sequence of elements, where each element is the same (nested) structure of components. Individual components of the structure can be of any type representable by tf$TypeSpec, including tf$Tensor, tf$sparse$SparseTensor, tf$RaggedTensor, tf$TensorArray, or tf$data$Dataset.\nThe constructs that can be used to express the (nested) structure of elements include tuple, dict, NamedTuple, and OrderedDict. In particular, list is not a valid construct for expressing the structure of dataset elements. This is because early tfdataset users felt strongly about list inputs (e.g. passed to tensors_dataset()) being automatically packed as tensors and list outputs (e.g. return values of user-defined functions) being coerced into a tuple. As a consequence, if you would like a list input to be treated as a structure, you need to convert it into tuple and if you would like a list output to be a single component, then you need to explicitly pack it using tf$stack.\nThe dataset_element_spec property allows you to inspect the type of each element component. The property returns a nested structure of tf$TypeSpec objects, matching the structure of the element, which may be a single component, a tuple of components, or a nested tuple of components. For example:\n\ndataset1 <- tensor_slices_dataset(tf$random$uniform(shape(4, 10)))\ndataset1$element_spec\n\nTensorSpec(shape=(10,), dtype=tf.float32, name=None)\n\n\n\ndataset2 <- tensor_slices_dataset(reticulate::tuple(\n  tf$random$uniform(shape(4)),\n  tf$random$uniform(shape(4, 100), maxval = 100L, dtype = tf$int32)\n))\n\ndataset2$element_spec\n\n[[1]]\nTensorSpec(shape=(), dtype=tf.float32, name=None)\n\n[[2]]\nTensorSpec(shape=(100,), dtype=tf.int32, name=None)\n\n\n\ndataset3 <- zip_datasets(dataset1, dataset2)\ndataset3$element_spec\n\n[[1]]\nTensorSpec(shape=(10,), dtype=tf.float32, name=None)\n\n[[2]]\n[[2]][[1]]\nTensorSpec(shape=(), dtype=tf.float32, name=None)\n\n[[2]][[2]]\nTensorSpec(shape=(100,), dtype=tf.int32, name=None)\n\n\n\n# Dataset containing a sparse tensor.\nsparse <- tf$SparseTensor(\n  indices = list(c(0L,0L), c(1L,2L)), \n  values = c(1,2),\n  dense_shape = shape(3,4)\n)\ndataset4 <- tensors_dataset(sparse)\ndataset4$element_spec\n\nSparseTensorSpec(TensorShape([3, 4]), tf.float32)\n\n\n\n# Use value_type to see the type of value represented by the element spec\ndataset4$element_spec$value_type\n\n<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>\n\n\nThe Dataset transformations support datasets of any structure. When using the dataset_map(), and dataset_filter() transformations, which apply a function to each element, the element structure determines the arguments of the function:\n\ndataset1 <- tensor_slices_dataset(\n    tf$random$uniform(shape(4, 10), minval = 1L, maxval = 10L, dtype = tf$int32))\ndataset1\n\n<TensorSliceDataset element_spec=TensorSpec(shape=(10,), dtype=tf.int32, name=None)>\n\n\n\ndataset1 %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next()\n\ntf.Tensor([1 1 9 7 2 3 3 2 8 3], shape=(10), dtype=int32)\n\n\n\ndataset2 <- tensor_slices_dataset(reticulate::tuple(\n  tf$random$uniform(shape(4)),\n  tf$random$uniform(shape(4, 100), maxval = 100L, dtype = tf$int32)\n))\ndataset2\n\n<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(100,), dtype=tf.int32, name=None))>\n\n\n\ndataset3 <- zip_datasets(dataset1, dataset2)\ndataset3\n\n<ZipDataset element_spec=(TensorSpec(shape=(10,), dtype=tf.int32, name=None), (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(100,), dtype=tf.int32, name=None)))>\n\n\n\ndataset3 %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next() %>% \n  str()\n\nList of 2\n $ :<tf.Tensor: shape=(10), dtype=int32, numpy=array([1, 1, 9, 7, 2, 3, 3, 2, 8, 3], dtype=int32)>\n $ :List of 2\n  ..$ :<tf.Tensor: shape=(), dtype=float32, numpy=0.33178997>\n  ..$ :<tf.Tensor: shape=(100), dtype=int32, numpy=…>"
  },
  {
    "objectID": "guides/data/data.html#reading-input-data",
    "href": "guides/data/data.html#reading-input-data",
    "title": "Build TensorFlow input pipelines",
    "section": "Reading input data",
    "text": "Reading input data\n\nConsuming R arrays\nSee Loading NumPy arrays for more examples.\nIf all of your input data fits in memory, the simplest way to create a Dataset from them is to convert them to tf$Tensor objects and use tensor_slices_dataset().\n\nc(train, test) %<-% dataset_fashion_mnist()\n\n\ntrain[[1]][] <- train[[1]]/255\ndataset <- tensor_slices_dataset(train)\ndataset\n\n<TensorSliceDataset element_spec={'x': TensorSpec(shape=(28, 28), dtype=tf.float64, name=None), 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}>\n\n\nNote: The above code snippet will embed the features and labels arrays in your TensorFlow graph as tf$constant() operations. This works well for a small dataset, but wastes memory—because the contents of the array will be copied multiple times—and can run into the 2GB limit for the tf$GraphDef protocol buffer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsuming TFRecord data\nSee Loading TFRecords for an end-to-end example.\nThe tfdatasets API supports a variety of file formats so that you can process large datasets that do not fit in memory. For example, the TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data. The tfrecord_dataset() class enables you to stream over the contents of one or more TFRecord files as part of an input pipeline.\nHere is an example using the test file from the French Street Name Signs (FSNS).\n\n# Creates a dataset that reads all of the examples from two files.\nfsns_test_file <- get_file(\n  \"fsns.tfrec\", \n  \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\"\n)\n\nThe filenames argument to the tfrecord_dataset() initializer can either be a string, a list of strings, or a tf$Tensor of strings. Therefore if you have two sets of files for training and validation purposes, you can create a factory method that produces the dataset, taking filenames as an input argument:\n\ndataset <- tfrecord_dataset(filenames = list(fsns_test_file))\ndataset\n\n<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n\n\nMany TensorFlow projects use serialized tf$train$Example records in their TFRecord files. These need to be decoded before they can be inspected:\n\nraw_example <- dataset %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next()\nparsed <- tf$train$Example$FromString(raw_example$numpy())\nparsed$features$feature['image/text']\n\nbytes_list {\n  value: \"Rue Perreyon\"\n}\n\n\n\n\nConsuming text data\nSee Loading Text for an end to end example.\nMany datasets are distributed as one or more text files. The text_line_dataset() provides an easy way to extract lines from one or more text files. Given one or more filenames, a text_line_dataset() will produce one string-valued element per line of those files.\n\ndirectory_url <- 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\nfile_names <- c('cowper.txt', 'derby.txt', 'butler.txt')\n\nfile_paths <- lapply(file_names, function(file_name) {\n get_file(file_name, paste0(directory_url, file_name)) \n})\n\n\ndataset <- text_line_dataset(file_paths)\n\nHere are the first few lines of the first file:\n\ndataset %>% \n  dataset_take(5) %>% \n  coro::collect(5) %>% \n  str()\n\nList of 5\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\">\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'His wrath pernicious, who ten thousand woes'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b\"Caused to Achaia's host, sent many a soul\">\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'Illustrious into Ades premature,'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'And Heroes gave (so stood the will of Jove)'>\n\n\nTo alternate lines between files use dataset_interleave(). This makes it easier to shuffle files together. Here are the first, second and third lines from each translation:\n\nfiles_ds <- tensor_slices_dataset(unlist(file_paths))\nlines_ds <- files_ds %>% \n  dataset_interleave(text_line_dataset, cycle_length = 3)\n\nlines_ds %>% \n  coro::collect(9) %>% \n  str()\n\nList of 9\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\">\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b\"\\xef\\xbb\\xbfOf Peleus' son, Achilles, sing, O Muse,\">\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'\\xef\\xbb\\xbfSing, O goddess, the anger of Achilles son of Peleus, that brought'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'His wrath pernicious, who ten thousand woes'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'The vengeance, deep and deadly; whence to Greece'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'countless ills upon the Achaeans. Many a brave soul did it send'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b\"Caused to Achaia's host, sent many a soul\">\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'Unnumbered ills arose; which many a soul'>\n  [list output truncated]\n\n\nBy default, a text_line_dataset() yields every line of each file, which may not be desirable, for example, if the file starts with a header line, or contains comments. These lines can be removed using the dataset_skip() or dataset_filter() transformations. Here, you skip the first line, then filter to find only survivors.\n\ntitanic_file <- get_file(\n  \"train.csv\", \n  \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n)\ntitanic_lines <- text_line_dataset(titanic_file)\n\n\ntitanic_lines %>% \n  coro::collect(10) %>% \n  str()\n\nList of 10\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'0,male,22.0,1,0,7.25,Third,unknown,Southampton,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,38.0,1,0,71.2833,First,C,Cherbourg,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,26.0,0,0,7.925,Third,unknown,Southampton,y'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,35.0,1,0,53.1,First,C,Southampton,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'0,male,2.0,3,1,21.075,Third,unknown,Southampton,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n'>\n  [list output truncated]\n\n\n\nsurvived <- function(line) {\n  tf$not_equal(tf$strings$substr(line, 0L, 1L), \"0\")\n}\n\nsurvivors <- titanic_lines %>% \n  dataset_skip(1) %>% \n  dataset_filter(survived)\n\n\nsurvivors %>% \n  coro::collect(10) %>% \n  str()\n\nList of 10\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,38.0,1,0,71.2833,First,C,Cherbourg,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,26.0,0,0,7.925,Third,unknown,Southampton,y'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,35.0,1,0,53.1,First,C,Southampton,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,4.0,1,1,16.7,Third,G,Southampton,n'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,male,28.0,0,0,13.0,Second,unknown,Southampton,y'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'1,female,28.0,0,0,7.225,Third,unknown,Cherbourg,y'>\n  [list output truncated]\n\n\n\n\nConsuming CSV data\nSee Loading CSV Files, and Loading Data Frames for more examples.\nThe CSV file format is a popular format for storing tabular data in plain text.\nFor example:\n\ntitanic_file <- get_file(\n  \"train.csv\", \n  \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n)\n\n\ndf <- readr::read_csv(titanic_file)\n\nRows: 627 Columns: 10\n── Column specification ────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): sex, class, deck, embark_town, alone\ndbl (5): survived, age, n_siblings_spouses, parch, fare\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(df)\n\n# A tibble: 6 × 10\n  survived sex      age n_siblings_spou… parch  fare class deck  embark_town\n     <dbl> <chr>  <dbl>            <dbl> <dbl> <dbl> <chr> <chr> <chr>      \n1        0 male      22                1     0  7.25 Third unkn… Southampton\n2        1 female    38                1     0 71.3  First C     Cherbourg  \n3        1 female    26                0     0  7.92 Third unkn… Southampton\n4        1 female    35                1     0 53.1  First C     Southampton\n5        0 male      28                0     0  8.46 Third unkn… Queenstown \n6        0 male       2                3     1 21.1  Third unkn… Southampton\n# … with 1 more variable: alone <chr>\n\n\nIf your data fits in memory the same tensor_slices_dataset() method works on lists, allowing this data to be easily imported:\n\ntitanic_slices <- tensor_slices_dataset(df)\n\ntitanic_slices %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next() %>% \n  str()\n\nList of 10\n $ survived          :<tf.Tensor: shape=(), dtype=float32, numpy=0.0>\n $ sex               :<tf.Tensor: shape=(), dtype=string, numpy=b'male'>\n $ age               :<tf.Tensor: shape=(), dtype=float32, numpy=22.0>\n $ n_siblings_spouses:<tf.Tensor: shape=(), dtype=float32, numpy=1.0>\n $ parch             :<tf.Tensor: shape=(), dtype=float32, numpy=0.0>\n $ fare              :<tf.Tensor: shape=(), dtype=float32, numpy=7.25>\n $ class             :<tf.Tensor: shape=(), dtype=string, numpy=b'Third'>\n $ deck              :<tf.Tensor: shape=(), dtype=string, numpy=b'unknown'>\n  [list output truncated]\n\n\nA more scalable approach is to load from disk as necessary.\nThe tfdatasets package provides methods to extract records from one or more CSV files that comply with RFC 4180.\nThe experimental$make_csv_dataset function is the high level interface for reading sets of csv files. It supports column type inference and many other features, like batching and shuffling, to make usage simple.\n\ntitanic_batches <- tf$data$experimental$make_csv_dataset(\n  titanic_file, \n  batch_size = 4L,\n  label_name = \"survived\"\n)\n\n\ntitanic_batches %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next() %>% \n  str()\n\nList of 2\n $ :OrderedDict([('sex', <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'male', b'female', b'male', b'male'], dtype=object)>), ('age', <tf.Tensor: shape=(4,), dtype=float32, numpy=array([56., 28., 28., 40.], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>), ('parch', <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>), ('fare', <tf.Tensor: shape=(4,), dtype=float32, numpy=array([26.55, 33.  ,  0.  ,  0.  ], dtype=float32)>), ('class', <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'First', b'Second', b'Second', b'First'], dtype=object)>), ('deck', <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'B'], dtype=object)>), ('embark_town', <tf.Tensor: shape=(4,), dtype=string, numpy=\narray([b'Southampton', b'Southampton', b'Southampton', b'Southampton'],\n      dtype=object)>), ('alone', <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'y', b'y', b'y', b'y'], dtype=object)>)])\n $ :<tf.Tensor: shape=(4), dtype=int32, numpy=array([0, 1, 0, 0], dtype=int32)>\n\n\nYou can use the select_columns argument if you only need a subset of columns.\n\ntitanic_batches <- tf$data$experimental$make_csv_dataset(\n  titanic_file, \n  batch_size = 4L,\n  label_name = \"survived\", \n  select_columns = c('class', 'fare', 'survived')\n)\n\n\ntitanic_batches %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next() %>% \n  str()\n\nList of 2\n $ :OrderedDict([('fare', <tf.Tensor: shape=(4,), dtype=float32, numpy=array([69.55  , 51.8625,  7.225 , 16.1   ], dtype=float32)>), ('class', <tf.Tensor: shape=(4,), dtype=string, numpy=array([b'Third', b'First', b'Third', b'Third'], dtype=object)>)])\n $ :<tf.Tensor: shape=(4), dtype=int32, numpy=array([0, 1, 0, 0], dtype=int32)>\n\n\nThere is also a lower-level tf$experimental$CsvDataset class which provides finer grained control. It does not support column type inference. Instead you must specify the type of each column.\n\ntitanic_types  = list(tf$int32, tf$string, tf$float32, tf$int32, tf$int32, tf$float32, tf$string, tf$string, tf$string, tf$string)\ndataset <- tf$data$experimental$CsvDataset(titanic_file, titanic_types , header = TRUE)\n\ndataset %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next() %>% \n  str()\n\nList of 10\n $ :<tf.Tensor: shape=(), dtype=int32, numpy=0>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'male'>\n $ :<tf.Tensor: shape=(), dtype=float32, numpy=22.0>\n $ :<tf.Tensor: shape=(), dtype=int32, numpy=1>\n $ :<tf.Tensor: shape=(), dtype=int32, numpy=0>\n $ :<tf.Tensor: shape=(), dtype=float32, numpy=7.25>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'Third'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'unknown'>\n  [list output truncated]\n\n\nIf some columns are empty, this low-level interface allows you to provide default values instead of column types.\n\nwriteLines(con = \"missing.csv\", text = \n\"1,2,3,4\n,2,3,4\n1,,3,4\n1,2,,4\n1,2,3,\n,,,\"\n)\n\n\n# Creates a dataset that reads all of the records from two CSV files, each with\n# four float columns which may have missing values.\n\nrecord_defaults <- c(999,999,999,999)\ndataset <- tf$data$experimental$CsvDataset(\"missing.csv\", record_defaults)\ndataset <- dataset %>% \n  dataset_map(function(...) tf$stack(list(...)))\ndataset\n\n<MapDataset element_spec=TensorSpec(shape=(4,), dtype=tf.float32, name=None)>\n\n\n\ndataset %>% \n  coro::collect() %>% \n  str()\n\nList of 6\n $ :<tf.Tensor: shape=(4), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>\n $ :<tf.Tensor: shape=(4), dtype=float32, numpy=array([999.,   2.,   3.,   4.], dtype=float32)>\n $ :<tf.Tensor: shape=(4), dtype=float32, numpy=array([  1., 999.,   3.,   4.], dtype=float32)>\n $ :<tf.Tensor: shape=(4), dtype=float32, numpy=array([  1.,   2., 999.,   4.], dtype=float32)>\n $ :<tf.Tensor: shape=(4), dtype=float32, numpy=array([  1.,   2.,   3., 999.], dtype=float32)>\n $ :<tf.Tensor: shape=(4), dtype=float32, numpy=array([999., 999., 999., 999.], dtype=float32)>\n\n\nBy default, a CsvDataset yields every column of every line of the file, which may not be desirable, for example if the file starts with a header line that should be ignored, or if some columns are not required in the input. These lines and fields can be removed with the header and select_cols arguments respectively.\n\n# Creates a dataset that reads all of the records from two CSV files with\n# headers, extracting float data from columns 2 and 4.\nrecord_defaults <- c(999, 999) # Only provide defaults for the selected columns\ndataset <- tf$data$experimental$CsvDataset(\n  \"missing.csv\", \n  record_defaults, \n  select_cols = c(1L, 3L)\n)\ndataset <- dataset %>% \n  dataset_map(function(...) tf$stack(list(...)))\ndataset\n\n<MapDataset element_spec=TensorSpec(shape=(2,), dtype=tf.float32, name=None)>\n\n\n\ndataset %>% \n  coro::collect() %>% \n  str()\n\nList of 6\n $ :<tf.Tensor: shape=(2), dtype=float32, numpy=array([2., 4.], dtype=float32)>\n $ :<tf.Tensor: shape=(2), dtype=float32, numpy=array([2., 4.], dtype=float32)>\n $ :<tf.Tensor: shape=(2), dtype=float32, numpy=array([999.,   4.], dtype=float32)>\n $ :<tf.Tensor: shape=(2), dtype=float32, numpy=array([2., 4.], dtype=float32)>\n $ :<tf.Tensor: shape=(2), dtype=float32, numpy=array([  2., 999.], dtype=float32)>\n $ :<tf.Tensor: shape=(2), dtype=float32, numpy=array([999., 999.], dtype=float32)>\n\n\n\n\nConsuming sets of files\nThere are many datasets distributed as a set of files, where each file is an example.\n\nflowers_root <- get_file(\n  'flower_photos',\n  'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n  untar = TRUE\n)\n\nNote: these images are licensed CC-BY, see LICENSE.txt for details.\nThe root directory contains a directory for each class:\n\nfs::dir_ls(flowers_root)\n\n/Users/dfalbel/.keras/datasets/flower_photos/LICENSE.txt\n/Users/dfalbel/.keras/datasets/flower_photos/daisy\n/Users/dfalbel/.keras/datasets/flower_photos/dandelion\n/Users/dfalbel/.keras/datasets/flower_photos/roses\n/Users/dfalbel/.keras/datasets/flower_photos/sunflowers\n/Users/dfalbel/.keras/datasets/flower_photos/tulips\n\n\nThe files in each class directory are examples:\n\nlist_ds <- file_list_dataset(fs::path(flowers_root, \"*\", \"*\"))\nlist_ds %>% \n  dataset_take(5) %>% \n  coro::collect() %>% \n  str()\n\nList of 5\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'/Users/dfalbel/.keras/datasets/flower_photos/roses/15738649506_2b4c2fd933_m.jpg'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'/Users/dfalbel/.keras/datasets/flower_photos/tulips/14487712670_aebe715525_m.jpg'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'/Users/dfalbel/.keras/datasets/flower_photos/dandelion/18001393975_2a6acaabd8.jpg'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'/Users/dfalbel/.keras/datasets/flower_photos/dandelion/15644450971_6a28298454_n.jpg'>\n $ :<tf.Tensor: shape=(), dtype=string, numpy=b'/Users/dfalbel/.keras/datasets/flower_photos/tulips/18270448366_d5676dec64_z.jpg'>\n\n\nRead the data using the tf$io$read_file function and extract the label from the path, returning (image, label) pairs:\n\nprocess_path <- function(file_path) {\n  label <- tf$strings$split(file_path, \"/\")[-2]\n  list(\n    tf$io$read_file(file_path), \n    label\n  )\n}\n\nlabeled_ds <- list_ds %>% \n  dataset_map(process_path)\n\nWarning: Negative numbers are interpreted python-style when subsetting tensorflow tensors.\nSee: ?`[.tensorflow.tensor` for details.\nTo turn off this warning, set `options(tensorflow.extract.warn_negatives_pythonic = FALSE)`\n\n\n\nel <- labeled_ds %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next()\nel[[1]]$shape\n\nTensorShape([])\n\nel[[2]]\n\ntf.Tensor(b'dandelion', shape=(), dtype=string)"
  },
  {
    "objectID": "guides/data/data.html#batching-dataset-elements",
    "href": "guides/data/data.html#batching-dataset-elements",
    "title": "Build TensorFlow input pipelines",
    "section": "Batching dataset elements",
    "text": "Batching dataset elements\n\nSimple batching\nThe simplest form of batching stacks n consecutive elements of a dataset into a single element. The dataset_batch() transformation does exactly this, with the same constraints as the tf$stack() operator, applied to each component of the elements: ie. for each component i, all elements must have a tensor of the exact same shape.\n\ninc_dataset <- range_dataset(to = 100)\ndec_dataset <- range_dataset(0, -100, -1)\ndataset <- zip_datasets(inc_dataset, dec_dataset)\n\nbatched_dataset <- dataset %>% \n  dataset_batch(4)\n\nbatched_dataset %>% \n  coro::collect(4) %>% \n  str()\n\nList of 4\n $ :List of 2\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([0, 1, 2, 3])>\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([ 0, -1, -2, -3])>\n $ :List of 2\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([4, 5, 6, 7])>\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([-4, -5, -6, -7])>\n $ :List of 2\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([ 8,  9, 10, 11])>\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([ -8,  -9, -10, -11])>\n $ :List of 2\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([12, 13, 14, 15])>\n  ..$ :<tf.Tensor: shape=(4), dtype=int64, numpy=array([-12, -13, -14, -15])>\n\n\nWhile tfdatasets tries to propagate shape information, the default settings of dataset_batch result in an unknown batch size because the last batch may not be full. Note the NULLs in the shape:\n\nbatched_dataset\n\n<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n\n\nUse the drop_remainder argument to ignore that last batch, and get full shape propagation:\n\nbatched_dataset <- dataset %>% dataset_batch(7, drop_remainder = TRUE)\nbatched_dataset\n\n<BatchDataset element_spec=(TensorSpec(shape=(7,), dtype=tf.int64, name=None), TensorSpec(shape=(7,), dtype=tf.int64, name=None))>\n\n\n\n\nBatching tensors with padding\nThe above recipe works for tensors that all have the same size. However, many models (e.g. sequence models) work with input data that can have varying size (e.g. sequences of different lengths). To handle this case, the dataset_padded_batch() transformation enables you to batch tensors of different shape by specifying one or more dimensions in which they may be padded.\n\ndataset <- range_dataset(to = 100)\ndataset <- dataset %>% \n  dataset_map(function(x) tf$fill(list(tf$cast(x, tf$int32)), x)) %>% \n  dataset_padded_batch(4, padded_shapes = shape(NULL))\n\ndataset %>% \n  coro::collect(2) %>% \n  str()\n\nList of 2\n $ :<tf.Tensor: shape=(4, 3), dtype=int64, numpy=…>\n $ :<tf.Tensor: shape=(4, 7), dtype=int64, numpy=…>\n\n\nThe dataset_padded_batch() transformation allows you to set different padding for each dimension of each component, and it may be variable-length (signified by NULL in the example above) or constant-length. It is also possible to override the padding value, which defaults to 0."
  },
  {
    "objectID": "guides/data/data.html#training-workflows",
    "href": "guides/data/data.html#training-workflows",
    "title": "Build TensorFlow input pipelines",
    "section": "Training workflows",
    "text": "Training workflows\n\nProcessing multiple epochs\nThe tfdatasets API offers two main ways to process multiple epochs of the same data.\nThe simplest way to iterate over a dataset in multiple epochs is to use the dataset_repeat() transformation. First, create a dataset of titanic data:\n\ntitanic_file <- get_file(\n  \"train.csv\", \n  \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n)\ntitanic_lines <- text_line_dataset(titanic_file)\n\n\nplot_batch_sizes <- function(ds) {    \n  batch_sizes <- ds %>% \n    coro::collect() %>% \n    sapply(function(x) as.numeric(x$shape[1]))\n  plot(seq_along(batch_sizes), batch_sizes)\n}\n\nApplying the dataset_repeat() transformation with no arguments will repeat the input indefinitely.\nThe dataset_repeat() transformation concatenates its arguments without signaling the end of one epoch and the beginning of the next epoch. Because of this a dataset_batch() applied after dataset_repeat() will yield batches that straddle epoch boundaries:\n\ntitanic_batches <- titanic_lines %>% \n  dataset_repeat(3) %>% \n  dataset_batch(128)\nplot_batch_sizes(titanic_batches)\n\n\n\n\nIf you need clear epoch separation, put dataset_batch() before the repeat:\n\ntitanic_batches <- titanic_lines %>% \n  dataset_batch(128) %>% \n  dataset_repeat(3)\n\nplot_batch_sizes(titanic_batches)\n\n\n\n\nIf you would like to perform a custom computation (e.g. to collect statistics) at the end of each epoch then it’s simplest to restart the dataset iteration on each epoch:\n\nepochs <- 3\ndataset <- titanic_lines %>% \n  dataset_batch(128)\n\nfor(epoch in seq_len(epochs)) {\n  coro::loop(for(batch in dataset) {\n    print(batch$shape)\n  })\n  cat(\"End of epoch \", epoch, \"\\n\")\n}\n\nTensorShape([128])\nTensorShape([128])\nTensorShape([128])\nTensorShape([128])\nTensorShape([116])\nEnd of epoch  1 \nTensorShape([128])\nTensorShape([128])\nTensorShape([128])\nTensorShape([128])\nTensorShape([116])\nEnd of epoch  2 \nTensorShape([128])\nTensorShape([128])\nTensorShape([128])\nTensorShape([128])\nTensorShape([116])\nEnd of epoch  3 \n\n\n\n\nRandomly shuffling input data\nThe dataset_shuffle() transformation maintains a fixed-size buffer and chooses the next element uniformly at random from that buffer.\nNote: While large buffer_sizes shuffle more thoroughly, they can take a lot of memory, and significant time to fill. Consider using dataset_interleave() across files if this becomes a problem.\nAdd an index to the dataset so you can see the effect:\n\nlines <- text_line_dataset(titanic_file)\ncounter <- tf$data$experimental$Counter()\n\ndataset <- zip_datasets(counter, lines)\ndataset <- dataset %>% \n  dataset_shuffle(buffer_size = 100) %>% \n  dataset_batch(20)\ndataset\n\n<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None))>\n\n\nSince the buffer_size is 100, and the batch size is 20, the first batch contains no elements with an index over 120.\n\nline_batch <- coro::collect(dataset, 1)\nline_batch[[1]][[1]]\n\ntf.Tensor(\n[ 85  99  61  25  78 102  81  11  32  49   0   6  39  87  36  33  44  70\n  56  24], shape=(20), dtype=int64)\n\n\nAs with dataset_batch() the order relative to dataset_repeat() matters.\ndataset_shuffle() doesn’t signal the end of an epoch until the shuffle buffer is empty. So a shuffle placed before a repeat will show every element of one epoch before moving to the next:\n\ndataset <- zip_datasets(counter, lines)\nshuffled <- dataset %>% \n  dataset_shuffle(buffer_size = 100) %>% \n  dataset_batch(10) %>% \n  dataset_repeat(2)\n\ncat(\"Here are the item ID's near the epoch boundary:\\n\")\n\nHere are the item ID's near the epoch boundary:\n\nshuffled %>% \n  dataset_skip(60) %>% \n  dataset_take(5) %>% \n  dataset_collect() %>% \n  lapply(function(x) x[[1]])\n\n[[1]]\ntf.Tensor([617 498 594 517 576 611 497 603 580 595], shape=(10), dtype=int64)\n\n[[2]]\ntf.Tensor([499 555 556 453 441 599 346 604 531 622], shape=(10), dtype=int64)\n\n[[3]]\ntf.Tensor([621 424 312 536 614 554 501 533], shape=(8), dtype=int64)\n\n[[4]]\ntf.Tensor([ 8 71 81 39 73 63 30 97 56  0], shape=(10), dtype=int64)\n\n[[5]]\ntf.Tensor([ 49   1 102 104  19  18  89  47 114   6], shape=(10), dtype=int64)\n\n\n\nshuffle_repeat <- shuffled %>% \n  coro::collect() %>% \n  sapply(function(x) mean(as.numeric(x[[1]])))\nplot(shuffle_repeat)\n\n\n\n\nBut a repeat before a shuffle mixes the epoch boundaries together:\n\ndataset <- zip_datasets(counter, lines)\nshuffled <- dataset %>% \n  dataset_repeat(2) %>% \n  dataset_shuffle(buffer_size = 100) %>% \n  dataset_batch(10)\n\ncat(\"Here are the item ID's near the epoch boundary:\\n\")\n\nHere are the item ID's near the epoch boundary:\n\nshuffled %>% \n  dataset_skip(55) %>% \n  dataset_take(15) %>% \n  coro::collect() %>% \n  lapply(function(x) x[[1]]) %>% \n  str()\n\nList of 15\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([603, 615, 590, 135, 485, 621, 475, 624, 575, 584])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([ 14, 552, 497,  11, 614, 548,  37,  18, 535,  28])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([544, 474, 607, 576, 609,  24, 580, 578, 512,  44])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([538, 599,  40,  51,  47, 554,  50, 564, 509,  29])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([ 61,  59, 561, 522, 534,  33,  36, 581,  17, 533])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([  3, 625, 583, 525,  42,  73, 553, 300,  57, 311])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([559,  70,  46, 460,  75, 573,  22,  85, 600, 598])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([ 43,  71,  90,   7, 570, 602,  67,  35,  27,  10])>\n  [list output truncated]\n\n\n\nrepeat_shuffle <- shuffled %>% \n  coro::collect() %>% \n  sapply(function(x) mean(as.numeric(x[[1]])))\nplot(repeat_shuffle)"
  },
  {
    "objectID": "guides/data/data.html#preprocessing-data",
    "href": "guides/data/data.html#preprocessing-data",
    "title": "Build TensorFlow input pipelines",
    "section": "Preprocessing data",
    "text": "Preprocessing data\nThe dataset_map(f) transformation produces a new dataset by applying a given function f to each element of the input dataset. It is based on the map() function that is commonly applied to lists (and other structures) in functional programming languages. The function f takes the tf$Tensor objects that represent a single element in the input, and returns the tf$Tensor objects that will represent a single element in the new dataset. Its implementation uses standard TensorFlow operations to transform one element into another.\nThis section covers common examples of how to use dataset_map().\n\nDecoding image data and resizing it\n\nWhen training a neural network on real-world image data, it is often necessary to convert images of different sizes to a common size, so that they may be batched into a fixed size.\nRebuild the flower filenames dataset:\n\nlist_ds <- file_list_dataset(file.path(flowers_root, \"*\", \"*\"))\n\nWrite a function that manipulates the dataset elements.\n\n# Reads an image from a file, decodes it into a dense tensor, and resizes it\n# to a fixed shape.\n\nparse_image <- function(filename) {\n  parts <- tf$strings$split(filename, \"/\")\n  label <- parts[-2]\n\n  image <- tf$io$read_file(filename)\n  image <- tf$io$decode_jpeg(image)\n  image <- tf$image$convert_image_dtype(image, tf$float32)\n  image <- tf$image$resize(image, shape(128, 128))\n  \n  list(image, label)\n}\n\nTest that it works.\n\nparsed <- list_ds %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next() %>% \n  parse_image()\n\nshow <- function(parsed, maxcolor=1) {  \n  plot(as.raster(as.array(parsed[[1]]), max = maxcolor))\n  title(as.character(parsed[[2]]))\n}\n\nshow(parsed)\n\n\n\n\nMap it over the dataset.\n\nimages_ds <- list_ds %>% \n  dataset_map(parse_image)\n\nimages_ds %>% \n  dataset_take(2) %>% \n  coro::collect() %>% \n  lapply(show)\n\n\n\n\n\n\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParsing tf$Example protocol buffer messages\nMany input pipelines extract tf$train$Example protocol buffer messages from a TFRecord format. Each tf$train$Example record contains one or more “features”, and the input pipeline typically converts these features into tensors.\n\nfsns_test_file <- get_file(\n  \"fsns.tfrec\", \n  \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\"\n)\ndataset <- tfrecord_dataset(filenames = fsns_test_file)\ndataset\n\n<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n\n\nYou can work with tf$train$Example protos outside of a tf$data$Dataset to understand the data:\n\nraw_example <- dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\nparsed <- tf$train$Example$FromString(raw_example$numpy())\n\nfeature <- parsed$features$feature\nraw_img <- feature['image/encoded']$bytes_list$value[0]\nimg <- tf$image$decode_png(raw_img)\nimg %>% \n  as.array() %>% \n  as.raster(max = 255) %>% \n  plot()\n\n\n\n\n\nraw_example <- dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n\n\ntf_parse <- function(eg) {\n  example <- tf$io$parse_example(\n      eg[tf$newaxis], \n      reticulate::dict(\n        'image/encoded' = tf$io$FixedLenFeature(shape = shape(), dtype = tf$string),\n        'image/text' = tf$io$FixedLenFeature(shape = shape(), dtype = tf$string)\n      )\n  )\n  out <- list(example[['image/encoded']][1], example[['image/text']][1])\n  out[[1]] <- tf$image$decode_png(out[[1]])\n  out\n}\n\n\nexample <- tf_parse(raw_example)\nprint(as.character(example[[2]]))\n\n[1] \"Rue Perreyon\"\n\nshow(example, maxcolor = 255)\n\n\n\n\n\ndecoded <- dataset %>% \n  dataset_map(tf_parse)\ndecoded\n\n<MapDataset element_spec=(TensorSpec(shape=(None, None, None), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>\n\n\n\ndecoded %>% \n  dataset_batch(10) %>% \n  coro::collect(1) %>% \n  str()\n\nList of 1\n $ :List of 2\n  ..$ :<tf.Tensor: shape=(10, 150, 600, 3), dtype=uint8, numpy=…>\n  ..$ :<tf.Tensor: shape=(10), dtype=string, numpy=…>\n\n\n\n\nTime series windowing\nFor an end to end time series example see: Time series forecasting. Time series data is often organized with the time axis intact. Use a simple range_dataset() to demonstrate:\n\nrange_ds <- range_dataset(to = 100000)\n\nTypically, models based on this sort of data will want a contiguous time slice. The simplest approach would be to batch the data:\n\nUsing batch\n\nbatches <- range_ds %>% \n  dataset_batch(10, drop_remainder = TRUE)\n\nbatches %>% coro::collect(5) %>% str()\n\nList of 5\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])>\n\n\nOr to make dense predictions one step into the future, you might shift the features and labels by one step relative to each other:\n\ndense_1_step <- function(batch) {\n  # Shift features and labels one step relative to each other.\n  list(batch[NULL:-1], batch[2:NULL])\n}\n  \npredict_dense_1_step <- batches %>% dataset_map(dense_1_step)\n\npredict_dense_1_step %>% \n  coro::collect(3)\n\n[[1]]\n[[1]][[1]]\ntf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10), dtype=int64)\n\n[[1]][[2]]\ntf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9), dtype=int64)\n\n\n[[2]]\n[[2]][[1]]\ntf.Tensor([10 11 12 13 14 15 16 17 18 19], shape=(10), dtype=int64)\n\n[[2]][[2]]\ntf.Tensor([11 12 13 14 15 16 17 18 19], shape=(9), dtype=int64)\n\n\n[[3]]\n[[3]][[1]]\ntf.Tensor([20 21 22 23 24 25 26 27 28 29], shape=(10), dtype=int64)\n\n[[3]][[2]]\ntf.Tensor([21 22 23 24 25 26 27 28 29], shape=(9), dtype=int64)\n\n\nTo predict a whole window instead of a fixed offset you can split the batches into two parts:\n\nbatches <- range_ds %>% \n  dataset_batch(15, drop_remainder = TRUE)\n\nlabel_next_5_steps <- function(batch) {\n list(\n   batch[NULL:-6],# Inputs: All except the last 5 steps\n   batch[-5:NULL] # Labels: The last 5 steps\n )   \n}\n\npredict_5_steps <- batches %>% dataset_map(label_next_5_steps)\n\npredict_5_steps %>% coro::collect(3)\n\n[[1]]\n[[1]][[1]]\ntf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10), dtype=int64)\n\n[[1]][[2]]\ntf.Tensor([10 11 12 13 14], shape=(5), dtype=int64)\n\n\n[[2]]\n[[2]][[1]]\ntf.Tensor([15 16 17 18 19 20 21 22 23 24], shape=(10), dtype=int64)\n\n[[2]][[2]]\ntf.Tensor([25 26 27 28 29], shape=(5), dtype=int64)\n\n\n[[3]]\n[[3]][[1]]\ntf.Tensor([30 31 32 33 34 35 36 37 38 39], shape=(10), dtype=int64)\n\n[[3]][[2]]\ntf.Tensor([40 41 42 43 44], shape=(5), dtype=int64)\n\n\nTo allow some overlap between the features of one batch and the labels of another, use zip_datasets():\n\nfeature_length <- 10\nlabel_length <- 3\n\nfeatures <- range_ds %>% \n  dataset_batch(feature_length, drop_remainder = TRUE)\nlabels <- range_ds %>% \n  dataset_batch(feature_length) %>% \n  dataset_skip(1) %>% \n  dataset_map(function(labels) labels[NULL:label_length])\n\npredicted_steps <- zip_datasets(features, labels)\ncoro::collect(predicted_steps, 5)\n\n[[1]]\n[[1]][[1]]\ntf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10), dtype=int64)\n\n[[1]][[2]]\ntf.Tensor([10 11 12], shape=(3), dtype=int64)\n\n\n[[2]]\n[[2]][[1]]\ntf.Tensor([10 11 12 13 14 15 16 17 18 19], shape=(10), dtype=int64)\n\n[[2]][[2]]\ntf.Tensor([20 21 22], shape=(3), dtype=int64)\n\n\n[[3]]\n[[3]][[1]]\ntf.Tensor([20 21 22 23 24 25 26 27 28 29], shape=(10), dtype=int64)\n\n[[3]][[2]]\ntf.Tensor([30 31 32], shape=(3), dtype=int64)\n\n\n[[4]]\n[[4]][[1]]\ntf.Tensor([30 31 32 33 34 35 36 37 38 39], shape=(10), dtype=int64)\n\n[[4]][[2]]\ntf.Tensor([40 41 42], shape=(3), dtype=int64)\n\n\n[[5]]\n[[5]][[1]]\ntf.Tensor([40 41 42 43 44 45 46 47 48 49], shape=(10), dtype=int64)\n\n[[5]][[2]]\ntf.Tensor([50 51 52], shape=(3), dtype=int64)\n\n\n\n\nUsing window\nWhile using dataset_batch works, there are situations where you may need finer control. The dataset_window() method gives you complete control, but requires some care: it returns a Dataset of Datasets. See Dataset structure for details.\n\nwindow_size <- 5\nwindows <- range_ds %>% \n  dataset_window(window_size, shift = 1)\ncoro::collect(windows, 5)\n\n[[1]]\n<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n\n[[2]]\n<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n\n[[3]]\n<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n\n[[4]]\n<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n\n[[5]]\n<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n\n\nThe dataset_flat_map method can take a dataset of datasets and flatten it into a single dataset:\n\nwindows %>% \n  dataset_flat_map(function(x) x) %>% \n  dataset_take(30) %>% \n  coro::collect()\n\n[[1]]\ntf.Tensor(0, shape=(), dtype=int64)\n\n[[2]]\ntf.Tensor(1, shape=(), dtype=int64)\n\n[[3]]\ntf.Tensor(2, shape=(), dtype=int64)\n\n[[4]]\ntf.Tensor(3, shape=(), dtype=int64)\n\n[[5]]\ntf.Tensor(4, shape=(), dtype=int64)\n\n[[6]]\ntf.Tensor(1, shape=(), dtype=int64)\n\n[[7]]\ntf.Tensor(2, shape=(), dtype=int64)\n\n[[8]]\ntf.Tensor(3, shape=(), dtype=int64)\n\n[[9]]\ntf.Tensor(4, shape=(), dtype=int64)\n\n[[10]]\ntf.Tensor(5, shape=(), dtype=int64)\n\n[[11]]\ntf.Tensor(2, shape=(), dtype=int64)\n\n[[12]]\ntf.Tensor(3, shape=(), dtype=int64)\n\n[[13]]\ntf.Tensor(4, shape=(), dtype=int64)\n\n[[14]]\ntf.Tensor(5, shape=(), dtype=int64)\n\n[[15]]\ntf.Tensor(6, shape=(), dtype=int64)\n\n[[16]]\ntf.Tensor(3, shape=(), dtype=int64)\n\n[[17]]\ntf.Tensor(4, shape=(), dtype=int64)\n\n[[18]]\ntf.Tensor(5, shape=(), dtype=int64)\n\n[[19]]\ntf.Tensor(6, shape=(), dtype=int64)\n\n[[20]]\ntf.Tensor(7, shape=(), dtype=int64)\n\n[[21]]\ntf.Tensor(4, shape=(), dtype=int64)\n\n[[22]]\ntf.Tensor(5, shape=(), dtype=int64)\n\n[[23]]\ntf.Tensor(6, shape=(), dtype=int64)\n\n[[24]]\ntf.Tensor(7, shape=(), dtype=int64)\n\n[[25]]\ntf.Tensor(8, shape=(), dtype=int64)\n\n[[26]]\ntf.Tensor(5, shape=(), dtype=int64)\n\n[[27]]\ntf.Tensor(6, shape=(), dtype=int64)\n\n[[28]]\ntf.Tensor(7, shape=(), dtype=int64)\n\n[[29]]\ntf.Tensor(8, shape=(), dtype=int64)\n\n[[30]]\ntf.Tensor(9, shape=(), dtype=int64)\n\n\nIn nearly all cases, you will want to .batch the dataset first:\n\nsub_to_batch <- function(sub) {\n  sub %>% \n    dataset_batch(window_size, drop_remainder = TRUE)\n}\n\nwindows %>% \n  dataset_flat_map(sub_to_batch) %>% \n  dataset_take(5) %>% \n  coro::collect()\n\n[[1]]\ntf.Tensor([0 1 2 3 4], shape=(5), dtype=int64)\n\n[[2]]\ntf.Tensor([1 2 3 4 5], shape=(5), dtype=int64)\n\n[[3]]\ntf.Tensor([2 3 4 5 6], shape=(5), dtype=int64)\n\n[[4]]\ntf.Tensor([3 4 5 6 7], shape=(5), dtype=int64)\n\n[[5]]\ntf.Tensor([4 5 6 7 8], shape=(5), dtype=int64)\n\n\nNow, you can see that the shift argument controls how much each window moves over. Putting this together you might write this function:\n\nmake_window_dataset <- function(ds, window_size = 5, shift = 1, stride = 1) {\n  windows <- ds %>% \n    dataset_window(window_size, shift = shift, stride = stride)\n\n  sub_to_batch <- function(sub) {\n    sub %>% \n      dataset_batch(window_size, drop_remainder = TRUE)\n  }\n  \n  windows %>% \n    dataset_flat_map(sub_to_batch)\n}\n\n\nds <- make_window_dataset(range_ds, window_size = 10, shift = 5, stride = 3)\ncoro::collect(ds, 10) %>% \n  str()\n\nList of 10\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([ 5,  8, 11, 14, 17, 20, 23, 26, 29, 32])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([10, 13, 16, 19, 22, 25, 28, 31, 34, 37])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([15, 18, 21, 24, 27, 30, 33, 36, 39, 42])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([20, 23, 26, 29, 32, 35, 38, 41, 44, 47])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([25, 28, 31, 34, 37, 40, 43, 46, 49, 52])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([30, 33, 36, 39, 42, 45, 48, 51, 54, 57])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([35, 38, 41, 44, 47, 50, 53, 56, 59, 62])>\n  [list output truncated]\n\n\nThen it’s easy to extract labels, as before:\n\ndense_labels_ds <- ds %>% \n  dataset_map(dense_1_step)\n\ncoro::collect(dense_labels_ds, 1)\n\n[[1]]\n[[1]][[1]]\ntf.Tensor([ 0  3  6  9 12 15 18 21 24 27], shape=(10), dtype=int64)\n\n[[1]][[2]]\ntf.Tensor([ 3  6  9 12 15 18 21 24 27], shape=(9), dtype=int64)\n\n\n\n\n\nResampling\nWhen working with a dataset that is very class-imbalanced, you may want to resample the dataset. tfdatasets provides two methods to do this. The credit card fraud dataset is a good example of this sort of problem.\nNote: See Imbalanced Data for a full tutorial.\n\nzip_path <- get_file(\n  origin = 'https://storage.googleapis.com/download.tensorflow.org/data/creditcard.zip',\n  fname = 'creditcard.zip',\n  extract = TRUE\n)\n\ncsv_path <- gsub(\"zip\", \"csv\", zip_path)\n\n\ncreditcard_ds <- tf$data$experimental$make_csv_dataset(\n  csv_path, \n  batch_size = 1024L, \n  label_name = \"Class\",\n  # Set the column types: 30 floats and an int.\n  column_defaults = c(lapply(seq_len(30), function(x) tf$float32), tf$int64)\n)\n\nNow, check the distribution of classes, it is highly skewed:\n\ncount <- function(counts, batch) {\n  \n  class_1 <- batch[[2]] == 1\n  class_1 <- tf$cast(class_1, tf$int32)\n\n  class_0 <- batch[[2]] == 0\n  class_0 <- tf$cast(class_0, tf$int32)\n\n  counts[['class_0']] <- counts[['class_0']] + tf$reduce_sum(class_0)\n  counts[['class_1']] <- counts[['class_1']] + tf$reduce_sum(class_1)\n\n  counts\n}\n\n\ncounts <- creditcard_ds %>% \n  dataset_take(10) %>% \n  dataset_reduce(\n    initial_state = list('class_0' = 0L, 'class_1' = 0L),\n    reduce_func = count\n  )\n\ncounts\n\n$class_0\ntf.Tensor(10196, shape=(), dtype=int32)\n\n$class_1\ntf.Tensor(44, shape=(), dtype=int32)\n\n\nA common approach to training with an imbalanced dataset is to balance it. tfdatasets includes a few methods which enable this workflow:\n\nDatasets sampling\nOne approach to resampling a dataset is to use sample_from_datasets. This is more applicable when you have a separate data$Dataset for each class.\nHere, just use filter to generate them from the credit card fraud data:\n\nnegative_ds <- creditcard_ds %>% \n  dataset_unbatch() %>% \n  dataset_filter(function(features, label) label == 0) %>% \n  dataset_repeat()\n  \npositive_ds <- creditcard_ds %>% \n  dataset_unbatch() %>% \n  dataset_filter(function(features, label) label == 1) %>% \n  dataset_repeat()\n\n\npositive_ds %>% \n  coro::collect(1)\n\n[[1]]\n[[1]][[1]]\nDict (30 items)\n\n[[1]][[2]]\ntf.Tensor(1, shape=(), dtype=int64)\n\n\nTo use sample_from_datasets pass the datasets, and the weight for each:\n\nbalanced_ds <- list(negative_ds, positive_ds) %>% \n  sample_from_datasets(c(0.5, 0.5)) %>% \n  dataset_batch(10)\n\nNow the dataset produces examples of each class with 50/50 probability:\n\nbalanced_ds %>% \n  dataset_map(function(x, y) y) %>% \n  coro::collect(10) %>% \n  str()\n\nList of 10\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 0, 1, 0, 0, 0, 1, 0, 1, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 0, 0, 1, 1, 0, 1, 0, 0, 0])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 0, 1, 1, 1, 1, 0, 0, 1, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([0, 1, 1, 0, 0, 0, 1, 0, 1, 0])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 1, 0, 1, 1, 1, 1, 0, 1, 0])>\n  [list output truncated]\n\n\n\n\nRejection resampling\nOne problem with the above sample_from_datasets approach is that it needs a separate TensorFlow Dataset per class. You could use dataset_filter to create those two datasets, but that results in all the data being loaded twice.\nThe dataset_rejection_resample() method can be applied to a dataset to rebalance it, while only loading it once. Elements will be dropped from the dataset to achieve balance.\ndataset_rejection_resample() takes a class_func argument. This class_func is applied to each dataset element, and is used to determine which class an example belongs to for the purposes of balancing.\nThe goal here is to balance the lable distribution, and the elements of creditcard_ds are already (features, label) pairs. So the class_func just needs to return those labels:\n\nclass_func <- function(features, label) { \n  label\n}\n\nThe resampling method deals with individual examples, so in this case you must unbatch the dataset before applying that method.\nThe method needs a target distribution, and optionally an initial distribution estimate as inputs.\n\nresample_ds <- creditcard_ds %>% \n  dataset_unbatch() %>% \n  dataset_rejection_resample(\n    class_func, \n    target_dist = c(0.5,0.5),\n    initial_dist = prop.table(sapply(counts, as.numeric))\n  ) %>% \n  dataset_batch(10)\n\nThe dataset_rejection_resample() method returns (class, example) pairs where the class is the output of the class_func. In this case, the example was already a (feature, label) pair, so use map to drop the extra copy of the labels:\n\nbalanced_ds <- resample_ds %>% \n  dataset_map(function(extra_label, features_and_label) features_and_label)\n\nNow the dataset produces examples of each class with 50/50 probability:\n\nbalanced_ds %>% \n  dataset_map(function(feat, label) label) %>% \n  coro::collect(10) %>% \n  str()\n\nList of 10\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([0, 1, 0, 1, 0, 1, 1, 1, 1, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 0, 0, 0, 1, 0, 0, 1, 1, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([0, 0, 1, 1, 0, 1, 1, 0, 0, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([0, 0, 1, 0, 0, 1, 0, 1, 1, 0])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([0, 0, 0, 0, 1, 0, 1, 1, 1, 0])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 1, 0, 0, 1, 0, 1, 1, 0, 1])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([1, 0, 1, 1, 1, 0, 1, 1, 0, 0])>\n $ :<tf.Tensor: shape=(10), dtype=int64, numpy=array([0, 1, 1, 1, 0, 1, 0, 0, 0, 0])>\n  [list output truncated]"
  },
  {
    "objectID": "guides/data/data.html#iterator-checkpointing",
    "href": "guides/data/data.html#iterator-checkpointing",
    "title": "Build TensorFlow input pipelines",
    "section": "Iterator Checkpointing",
    "text": "Iterator Checkpointing\nTensorflow supports taking checkpoints so that when your training process restarts it can restore the latest checkpoint to recover most of its progress. In addition to checkpointing the model variables, you can also checkpoint the progress of the dataset iterator. This could be useful if you have a large dataset and don’t want to start the dataset from the beginning on each restart. Note however that iterator checkpoints may be large, since transformations such as shuffle and prefetch require buffering elements within the iterator.\nTo include your iterator in a checkpoint, pass the iterator to the tf$train$Checkpoint constructor.\n\nrange_ds <- range_dataset(to = 20)\niterator <- reticulate::as_iterator(range_ds)\nckpt <- tf$train$Checkpoint(step = tf$Variable(0), iterator = iterator)\nmanager <- tf$train$CheckpointManager(ckpt, '/tmp/my_ckpt', max_to_keep = 3)\n\nfor (i in 1:5) {\n  print(reticulate::iter_next(iterator))\n}\n\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(3, shape=(), dtype=int64)\ntf.Tensor(4, shape=(), dtype=int64)\n\nsave_path <- manager$save()\n\nfor (i in 1:5) {\n  print(reticulate::iter_next(iterator))\n}\n\ntf.Tensor(5, shape=(), dtype=int64)\ntf.Tensor(6, shape=(), dtype=int64)\ntf.Tensor(7, shape=(), dtype=int64)\ntf.Tensor(8, shape=(), dtype=int64)\ntf.Tensor(9, shape=(), dtype=int64)\n\nckpt$restore(manager$latest_checkpoint)\n\n<tensorflow.python.training.tracking.util.CheckpointLoadStatus object at 0x7fb91205afd0>\n\nfor (i in 1:5) {\n  print(reticulate::iter_next(iterator))\n}\n\ntf.Tensor(5, shape=(), dtype=int64)\ntf.Tensor(6, shape=(), dtype=int64)\ntf.Tensor(7, shape=(), dtype=int64)\ntf.Tensor(8, shape=(), dtype=int64)\ntf.Tensor(9, shape=(), dtype=int64)\n\n\nNote: It is not possible to checkpoint an iterator which relies on external state such as a tf$py_function. Attempting to do so will raise an exception complaining about the external state."
  },
  {
    "objectID": "guides/data/data.html#using-tfdatasets-with-keras",
    "href": "guides/data/data.html#using-tfdatasets-with-keras",
    "title": "Build TensorFlow input pipelines",
    "section": "Using tfdatasets with Keras",
    "text": "Using tfdatasets with Keras\nThe Keras API simplifies many aspects of creating and executing machine learning models. Its fit() and evaluate() and predict() APIs support datasets as inputs. Here is a quick dataset and model setup:\n\nc(train, test) %<-% dataset_fashion_mnist()\n\n\nfmnist_train_ds <- train %>% \n  tensor_slices_dataset() %>% \n  dataset_map(unname) %>% \n  dataset_shuffle(5000) %>% \n  dataset_batch(32)\n\nmodel <- keras_model_sequential() %>% \n  layer_rescaling(scale = 1/255) %>% \n  layer_flatten() %>% \n  layer_dense(10)\n\nmodel %>% compile(\n  optimizer = 'adam',\n  loss = loss_sparse_categorical_crossentropy(from_logits = TRUE), \n  metrics = 'accuracy'\n)\n\nPassing a dataset of (feature, label) pairs is all that’s needed for fit() and evaluate():\n\nmodel %>% fit(fmnist_train_ds, epochs = 2)\n\nIf you pass an infinite dataset, for example by calling dataset_repeat(), you just need to also pass the steps_per_epoch argument:\n\nmodel %>% fit(\n  fmnist_train_ds %>% dataset_repeat(), \n  epochs = 2, \n  steps_per_epoch = 20\n)\n\nFor evaluation you can pass the number of evaluation steps:\n\nmodel %>% evaluate(fmnist_train_ds)\n\n     loss  accuracy \n0.4346840 0.8509333 \n\n\nFor long datasets, set the number of steps to evaluate:\n\nmodel %>% evaluate(\n  fmnist_train_ds %>% dataset_repeat(), \n  steps = 10\n)\n\n     loss  accuracy \n0.3874657 0.8562500 \n\n\nThe labels are not required in when calling Model$predict.\n\npredict_ds <- tensor_slices_dataset(train$x) %>% \n  dataset_batch(32)\nresult <- predict(model, predict_ds, steps = 10)\ndim(result)\n\n[1] 320  10\n\n\nBut the labels are ignored if you do pass a dataset containing them:\n\nresult <- predict(model, fmnist_train_ds, steps = 10)\ndim(result)\n\n[1] 320  10"
  },
  {
    "objectID": "guides/data/data.html#environment-details",
    "href": "guides/data/data.html#environment-details",
    "title": "Build TensorFlow input pipelines",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                                     \"Daniels-MBP\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html",
    "href": "guides/keras/customizing_what_happens_in_fit.html",
    "title": "Customizing what happens in fit()",
    "section": "",
    "text": "When you’re doing supervised learning, you can use fit() and everything works smoothly.\nWhen you need to write your own training loop from scratch, you can use the GradientTape and take control of every little detail.\nBut what if you need a custom training algorithm, but you still want to benefit from the convenient features of fit(), such as callbacks, built-in distribution support, or step fusing?\nA core principle of Keras is progressive disclosure of complexity. You should always be able to get into lower-level workflows in a gradual way. You shouldn’t fall off a cliff if the high-level functionality doesn’t exactly match your use case. You should be able to gain more control over the small details while retaining a commensurate amount of high-level convenience.\nWhen you need to customize what fit() does, you should override the training step function of the Model class. This is the function that is called by fit() for every batch of data. You will then be able to call fit() as usual – and it will be running your own learning algorithm.\nNote that this pattern does not prevent you from building models with the Functional API. You can do this whether you’re building Sequential models, Functional API models, or subclassed models.\nLet’s see how that works."
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html#setup",
    "href": "guides/keras/customizing_what_happens_in_fit.html#setup",
    "title": "Customizing what happens in fit()",
    "section": "Setup",
    "text": "Setup\nRequires TensorFlow 2.2 or later.\n\nlibrary(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html#a-first-simple-example",
    "href": "guides/keras/customizing_what_happens_in_fit.html#a-first-simple-example",
    "title": "Customizing what happens in fit()",
    "section": "A first simple example",
    "text": "A first simple example\nLet’s start from a simple example:\n\nWe create a new model class by calling new_model_class().\nWe just override the method train_step(data).\nWe return a dictionary mapping metric names (including the loss) to their current value.\n\nThe input argument data is what gets passed to fit as training data:\n\nIf you pass arrays, by calling fit(x, y, ...), then data will be the tuple (x, y)\nIf you pass a tf$data$Dataset, by calling fit(dataset, ...), then data will be what gets yielded by dataset at each batch.\n\nIn the body of the train_step method, we implement a regular training update, similar to what you are already familiar with. Importantly, we compute the loss via self$compiled_loss, which wraps the loss(es) function(s) that were passed to compile().\nSimilarly, we call self$compiled_metrics$update_state(y, y_pred) to update the state of the metrics that were passed in compile(), and we query results from self$metrics at the end to retrieve their current value.\n\nCustomModel <- new_model_class(\n  classname = \"CustomModel\",\n  train_step = function(data) {\n    # Unpack the data. Its structure depends on your model and\n    # on what you pass to `fit()`.\n    c(x, y) %<-% data\n    \n    with(tf$GradientTape() %as% tape, {\n      y_pred <- self(x, training = TRUE)  # Forward pass\n      # Compute the loss value\n      # (the loss function is configured in `compile()`)\n      loss <-\n        self$compiled_loss(y, y_pred, regularization_losses = self$losses)\n    })\n    \n    # Compute gradients\n    trainable_vars <- self$trainable_variables\n    gradients <- tape$gradient(loss, trainable_vars)\n    # Update weights\n    self$optimizer$apply_gradients(zip_lists(gradients, trainable_vars))\n    # Update metrics (includes the metric that tracks the loss)\n    self$compiled_metrics$update_state(y, y_pred)\n    \n    # Return a named list mapping metric names to current value\n    results <- list()\n    for (m in self$metrics)\n      results[[m$name]] <- m$result()\n    results\n  }\n)\n\nLoaded Tensorflow version 2.9.1\n\n\nLet’s try this out:\n\n# Construct and compile an instance of CustomModel\ninputs <- layer_input(shape(32))\noutputs <- inputs %>%  layer_dense(1)\nmodel <- CustomModel(inputs, outputs)\nmodel %>% compile(optimizer = \"adam\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\n# Just use `fit` as usual\nx <- k_random_uniform(c(1000, 32))\ny <- k_random_uniform(c(1000, 1))\nmodel %>% fit(x, y, epochs = 3)"
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html#going-lower-level",
    "href": "guides/keras/customizing_what_happens_in_fit.html#going-lower-level",
    "title": "Customizing what happens in fit()",
    "section": "Going lower-level",
    "text": "Going lower-level\nNaturally, you could just skip passing a loss function in compile(), and instead do everything manually in train_step. Likewise for metrics.\nHere’s a lower-level example, that only uses compile() to configure the optimizer:\n\nWe start by creating Metric instances to track our loss and a MAE score.\nWe implement a custom train_step() that updates the state of these metrics (by calling update_state() on them), then query them (via result()) to return their current average value, to be displayed by the progress bar and to be pass to any callback.\nNote that we would need to call reset_states() on our metrics between each epoch! Otherwise calling result() would return an average since the start of training, whereas we usually work with per-epoch averages. Thankfully, the framework can do that for us: just list any metric you want to reset in the metrics property of the model. The model will call reset_states() on any object listed here at the beginning of each fit() epoch or at the beginning of a call to evaluate().\n\n\nloss_tracker <- metric_mean(name = \"loss\")\nmae_metric <- metric_mean_absolute_error(name = \"mae\")\n\nCustomModel <- new_model_class(\n  classname = \"CustomModel\",\n  train_step = function(data) {\n    c(x, y) %<-% data\n    \n    with(tf$GradientTape() %as% tape, {\n      y_pred <- self(x, training = TRUE)  # Forward pass\n      # Compute our own loss\n      loss <- keras$losses$mean_squared_error(y, y_pred)\n    })\n    \n    # Compute gradients\n    trainable_vars <- self$trainable_variables\n    gradients <- tape$gradient(loss, trainable_vars)\n    \n    # Update weights\n    self$optimizer$apply_gradients(zip_lists(gradients, trainable_vars))\n    \n    # Compute our own metrics\n    loss_tracker$update_state(loss)\n    mae_metric$update_state(y, y_pred)\n    list(loss = loss_tracker$result(), \n         mae = mae_metric$result())\n  },\n  \n  metrics = mark_active(function() {\n    # We list our `Metric` objects here so that `reset_states()` can be\n    # called automatically at the start of each epoch\n    # or at the start of `evaluate()`.\n    # If you don't implement this active property, you have to call\n    # `reset_states()` yourself at the time of your choosing.\n    list(loss_tracker, mae_metric)\n  })\n)\n\n\n# Construct an instance of CustomModel\ninputs <- layer_input(shape(32))\noutputs <- inputs %>% layer_dense(1)\nmodel <- CustomModel(inputs, outputs)\n\n# We don't pass a loss or metrics here.\nmodel %>% compile(optimizer = \"adam\")\n\n# Just use `fit` as usual -- you can use callbacks, etc.\nx <- k_random_uniform(c(1000, 32))\ny <- k_random_uniform(c(1000, 1))\nmodel %>% fit(x, y, epochs = 5)"
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html#supporting-sample_weight-class_weight",
    "href": "guides/keras/customizing_what_happens_in_fit.html#supporting-sample_weight-class_weight",
    "title": "Customizing what happens in fit()",
    "section": "Supporting sample_weight & class_weight",
    "text": "Supporting sample_weight & class_weight\nYou may have noticed that our first basic example didn’t make any mention of sample weighting. If you want to support the fit() arguments sample_weight and class_weight, you’d simply do the following:\n\nUnpack sample_weight from the data argument\nPass it to compiled_loss & compiled_metrics (of course, you could also just apply it manually if you don’t rely on compile() for losses & metrics)\nThat’s it. That’s the list.\n\n\nCustomModel <- new_model_class(\n  classname = \"CustomModel\",\n  train_step = function(data) {\n    # Unpack the data. Its structure depends on your model and on what you pass\n    # to `fit()`.  A third element in `data` is optional, but if present it's\n    # assigned to sample_weight. If a thrid element is missing, sample_weight\n    # defaults to NULL\n    c(x, y, sample_weight = NULL) %<-% data\n    \n    with(tf$GradientTape() %as% tape, {\n      y_pred <- self(x, training = TRUE)  # Forward pass\n      # Compute the loss value.\n      # The loss function is configured in `compile()`.\n      loss <- self$compiled_loss(y,\n                                 y_pred,\n                                 sample_weight = sample_weight,\n                                 regularization_losses = self$losses)\n    })\n    \n    # Compute gradients\n    trainable_vars <- self$trainable_variables\n    gradients <- tape$gradient(loss, trainable_vars)\n    \n    # Update weights\n    self$optimizer$apply_gradients(zip_lists(gradients, trainable_vars))\n    \n    # Update the metrics.\n    # Metrics are configured in `compile()`.\n    self$compiled_metrics$update_state(y, y_pred, sample_weight = sample_weight)\n    \n    # Return a named list mapping metric names to current value.\n    # Note that it will include the loss (tracked in self$metrics).\n    results <- list()\n    for (m in self$metrics)\n      results[[m$name]] <- m$result()\n    results\n  }\n)\n\n\n# Construct and compile an instance of CustomModel\n\ninputs <- layer_input(shape(32))\noutputs <- inputs %>% layer_dense(1)\nmodel <- CustomModel(inputs, outputs)\nmodel %>% compile(optimizer = \"adam\",\n                  loss = \"mse\",\n                  metrics = \"mae\")\n\n# You can now use sample_weight argument\n\nx <- k_random_uniform(c(1000, 32))\ny <- k_random_uniform(c(1000, 1))\nsw <- k_random_uniform(c(1000, 1))\nmodel %>% fit(x, y, sample_weight = sw, epochs = 3)"
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html#providing-your-own-evaluation-step",
    "href": "guides/keras/customizing_what_happens_in_fit.html#providing-your-own-evaluation-step",
    "title": "Customizing what happens in fit()",
    "section": "Providing your own evaluation step",
    "text": "Providing your own evaluation step\nWhat if you want to do the same for calls to model$evaluate()? Then you would override test_step in exactly the same way. Here’s what it looks like:\n\nCustomModel <- new_model_class(\n  classname = \"CustomModel\",\n  train_step = function(data) {\n    # Unpack the data\n    c(x, y) %<-% data\n    # Compute predictions\n    y_pred <- self(x, training = FALSE)\n    # Updates the metrics tracking the loss\n    self$compiled_loss(y, y_pred, regularization_losses = self$losses)\n    # Update the metrics.\n    self$compiled_metrics$update_state(y, y_pred)\n    # Return a named list mapping metric names to current value.\n    # Note that it will include the loss (tracked in self$metrics).\n    results <- list()\n    for (m in self$metrics)\n      results[[m$name]] <- m$result()\n    results\n  }\n)\n\n# Construct an instance of CustomModel\ninputs <- layer_input(shape(32))\noutputs <- inputs %>% layer_dense(1)\nmodel <- CustomModel(inputs, outputs)\nmodel %>% compile(loss = \"mse\", metrics = \"mae\")\n\n# Evaluate with our custom test_step\nx <- k_random_uniform(c(1000, 32))\ny <- k_random_uniform(c(1000, 1))\nmodel %>% evaluate(x, y)\n\n     loss       mae \n0.6314114 0.6621075"
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html#wrapping-up-an-end-to-end-gan-example",
    "href": "guides/keras/customizing_what_happens_in_fit.html#wrapping-up-an-end-to-end-gan-example",
    "title": "Customizing what happens in fit()",
    "section": "Wrapping up: an end-to-end GAN example",
    "text": "Wrapping up: an end-to-end GAN example\nLet’s walk through an end-to-end example that leverages everything you just learned.\nLet’s consider:\n\nA generator network meant to generate 28x28x1 images.\nA discriminator network meant to classify 28x28x1 images into two classes (“fake” and “real”).\nOne optimizer for each.\nA loss function to train the discriminator.\n\n\n# Create the discriminator\ndiscriminator <-\n  keras_model_sequential(name = \"discriminator\",\n                         input_shape = c(28, 28, 1)) %>%\n  layer_conv_2d(64, c(3, 3), strides = c(2, 2), padding = \"same\") %>%\n  layer_activation_leaky_relu(alpha = 0.2) %>%\n  layer_conv_2d(128, c(3, 3), strides = c(2, 2), padding = \"same\") %>%\n  layer_activation_leaky_relu(alpha = 0.2) %>%\n  layer_global_max_pooling_2d() %>%\n  layer_dense(1)\n\n# Create the generator\nlatent_dim <- 128\ngenerator <- \n  keras_model_sequential(name = \"generator\",\n                         input_shape = c(latent_dim)) %>%\n  # We want to generate 128 coefficients to reshape into a 7x7x128 map\n  layer_dense(7 * 7 * 128) %>%\n  layer_activation_leaky_relu(alpha = 0.2) %>%\n  layer_reshape(c(7, 7, 128)) %>%\n  layer_conv_2d_transpose(128, c(4, 4), strides = c(2, 2), padding = \"same\") %>%\n  layer_activation_leaky_relu(alpha = 0.2) %>%\n  layer_conv_2d_transpose(128, c(4, 4), strides = c(2, 2), padding = \"same\") %>%\n  layer_activation_leaky_relu(alpha = 0.2) %>%\n  layer_conv_2d(1, c(7, 7), padding = \"same\", activation = \"sigmoid\")\n\nHere’s a feature-complete GAN class, overriding compile() to use its own signature, and implementing the entire GAN algorithm in 17 lines in train_step:\n\nGAN <- new_model_class(\n  classname = \"GAN\",\n  initialize = function(discriminator, generator, latent_dim) {\n    super$initialize()\n    self$discriminator <- discriminator\n    self$generator <- generator\n    self$latent_dim <- as.integer(latent_dim)\n  },\n  \n  compile = function(d_optimizer, g_optimizer, loss_fn) {\n    super$compile()\n    self$d_optimizer <- d_optimizer\n    self$g_optimizer <- g_optimizer\n    self$loss_fn <- loss_fn\n  },\n  \n  \n  train_step = function(real_images) {\n    # Sample random points in the latent space\n    batch_size <- tf$shape(real_images)[1]\n    random_latent_vectors <-\n      tf$random$normal(shape = c(batch_size, self$latent_dim))\n    \n    # Decode them to fake images\n    generated_images <- self$generator(random_latent_vectors)\n    \n    # Combine them with real images\n    combined_images <-\n      tf$concat(list(generated_images, real_images),\n                axis = 0L)\n    \n    # Assemble labels discriminating real from fake images\n    labels <-\n      tf$concat(list(tf$ones(c(batch_size, 1L)),\n                     tf$zeros(c(batch_size, 1L))),\n                axis = 0L)\n    \n    # Add random noise to the labels - important trick!\n    labels %<>% `+`(tf$random$uniform(tf$shape(.), maxval = 0.05))\n    \n    # Train the discriminator\n    with(tf$GradientTape() %as% tape, {\n      predictions <- self$discriminator(combined_images)\n      d_loss <- self$loss_fn(labels, predictions)\n    })\n    grads <- tape$gradient(d_loss, self$discriminator$trainable_weights)\n    self$d_optimizer$apply_gradients(\n      zip_lists(grads, self$discriminator$trainable_weights))\n    \n    # Sample random points in the latent space\n    random_latent_vectors <-\n      tf$random$normal(shape = c(batch_size, self$latent_dim))\n    \n    # Assemble labels that say \"all real images\"\n    misleading_labels <- tf$zeros(c(batch_size, 1L))\n    \n    # Train the generator (note that we should *not* update the weights\n    # of the discriminator)!\n    with(tf$GradientTape() %as% tape, {\n      predictions <- self$discriminator(self$generator(random_latent_vectors))\n      g_loss <- self$loss_fn(misleading_labels, predictions)\n    })\n    grads <- tape$gradient(g_loss, self$generator$trainable_weights)\n    self$g_optimizer$apply_gradients(\n      zip_lists(grads, self$generator$trainable_weights))\n    \n    list(d_loss = d_loss, g_loss = g_loss)\n  }\n)\n\nLet’s test-drive it:\n\nlibrary(tfdatasets)\n# Prepare the dataset. We use both the training & test MNIST digits.\n\nbatch_size <- 64\nall_digits <- dataset_mnist() %>%\n  { k_concatenate(list(.$train$x, .$test$x), axis = 1) } %>%\n  k_cast(\"float32\") %>%\n  { . / 255 } %>%\n  k_reshape(c(-1, 28, 28, 1))\n\n\ndataset <- tensor_slices_dataset(all_digits) %>%\n  dataset_shuffle(buffer_size = 1024) %>%\n  dataset_batch(batch_size)\n\ngan <-\n  GAN(discriminator = discriminator,\n      generator = generator,\n      latent_dim = latent_dim)\ngan %>% compile(\n  d_optimizer = optimizer_adam(learning_rate = 0.0003),\n  g_optimizer = optimizer_adam(learning_rate = 0.0003),\n  loss_fn = loss_binary_crossentropy(from_logits = TRUE)\n)\n\n# To limit the execution time, we only train on 100 batches. You can train on\n# the entire dataset. You will need about 20 epochs to get nice results.\ngan %>% fit(dataset %>% dataset_take(100), epochs = 1)\n\nHappy training!"
  },
  {
    "objectID": "guides/keras/customizing_what_happens_in_fit.html#environment-details",
    "href": "guides/keras/customizing_what_happens_in_fit.html#environment-details",
    "title": "Customizing what happens in fit()",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/functional_api.html",
    "href": "guides/keras/functional_api.html",
    "title": "The Functional API",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/functional_api.html#introduction",
    "href": "guides/keras/functional_api.html#introduction",
    "title": "The Functional API",
    "section": "Introduction",
    "text": "Introduction\nThe Keras functional API is a way to create models that are more flexible than the sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\nThe main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\nConsider the following model:\n\n(input: 784-dimensional vectors)\n       ↧\n[Dense (64 units, relu activation)]\n       ↧\n[Dense (64 units, relu activation)]\n       ↧\n[Dense (10 units, softmax activation)]\n       ↧\n(output: logits of a probability distribution over 10 classes)\n\nThis is a basic graph with three layers. To build this model using the functional API, start by creating an input node:\n\ninputs <- layer_input(shape = c(784))\n\nLoaded Tensorflow version 2.9.1\n\n\nThe shape of the data is set as a 784-dimensional vector. The batch size is always omitted since only the shape of each sample is specified.\nIf, for example, you have an image input with a shape of (32, 32, 3), you would use:\n\n# Just for demonstration purposes.\nimg_inputs <- layer_input(shape = c(32, 32, 3))\n\nThe inputs that is returned contains information about the shape and dtype of the input data that you feed to your model. Here’s the shape:\n\ninputs$shape\n\nTensorShape([None, 784])\n\n\nHere’s the dtype:\n\ninputs$dtype\n\ntf.float32\n\n\nYou create a new node in the graph of layers by calling a layer on this inputs object:\n\ndense <- layer_dense(units = 64, activation = \"relu\")\nx <- dense(inputs)\n\nThe “layer call” action is like drawing an arrow from “inputs” to this layer you created. You’re “passing” the inputs to the dense layer, and you get x as the output.\nYou can also conveniently create the layer and compose it with inputs in one step, like this:\n\nx <- inputs %>% \n  layer_dense(units = 64, activation = \"relu\") \n\nLet’s add a few more layers to the graph of layers:\n\noutputs <- x %>% \n  layer_dense(64, activation = \"relu\") %>% \n  layer_dense(10)\n\nAt this point, you can create a Model by specifying its inputs and outputs in the graph of layers:\n\nmodel <- keras_model(inputs = inputs, outputs = outputs, \n                     name = \"mnist_model\")\n\nLet’s check out what the model summary looks like:\n\nmodel\n\nModel: \"mnist_model\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n input_1 (InputLayer)             [(None, 784)]                 0           \n dense_1 (Dense)                  (None, 64)                    50240       \n dense_3 (Dense)                  (None, 64)                    4160        \n dense_2 (Dense)                  (None, 10)                    650         \n============================================================================\nTotal params: 55,050\nTrainable params: 55,050\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nYou can also plot the model as a graph:\n\nplot(model)\n\n\n\n\nAnd, optionally, display the input and output shapes of each layer in the plotted graph:\n\nplot(model, show_shapes = TRUE)\n\n\n\n\nThis figure and the code are almost identical. In the code version, the connection arrows are replaced by %>% operator.\nA “graph of layers” is an intuitive mental image for a deep learning model, and the functional API is a way to create models that closely mirrors this."
  },
  {
    "objectID": "guides/keras/functional_api.html#training-evaluation-and-inference",
    "href": "guides/keras/functional_api.html#training-evaluation-and-inference",
    "title": "The Functional API",
    "section": "Training, evaluation, and inference",
    "text": "Training, evaluation, and inference\nTraining, evaluation, and inference work exactly in the same way for models built using the functional API as for Sequential models.\nThe Model class offers a built-in training loop (the fit() method) and a built-in evaluation loop (the evaluate() method). Note that you can easily customize these loops to implement training routines beyond supervised learning (e.g. GANs).\nHere, load the MNIST image data, reshape it into vectors, fit the model on the data (while monitoring performance on a validation split), then evaluate the model on the test data:\n\nc(c(x_train, y_train), c(x_test, y_test)) %<-% keras::dataset_mnist()\n\nx_train <- array_reshape(x_train, c(60000, 784)) / 255\nx_test <-  array_reshape(x_test, c(10000, 784)) / 255 \n\nmodel %>% compile(\n  loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),\n  optimizer = optimizer_rmsprop(),\n  metrics = \"accuracy\"\n)\n\nhistory <- model %>% fit(\n  x_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2)\n\ntest_scores <- model %>% evaluate(x_test, y_test, verbose = 2)\nprint(test_scores)\n\n     loss  accuracy \n0.1439689 0.9564000 \n\n\nFor further reading, see the training and evaluation guide."
  },
  {
    "objectID": "guides/keras/functional_api.html#save-and-serialize",
    "href": "guides/keras/functional_api.html#save-and-serialize",
    "title": "The Functional API",
    "section": "Save and serialize",
    "text": "Save and serialize\nSaving the model and serialization work the same way for models built using the functional API as they do for Sequential models. The standard way to save a functional model is to call save_model_tf() to save the entire model as a single file. You can later recreate the same model from this file, even if the code that built the model is no longer available.\nThis saved file includes the: - model architecture - model weight values (that were learned during training) - model training config, if any (as passed to compile) - optimizer and its state, if any (to restart training where you left off)\n\npath_to_my_model <- tempfile()\nsave_model_tf(model, path_to_my_model)\n\nrm(model)\n# Recreate the exact same model purely from the file:\nmodel <- load_model_tf(path_to_my_model)\n\nFor details, read the model serialization & saving guide."
  },
  {
    "objectID": "guides/keras/functional_api.html#use-the-same-graph-of-layers-to-define-multiple-models",
    "href": "guides/keras/functional_api.html#use-the-same-graph-of-layers-to-define-multiple-models",
    "title": "The Functional API",
    "section": "Use the same graph of layers to define multiple models",
    "text": "Use the same graph of layers to define multiple models\nIn the functional API, models are created by specifying their inputs and outputs in a graph of layers. That means that a single graph of layers can be used to generate multiple models.\nIn the example below, you use the same stack of layers to instantiate two models: an encoder model that turns image inputs into 16-dimensional vectors, and an end-to-end autoencoder model for training.\n\nencoder_input <- layer_input(shape = c(28, 28, 1), \n                             name = \"img\")\nencoder_output <- encoder_input %>%\n  layer_conv_2d(16, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(3) %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(16, 3, activation = \"relu\") %>%\n  layer_global_max_pooling_2d()\n\nencoder <- keras_model(encoder_input, encoder_output, \n                       name = \"encoder\")\nencoder\n\nModel: \"encoder\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n img (InputLayer)                 [(None, 28, 28, 1)]           0           \n conv2d_3 (Conv2D)                (None, 26, 26, 16)            160         \n conv2d_2 (Conv2D)                (None, 24, 24, 32)            4640        \n max_pooling2d (MaxPooling2D)     (None, 8, 8, 32)              0           \n conv2d_1 (Conv2D)                (None, 6, 6, 32)              9248        \n conv2d (Conv2D)                  (None, 4, 4, 16)              4624        \n global_max_pooling2d (GlobalMaxP  (None, 16)                   0           \n ooling2D)                                                                  \n============================================================================\nTotal params: 18,672\nTrainable params: 18,672\nNon-trainable params: 0\n____________________________________________________________________________\n\ndecoder_output <- encoder_output %>%\n  layer_reshape(c(4, 4, 1)) %>%\n  layer_conv_2d_transpose(16, 3, activation = \"relu\") %>%\n  layer_conv_2d_transpose(32, 3, activation = \"relu\") %>%\n  layer_upsampling_2d(3) %>%\n  layer_conv_2d_transpose(16, 3, activation = \"relu\") %>%\n  layer_conv_2d_transpose(1, 3, activation = \"relu\")\n\nautoencoder <- keras_model(encoder_input, decoder_output, \n                           name = \"autoencoder\")\nautoencoder\n\nModel: \"autoencoder\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n img (InputLayer)                 [(None, 28, 28, 1)]           0           \n conv2d_3 (Conv2D)                (None, 26, 26, 16)            160         \n conv2d_2 (Conv2D)                (None, 24, 24, 32)            4640        \n max_pooling2d (MaxPooling2D)     (None, 8, 8, 32)              0           \n conv2d_1 (Conv2D)                (None, 6, 6, 32)              9248        \n conv2d (Conv2D)                  (None, 4, 4, 16)              4624        \n global_max_pooling2d (GlobalMaxP  (None, 16)                   0           \n ooling2D)                                                                  \n reshape (Reshape)                (None, 4, 4, 1)               0           \n conv2d_transpose_3 (Conv2DTransp  (None, 6, 6, 16)             160         \n ose)                                                                       \n conv2d_transpose_2 (Conv2DTransp  (None, 8, 8, 32)             4640        \n ose)                                                                       \n up_sampling2d (UpSampling2D)     (None, 24, 24, 32)            0           \n conv2d_transpose_1 (Conv2DTransp  (None, 26, 26, 16)           4624        \n ose)                                                                       \n conv2d_transpose (Conv2DTranspos  (None, 28, 28, 1)            145         \n e)                                                                         \n============================================================================\nTotal params: 28,241\nTrainable params: 28,241\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nHere, the decoding architecture is strictly symmetrical to the encoding architecture, so the output shape is the same as the input shape (28, 28, 1).\nThe reverse of a Conv2D layer is a Conv2DTranspose layer, and the reverse of a MaxPooling2D layer is an UpSampling2D layer."
  },
  {
    "objectID": "guides/keras/functional_api.html#all-models-are-callable-just-like-layers",
    "href": "guides/keras/functional_api.html#all-models-are-callable-just-like-layers",
    "title": "The Functional API",
    "section": "All models are callable, just like layers",
    "text": "All models are callable, just like layers\nYou can treat any model as if it were a layer by invoking it on an Input or on the output of another layer. By calling a model you aren’t just reusing the architecture of the model, you’re also reusing its weights.\nTo see this in action, here’s a different take on the autoencoder example that creates an encoder model, a decoder model, and chains them in two calls to obtain the autoencoder model:\n\nencoder_input <- layer_input(shape = c(28, 28, 1), name = \"original_img\")\nencoder_output <- encoder_input %>%\n  layer_conv_2d(16, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(3) %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(16, 3, activation = \"relu\") %>%\n  layer_global_max_pooling_2d()\n\nencoder <- keras_model(encoder_input, encoder_output, name = \"encoder\")\nencoder\n\nModel: \"encoder\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n original_img (InputLayer)        [(None, 28, 28, 1)]           0           \n conv2d_7 (Conv2D)                (None, 26, 26, 16)            160         \n conv2d_6 (Conv2D)                (None, 24, 24, 32)            4640        \n max_pooling2d_1 (MaxPooling2D)   (None, 8, 8, 32)              0           \n conv2d_5 (Conv2D)                (None, 6, 6, 32)              9248        \n conv2d_4 (Conv2D)                (None, 4, 4, 16)              4624        \n global_max_pooling2d_1 (GlobalMa  (None, 16)                   0           \n xPooling2D)                                                                \n============================================================================\nTotal params: 18,672\nTrainable params: 18,672\nNon-trainable params: 0\n____________________________________________________________________________\n\ndecoder_input <- layer_input(shape = c(16), name = \"encoded_img\")\ndecoder_output <- decoder_input %>%\n  layer_reshape(c(4, 4, 1)) %>%\n  layer_conv_2d_transpose(16, 3, activation = \"relu\") %>%\n  layer_conv_2d_transpose(32, 3, activation = \"relu\") %>%\n  layer_upsampling_2d(3) %>%\n  layer_conv_2d_transpose(16, 3, activation = \"relu\") %>%\n  layer_conv_2d_transpose(1, 3, activation = \"relu\")\n\ndecoder <- keras_model(decoder_input, decoder_output, \n                       name = \"decoder\")\ndecoder\n\nModel: \"decoder\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n encoded_img (InputLayer)         [(None, 16)]                  0           \n reshape_1 (Reshape)              (None, 4, 4, 1)               0           \n conv2d_transpose_7 (Conv2DTransp  (None, 6, 6, 16)             160         \n ose)                                                                       \n conv2d_transpose_6 (Conv2DTransp  (None, 8, 8, 32)             4640        \n ose)                                                                       \n up_sampling2d_1 (UpSampling2D)   (None, 24, 24, 32)            0           \n conv2d_transpose_5 (Conv2DTransp  (None, 26, 26, 16)           4624        \n ose)                                                                       \n conv2d_transpose_4 (Conv2DTransp  (None, 28, 28, 1)            145         \n ose)                                                                       \n============================================================================\nTotal params: 9,569\nTrainable params: 9,569\nNon-trainable params: 0\n____________________________________________________________________________\n\nautoencoder_input <- layer_input(shape = c(28, 28, 1), name = \"img\")\nencoded_img <- encoder(autoencoder_input)\ndecoded_img <- decoder(encoded_img)\nautoencoder <- keras_model(autoencoder_input, decoded_img, \n                           name = \"autoencoder\")\nautoencoder\n\nModel: \"autoencoder\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n img (InputLayer)                 [(None, 28, 28, 1)]           0           \n encoder (Functional)             (None, 16)                    18672       \n decoder (Functional)             (None, 28, 28, 1)             9569        \n============================================================================\nTotal params: 28,241\nTrainable params: 28,241\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nAs you can see, the model can be nested: a model can contain sub-models (since a model is just like a layer). A common use case for model nesting is ensembling. For example, here’s how to ensemble a set of models into a single model that averages their predictions:\n\nget_model <- function() {\n  inputs <- layer_input(shape = c(128))\n  outputs <- inputs %>% layer_dense(1)\n  keras_model(inputs, outputs)\n}\n\nmodel1 <- get_model()\nmodel2 <- get_model()\nmodel3 <- get_model()\n\ninputs <- layer_input(shape = c(128))\ny1 <- model1(inputs)\ny2 <- model2(inputs)\ny3 <- model3(inputs)\noutputs <- layer_average(list(y1, y2, y3))\nensemble_model <- keras_model(inputs = inputs, outputs = outputs)"
  },
  {
    "objectID": "guides/keras/functional_api.html#manipulate-complex-graph-topologies",
    "href": "guides/keras/functional_api.html#manipulate-complex-graph-topologies",
    "title": "The Functional API",
    "section": "Manipulate complex graph topologies",
    "text": "Manipulate complex graph topologies\n\nModels with multiple inputs and outputs\nThe functional API makes it easy to manipulate multiple inputs and outputs. This cannot be handled with the Sequential API.\nFor example, if you’re building a system for ranking customer issue tickets by priority and routing them to the correct department, then the model will have three inputs:\n\nthe title of the ticket (text input),\nthe text body of the ticket (text input), and\nany tags added by the user (categorical input)\n\nThis model will have two outputs:\n\nthe priority score between 0 and 1 (scalar sigmoid output), and\nthe department that should handle the ticket (softmax output over the set of departments).\n\nYou can build this model in a few lines with the functional API:\n\nnum_tags <- 12  # Number of unique issue tags\nnum_words <- 10000  # Size of vocabulary obtained when preprocessing text data\nnum_departments <- 4  # Number of departments for predictions\n\ntitle_input <- layer_input(shape = c(NA), name = \"title\")  # Variable-length sequence of ints\nbody_input <- layer_input(shape = c(NA), name = \"body\")  # Variable-length sequence of ints\ntags_input <- layer_input(shape = c(num_tags), name = \"tags\")  # Binary vectors of size `num_tags`\n\n\n# Embed each word in the title into a 64-dimensional vector\ntitle_features <- title_input %>% layer_embedding(num_words, 64)\n\n# Embed each word in the text into a 64-dimensional vector\nbody_features <- body_input %>% layer_embedding(num_words, 64)\n\n# Reduce sequence of embedded words in the title into a single 128-dimensional vector\ntitle_features <- title_features %>% layer_lstm(128)\n\n# Reduce sequence of embedded words in the body into a single 32-dimensional vector\nbody_features <- body_features %>% layer_lstm(32)\n\n# Merge all available features into a single large vector via concatenation\nx <- layer_concatenate(list(title_features, body_features, tags_input))\n\n# Stick a logistic regression for priority prediction on top of the features\npriority_pred <- x %>% layer_dense(1, name = \"priority\")\n\n# Stick a department classifier on top of the features\ndepartment_pred <- x %>% layer_dense(num_departments, name = \"department\")\n\n# Instantiate an end-to-end model predicting both priority and department\nmodel <- keras_model(\n  inputs <- list(title_input, body_input, tags_input),\n  outputs <- list(priority_pred, department_pred)\n)\n\nNow plot the model:\n\nplot(model, show_shapes = TRUE)\n\n\n\n\nWhen compiling this model, you can assign different losses to each output. You can even assign different weights to each loss – to modulate their contribution to the total training loss.\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    loss_binary_crossentropy(from_logits = TRUE),\n    loss_categorical_crossentropy(from_logits = TRUE)\n  ),\n  loss_weights <- c(1, 0.2)\n)\n\nSince the output layers have different names, you could also specify the losses and loss weights with the corresponding layer names:\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    priority = loss_binary_crossentropy(from_logits = TRUE),\n    department = loss_categorical_crossentropy(from_logits = TRUE)\n  ),\n  loss_weights = c(priority =  1.0, department = 0.2),\n)\n\nTrain the model by passing lists of NumPy arrays of inputs and targets:\n\n# some helpers to generate dummy input data\nrandom_uniform_array <- function(dim) \n  array(runif(prod(dim)), dim)\n\nrandom_vectorized_array <- function(num_words, dim)\n  array(sample(0:(num_words - 1), prod(dim), replace = TRUE), dim)\n\n# Dummy input data\ntitle_data <- random_vectorized_array(num_words, c(1280, 10))\nbody_data <- random_vectorized_array(num_words, c(1280, 100))\ntags_data <- random_vectorized_array(2, c(1280, num_tags))\n# storage.mode(tags_data) <- \"double\" # from integer\n\n# Dummy target data\npriority_targets <- random_uniform_array(c(1280, 1))\ndept_targets <- random_vectorized_array(2, c(1280, num_departments))\n\nmodel %>% fit(\n  list(title = title_data, body = body_data, tags = tags_data),\n  list(priority = priority_targets, department = dept_targets),\n  epochs = 2,\n  batch_size = 32\n)\n\nWhen calling fit with a tfdataset object, it should yield either a tuple of lists like tuple(list(title_data, body_data, tags_data), list(priority_targets, dept_targets)) or a tuple of named lists like tuple(list(title = title_data, body = body_data, tags = tags_data), list(priority= priority_targets, department= dept_targets)).\nFor more detailed explanation, refer to the training and evaluation guide.\n\n\nA toy ResNet model\nIn addition to models with multiple inputs and outputs, the functional API makes it easy to manipulate non-linear connectivity topologies – these are models with layers that are not connected sequentially, which the Sequential API cannot handle.\nA common use case for this is residual connections. Let’s build a toy ResNet model for CIFAR10 to demonstrate this:\n\ninputs <- layer_input(shape = c(32, 32, 3), name = \"img\")\nblock_1_output <- inputs %>% \n  layer_conv_2d(32, 3, activation = \"relu\") %>% \n  layer_conv_2d(64, 3, activation = \"relu\") %>% \n  layer_max_pooling_2d(3)\n\nblock_2_output <- block_1_output %>% \n  layer_conv_2d(64, 3, activation = \"relu\", padding = \"same\") %>% \n  layer_conv_2d(64, 3, activation = \"relu\", padding = \"same\") %>% \n  layer_add(block_1_output)\n\nblock_3_output <- block_2_output %>% \n  layer_conv_2d(64, 3, activation = \"relu\", padding = \"same\") %>% \n  layer_conv_2d(64, 3, activation = \"relu\", padding = \"same\") %>% \n  layer_add(block_2_output) \n\noutputs <- block_3_output %>%\n  layer_conv_2d(64, 3, activation = \"relu\") %>%\n  layer_global_average_pooling_2d() %>%\n  layer_dense(256, activation = \"relu\") %>%\n  layer_dropout(0.5) %>%\n  layer_dense(10)\n\nmodel <- keras_model(inputs, outputs, name = \"toy_resnet\")\nmodel\n\nModel: \"toy_resnet\"\n____________________________________________________________________________\n Layer (type)            Output Shape    Param #  Connected to              \n============================================================================\n img (InputLayer)        [(None, 32, 32  0        []                        \n                         , 3)]                                              \n conv2d_9 (Conv2D)       (None, 30, 30,  896      ['img[0][0]']             \n                          32)                                               \n conv2d_8 (Conv2D)       (None, 28, 28,  18496    ['conv2d_9[0][0]']        \n                          64)                                               \n max_pooling2d_2 (MaxPoo  (None, 9, 9, 6  0       ['conv2d_8[0][0]']        \n ling2D)                 4)                                                 \n conv2d_11 (Conv2D)      (None, 9, 9, 6  36928    ['max_pooling2d_2[0][0]'] \n                         4)                                                 \n conv2d_10 (Conv2D)      (None, 9, 9, 6  36928    ['conv2d_11[0][0]']       \n                         4)                                                 \n add (Add)               (None, 9, 9, 6  0        ['conv2d_10[0][0]',       \n                         4)                        'max_pooling2d_2[0][0]'] \n conv2d_13 (Conv2D)      (None, 9, 9, 6  36928    ['add[0][0]']             \n                         4)                                                 \n conv2d_12 (Conv2D)      (None, 9, 9, 6  36928    ['conv2d_13[0][0]']       \n                         4)                                                 \n add_1 (Add)             (None, 9, 9, 6  0        ['conv2d_12[0][0]',       \n                         4)                        'add[0][0]']             \n conv2d_14 (Conv2D)      (None, 7, 7, 6  36928    ['add_1[0][0]']           \n                         4)                                                 \n global_average_pooling2  (None, 64)     0        ['conv2d_14[0][0]']       \n d (GlobalAveragePooling                                                    \n 2D)                                                                        \n dense_8 (Dense)         (None, 256)     16640    ['global_average_pooling2d\n                                                  [0][0]']                  \n dropout (Dropout)       (None, 256)     0        ['dense_8[0][0]']         \n dense_7 (Dense)         (None, 10)      2570     ['dropout[0][0]']         \n============================================================================\nTotal params: 223,242\nTrainable params: 223,242\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nPlot the model:\n\nplot(model, show_shapes = TRUE)\n\n\n\n\nNow train the model:\n\nc(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_cifar10()  \n\nx_train <- x_train / 255\nx_test <- x_test / 255\ny_train <- to_categorical(y_train, 10)\ny_test <- to_categorical(y_test, 10)\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = loss_categorical_crossentropy(from_logits = TRUE),\n  metrics = \"acc\"\n)\n# We restrict the data to the first 1000 samples so as to limit execution time\n# for this guide. Try to train on the entire dataset until convergence!\nmodel %>% fit(\n  x_train[1:1000, , , ],\n  y_train[1:1000, ],\n  batch_size = 64,\n  epochs = 1,\n  validation_split = 0.2\n)"
  },
  {
    "objectID": "guides/keras/functional_api.html#shared-layers",
    "href": "guides/keras/functional_api.html#shared-layers",
    "title": "The Functional API",
    "section": "Shared layers",
    "text": "Shared layers\nAnother good use for the functional API are models that use shared layers. Shared layers are layer instances that are reused multiple times in the same model – they learn features that correspond to multiple paths in the graph-of-layers.\nShared layers are often used to encode inputs from similar spaces (say, two different pieces of text that feature similar vocabulary). They enable sharing of information across these different inputs, and they make it possible to train such a model on less data. If a given word is seen in one of the inputs, that will benefit the processing of all inputs that pass through the shared layer.\nTo share a layer in the functional API, call the same layer instance multiple times. For instance, here’s an Embedding layer shared across two different text inputs:\n\n# Embedding for 1000 unique words mapped to 128-dimensional vectors\nshared_embedding <- layer_embedding(input_dim = 1000, output_dim = 128)\n\n# Variable-length sequence of integers\ntext_input_a <- layer_input(shape = c(NA), dtype = \"int32\")\n\n# Variable-length sequence of integers\ntext_input_b <- layer_input(shape = c(NA), dtype = \"int32\")\n\n# Reuse the same layer to encode both inputs\nencoded_input_a <- shared_embedding(text_input_a)\nencoded_input_b <- shared_embedding(text_input_b)"
  },
  {
    "objectID": "guides/keras/functional_api.html#extract-and-reuse-nodes-in-the-graph-of-layers",
    "href": "guides/keras/functional_api.html#extract-and-reuse-nodes-in-the-graph-of-layers",
    "title": "The Functional API",
    "section": "Extract and reuse nodes in the graph of layers",
    "text": "Extract and reuse nodes in the graph of layers\nBecause the graph of layers you are manipulating is a static data structure, it can be accessed and inspected. And this is how you are able to plot functional models as images.\nThis also means that you can access the activations of intermediate layers (“nodes” in the graph) and reuse them elsewhere – which is very useful for something like feature extraction.\nLet’s look at an example. This is a VGG19 model with weights pretrained on ImageNet:\n\nvgg19 <- application_vgg19()\n\nAnd these are the intermediate activations of the model, obtained by querying the graph data structure:\n\nfeatures_list <- lapply(vgg19$layers, \\(layer) layer$output)\n\nUse these features to create a new feature-extraction model that returns the values of the intermediate layer activations:\n\nfeat_extraction_model <-  keras_model(inputs = vgg19$input, \n                                      outputs = features_list)\n\nimg <- random_uniform_array(c(1, 224, 224, 3))\nextracted_features <- feat_extraction_model(img)\n\nThis comes in handy for tasks like neural style transfer, among other things."
  },
  {
    "objectID": "guides/keras/functional_api.html#extend-the-api-using-custom-layers",
    "href": "guides/keras/functional_api.html#extend-the-api-using-custom-layers",
    "title": "The Functional API",
    "section": "Extend the API using custom layers",
    "text": "Extend the API using custom layers\ntf$keras includes a wide range of built-in layers, for example:\n\nConvolutional layers: Conv1D, Conv2D, Conv3D, Conv2DTranspose\nPooling layers: MaxPooling1D, MaxPooling2D, MaxPooling3D, AveragePooling1D\nRNN layers: GRU, LSTM, ConvLSTM2D\nBatchNormalization, Dropout, Embedding, etc.\n\nBut if you don’t find what you need, it’s easy to extend the API by creating your own layers. All layers subclass the Layer class and implement:\n\ncall method, that specifies the computation done by the layer.\nbuild method, that creates the weights of the layer (this is just a style convention since you can create weights in __init__, as well).\n\nTo learn more about creating layers from scratch, read custom layers and models guide.\nThe following is a basic implementation of layer_dense():\n\nlibrary(tensorflow)\nlibrary(keras)\nlayer_custom_dense <- new_layer_class(\n  \"CustomDense\",\n  initialize = function(units = 32) {\n    super$initialize()\n    self$units = as.integer(units)\n  },\n  build = function(input_shape) {\n    self$w <- self$add_weight(\n      shape = shape(tail(input_shape, 1), self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n    self$b <- self$add_weight(\n      shape = shape(self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n  },\n  call = function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n)\n\n\ninputs <- layer_input(c(4))\noutputs <- inputs %>% layer_custom_dense(10)\n\nmodel <- keras_model(inputs, outputs)\n\nFor serialization support in your custom layer, define a get_config method that returns the constructor arguments of the layer instance:\n\nlayer_custom_dense <- new_layer_class(\n  \"CustomDense\",\n  initialize = function(units = 32) {\n    super$initialize()\n    self$units <- as.integer(units)\n  },\n  \n  build = function(input_shape) {\n    self$w <-\n      self$add_weight(\n        shape = shape(tail(input_shape, 1), self$units),\n        initializer = \"random_normal\",\n        trainable = TRUE\n      )\n    self$b <- self$add_weight(\n      shape = shape(self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n  },\n  \n  call = function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  },\n  \n  get_config = function() {\n    list(units = self$units)\n  }\n)\n\n\ninputs <- layer_input(c(4))\noutputs <- inputs %>% layer_custom_dense(10)\n\nmodel <- keras_model(inputs, outputs)\nconfig <- model %>% get_config()\n\nnew_model <- from_config(config, custom_objects = list(layer_custom_dense))\n\nOptionally, implement the class method from_config(class_constructor, config) which is used when recreating a layer instance given its config. The default implementation of from_config is approximately:\n\nfrom_config <- function(layer_constructor, config) \n  do.call(layer_constructor, config)"
  },
  {
    "objectID": "guides/keras/functional_api.html#when-to-use-the-functional-api",
    "href": "guides/keras/functional_api.html#when-to-use-the-functional-api",
    "title": "The Functional API",
    "section": "When to use the functional API",
    "text": "When to use the functional API\nShould you use the Keras functional API to create a new model, or just subclass the Model class directly? In general, the functional API is higher-level, easier and safer, and has a number of features that subclassed models do not support.\nHowever, model subclassing provides greater flexibility when building models that are not easily expressible as directed acyclic graphs of layers. For example, you could not implement a Tree-RNN with the functional API and would have to subclass Model directly.\nFor an in-depth look at the differences between the functional API and model subclassing, read What are Symbolic and Imperative APIs in TensorFlow 2.0?.\n\nFunctional API strengths:\nThe following properties are also true for Sequential models (which are also data structures), but are not true for subclassed models (which are R code, not data structures).\n\nLess verbose\nThere is no super$initialize(...), no call <- function(...) {   }, etc.\nCompare:\n\ninputs <- layer_input(shape = c(32))\noutputs <- inputs %>% \n  layer_dense(64, activation = 'relu') %>% \n  layer_dense(10)\nmlp <- keras_model(inputs, outputs)\n\nWith the subclassed version:\n\nMLP <- new_model_class(\n  classname = \"MLP\",\n  \n  initialize = function(...) {\n    super$initialize(...)\n    self$dense_1 <- layer_dense(units = 64, activation = 'relu')\n    self$dense_2 <- layer_dense(units = 10)\n  },\n  \n  call = function(inputs) {\n    inputs %>% \n      self$dense_1() %>% \n      self$dense_2()\n  }\n)\n\n# Instantiate the model.\nmlp <- MLP()\n\n# Necessary to create the model's state.\n# The model doesn't have a state until it's called at least once.\ninvisible(mlp(tf$zeros(shape(1, 32))))\n\n\n\nModel validation while defining its connectivity graph\nIn the functional API, the input specification (shape and dtype) is created in advance (using layer_input). Every time you call a layer, the layer checks that the specification passed to it matches its assumptions, and it will raise a helpful error message if not.\nThis guarantees that any model you can build with the functional API will run. All debugging – other than convergence-related debugging – happens statically during the model construction and not at execution time. This is similar to type checking in a compiler.\n\n\nA functional model is plottable and inspectable\nYou can plot the model as a graph, and you can easily access intermediate nodes in this graph. For example, to extract and reuse the activations of intermediate layers (as seen in a previous example):\n\nfeatures_list <- lapply(vgg19$layers, \\(layer) layer$output)\nfeat_extraction_model <- keras_model(inputs = vgg19$input,\n                                     outputs = features_list)\n\n\n\nA functional model can be serialized or cloned\nBecause a functional model is a data structure rather than a piece of code, it is safely serializable and can be saved as a single file that allows you to recreate the exact same model without having access to any of the original code. See the serialization & saving guide.\nTo serialize a subclassed model, it is necessary for the implementer to specify a get_config() and from_config() method at the model level.\n\n\n\nFunctional API weakness:\n\nIt does not support dynamic architectures\nThe functional API treats models as DAGs of layers. This is true for most deep learning architectures, but not all – for example, recursive networks or Tree RNNs do not follow this assumption and cannot be implemented in the functional API."
  },
  {
    "objectID": "guides/keras/functional_api.html#mix-and-match-api-styles",
    "href": "guides/keras/functional_api.html#mix-and-match-api-styles",
    "title": "The Functional API",
    "section": "Mix-and-match API styles",
    "text": "Mix-and-match API styles\nChoosing between the functional API or Model subclassing isn’t a binary decision that restricts you into one category of models. All models in the tf$keras API can interact with each other, whether they’re Sequential models, functional models, or subclassed models that are written from scratch.\nYou can always use a functional model or Sequential model as part of a subclassed model or layer:\n\nunits <- 32L\ntimesteps <- 10L\ninput_dim <- 5L\n\n# Define a Functional model\n\ninputs <- layer_input(c(NA, units))\noutputs <- inputs %>% \n  layer_global_average_pooling_1d() %>% \n  layer_dense(1)\nmodel <- keras_model(inputs, outputs)\n\n\n\nlayer_custom_rnn <- new_layer_class(\n  \"CustomRNN\",\n  initialize = function() {\n    super$initialize()\n    self$units <- units\n    self$projection_1 <-\n      layer_dense(units = units, activation = \"tanh\")\n    self$projection_2 <-\n      layer_dense(units = units, activation = \"tanh\")\n    # Our previously-defined Functional model\n    self$classifier <- model\n  },\n  \n  call = function(inputs) {\n    message(\"inputs shape: \", format(inputs$shape))\n    c(batch_size, timesteps, channels) %<-% dim(inputs)\n    outputs <- vector(\"list\", timesteps)\n    state <- tf$zeros(shape(batch_size, self$units))\n    for (t in 1:timesteps) {\n      # iterate over each time_step\n      outputs[[t]] <- state <-\n        inputs[, t, ] %>%\n        self$projection_1() %>%\n        { . + self$projection_2(state) }\n    }\n    \n    features <- tf$stack(outputs, axis = 1L) # axis is 1-based\n    message(\"features shape: \", format(features$shape))\n    self$classifier(features)\n  }\n)\n\nlayer_custom_rnn(tf$zeros(shape(1, timesteps, input_dim)))\n\ninputs shape: (1, 10, 5)\n\n\nfeatures shape: (1, 10, 32)\n\n\nYou can use any subclassed layer or model in the functional API as long as it implements a call method that follows one of the following patterns:\n\ncall(inputs, ..., training = NULL, mask = NULL) – Where inputs is a tensor or a nested structure of tensors (e.g. a list of tensors), and where optional named arguments training and mask can be present.\nare non-tensor arguments (non-inputs).\ncall(self, inputs, training = NULL, **kwargs) – Where training is a boolean indicating whether the layer should behave in training mode and inference mode.\ncall(self, inputs, mask = NULL, **kwargs) – Where mask is a boolean mask tensor (useful for RNNs, for instance).\ncall(self, inputs, training = NULL, mask = NULL, **kwargs) – Of course, you can have both masking and training-specific behavior at the same time.\n\nAdditionally, if you implement the get_config method on your custom Layer or model, the functional models you create will still be serializable and cloneable.\nHere’s a quick example of a custom RNN, written from scratch, being used in a functional model:\n\nunits <- 32 \ntimesteps <- 10 \ninput_dim <- 5 \nbatch_size <- 16\n\nlayer_custom_rnn <- new_layer_class(\n  \"CustomRNN\",\n  initialize = function() {\n    super$initialize()\n    self$units <- units  \n    self$projection_1 <- layer_dense(units = units, activation = \"tanh\")\n    self$projection_2 <- layer_dense(units = units, activation = \"tanh\")\n    self$classifier <- layer_dense(units = 1)\n  },\n  \n  call = function(inputs) {\n    c(batch_size, timesteps, channels) %<-% dim(inputs)\n    outputs <- vector(\"list\", timesteps)\n    state <- tf$zeros(shape(batch_size, self$units))\n    for (t in 1:timesteps) {\n      # iterate over each time_step\n      outputs[[t]] <- state <-\n        inputs[, t, ] %>%\n        self$projection_1() %>%\n        { . + self$projection_2(state) }\n    }\n    \n    features <- tf$stack(outputs, axis = 1L) # axis arg is 1-based\n    self$classifier(features)\n  }\n)\n    \n# Note that you specify a static batch size for the inputs with the `batch_shape`\n# arg, because the inner computation of `CustomRNN` requires a static batch size\n# (when you create the `state` zeros tensor).\ninputs <- layer_input(batch_shape = c(batch_size, timesteps, input_dim))\noutputs <- inputs %>% \n  layer_conv_1d(32, 3) %>% \n  layer_custom_rnn()\n\nmodel <- keras_model(inputs, outputs)\nmodel(tf$zeros(shape(1, 10, 5)))\n\ntf.Tensor(\n[[[0.]\n  [0.]\n  [0.]\n  [0.]\n  [0.]\n  [0.]\n  [0.]\n  [0.]]], shape=(1, 8, 1), dtype=float32)"
  },
  {
    "objectID": "guides/keras/functional_api.html#environment-details",
    "href": "guides/keras/functional_api.html#environment-details",
    "title": "The Functional API",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "",
    "text": "library(magrittr)\n\nWarning: package 'magrittr' was built under R version 4.1.2\n\nlibrary(tensorflow)\nlibrary(tfdatasets)\nlibrary(keras)\n\ntf_version()\n\nLoaded Tensorflow version 2.9.1\n\n\n[1] '2.9'"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-layer-class-a-combination-of-state-weights-and-some-computation",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-layer-class-a-combination-of-state-weights-and-some-computation",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "The Layer class: a combination of state (weights) and some computation",
    "text": "The Layer class: a combination of state (weights) and some computation\nOne of the central abstractions in Keras is the Layer class. A layer encapsulates both a state (the layer’s “weights”) and a transformation from inputs to outputs (a “call”, the layer’s forward pass).\nHere’s a densely-connected layer. It has a state: the variables w and b.\n\nLinear(keras$layers$Layer) %py_class% {\n  initialize <- function(units = 32, input_dim = 32) {\n    super$initialize()\n    w_init <- tf$random_normal_initializer()\n    self$w <- tf$Variable(\n      initial_value = w_init(\n        shape = shape(input_dim, units),\n        dtype = \"float32\"\n      ),\n      trainable = TRUE\n    )\n    b_init <- tf$zeros_initializer()\n    self$b <- tf$Variable(\n      initial_value = b_init(shape = shape(units), dtype = \"float32\"),\n      trainable = TRUE\n    )\n  }\n\n  call <- function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n}\n\nYou would use a layer by calling it on some tensor input(s), much like a regular function.\n\nx <- tf$ones(shape(2, 2))\nlinear_layer <- Linear(4, 2)\ny <- linear_layer(x)\nprint(y)\n\ntf.Tensor(\n[[-0.00647149 -0.05578769  0.03210767  0.07069797]\n [-0.00647149 -0.05578769  0.03210767  0.07069797]], shape=(2, 4), dtype=float32)\n\n\nLinear behaves similarly to a layer present in the Python interface to keras (e.g., keras$layers$Dense).\nHowever, one additional step is needed to make it behave like the builtin layers present in the keras R package (e.g., layer_dense()).\nKeras layers in R are designed to compose nicely with the pipe operator (%>%), so that the layer instance is conveniently created on demand when an existing model or tensor is piped in. In order to make a custom layer similarly compose nicely with the pipe, you can call create_layer_wrapper() on the layer class constructor.\n\nlayer_linear <- create_layer_wrapper(Linear)\n\nNow layer_linear is a layer constructor that composes nicely with %>%, just like the built-in layers:\n\nmodel <- keras_model_sequential() %>%\n  layer_linear(4, 2)\n\nmodel(k_ones(c(2, 2)))\n\ntf.Tensor(\n[[-0.03112034  0.06114008  0.09245743  0.0617287 ]\n [-0.03112034  0.06114008  0.09245743  0.0617287 ]], shape=(2, 4), dtype=float32)\n\nmodel\n\nModel: \"sequential\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n linear_1 (Linear)                (2, 4)                        12          \n============================================================================\nTotal params: 12\nTrainable params: 12\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nBecause the pattern above is so common, there is a convenience function that combines the steps of subclassing keras$layers$Layer and calling create_layer_wrapper on the output: the Layer function. The layer_linear defined below is identical to the layer_linear defined above.\n\nlayer_linear <- Layer(\n  \"Linear\",\n  initialize =  function(units = 32, input_dim = 32) {\n    super$initialize()\n    w_init <- tf$random_normal_initializer()\n    self$w <- tf$Variable(initial_value = w_init(shape = shape(input_dim, units),\n                                                 dtype = \"float32\"),\n                          trainable = TRUE)\n    b_init <- tf$zeros_initializer()\n    self$b <- tf$Variable(initial_value = b_init(shape = shape(units),\n                                                 dtype = \"float32\"),\n                          trainable = TRUE)\n  },\n\n  call = function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n)\n\nFor the remainder of this vignette we’ll be using the %py_class% constructor. However, in your own code feel free to use create_layer_wrapper and/or Layer if you prefer.\nNote that the weights w and b are automatically tracked by the layer upon being set as layer attributes:\n\nstopifnot(all.equal(\n  linear_layer$weights,\n  list(linear_layer$w, linear_layer$b)\n))\n\nYou also have access to a quicker shortcut for adding a weight to a layer: the add_weight() method:\n\nLinear(keras$layers$Layer) %py_class% {\n  initialize <- function(units = 32, input_dim = 32) {\n    super$initialize()\n    w_init <- tf$random_normal_initializer()\n    self$w <- self$add_weight(\n      shape = shape(input_dim, units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n    self$b <- self$add_weight(\n      shape = shape(units),\n      initializer = \"zeros\",\n      trainable = TRUE\n    )\n  }\n\n  call <- function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n}\n\nx <- tf$ones(shape(2, 2))\nlinear_layer <- Linear(4, 2)\ny <- linear_layer(x)\nprint(y)\n\ntf.Tensor(\n[[-0.04482888 -0.07073172  0.01847215  0.08916104]\n [-0.04482888 -0.07073172  0.01847215  0.08916104]], shape=(2, 4), dtype=float32)"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#layers-can-have-non-trainable-weights",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#layers-can-have-non-trainable-weights",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Layers can have non-trainable weights",
    "text": "Layers can have non-trainable weights\nBesides trainable weights, you can add non-trainable weights to a layer as well. Such weights are meant not to be taken into account during backpropagation, when you are training the layer.\nHere’s how to add and use a non-trainable weight:\n\nComputeSum(keras$layers$Layer) %py_class% {\n  initialize <- function(input_dim) {\n    super$initialize()\n    self$total <- tf$Variable(\n      initial_value = tf$zeros(shape(input_dim)),\n      trainable = FALSE\n    )\n  }\n\n  call <- function(inputs) {\n    self$total$assign_add(tf$reduce_sum(inputs, axis = 0L))\n    self$total\n  }\n}\n\nx <- tf$ones(shape(2, 2))\nmy_sum <- ComputeSum(2)\ny <- my_sum(x)\nprint(as.numeric(y))\n\n[1] 2 2\n\ny <- my_sum(x)\nprint(as.numeric(y))\n\n[1] 4 4\n\n\nIt’s part of layer$weights, but it gets categorized as a non-trainable weight:\n\ncat(\"weights:\", length(my_sum$weights), \"\\n\")\n\nweights: 1 \n\ncat(\"non-trainable weights:\", length(my_sum$non_trainable_weights), \"\\n\")\n\nnon-trainable weights: 1 \n\n# It's not included in the trainable weights:\ncat(\"trainable_weights:\", my_sum$trainable_weights, \"\\n\")\n\ntrainable_weights:"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Best practice: deferring weight creation until the shape of the inputs is known",
    "text": "Best practice: deferring weight creation until the shape of the inputs is known\nOur Linear layer above took an input_dimargument that was used to compute the shape of the weights w and b in initialize():\n\nLinear(keras$layers$Layer) %py_class% {\n  initialize <- function(units = 32, input_dim = 32) {\n    super$initialize()\n    self$w <- self$add_weight(\n      shape = shape(input_dim, units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n    self$b <- self$add_weight(\n      shape = shape(units),\n      initializer = \"zeros\",\n      trainable = TRUE\n    )\n  }\n\n  call <- function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n}\n\nIn many cases, you may not know in advance the size of your inputs, and you would like to lazily create weights when that value becomes known, some time after instantiating the layer.\nIn the Keras API, we recommend creating layer weights in the build(self, inputs_shape) method of your layer. Like this:\n\nLinear(keras$layers$Layer) %py_class% {\n  initialize <- function(units = 32) {\n    super$initialize()\n    self$units <- units\n  }\n\n  build <- function(input_shape) {\n    self$w <- self$add_weight(\n      shape = shape(tail(input_shape, 1), self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n    self$b <- self$add_weight(\n      shape = shape(self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n  }\n\n  call <- function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n}\n\nThe build() method of your layer will automatically run the first time your layer instance is called. You now have a layer that can handle an arbitrary number of input features:\n\n# At instantiation, we don't know on what inputs this is going to get called\nlinear_layer <- Linear(32)\n\n# The layer's weights are created dynamically the first time the layer is called\ny <- linear_layer(x)\n\nImplementing build() separately as shown above nicely separates creating weights only once from using weights in every call. However, for some advanced custom layers, it can become impractical to separate the state creation and computation. Layer implementers are allowed to defer weight creation to the first call(), but need to take care that later calls use the same weights. In addition, since call() is likely to be executed for the first time inside a tf_function(), any variable creation that takes place in call() should be wrapped in a tf$init_scope()."
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#layers-are-recursively-composable",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#layers-are-recursively-composable",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Layers are recursively composable",
    "text": "Layers are recursively composable\nIf you assign a Layer instance as an attribute of another Layer, the outer layer will start tracking the weights created by the inner layer.\nWe recommend creating such sublayers in the initialize() method and leave it to the first call() to trigger building their weights.\n\n# Let's assume we are reusing the Linear class\n# with a `build` method that we defined above.\nMLPBlock(keras$layers$Layer) %py_class% {\n  initialize <- function() {\n    super$initialize()\n    self$linear_1 <- Linear(32)\n    self$linear_2 <- Linear(32)\n    self$linear_3 <- Linear(1)\n  }\n\n  call <- function(inputs) {\n    x <- self$linear_1(inputs)\n    x <- tf$nn$relu(x)\n    x <- self$linear_2(x)\n    x <- tf$nn$relu(x)\n    self$linear_3(x)\n  }\n}\n\nmlp <- MLPBlock()\ny <- mlp(tf$ones(shape = shape(3, 64))) # The first call to the `mlp` will create the weights\ncat(\"weights:\", length(mlp$weights), \"\\n\")\n\nweights: 6 \n\ncat(\"trainable weights:\", length(mlp$trainable_weights), \"\\n\")\n\ntrainable weights: 6"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-add_loss-method",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-add_loss-method",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "The add_loss() method",
    "text": "The add_loss() method\nWhen writing the call() method of a layer, you can create loss tensors that you will want to use later, when writing your training loop. This is doable by calling self$add_loss(value):\n\n# A layer that creates an activity regularization loss\nActivityRegularizationLayer(keras$layers$Layer) %py_class% {\n  initialize <- function(rate = 1e-2) {\n    super$initialize()\n    self$rate <- rate\n  }\n\n  call <- function(inputs) {\n    self$add_loss(self$rate * tf$reduce_sum(inputs))\n    inputs\n  }\n}\n\nThese losses (including those created by any inner layer) can be retrieved via layer$losses. This property is reset at the start of every call() to the top-level layer, so that layer$losses always contains the loss values created during the last forward pass.\n\nOuterLayer(keras$layers$Layer) %py_class% {\n  initialize <- function() {\n    super$initialize()\n    self$activity_reg <- ActivityRegularizationLayer(1e-2)\n  }\n  call <- function(inputs) {\n    self$activity_reg(inputs)\n  }\n}\n\nlayer <- OuterLayer()\nstopifnot(length(layer$losses) == 0) # No losses yet since the layer has never been called\n\nlayer(tf$zeros(shape(1, 1))) |> invisible()\nstopifnot(length(layer$losses) == 1) # We created one loss value\n\n# `layer$losses` gets reset at the start of each call()\nlayer(tf$zeros(shape(1, 1))) |> invisible()\nstopifnot(length(layer$losses) == 1) # This is the loss created during the call above\n\nIn addition, the loss property also contains regularization losses created for the weights of any inner layer:\n\nOuterLayerWithKernelRegularizer(keras$layers$Layer) %py_class% {\n  initialize <- function() {\n    super$initialize()\n    self$dense <- layer_dense(units = 32, kernel_regularizer = regularizer_l2(1e-3))\n  }\n  call <- function(inputs) {\n    self$dense(inputs)\n  }\n}\n\nlayer <- OuterLayerWithKernelRegularizer()\nlayer(tf$zeros(shape(1, 1))) |> invisible()\n\n# This is `1e-3 * sum(layer$dense$kernel ** 2)`,\n# created by the `kernel_regularizer` above.\nprint(layer$losses)\n\n[[1]]\ntf.Tensor(0.0019065848, shape=(), dtype=float32)\n\n\nThese losses are meant to be taken into account when writing training loops, like this:\n\n# Instantiate an optimizer.\noptimizer <- optimizer_sgd(learning_rate = 1e-3)\nloss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)\n\n# Iterate over the batches of a dataset.\ndataset_iterator <- reticulate::as_iterator(train_dataset)\nwhile(!is.null(batch <- iter_next(dataset_iterator))) {\n  c(x_batch_train, y_batch_train) %<-% batch\n  with(tf$GradientTape() %as% tape, {\n    logits <- layer(x_batch_train) # Logits for this minibatch\n    # Loss value for this minibatch\n    loss_value <- loss_fn(y_batch_train, logits)\n    # Add extra losses created during this forward pass:\n    loss_value <- loss_value + sum(model$losses)\n  })\n  grads <- tape$gradient(loss_value, model$trainable_weights)\n  optimizer$apply_gradients(\n    purrr::transpose(list(grads, model$trainable_weights)))\n}\n\nFor a detailed guide about writing training loops, see the guide to writing a training loop from scratch.\nThese losses also work seamlessly with fit() (they get automatically summed and added to the main loss, if any):\n\ninput <- layer_input(shape(3))\noutput <- input %>% layer_activity_regularization()\n# output <- ActivityRegularizationLayer()(input)\nmodel <- keras_model(input, output)\n\n# If there is a loss passed in `compile`, the regularization\n# losses get added to it\nmodel %>% compile(optimizer = \"adam\", loss = \"mse\")\nmodel %>% fit(k_random_uniform(c(2, 3)),\n  k_random_uniform(c(2, 3)),\n  epochs = 1, verbose = FALSE\n)\n\n# It's also possible not to pass any loss in `compile`,\n# since the model already has a loss to minimize, via the `add_loss`\n# call during the forward pass!\nmodel %>% compile(optimizer = \"adam\")\nmodel %>% fit(k_random_uniform(c(2, 3)),\n  k_random_uniform(c(2, 3)),\n  epochs = 1, verbose = FALSE\n)"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-add_metric-method",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-add_metric-method",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "The add_metric() method",
    "text": "The add_metric() method\nSimilarly to add_loss(), layers also have an add_metric() method for tracking the moving average of a quantity during training.\nConsider the following layer: a “logistic endpoint” layer. It takes as inputs predictions and targets, it computes a loss which it tracks via add_loss(), and it computes an accuracy scalar, which it tracks via add_metric().\n\nLogisticEndpoint(keras$layers$Layer) %py_class% {\n  initialize <- function(name = NULL) {\n    super$initialize(name = name)\n    self$loss_fn <- loss_binary_crossentropy(from_logits = TRUE)\n    self$accuracy_fn <- metric_binary_accuracy()\n  }\n\n  call <- function(targets, logits, sample_weights = NULL) {\n    # Compute the training-time loss value and add it\n    # to the layer using `self$add_loss()`.\n    loss <- self$loss_fn(targets, logits, sample_weights)\n    self$add_loss(loss)\n\n    # Log accuracy as a metric and add it\n    # to the layer using `self.add_metric()`.\n    acc <- self$accuracy_fn(targets, logits, sample_weights)\n    self$add_metric(acc, name = \"accuracy\")\n\n    # Return the inference-time prediction tensor (for `.predict()`).\n    tf$nn$softmax(logits)\n  }\n}\n\nMetrics tracked in this way are accessible via layer$metrics:\n\nlayer <- LogisticEndpoint()\n\ntargets <- tf$ones(shape(2, 2))\nlogits <- tf$ones(shape(2, 2))\ny <- layer(targets, logits)\n\ncat(\"layer$metrics: \")\n\nlayer$metrics: \n\nstr(layer$metrics)\n\nList of 1\n $ :BinaryAccuracy(name=binary_accuracy,dtype=float32,threshold=0.5)\n\ncat(\"current accuracy value:\", as.numeric(layer$metrics[[1]]$result()), \"\\n\")\n\ncurrent accuracy value: 1 \n\n\nJust like for add_loss(), these metrics are tracked by fit():\n\ninputs <- layer_input(shape(3), name = \"inputs\")\ntargets <- layer_input(shape(10), name = \"targets\")\nlogits <- inputs %>% layer_dense(10)\npredictions <- LogisticEndpoint(name = \"predictions\")(logits, targets)\n\nmodel <- keras_model(inputs = list(inputs, targets), outputs = predictions)\nmodel %>% compile(optimizer = \"adam\")\n\ndata <- list(\n  inputs = k_random_uniform(c(3, 3)),\n  targets = k_random_uniform(c(3, 10))\n)\n\nmodel %>% fit(data, epochs = 1, verbose = FALSE)"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#you-can-optionally-enable-serialization-on-your-layers",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#you-can-optionally-enable-serialization-on-your-layers",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "You can optionally enable serialization on your layers",
    "text": "You can optionally enable serialization on your layers\nIf you need your custom layers to be serializable as part of a Functional model, you can optionally implement a get_config() method:\n\nLinear(keras$layers$Layer) %py_class% {\n  initialize <- function(units = 32) {\n    super$initialize()\n    self$units <- units\n  }\n\n  build <- function(input_shape) {\n    self$w <- self$add_weight(\n      shape = shape(tail(input_shape, 1), self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n    self$b <- self$add_weight(\n      shape = shape(self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n  }\n\n  call <- function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n\n  get_config <- function() {\n    list(units = self$units)\n  }\n}\n\n\n# Now you can recreate the layer from its config:\nlayer <- Linear(64)\nconfig <- layer$get_config()\nprint(config)\n\n$units\n[1] 64\n\nnew_layer <- Linear$from_config(config)\n\nNote that the initialize() method of the base Layer class takes some additional named arguments, in particular a name and a dtype. It’s good practice to pass these arguments to the parent class in initialize() and to include them in the layer config:\n\nLinear(keras$layers$Layer) %py_class% {\n  initialize <- function(units = 32, ...) {\n    super$initialize(...)\n    self$units <- units\n  }\n\n  build <- function(input_shape) {\n    self$w <- self$add_weight(\n      shape = shape(tail(input_shape, 1), self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n    self$b <- self$add_weight(\n      shape = shape(self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n  }\n\n  call <- function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  }\n\n  get_config <- function() {\n    config <- super$get_config()\n    config$units <- self$units\n    config\n  }\n}\n\n\nlayer <- Linear(64)\nconfig <- layer$get_config()\nstr(config)\n\nList of 4\n $ name     : chr \"linear_9\"\n $ trainable: logi TRUE\n $ dtype    : chr \"float32\"\n $ units    : num 64\n\nnew_layer <- Linear$from_config(config)\n\nIf you need more flexibility when deserializing the layer from its config, you can also override the from_config() class method. This is the base implementation of from_config():\n\nfrom_config <- function(cls, config) do.call(cls, config)\n\nTo learn more about serialization and saving, see the complete guide to saving and serializing models."
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#privileged-training-argument-in-the-call-method",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#privileged-training-argument-in-the-call-method",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Privileged training argument in the call() method",
    "text": "Privileged training argument in the call() method\nSome layers, in particular the BatchNormalization layer and the Dropout layer, have different behaviors during training and inference. For such layers, it is standard practice to expose a training (boolean) argument in the call() method.\nBy exposing this argument in call(), you enable the built-in training and evaluation loops (e.g. fit()) to correctly use the layer in training and inference. Note, the default of NULL means that the training parameter will be inferred by keras from the training context (e.g., it will be TRUE if called from fit(), FALSE if called from predict())\n\nCustomDropout(keras$layers$Layer) %py_class% {\n  initialize <- function(rate, ...) {\n    super$initialize(...)\n    self$rate <- rate\n  }\n  call <- function(inputs, training = NULL) {\n    if (isTRUE(training)) {\n      return(tf$nn$dropout(inputs, rate = self$rate))\n    }\n    inputs\n  }\n}"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#privileged-mask-argument-in-the-call-method",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#privileged-mask-argument-in-the-call-method",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Privileged mask argument in the call() method",
    "text": "Privileged mask argument in the call() method\nThe other privileged argument supported by call() is the mask argument.\nYou will find it in all Keras RNN layers. A mask is a boolean tensor (one boolean value per timestep in the input) used to skip certain input timesteps when processing timeseries data.\nKeras will automatically pass the correct mask argument to call() for layers that support it, when a mask is generated by a prior layer. Mask-generating layers are the Embedding layer configured with mask_zero=True, and the Masking layer.\nTo learn more about masking and how to write masking-enabled layers, please check out the guide “understanding padding and masking”."
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-model-class",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#the-model-class",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "The Model class",
    "text": "The Model class\nIn general, you will use the Layer class to define inner computation blocks, and will use the Model class to define the outer model – the object you will train.\nFor instance, in a ResNet50 model, you would have several ResNet blocks subclassing Layer, and a single Model encompassing the entire ResNet50 network.\nThe Model class has the same API as Layer, with the following differences:\n\nIt has support for built-in training, evaluation, and prediction methods (fit(), evaluate(), predict()).\nIt exposes the list of its inner layers, via the model$layers property.\nIt exposes saving and serialization APIs (save_model_tf(), save_model_weights_tf(), …)\n\nEffectively, the Layer class corresponds to what we refer to in the literature as a “layer” (as in “convolution layer” or “recurrent layer”) or as a “block” (as in “ResNet block” or “Inception block”).\nMeanwhile, the Model class corresponds to what is referred to in the literature as a “model” (as in “deep learning model”) or as a “network” (as in “deep neural network”).\nSo if you’re wondering, “should I use the Layer class or the Model class?”, ask yourself: will I need to call fit() on it? Will I need to call save() on it? If so, go with Model. If not (either because your class is just a block in a bigger system, or because you are writing training & saving code yourself), use Layer.\nFor instance, we could take our mini-resnet example above, and use it to build a Model that we could train with fit(), and that we could save with save_model_weights_tf():\n\nResNet(keras$Model) %py_class% {\n  initialize <- function(num_classes = 1000) {\n    super$initialize()\n    self$block_1 <- ResNetBlock()\n    self$block_2 <- ResNetBlock()\n    self$global_pool <- layer_global_average_pooling_2d()\n    self$classifier <- layer_dense(units = num_classes)\n  }\n\n  call <- function(inputs) {\n    x <- self$block_1(inputs)\n    x <- self$block_2(x)\n    x <- self$global_pool(x)\n    self$classifier(x)\n  }\n}\n\n\nresnet <- ResNet()\ndataset <- ...\nresnet %>% fit(dataset, epochs = 10)\nresnet %>% save_model_tf(filepath)"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#putting-it-all-together-an-end-to-end-example",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#putting-it-all-together-an-end-to-end-example",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Putting it all together: an end-to-end example",
    "text": "Putting it all together: an end-to-end example\nHere’s what you’ve learned so far:\n\nA Layer encapsulates a state (created in initialize() or build()), and some computation (defined in call()).\nLayers can be recursively nested to create new, bigger computation blocks.\nLayers can create and track losses (typically regularization losses) as well as metrics, via add_loss() and add_metric()\nThe outer container, the thing you want to train, is a Model. A Model is just like a Layer, but with added training and serialization utilities.\n\nLet’s put all of these things together into an end-to-end example: we’re going to implement a Variational AutoEncoder (VAE). We’ll train it on MNIST digits.\nOur VAE will be a subclass of Model, built as a nested composition of layers that subclass Layer. It will feature a regularization loss (KL divergence).\n\nSampling(keras$layers$Layer) %py_class% {\n  call <- function(inputs) {\n    c(z_mean, z_log_var) %<-% inputs\n    batch <- tf$shape(z_mean)[1]\n    dim <- tf$shape(z_mean)[2]\n    epsilon <- k_random_normal(shape = c(batch, dim))\n    z_mean + exp(0.5 * z_log_var) * epsilon\n  }\n}\n\n\nEncoder(keras$layers$Layer) %py_class% {\n  \"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\n\n  initialize <- function(latent_dim = 32, intermediate_dim = 64, name = \"encoder\", ...) {\n    super$initialize(name = name, ...)\n    self$dense_proj <- layer_dense(units = intermediate_dim, activation = \"relu\")\n    self$dense_mean <- layer_dense(units = latent_dim)\n    self$dense_log_var <- layer_dense(units = latent_dim)\n    self$sampling <- Sampling()\n  }\n\n  call <- function(inputs) {\n    x <- self$dense_proj(inputs)\n    z_mean <- self$dense_mean(x)\n    z_log_var <- self$dense_log_var(x)\n    z <- self$sampling(c(z_mean, z_log_var))\n    list(z_mean, z_log_var, z)\n  }\n}\n\n\nDecoder(keras$layers$Layer) %py_class% {\n  \"Converts z, the encoded digit vector, back into a readable digit.\"\n\n  initialize <- function(original_dim, intermediate_dim = 64, name = \"decoder\", ...) {\n    super$initialize(name = name, ...)\n    self$dense_proj <- layer_dense(units = intermediate_dim, activation = \"relu\")\n    self$dense_output <- layer_dense(units = original_dim, activation = \"sigmoid\")\n  }\n\n  call <- function(inputs) {\n    x <- self$dense_proj(inputs)\n    self$dense_output(x)\n  }\n}\n\n\nVariationalAutoEncoder(keras$Model) %py_class% {\n  \"Combines the encoder and decoder into an end-to-end model for training.\"\n\n  initialize <- function(original_dim, intermediate_dim = 64, latent_dim = 32,\n                         name = \"autoencoder\", ...) {\n    super$initialize(name = name, ...)\n    self$original_dim <- original_dim\n    self$encoder <- Encoder(\n      latent_dim = latent_dim,\n      intermediate_dim = intermediate_dim\n    )\n    self$decoder <- Decoder(original_dim, intermediate_dim = intermediate_dim)\n  }\n\n  call <- function(inputs) {\n    c(z_mean, z_log_var, z) %<-% self$encoder(inputs)\n    reconstructed <- self$decoder(z)\n    # Add KL divergence regularization loss.\n    kl_loss <- -0.5 * tf$reduce_mean(z_log_var - tf$square(z_mean) - tf$exp(z_log_var) + 1)\n    self$add_loss(kl_loss)\n    reconstructed\n  }\n}\n\nLet’s write a simple training loop on MNIST:\n\nlibrary(tfautograph)\nlibrary(tfdatasets)\n\n\noriginal_dim <- 784\nvae <- VariationalAutoEncoder(original_dim, 64, 32)\n\noptimizer <- optimizer_adam(learning_rate = 1e-3)\nmse_loss_fn <- loss_mean_squared_error()\n\nloss_metric <- metric_mean()\n\nx_train <- dataset_mnist()$train$x %>%\n  array_reshape(c(60000, 784)) %>%\n  `/`(255)\n\ntrain_dataset <- tensor_slices_dataset(x_train) %>%\n  dataset_shuffle(buffer_size = 1024) %>%\n  dataset_batch(64)\n\nepochs <- 2\n\n# Iterate over epochs.\nfor (epoch in seq(epochs)) {\n  cat(sprintf(\"Start of epoch %d\\n\", epoch))\n\n  # Iterate over the batches of the dataset.\n  # autograph lets you use tfdatasets in `for` and `while`\n  autograph({\n    step <- 0\n    for (x_batch_train in train_dataset) {\n      with(tf$GradientTape() %as% tape, {\n        ## Note: we're four opaque contexts deep here (for, autograph, for,\n        ## with), When in doubt about the objects or methods that are available\n        ## (e.g., what is `tape` here?), remember you can always drop into a\n        ## debugger right here:\n        # browser()\n\n        reconstructed <- vae(x_batch_train)\n        # Compute reconstruction loss\n        loss <- mse_loss_fn(x_batch_train, reconstructed)\n\n        loss %<>% add(vae$losses[[1]]) # Add KLD regularization loss\n      })\n      grads <- tape$gradient(loss, vae$trainable_weights)\n      optimizer$apply_gradients(\n        purrr::transpose(list(grads, vae$trainable_weights)))\n\n      loss_metric(loss)\n\n      step %<>% add(1)\n      if (step %% 100 == 0) {\n        cat(sprintf(\"step %d: mean loss = %.4f\\n\", step, loss_metric$result()))\n      }\n    }\n  })\n}\n\nStart of epoch 1\nstep 100: mean loss = 0.1279\nstep 200: mean loss = 0.1003\nstep 300: mean loss = 0.0899\nstep 400: mean loss = 0.0848\nstep 500: mean loss = 0.0813\nstep 600: mean loss = 0.0791\nstep 700: mean loss = 0.0774\nstep 800: mean loss = 0.0762\nstep 900: mean loss = 0.0752\nStart of epoch 2\nstep 100: mean loss = 0.0742\nstep 200: mean loss = 0.0737\nstep 300: mean loss = 0.0732\nstep 400: mean loss = 0.0728\nstep 500: mean loss = 0.0724\nstep 600: mean loss = 0.0721\nstep 700: mean loss = 0.0718\nstep 800: mean loss = 0.0716\nstep 900: mean loss = 0.0713\n\n\nNote that since the VAE is subclassing Model, it features built-in training loops. So you could also have trained it like this:\n\nvae <- VariationalAutoEncoder(784, 64, 32)\n\noptimizer <- optimizer_adam(learning_rate = 1e-3)\n\nvae %>% compile(optimizer, loss = loss_mean_squared_error())\nvae %>% fit(x_train, x_train, epochs = 2, batch_size = 64)"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#beyond-object-oriented-development-the-functional-api",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#beyond-object-oriented-development-the-functional-api",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Beyond object-oriented development: the Functional API",
    "text": "Beyond object-oriented development: the Functional API\nIf you prefer a less object-oriented way of programming, you can also build models using the Functional API. Importantly, choosing one style or another does not prevent you from leveraging components written in the other style: you can always mix-and-match.\nFor instance, the Functional API example below reuses the same Sampling layer we defined in the example above:\n\noriginal_dim <- 784\nintermediate_dim <- 64\nlatent_dim <- 32\n\n# Define encoder model.\noriginal_inputs <- layer_input(shape = original_dim, name = \"encoder_input\")\nx <- layer_dense(units = intermediate_dim, activation = \"relu\")(original_inputs)\nz_mean <- layer_dense(units = latent_dim, name = \"z_mean\")(x)\nz_log_var <- layer_dense(units = latent_dim, name = \"z_log_var\")(x)\nz <- Sampling()(list(z_mean, z_log_var))\nencoder <- keras_model(inputs = original_inputs, outputs = z, name = \"encoder\")\n\n# Define decoder model.\nlatent_inputs <- layer_input(shape = latent_dim, name = \"z_sampling\")\nx <- layer_dense(units = intermediate_dim, activation = \"relu\")(latent_inputs)\noutputs <- layer_dense(units = original_dim, activation = \"sigmoid\")(x)\ndecoder <- keras_model(inputs = latent_inputs, outputs = outputs, name = \"decoder\")\n\n# Define VAE model.\noutputs <- decoder(z)\nvae <- keras_model(inputs = original_inputs, outputs = outputs, name = \"vae\")\n\n# Add KL divergence regularization loss.\nkl_loss <- -0.5 * tf$reduce_mean(z_log_var - tf$square(z_mean) - tf$exp(z_log_var) + 1)\nvae$add_loss(kl_loss)\n\n# Train.\noptimizer <- keras$optimizers$Adam(learning_rate = 1e-3)\nvae %>% compile(optimizer, loss = loss_mean_squared_error())\nvae %>% fit(x_train, x_train, epochs = 3, batch_size = 64)\n\nFor more information, make sure to read the Functional API guide."
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#defining-custom-layers-and-models-in-an-r-package",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#defining-custom-layers-and-models-in-an-r-package",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Defining custom layers and models in an R package",
    "text": "Defining custom layers and models in an R package\nUnfortunately you can’t use anything that creates references to Python objects, at the top-level of an R package.\nHere is why: when you build an R package, all the R files in the R/ directory get sourced in an R environment (the package namespace), and then that environment is saved as part of the package bundle. Loading the package means restoring the saved R environment. This means that the R code only gets sourced once, at build time. If you create references to external objects (e.g., Python objects) at package build time, they will be NULL pointers when the package is loaded, because the external objects they pointed to at build time no longer exist at load time.\nThe solution is to delay creating references to Python objects until run time. Fortunately, %py_class%, Layer(), and create_layer_wrapper(R6Class(...)) are all lazy about initializing the Python reference, so they are safe to define and export in an R package.\nIf you’re writing an R package that uses keras and reticulate, this article might be helpful to read over."
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#summary",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#summary",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Summary",
    "text": "Summary\nIn this guide you learned about creating custom layers and models in keras.\n\nThe constructors available: new_layer_class(), %py_class%, create_layer_wrapper(), R6Class(), Layer().\nWhat methods to you might want to define to your model: initialize(), build(), call(), and get_config().\nWhat convenience methods are available when you subclass keras$layers$Layer: add_weight(), add_loss(), and add_metric()"
  },
  {
    "objectID": "guides/keras/making_new_layers_and_models_via_subclassing.html#environment-details",
    "href": "guides/keras/making_new_layers_and_models_via_subclassing.html#environment-details",
    "title": "Writing Layer and Model objects from scratch.",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html",
    "href": "guides/keras/preprocessing_layers.html",
    "title": "Working with preprocessing layers",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#keras-preprocessing",
    "href": "guides/keras/preprocessing_layers.html#keras-preprocessing",
    "title": "Working with preprocessing layers",
    "section": "Keras preprocessing",
    "text": "Keras preprocessing\nThe Keras preprocessing layers API allows developers to build Keras-native input processing pipelines. These input processing pipelines can be used as independent preprocessing code in non-Keras workflows, combined directly with Keras models, and exported as part of a Keras SavedModel.\nWith Keras preprocessing layers, you can build and export models that are truly end-to-end: models that accept raw images or raw structured data as input; models that handle feature normalization or feature value indexing on their own."
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#available-preprocessing-layers",
    "href": "guides/keras/preprocessing_layers.html#available-preprocessing-layers",
    "title": "Working with preprocessing layers",
    "section": "Available preprocessing layers",
    "text": "Available preprocessing layers\n\nText preprocessing\n\nlayer_text_vectorization(): turns raw strings into an encoded representation that can be read by a layer_embedding() or layer_dense() layer.\n\n\n\nNumerical features preprocessing\n\nlayer_normalization(): performs feature-wise normalization of input features.\nlayer_discretization(): turns continuous numerical features into integer categorical features.\n\n\n\nCategorical features preprocessing\n\nlayer_category_encoding(): turns integer categorical features into one-hot, multi-hot, or count-based, dense representations.\nlayer_hashing(): performs categorical feature hashing, also known as the “hashing trick”.\nlayer_string_lookup(): turns string categorical values into an encoded representation that can be read by an Embedding layer or Dense layer.\nlayer_integer_lookup(): turns integer categorical values into an encoded representation that can be read by an Embedding layer or Dense layer.\n\n\n\nImage preprocessing\nThese layers are for standardizing the inputs of an image model.\n\nlayer_resizing(): resizes a batch of images to a target size.\nlayer_rescaling(): rescales and offsets the values of a batch of images (e.g., going from inputs in the [0, 255] range to inputs in the [0, 1] range.\nlayer_center_crop(): returns a center crop of a batch of images.\n\n\n\nImage data augmentation\nThese layers apply random augmentation transforms to a batch of images. They are only active during training.\n\nlayer_random_crop()\nlayer_random_flip()\nlayer_random_flip()\nlayer_random_translation()\nlayer_random_rotation()\nlayer_random_zoom()\nlayer_random_height()\nlayer_random_width()\nlayer_random_contrast()"
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#the-adapt-function",
    "href": "guides/keras/preprocessing_layers.html#the-adapt-function",
    "title": "Working with preprocessing layers",
    "section": "The adapt() function",
    "text": "The adapt() function\nSome preprocessing layers have an internal state that can be computed based on a sample of the training data. The list of stateful preprocessing layers is:\n\nlayer_text_vectorization(): holds a mapping between string tokens and integer indices\nlayer_string_lookup() and layer_integer_lookup(): hold a mapping between input values and integer indices.\nlayer_normalization(): holds the mean and standard deviation of the features.\nlayer_discretization(): holds information about value bucket boundaries.\n\nCrucially, these layers are non-trainable. Their state is not set during training; it must be set before training, either by initializing them from a precomputed constant, or by “adapting” them on data.\nYou set the state of a preprocessing layer by exposing it to training data, via adapt():\n\ndata <- rbind(c(0.1, 0.2, 0.3),\n              c(0.8, 0.9, 1.0),\n              c(1.5, 1.6, 1.7))\nlayer <- layer_normalization()\n\nLoaded Tensorflow version 2.9.1\n\nadapt(layer, data)\nnormalized_data <- as.array(layer(data))\n\nsprintf(\"Features mean: %.2f\", mean(normalized_data))\n\n[1] \"Features mean: -0.00\"\n\nsprintf(\"Features std: %.2f\", sd(normalized_data))\n\n[1] \"Features std: 1.06\"\n\n\nadapt() takes either an array or a tf_dataset. In the case of layer_string_lookup() and layer_text_vectorization(), you can also pass a character vector:\n\ndata <- c(\n  \"Congratulations!\",\n  \"Today is your day.\",\n  \"You're off to Great Places!\",\n  \"You're off and away!\",\n  \"You have brains in your head.\",\n  \"You have feet in your shoes.\",\n  \"You can steer yourself\",\n  \"any direction you choose.\",\n  \"You're on your own. And you know what you know.\",\n  \"And YOU are the one who'll decide where to go.\"\n)\n\nlayer = layer_text_vectorization()\nlayer %>% adapt(data)\nvectorized_text <- layer(data)\nprint(vectorized_text)\n\ntf.Tensor(\n[[31  0  0  0  0  0  0  0  0  0]\n [15 23  3 30  0  0  0  0  0  0]\n [ 4  7  6 25 19  0  0  0  0  0]\n [ 4  7  5 35  0  0  0  0  0  0]\n [ 2 10 34  9  3 24  0  0  0  0]\n [ 2 10 27  9  3 18  0  0  0  0]\n [ 2 33 17 11  0  0  0  0  0  0]\n [37 28  2 32  0  0  0  0  0  0]\n [ 4 22  3 20  5  2  8 14  2  8]\n [ 5  2 36 16 21 12 29 13  6 26]], shape=(10, 10), dtype=int64)\n\n\nIn addition, adaptable layers always expose an option to directly set state via constructor arguments or weight assignment. If the intended state values are known at layer construction time, or are calculated outside of the adapt() call, they can be set without relying on the layer’s internal computation. For instance, if external vocabulary files for the layer_text_vectorization(), layer_string_lookup(), or layer_integer_lookup() layers already exist, those can be loaded directly into the lookup tables by passing a path to the vocabulary file in the layer’s constructor arguments.\nHere’s an example where we instantiate a layer_string_lookup() layer with precomputed vocabulary:\n\nvocab <- c(\"a\", \"b\", \"c\", \"d\")\ndata <- as_tensor(rbind(c(\"a\", \"c\", \"d\"),\n                        c(\"d\", \"z\", \"b\")))\nlayer <- layer_string_lookup(vocabulary=vocab)\nvectorized_data <- layer(data)\nprint(vectorized_data)\n\ntf.Tensor(\n[[1 3 4]\n [4 0 2]], shape=(2, 3), dtype=int64)"
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#preprocessing-data-before-the-model-or-inside-the-model",
    "href": "guides/keras/preprocessing_layers.html#preprocessing-data-before-the-model-or-inside-the-model",
    "title": "Working with preprocessing layers",
    "section": "Preprocessing data before the model or inside the model",
    "text": "Preprocessing data before the model or inside the model\nThere are two ways you could be using preprocessing layers:\nOption 1: Make them part of the model, like this:\n\ninput <- layer_input(shape = input_shape)\noutput <- input %>%\n  preprocessing_layer() %>%\n  rest_of_the_model()\nmodel <- keras_model(input, output)\n\nWith this option, preprocessing will happen on device, synchronously with the rest of the model execution, meaning that it will benefit from GPU acceleration. If you’re training on GPU, this is the best option for the layer_normalization() layer, and for all image preprocessing and data augmentation layers.\nOption 2: apply it to your tf_dataset, so as to obtain a dataset that yields batches of preprocessed data, like this:\n\nlibrary(tfdatasets)\ndataset <- ... # define dataset\ndataset <- dataset %>%\n  dataset_map(function(x, y) list(preprocessing_layer(x), y))\n\nWith this option, your preprocessing will happen on CPU, asynchronously, and will be buffered before going into the model. In addition, if you call tfdatasets::dataset_prefetch() on your dataset, the preprocessing will happen efficiently in parallel with training:\n\ndataset <- dataset %>%\n  dataset_map(function(x, y) list(preprocessing_layer(x), y)) %>%\n  dataset_prefetch()\nmodel %>% fit(dataset)\n\nThis is the best option for layer_text_vectorization(), and all structured data preprocessing layers. It can also be a good option if you’re training on CPU and you use image preprocessing layers."
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#benefits-of-doing-preprocessing-inside-the-model-at-inference-time",
    "href": "guides/keras/preprocessing_layers.html#benefits-of-doing-preprocessing-inside-the-model-at-inference-time",
    "title": "Working with preprocessing layers",
    "section": "Benefits of doing preprocessing inside the model at inference time",
    "text": "Benefits of doing preprocessing inside the model at inference time\nEven if you go with option 2, you may later want to export an inference-only end-to-end model that will include the preprocessing layers. The key benefit to doing this is that it makes your model portable and it helps reduce the training/serving skew.\nWhen all data preprocessing is part of the model, other people can load and use your model without having to be aware of how each feature is expected to be encoded & normalized. Your inference model will be able to process raw images or raw structured data, and will not require users of the model to be aware of the details of e.g. the tokenization scheme used for text, the indexing scheme used for categorical features, whether image pixel values are normalized to [-1, +1] or to [0, 1], etc. This is especially powerful if you’re exporting your model to another runtime, such as TensorFlow.js: you won’t have to reimplement your preprocessing pipeline in JavaScript.\nIf you initially put your preprocessing layers in your tf_dataset pipeline, you can export an inference model that packages the preprocessing. Simply instantiate a new model that chains your preprocessing layers and your training model:\n\ninput <- layer_input(shape = input_shape)\noutput <- input %>%\n  preprocessing_layer(input) %>%\n  training_model()\ninference_model <- keras_model(input, output)"
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#preprocessing-during-multi-worker-training",
    "href": "guides/keras/preprocessing_layers.html#preprocessing-during-multi-worker-training",
    "title": "Working with preprocessing layers",
    "section": "Preprocessing during multi-worker training",
    "text": "Preprocessing during multi-worker training\nPreprocessing layers are compatible with the tf.distribute API for running training across multiple machines.\nIn general, preprocessing layers should be placed inside a strategy$scope() and called either inside or before the model as discussed above.\n\nwith(strategy$scope(), {\n    inputs <- layer_input(shape=input_shape)\n    preprocessing_layer <- layer_hashing(num_bins = 10)\n    dense_layer <- layer_dense(units = 16)\n})\n\nFor more details, refer to the preprocessing section of the distributed input guide."
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#quick-recipes",
    "href": "guides/keras/preprocessing_layers.html#quick-recipes",
    "title": "Working with preprocessing layers",
    "section": "Quick recipes",
    "text": "Quick recipes\n\nImage data augmentation\nNote that image data augmentation layers are only active during training (similar to the layer_dropout() layer).\n\nlibrary(keras)\nlibrary(tfdatasets)\n\n# Create a data augmentation stage with horizontal flipping, rotations, zooms\ndata_augmentation <-\n  keras_model_sequential() %>%\n  layer_random_flip(\"horizontal\") %>%\n  layer_random_rotation(0.1) %>%\n  layer_random_zoom(0.1)\n\n\n# Load some data\nc(c(x_train, y_train), ...) %<-% dataset_cifar10()\ninput_shape <- dim(x_train)[-1] # drop batch dim\nclasses <- 10\n\n# Create a tf_dataset pipeline of augmented images (and their labels)\ntrain_dataset <- tensor_slices_dataset(list(x_train, y_train)) %>%\n  dataset_batch(16) %>%\n  dataset_map( ~ list(data_augmentation(.x), .y)) # see ?purrr::map to learn about ~ notation\n\n\n# Create a model and train it on the augmented image data\nresnet <- application_resnet50(weights = NULL,\n                               input_shape = input_shape,\n                               classes = classes)\n\ninput <- layer_input(shape = input_shape)\noutput <- input %>%\n  layer_rescaling(1 / 255) %>%   # Rescale inputs\n  resnet()\n\nmodel <- keras_model(input, output) %>%\n  compile(optimizer = \"rmsprop\", loss = \"sparse_categorical_crossentropy\") %>%\n  fit(train_dataset, steps_per_epoch = 5)\n\nYou can see a similar setup in action in the example image classification from scratch.\n\n\nNormalizing numerical features\n\nlibrary(tensorflow)\nlibrary(keras)\nc(c(x_train, y_train), ...) %<-% dataset_cifar10()\nx_train <- x_train %>%\n  array_reshape(c(dim(x_train)[1], -1L)) # flatten each case\n\ninput_shape <- dim(x_train)[-1] # keras layers automatically add the batch dim\nclasses <- 10\n\n# Create a layer_normalization() layer and set its internal state using the training data\nnormalizer <- layer_normalization()\nnormalizer %>% adapt(x_train)\n\n# Create a model that include the normalization layer\ninput <- layer_input(shape = input_shape)\noutput <- input %>%\n  normalizer() %>%\n  layer_dense(classes, activation = \"softmax\")\n\nmodel <- keras_model(input, output) %>%\n  compile(optimizer = \"adam\",\n          loss = \"sparse_categorical_crossentropy\")\n\n# Train the model\nmodel %>%\n  fit(x_train, y_train)\n\n\n\nEncoding string categorical features via one-hot encoding\n\n# Define some toy data\ndata <- as_tensor(c(\"a\", \"b\", \"c\", \"b\", \"c\", \"a\")) %>%\n  k_reshape(c(-1, 1)) # reshape into matrix with shape: (6, 1)\n\n# Use layer_string_lookup() to build an index of \n# the feature values and encode output.\nlookup <- layer_string_lookup(output_mode=\"one_hot\")\nlookup %>% adapt(data)\n\n# Convert new test data (which includes unknown feature values)\ntest_data = as_tensor(matrix(c(\"a\", \"b\", \"c\", \"d\", \"e\", \"\")))\nencoded_data = lookup(test_data)\nprint(encoded_data)\n\ntf.Tensor(\n[[0. 0. 0. 1.]\n [0. 0. 1. 0.]\n [0. 1. 0. 0.]\n [1. 0. 0. 0.]\n [1. 0. 0. 0.]\n [1. 0. 0. 0.]], shape=(6, 4), dtype=float32)\n\n\nNote that, here, index 0 is reserved for out-of-vocabulary values (values that were not seen during adapt()).\nYou can see the layer_string_lookup() in action in the Structured data classification from scratch example.\n\n\nEncoding integer categorical features via one-hot encoding\n\n# Define some toy data\ndata <- as_tensor(matrix(c(10, 20, 20, 10, 30, 0)), \"int32\")\n\n# Use layer_integer_lookup() to build an \n# index of the feature values and encode output.\nlookup <- layer_integer_lookup(output_mode=\"one_hot\")\nlookup %>% adapt(data)\n\n# Convert new test data (which includes unknown feature values)\ntest_data <- as_tensor(matrix(c(10, 10, 20, 50, 60, 0)), \"int32\")\nencoded_data <- lookup(test_data)\nprint(encoded_data)\n\ntf.Tensor(\n[[0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0.]\n [1. 0. 0. 0. 0.]\n [1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1.]], shape=(6, 5), dtype=float32)\n\n\nNote that index 0 is reserved for missing values (which you should specify as the value 0), and index 1 is reserved for out-of-vocabulary values (values that were not seen during adapt()). You can configure this by using the mask_token and oov_token constructor arguments of layer_integer_lookup().\nYou can see the layer_integer_lookup() in action in the example structured data classification from scratch.\n\n\nApplying the hashing trick to an integer categorical feature\nIf you have a categorical feature that can take many different values (on the order of 10e3 or higher), where each value only appears a few times in the data, it becomes impractical and ineffective to index and one-hot encode the feature values. Instead, it can be a good idea to apply the “hashing trick”: hash the values to a vector of fixed size. This keeps the size of the feature space manageable, and removes the need for explicit indexing.\n\n# Sample data: 10,000 random integers with values between 0 and 100,000\ndata <- k_random_uniform(shape = c(10000, 1), dtype = \"int64\")\n\n# Use the Hashing layer to hash the values to the range [0, 64]\nhasher <- layer_hashing(num_bins = 64, salt = 1337)\n\n# Use the CategoryEncoding layer to multi-hot encode the hashed values\nencoder <- layer_category_encoding(num_tokens=64, output_mode=\"multi_hot\")\nencoded_data <- encoder(hasher(data))\nprint(encoded_data$shape)\n\nTensorShape([10000, 64])\n\n\n\n\nEncoding text as a sequence of token indices\nThis is how you should preprocess text to be passed to an Embedding layer.\n\nlibrary(tensorflow)\nlibrary(tfdatasets)\nlibrary(keras)\n\n# Define some text data to adapt the layer\nadapt_data <- as_tensor(c(\n  \"The Brain is wider than the Sky\",\n  \"For put them side by side\",\n  \"The one the other will contain\",\n  \"With ease and You beside\"\n))\n\n# Create a layer_text_vectorization() layer\ntext_vectorizer <- layer_text_vectorization(output_mode=\"int\")\n# Index the vocabulary via `adapt()`\ntext_vectorizer %>% adapt(adapt_data)\n\n# Try out the layer\ncat(\"Encoded text:\\n\",\n    as.array(text_vectorizer(\"The Brain is deeper than the sea\")))\n\nEncoded text:\n 2 19 14 1 9 2 1\n\n# Create a simple model\ninput <- layer_input(shape(NULL), dtype=\"int64\")\n\noutput <- input %>%\n  layer_embedding(input_dim = text_vectorizer$vocabulary_size(),\n                  output_dim = 16) %>%\n  layer_gru(8) %>%\n  layer_dense(1)\n\nmodel <- keras_model(input, output)\n\n# Create a labeled dataset (which includes unknown tokens)\ntrain_dataset <- tensor_slices_dataset(list(\n  c(\"The Brain is deeper than the sea\", \"for if they are held Blue to Blue\"),\n  c(1L, 0L)\n))\n\n# Preprocess the string inputs, turning them into int sequences\ntrain_dataset <- train_dataset %>%\n  dataset_batch(2) %>%\n  dataset_map(~list(text_vectorizer(.x), .y))\n\n# Train the model on the int sequences\ncat(\"Training model...\\n\")\n\nTraining model...\n\nmodel %>%\n  compile(optimizer = \"rmsprop\", loss = \"mse\") %>%\n  fit(train_dataset)\n\n# For inference, you can export a model that accepts strings as input\ninput <- layer_input(shape = 1, dtype=\"string\")\noutput <- input %>%\n  text_vectorizer() %>%\n  model()\n\nend_to_end_model <- keras_model(input, output)\n\n# Call the end-to-end model on test data (which includes unknown tokens)\ncat(\"Calling end-to-end model on test string...\\n\")\n\nCalling end-to-end model on test string...\n\ntest_data <- tf$constant(matrix(\"The one the other will absorb\"))\ntest_output <- end_to_end_model(test_data)\ncat(\"Model output:\", as.array(test_output), \"\\n\")\n\nModel output: 0.1007235 \n\n\nYou can see the layer_text_vectorization() layer in action, combined with an Embedding mode, in the example text classification from scratch.\nNote that when training such a model, for best performance, you should always use the layer_text_vectorization() layer as part of the input pipeline.\n\n\nEncoding text as a dense matrix of ngrams with multi-hot encoding\nThis is how you can preprocess text to be passed to a Dense layer.\n\n# Define some text data to adapt the layer\nadapt_data <- as_tensor(c(\n  \"The Brain is wider than the Sky\",\n  \"For put them side by side\",\n  \"The one the other will contain\",\n  \"With ease and You beside\"\n))\n\n# Instantiate layer_text_vectorization() with \"multi_hot\" output_mode\n# and ngrams=2 (index all bigrams)\ntext_vectorizer = layer_text_vectorization(output_mode=\"multi_hot\", ngrams=2)\n# Index the bigrams via `adapt()`\ntext_vectorizer %>% adapt(adapt_data)\n\n# Try out the layer\ncat(\"Encoded text:\\n\", \n    as.array(text_vectorizer(\"The Brain is deeper than the sea\")))\n\nEncoded text:\n 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n\n# Create a simple model\ninput = layer_input(shape = text_vectorizer$vocabulary_size(), dtype=\"int64\")\n\noutput <- input %>%\n  layer_dense(1)\n\nmodel <- keras_model(input, output)\n\n\n# Create a labeled dataset (which includes unknown tokens)\ntrain_dataset = tensor_slices_dataset(list(\n  c(\"The Brain is deeper than the sea\", \"for if they are held Blue to Blue\"),\n  c(1L, 0L)\n))\n\n# Preprocess the string inputs, turning them into int sequences\ntrain_dataset <- train_dataset %>%\n  dataset_batch(2) %>%\n  dataset_map(~list(text_vectorizer(.x), .y))\n\n# Train the model on the int sequences\ncat(\"Training model...\\n\")\n\nTraining model...\n\nmodel %>%\n  compile(optimizer=\"rmsprop\", loss=\"mse\") %>%\n  fit(train_dataset)\n\n# For inference, you can export a model that accepts strings as input\ninput <- layer_input(shape = 1, dtype=\"string\")\n\noutput <- input %>%\n  text_vectorizer() %>%\n  model()\n\nend_to_end_model = keras_model(input, output)\n\n# Call the end-to-end model on test data (which includes unknown tokens)\ncat(\"Calling end-to-end model on test string...\\n\")\n\nCalling end-to-end model on test string...\n\ntest_data <- tf$constant(matrix(\"The one the other will absorb\"))\ntest_output <- end_to_end_model(test_data)\ncat(\"Model output: \"); print(test_output); cat(\"\\n\")\n\nModel output: \n\n\ntf.Tensor([[0.46172485]], shape=(1, 1), dtype=float32)\n\n\n\n\nEncoding text as a dense matrix of ngrams with TF-IDF weighting\nThis is an alternative way of preprocessing text before passing it to a layer_dense layer.\n\n# Define some text data to adapt the layer\nadapt_data <- as_tensor(c(\n  \"The Brain is wider than the Sky\",\n  \"For put them side by side\",\n  \"The one the other will contain\",\n  \"With ease and You beside\"\n))\n\n# Instantiate layer_text_vectorization() with \"tf-idf\" output_mode\n# (multi-hot with TF-IDF weighting) and ngrams=2 (index all bigrams)\ntext_vectorizer = layer_text_vectorization(output_mode=\"tf-idf\", ngrams=2)\n# Index the bigrams and learn the TF-IDF weights via `adapt()`\n\n\nwith(tf$device(\"CPU\"), {\n  # A bug that prevents this from running on GPU for now.\n  text_vectorizer %>% adapt(adapt_data)\n})\n\n# Try out the layer\ncat(\"Encoded text:\\n\", \n    as.array(text_vectorizer(\"The Brain is deeper than the sea\")))\n\nEncoded text:\n 5.461647 1.694596 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1.098612 1.098612 1.098612 0 0 0 0 0 0 0 0 0 1.098612 0 0 0 0 0 0 0 1.098612 1.098612 0 0 0\n\n# Create a simple model\ninput <- layer_input(shape = text_vectorizer$vocabulary_size(), dtype=\"int64\")\noutput <- input %>% layer_dense(1)\nmodel <- keras_model(input, output)\n\n# Create a labeled dataset (which includes unknown tokens)\ntrain_dataset = tensor_slices_dataset(list(\n  c(\"The Brain is deeper than the sea\", \"for if they are held Blue to Blue\"),\n  c(1L, 0L)\n))\n\n# Preprocess the string inputs, turning them into int sequences\ntrain_dataset <- train_dataset %>%\n  dataset_batch(2) %>%\n  dataset_map(~list(text_vectorizer(.x), .y))\n\n\n# Train the model on the int sequences\ncat(\"Training model...\")\n\nTraining model...\n\nmodel %>%\n  compile(optimizer=\"rmsprop\", loss=\"mse\") %>%\n  fit(train_dataset)\n\n# For inference, you can export a model that accepts strings as input\ninput <- layer_input(shape = 1, dtype=\"string\")\n\noutput <- input %>%\n  text_vectorizer() %>%\n  model()\n\nend_to_end_model = keras_model(input, output)\n\n# Call the end-to-end model on test data (which includes unknown tokens)\ncat(\"Calling end-to-end model on test string...\\n\")\n\nCalling end-to-end model on test string...\n\ntest_data <- tf$constant(matrix(\"The one the other will absorb\"))\ntest_output <- end_to_end_model(test_data)\ncat(\"Model output: \"); print(test_output)\n\nModel output: \n\n\ntf.Tensor([[-0.00118748]], shape=(1, 1), dtype=float32)"
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#important-gotchas",
    "href": "guides/keras/preprocessing_layers.html#important-gotchas",
    "title": "Working with preprocessing layers",
    "section": "Important gotchas",
    "text": "Important gotchas\n\nWorking with lookup layers with very large vocabularies\nYou may find yourself working with a very large vocabulary in a layer_text_vectorization(), a layer_string_lookup() layer, or an layer_integer_lookup() layer. Typically, a vocabulary larger than 500MB would be considered “very large”.\nIn such case, for best performance, you should avoid using adapt(). Instead, pre-compute your vocabulary in advance (you could use Apache Beam or TF Transform for this) and store it in a file. Then load the vocabulary into the layer at construction time by passing the filepath as the vocabulary argument."
  },
  {
    "objectID": "guides/keras/preprocessing_layers.html#environment-details",
    "href": "guides/keras/preprocessing_layers.html#environment-details",
    "title": "Working with preprocessing layers",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/python_subclasses.html",
    "href": "guides/keras/python_subclasses.html",
    "title": "Python Subclasses",
    "section": "",
    "text": "When using keras, a desire to create Python-based subclasses can arise in a number of ways. For example, when you want to:\nIn such scenarios, the most powerful and flexible approach is to directly inherit from, and then modify and/or enhance an appropriate Python class.\nSubclassing a Python class in R is generally straightforward. Two syntaxes are provided: one that adheres to R conventions and uses R6::R6Class as the class constructor, and one that adheres more to Python conventions, and attempts to replicate Python syntax in R."
  },
  {
    "objectID": "guides/keras/python_subclasses.html#examples",
    "href": "guides/keras/python_subclasses.html#examples",
    "title": "Python Subclasses",
    "section": "Examples",
    "text": "Examples\n\nA custom constraint (R6)\nFor demonstration purposes, let’s say you want to implement a custom keras kernel constraint via subclassing. Using R6:\n\nNonNegative <- R6::R6Class(\"NonNegative\",\n  inherit = keras$constraints$Constraint,\n  public = list(\n    \"__call__\" = function(x) {\n       w * k_cast(w >= 0, k_floatx())\n    }\n  )\n)\nNonNegative <- r_to_py(NonNegative, convert=TRUE)\n\nLoaded Tensorflow version 2.9.1\n\n\nThe r_to_py method will convert an R6 class generator into a Python class generator. After conversion, Python class generators will be different from R6 class generators in a few ways:\n\nNew class instances are generated by calling the class directly: NonNegative() (not NonNegative$new())\nAll methods (functions) are (potentially) modified to ensure their first argument is self.\nAll methods have in scope __class__, super and the class name (NonNegative).\nFor convenience, some method names are treated as aliases:\n\ninitialize is treated as an alias for __init__()\nfinalize is treated as an alias for __del__()\n\nsuper can be accessed in 3 ways:\n\nR6 style, which supports only single inheritance (the most common type)\n\nsuper$initialize()\n\nPython 2 style, which requires explicitly providing the class generator and instance\n\nsuper(NonNegative, self)$`__init__`()\n\nPython 3 style\n\nsuper()$`__init__`()\nWhen subclassing Keras base classes, it is generally your responsibility to call super$initialize() if you are masking a superclass initializer by providing your own initialize method.\nPassing convert=FALSE to r_to_py() will mean that all R methods will receive Python objects as arguments, and are expected to return Python objects. This allows for some features not available with convert=TRUE, namely, modifying some Python objects, like dictionaries or lists, in-place.\nActive bindings (methods supplied to R6Class(active=...)) are converted to Python @property-decorated methods.\nR6 classes with private methods or attributes are not supported.\nThe argument supplied to inherit can be:\n\nmissing or NULL\na Python class generator\nan R6 class generator, as long as it can be converted to a Python class generator as well\na list of Python/R6 classes (for multiple inheritance)\nA list of superclasses, with optional additional keywords (e.g., metaclass=, only for advanced Python use cases)\n\n\n\n\nA custom constraint (%py_class%)\nAs an alternative to r_to_py(R6Class(...)), we also provide %py_class%, a more concise alternative syntax for achieving the same outcome. %py_class% is heavily inspired by the Python class statement syntax, and is especially convenient when translating Python code to R. Translating the above example, you could write the same using %py_class%:\n\nNonNegative(keras$constraints$Constraint) %py_class% {\n  \"__call__\" <- function(x) {\n    w * k_cast(w >= 0, k_floatx())\n  }\n}\n\nNotice, this is very similar to the equivalent Python code:\n\nclass NonNegative(tf.keras.constraints.Constraint):\n    def __call__(self, w):\n        return w * tf.cast(tf.math.greater_equal(w, 0.), w.dtype)\n\nSome (potentially surprising) notes about %py_class%:\n\nJust like the Python class statement, it assigns the constructed class in the current scope! (There is no need to write NonNegative <- ...).\nThe left hand side can be:\n\nA bare symbol, ClassName\nA pseudo-call, with superclasses and keywords as arguments: ClassName(Superclass1, Superclass2, metaclass=my_metaclass)\n\nThe right hand side is evaluated in a new environment to form the namespace for the class methods.\n%py_class% objects can be safely defined at the top level of an R package. (see details about delay_load below)\nTwo keywords are treated specially: convert and delay_load.\nIf you want to call r_to_py with convert=FALSE, pass it as a keyword:\n\n\nNonNegative(keras$constraints$Constraint, convert=FALSE) %py_class% { ... }\n\n\nYou can delay creating the python type object until this first time a class instance is created by passing delay_load=TRUE. The default value is FALSE for most contexts, but TRUE if you are in an R package. (The actual test performed is identical(topenv(), globalenv())). If a %py_class% type object is delayed, it will display \"<<R6type>.ClassName> (delayed)\" when printed.\nAn additional convenience is that if the first expression of a function body or the class body is a literal character string, it is automatically taken as the __doc__ attribute of the class or method. The doc string will then be visible to both python and R tools e.g. reticulate::py_help(). See ?py_class for an example.\n\nIn all other regards, %py_class% is equivalent to r_to_py(R6Class()) (indeed, under the hood, they do the same thing).\n\n\nA custom layer (R6)\nThe same pattern can be extended to all sorts of keras objects. For example, a custom layer can be written by subclassing the base Keras Layer:\n\nCustomLayer <- r_to_py(R6::R6Class(\n\n  classname = \"CustomLayer\",\n  inherit = keras$layers$Layer,\n\n  public = list(\n    initialize = function(output_dim) {\n      self$output_dim <- output_dim\n    },\n\n    build = function(input_shape) {\n      self$kernel <- self$add_weight(\n        name = 'kernel',\n        shape = list(input_shape[[2]], self$output_dim),\n        initializer = initializer_random_normal(),\n        trainable = TRUE\n      )\n    },\n\n    call = function(x, mask = NULL) {\n      k_dot(x, self$kernel)\n    },\n\n    compute_output_shape = function(input_shape) {\n      list(input_shape[[1]], self$output_dim)\n    }\n  )\n))\n\n\n\nA custom layer (%py_class%)\nor using %py_class%:\n\nCustomLayer(keras$layers$Layer) %py_class% {\n\n  initialize <- function(output_dim) {\n    self$output_dim <- output_dim\n  }\n\n  build <- function(input_shape) {\n    self$kernel <- self$add_weight(\n      name = 'kernel',\n      shape = list(input_shape[[2]], self$output_dim),\n      initializer = initializer_random_normal(),\n      trainable = TRUE\n    )\n  }\n\n  call <- function(x, mask = NULL) {\n    k_dot(x, self$kernel)\n  }\n\n  compute_output_shape <- function(input_shape) {\n    list(input_shape[[1]], self$output_dim)\n  }\n}"
  },
  {
    "objectID": "guides/keras/python_subclasses.html#environment-details",
    "href": "guides/keras/python_subclasses.html#environment-details",
    "title": "Python Subclasses",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/sequential_model.html",
    "href": "guides/keras/sequential_model.html",
    "title": "The Sequential model",
    "section": "",
    "text": "library(tensorflow)\n\nError in reticulate::use_virtualenv(\"r-tensorflow-site\", required = TRUE) : \n  Directory ~/.virtualenvs/r-tensorflow-site is not a Python virtualenv\n\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/sequential_model.html#when-to-use-a-sequential-model",
    "href": "guides/keras/sequential_model.html#when-to-use-a-sequential-model",
    "title": "The Sequential model",
    "section": "When to use a Sequential model",
    "text": "When to use a Sequential model\nA Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\nSchematically, the following Sequential model:\n\n# Define Sequential model with 3 layers\nmodel <- keras_model_sequential() %>% \n  layer_dense(2, activation = \"relu\", name = \"layer1\") %>% \n  layer_dense(3, activation = \"relu\", name = \"layer2\") %>% \n  layer_dense(4, name = \"layer3\")\n\nLoaded Tensorflow version 2.9.1\n\n# Call model on a test input\nx <- tf$ones(shape(3, 3))\ny <- model(x)\n\nis equivalent to this function:\n\n# Create 3 layers\nlayer1 <- layer_dense(units = 2, activation = \"relu\", name = \"layer1\")\nlayer2 <- layer_dense(units = 3, activation = \"relu\", name = \"layer2\")\nlayer3 <- layer_dense(units = 4, name = \"layer3\")\n\n# Call layers on a test input\nx <- tf$ones(shape(3, 3))\ny <- layer3(layer2(layer1(x)))\n\nA Sequential model is not appropriate when:\n\nYour model has multiple inputs or multiple outputs\nAny of your layers has multiple inputs or multiple outputs\nYou need to do layer sharing\nYou want non-linear topology (e.g. a residual connection, a multi-branch model)"
  },
  {
    "objectID": "guides/keras/sequential_model.html#creating-a-sequential-model",
    "href": "guides/keras/sequential_model.html#creating-a-sequential-model",
    "title": "The Sequential model",
    "section": "Creating a Sequential model",
    "text": "Creating a Sequential model\nYou can create a Sequential model by piping a model through a series layers.\n\nmodel <- keras_model_sequential() %>%\n  layer_dense(2, activation = \"relu\") %>%\n  layer_dense(3, activation = \"relu\") %>%\n  layer_dense(4)\n\nIts layers are accessible via the layers attribute:\n\nmodel$layers\n\n[[1]]\n<keras.layers.core.dense.Dense object at 0x7f9d0df43820>\n\n[[2]]\n<keras.layers.core.dense.Dense object at 0x7f9d0ded8d00>\n\n[[3]]\n<keras.layers.core.dense.Dense object at 0x7f9d0df11a90>\n\n\nYou can also create a Sequential model incrementally:\n\nmodel <- keras_model_sequential()\nmodel %>% layer_dense(2, activation = \"relu\")\nmodel %>% layer_dense(3, activation = \"relu\")\nmodel %>% layer_dense(4)\n\nNote that there’s also a corresponding pop() method to remove layers: a Sequential model behaves very much like a stack of layers.\n\nmodel %>% pop_layer()\nlength(model$layers)  # 2\n\n[1] 2\n\n\nAlso note that the Sequential constructor accepts a name argument, just like any layer or model in Keras. This is useful to annotate TensorBoard graphs with semantically meaningful names.\n\nmodel <- keras_model_sequential(name = \"my_sequential\")\nmodel %>% layer_dense(2, activation = \"relu\", name = \"layer1\")\nmodel %>% layer_dense(3, activation = \"relu\", name = \"layer2\")\nmodel %>% layer_dense(4, name = \"layer3\")"
  },
  {
    "objectID": "guides/keras/sequential_model.html#specifying-the-input-shape-in-advance",
    "href": "guides/keras/sequential_model.html#specifying-the-input-shape-in-advance",
    "title": "The Sequential model",
    "section": "Specifying the input shape in advance",
    "text": "Specifying the input shape in advance\nGenerally, all layers in Keras need to know the shape of their inputs in order to be able to create their weights. So when you create a layer like this, initially, it has no weights:\n\nlayer <- layer_dense(units = 3)\nlayer$weights  # Empty\n\nlist()\n\n\nIt creates its weights the first time it is called on an input, since the shape of the weights depends on the shape of the inputs:\n\n# Call layer on a test input\nx <- tf$ones(shape(1, 4))\ny <- layer(x)\nlayer$weights  # Now it has weights, of shape (4, 3) and (3,)\n\n[[1]]\n<tf.Variable 'dense_6/kernel:0' shape=(4, 3) dtype=float32, numpy=\narray([[ 0.5611099 ,  0.28887486,  0.16154385],\n       [ 0.6592573 , -0.09965378,  0.7208358 ],\n       [-0.3989585 , -0.8135034 , -0.9171356 ],\n       [-0.77588034, -0.01154035,  0.01568812]], dtype=float32)>\n\n[[2]]\n<tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n\n\nNaturally, this also applies to Sequential models. When you instantiate a Sequential model without an input shape, it isn’t “built”: it has no weights (and calling model$weights results in an error stating just this). The weights are created when the model first sees some input data:\n\nmodel <- keras_model_sequential() %>% \n        layer_dense(2, activation = \"relu\") %>% \n        layer_dense(3, activation = \"relu\") %>% \n        layer_dense(4)\n\n# No weights at this stage!\n# At this point, you can't do this:\n\ntry(model$weights)\n\nError in py_get_attr_impl(x, name, silent) : \n  ValueError: Weights for model sequential_3 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.\n\n# The model summary is also not available:\nsummary(model)\n\nModel: <no summary available, model was not built>\n\n# Call the model on a test input\nx <- tf$ones(shape(1, 4))\ny <- model(x)\ncat(\"Number of weights after calling the model:\", length(model$weights), \"\\n\")  # 6\n\nNumber of weights after calling the model: 6 \n\n\nOnce a model is “built”, you can call its summary() method to display its contents (the summary() method is also called by the default print() method:\n\nsummary(model)\n\nModel: \"sequential_3\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_9 (Dense)                  (1, 2)                        10          \n dense_8 (Dense)                  (1, 3)                        9           \n dense_7 (Dense)                  (1, 4)                        16          \n============================================================================\nTotal params: 35\nTrainable params: 35\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nHowever, it can be very useful when building a Sequential model incrementally to be able to display the summary of the model so far, including the current output shape. In this case, you should start your model by passing an input_shape argument to your model, so that it knows its input shape from the start:\n\nmodel <- keras_model_sequential(input_shape = c(4))\nmodel %>% layer_dense(2, activation = \"relu\")\n\nmodel\n\nModel: \"sequential_4\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_10 (Dense)                 (None, 2)                     10          \n============================================================================\nTotal params: 10\nTrainable params: 10\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nModels built with a predefined input shape like this always have weights (even before seeing any data) and always have a defined output shape.\nIn general, it’s a recommended best practice to always specify the input shape of a Sequential model in advance if you know what it is."
  },
  {
    "objectID": "guides/keras/sequential_model.html#a-common-debugging-workflow-summary",
    "href": "guides/keras/sequential_model.html#a-common-debugging-workflow-summary",
    "title": "The Sequential model",
    "section": "A common debugging workflow: %>% + summary()",
    "text": "A common debugging workflow: %>% + summary()\nWhen building a new Sequential architecture, it’s useful to incrementally stack layers and print model summaries. For instance, this enables you to monitor how a stack of Conv2D and MaxPooling2D layers is downsampling image feature maps:\n\nmodel <- keras_model_sequential(input_shape = c(250, 250, 3)) # 250x250 RGB images\n  \nmodel %>% \n  layer_conv_2d(32, 5, strides = 2, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(3) \n\n# Can you guess what the current output shape is at this point? Probably not.\n# Let's just print it:\nmodel\n\nModel: \"sequential_5\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n conv2d_1 (Conv2D)                (None, 123, 123, 32)          2432        \n conv2d (Conv2D)                  (None, 121, 121, 32)          9248        \n max_pooling2d (MaxPooling2D)     (None, 40, 40, 32)            0           \n============================================================================\nTotal params: 11,680\nTrainable params: 11,680\nNon-trainable params: 0\n____________________________________________________________________________\n\n# The answer was: (40, 40, 32), so we can keep downsampling...\nmodel %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(3) %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_max_pooling_2d(2) \n\n# And now?\nmodel\n\nModel: \"sequential_5\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n conv2d_1 (Conv2D)                (None, 123, 123, 32)          2432        \n conv2d (Conv2D)                  (None, 121, 121, 32)          9248        \n max_pooling2d (MaxPooling2D)     (None, 40, 40, 32)            0           \n conv2d_5 (Conv2D)                (None, 38, 38, 32)            9248        \n conv2d_4 (Conv2D)                (None, 36, 36, 32)            9248        \n max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 32)            0           \n conv2d_3 (Conv2D)                (None, 10, 10, 32)            9248        \n conv2d_2 (Conv2D)                (None, 8, 8, 32)              9248        \n max_pooling2d_1 (MaxPooling2D)   (None, 4, 4, 32)              0           \n============================================================================\nTotal params: 48,672\nTrainable params: 48,672\nNon-trainable params: 0\n____________________________________________________________________________\n\n# Now that we have 4x4 feature maps, time to apply global max pooling.\nmodel %>% layer_global_max_pooling_2d()\n\n# Finally, we add a classification layer.\nmodel %>% layer_dense(10)\n\nVery practical, right?"
  },
  {
    "objectID": "guides/keras/sequential_model.html#what-to-do-once-you-have-a-model",
    "href": "guides/keras/sequential_model.html#what-to-do-once-you-have-a-model",
    "title": "The Sequential model",
    "section": "What to do once you have a model",
    "text": "What to do once you have a model\nOnce your model architecture is ready, you will want to:\n\nTrain your model, evaluate it, and run inference. See our guide to training & evaluation with the built-in loops\nSave your model to disk and restore it. See our guide to serialization & saving.\nSpeed up model training by leveraging multiple GPUs. See our guide to multi-GPU and distributed training."
  },
  {
    "objectID": "guides/keras/sequential_model.html#feature-extraction-with-a-sequential-model",
    "href": "guides/keras/sequential_model.html#feature-extraction-with-a-sequential-model",
    "title": "The Sequential model",
    "section": "Feature extraction with a Sequential model",
    "text": "Feature extraction with a Sequential model\nOnce a Sequential model has been built, it behaves like a Functional API model. This means that every layer has an input and output attribute. These attributes can be used to do neat things, like quickly creating a model that extracts the outputs of all intermediate layers in a Sequential model:\n\ninitial_model <-\n  keras_model_sequential(input_shape = c(250, 250, 3)) %>%\n  layer_conv_2d(32, 5, strides = 2, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\")\n\nfeature_extractor <- keras_model(\n  inputs = initial_model$inputs,\n  outputs = lapply(initial_model$layers, \\(layer) layer$output)\n)\n\n# Call feature extractor on test input.\n\nx <- tf$ones(shape(1, 250, 250, 3))\nfeatures <- feature_extractor(x)\n\nHere’s a similar example that only extract features from one layer:\n\ninitial_model <-\n  keras_model_sequential(input_shape = c(250, 250, 3)) %>%\n  layer_conv_2d(32, 5, strides = 2, activation = \"relu\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\", name = \"my_intermediate_layer\") %>%\n  layer_conv_2d(32, 3, activation = \"relu\")\n\nfeature_extractor <- keras_model(\n  inputs = initial_model$inputs,\n  outputs =  get_layer(initial_model, name = \"my_intermediate_layer\")$output\n)\n\n# Call feature extractor on test input.\nx <- tf$ones(shape(1, 250, 250, 3))\nfeatures <- feature_extractor(x)"
  },
  {
    "objectID": "guides/keras/sequential_model.html#transfer-learning-with-a-sequential-model",
    "href": "guides/keras/sequential_model.html#transfer-learning-with-a-sequential-model",
    "title": "The Sequential model",
    "section": "Transfer learning with a Sequential model",
    "text": "Transfer learning with a Sequential model\nTransfer learning consists of freezing the bottom layers in a model and only training the top layers. If you aren’t familiar with it, make sure to read our guide to transfer learning.\nHere are two common transfer learning blueprint involving Sequential models.\nFirst, let’s say that you have a Sequential model, and you want to freeze all layers except the last one. In this case, you would simply iterate over model$layers and set layer$trainable = FALSE on each layer, except the last one. Like this:\n\nmodel <- keras_model_sequential(input_shape = c(784)) %>%\n  layer_dense(32, activation = 'relu') %>%\n  layer_dense(32, activation = 'relu') %>%\n  layer_dense(32, activation = 'relu') %>%\n  layer_dense(10)\n\n\n# Presumably you would want to first load pre-trained weights.\nmodel$load_weights(...)\n\n# Freeze all layers except the last one.\nfor (layer in head(model$layers, -1))\n  layer$trainable <- FALSE\n\n# can also just call: freeze_weights(model, to = -2)\n\n# Recompile and train (this will only update the weights of the last layer).\nmodel %>% compile(...)\nmodel %>% fit(...)\n\nAnother common blueprint is to use a Sequential model to stack a pre-trained model and some freshly initialized classification layers. Like this:"
  },
  {
    "objectID": "guides/keras/sequential_model.html#environment-details",
    "href": "guides/keras/sequential_model.html#environment-details",
    "title": "The Sequential model",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n::: {.callout-note appearance=“simple” collapse=“true”}\n\nR Environment Information\n\nsessionInfo()\n\nR version 4.1.0 Patched (2021-05-18 r80324)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] keras_2.9.0.9000      tensorflow_2.9.0.9000\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.9        rstudioapi_0.13   knitr_1.39        whisker_0.4      \n [5] magrittr_2.0.3    lattice_0.20-44   R6_2.5.1          rlang_1.0.4      \n [9] fastmap_1.1.0     stringr_1.4.0     tools_4.1.0       grid_4.1.0       \n[13] xfun_0.31         png_0.1-7         cli_3.3.0         htmltools_0.5.2  \n[17] tfruns_1.5.0      yaml_2.3.5        digest_0.6.29     Matrix_1.3-3     \n[21] base64enc_0.1-3   htmlwidgets_1.5.3 zeallot_0.1.0     evaluate_0.15    \n[25] rmarkdown_2.14    stringi_1.7.8     compiler_4.1.0    generics_0.1.2   \n[29] reticulate_1.25   jsonlite_1.8.0   \n\n\n\n\n\n\n\n\nPython Environment Information\n\n\n\n\n\n\nreticulate::py_config()\n\npython:         /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/bin/python\nlibpython:      /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/lib/libpython3.8.dylib\npythonhome:     /Users/dfalbel/Library/r-miniconda/envs/r-reticulate:/Users/dfalbel/Library/r-miniconda/envs/r-reticulate\nversion:        3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:47)  [Clang 12.0.1 ]\nnumpy:          /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/numpy\nnumpy_version:  1.22.4\ntensorflow:     /Users/dfalbel/Library/r-miniconda/envs/r-reticulate/lib/python3.8/site-packages/tensorflow\n\nNOTE: Python version was forced by RETICULATE_PYTHON\n\nreticulate:::pip_freeze(reticulate::py_exe())\n\n                          package\n1                         absl-py\n2                        appnope \n3                      asttokens \n4                      astunparse\n5                       backcall \n6  backports.functools-lru-cache \n7                      cachetools\n8                         certifi\n9              charset-normalizer\n10                       debugpy \n11                     decorator \n12                           dill\n13                   entrypoints \n14                          etils\n15                     executing \n16                    flatbuffers\n17                           gast\n18                    google-auth\n19           google-auth-oauthlib\n20                   google-pasta\n21       googleapis-common-protos\n22                         grpcio\n23                           h5py\n24                           idna\n25             importlib-metadata\n26            importlib-resources\n27                     ipykernel \n28                       ipython \n29                          jedi \n30                jupyter-client \n31                  jupyter-core \n32                          keras\n33            Keras-Preprocessing\n34                       libclang\n35                       Markdown\n36             matplotlib-inline \n37                  nest-asyncio \n38                         numpy \n39                       oauthlib\n40                     opt-einsum\n41                     packaging \n42                         parso \n43                       pexpect \n44                   pickleshare \n45                         Pillow\n46                        promise\n47                prompt-toolkit \n48                       protobuf\n49                        psutil \n50                    ptyprocess \n51                     pure-eval \n52                         pyasn1\n53                 pyasn1-modules\n54                         pydot \n55                      Pygments \n56                     pyparsing \n57               python-dateutil \n58                         pyzmq \n59                       requests\n60              requests-oauthlib\n61                            rsa\n62                         scipy \n63                           six \n64                    stack-data \n65                    tensorboard\n66        tensorboard-data-server\n67         tensorboard-plugin-wit\n68                     tensorflow\n69            tensorflow-datasets\n70           tensorflow-estimator\n71                 tensorflow-hub\n72   tensorflow-io-gcs-filesystem\n73            tensorflow-metadata\n74                      termcolor\n75                           toml\n76                       tornado \n77                           tqdm\n78                     traitlets \n79              typing_extensions\n80                        urllib3\n81                       wcwidth \n82                       Werkzeug\n83                          wrapt\n84                           zipp\n                                                                                                                       version\n1                                                                                                                        1.1.0\n2                                                 file:///home/conda/feedstock_root/build_artifacts/appnope_1649077682618/work\n3                                               file:///home/conda/feedstock_root/build_artifacts/asttokens_1618968359944/work\n4                                                                                                                        1.6.3\n5                                                file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n6                           file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n7                                                                                                                        5.2.0\n8                                                                                                                  2022.5.18.1\n9                                                                                                                       2.0.12\n10                                                        file:///Users/runner/miniforge3/conda-bld/debugpy_1649586603968/work\n11                                              file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\n12                                                                                                                     0.3.5.1\n13                                            file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\n14                                                                                                                       0.6.0\n15                                              file:///home/conda/feedstock_root/build_artifacts/executing_1646044401614/work\n16                                                                                                                        1.12\n17                                                                                                                       0.4.0\n18                                                                                                                       2.7.0\n19                                                                                                                       0.4.6\n20                                                                                                                       0.2.0\n21                                                                                                                      1.56.2\n22                                                                                                                      1.46.3\n23                                                                                                                       3.7.0\n24                                                                                                                         3.3\n25                                                                                                                      4.11.4\n26                                                                                                                       5.7.1\n27                                                      file:///Users/runner/miniforge3/conda-bld/ipykernel_1654565231778/work\n28                                                        file:///Users/runner/miniforge3/conda-bld/ipython_1653755011383/work\n29                                                           file:///Users/runner/miniforge3/conda-bld/jedi_1649067146773/work\n30                                         file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1654730843242/work\n31                                                   file:///Users/runner/miniforge3/conda-bld/jupyter_core_1652365306989/work\n32                                                                                                                       2.9.0\n33                                                                                                                       1.1.2\n34                                                                                                                      14.0.1\n35                                                                                                                       3.3.7\n36                                      file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\n37                                           file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1648959695634/work\n38                                                          file:///Users/runner/miniforge3/conda-bld/numpy_1653325830837/work\n39                                                                                                                       3.2.0\n40                                                                                                                       3.3.0\n41                                              file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\n42                                                  file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\n43                                                file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\n44                                            file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n45                                                                                                                       9.1.1\n46                                                                                                                         2.3\n47                                         file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1649130487073/work\n48                                                                                                                      3.19.4\n49                                                         file:///Users/runner/miniforge3/conda-bld/psutil_1653089386834/work\n50  file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n51                                              file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\n52                                                                                                                       0.4.8\n53                                                                                                                       0.2.8\n54                                                          file:///Users/runner/miniforge3/conda-bld/pydot_1636047909408/work\n55                                               file:///home/conda/feedstock_root/build_artifacts/pygments_1650904496387/work\n56                                              file:///home/conda/feedstock_root/build_artifacts/pyparsing_1652235407899/work\n57                                        file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\n58                                                          file:///Users/runner/miniforge3/conda-bld/pyzmq_1654181479158/work\n59                                                                                                                      2.28.0\n60                                                                                                                       1.3.1\n61                                                                                                                         4.8\n62                                                          file:///Users/runner/miniforge3/conda-bld/scipy_1653074091860/work\n63                                                    file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\n64                                             file:///home/conda/feedstock_root/build_artifacts/stack_data_1644872665635/work\n65                                                                                                                       2.9.1\n66                                                                                                                       0.6.1\n67                                                                                                                       1.8.1\n68                                                                                                                       2.9.1\n69                                                                                                                       4.6.0\n70                                                                                                                       2.9.0\n71                                                                                                                      0.12.0\n72                                                                                                                      0.26.0\n73                                                                                                                       1.8.0\n74                                                                                                                       1.1.0\n75                                                                                                                      0.10.2\n76                                                        file:///Users/runner/miniforge3/conda-bld/tornado_1648827543297/work\n77                                                                                                                      4.64.0\n78                                              file:///home/conda/feedstock_root/build_artifacts/traitlets_1654067514780/work\n79                                                                                                                       4.2.0\n80                                                                                                                      1.26.9\n81                                                file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\n82                                                                                                                       2.1.2\n83                                                                                                                      1.14.1\n84                                                                                                                       3.8.0\n                                                                                                                               requirement\n1                                                                                                                           absl-py==1.1.0\n2                                                   appnope @ file:///home/conda/feedstock_root/build_artifacts/appnope_1649077682618/work\n3                                               asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1618968359944/work\n4                                                                                                                        astunparse==1.6.3\n5                                                 backcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n6       backports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n7                                                                                                                        cachetools==5.2.0\n8                                                                                                                     certifi==2022.5.18.1\n9                                                                                                               charset-normalizer==2.0.12\n10                                                          debugpy @ file:///Users/runner/miniforge3/conda-bld/debugpy_1649586603968/work\n11                                              decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\n12                                                                                                                           dill==0.3.5.1\n13                                          entrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\n14                                                                                                                            etils==0.6.0\n15                                              executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1646044401614/work\n16                                                                                                                       flatbuffers==1.12\n17                                                                                                                             gast==0.4.0\n18                                                                                                                      google-auth==2.7.0\n19                                                                                                             google-auth-oauthlib==0.4.6\n20                                                                                                                     google-pasta==0.2.0\n21                                                                                                        googleapis-common-protos==1.56.2\n22                                                                                                                          grpcio==1.46.3\n23                                                                                                                             h5py==3.7.0\n24                                                                                                                               idna==3.3\n25                                                                                                              importlib-metadata==4.11.4\n26                                                                                                              importlib-resources==5.7.1\n27                                                      ipykernel @ file:///Users/runner/miniforge3/conda-bld/ipykernel_1654565231778/work\n28                                                          ipython @ file:///Users/runner/miniforge3/conda-bld/ipython_1653755011383/work\n29                                                                jedi @ file:///Users/runner/miniforge3/conda-bld/jedi_1649067146773/work\n30                                    jupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1654730843242/work\n31                                                jupyter-core @ file:///Users/runner/miniforge3/conda-bld/jupyter_core_1652365306989/work\n32                                                                                                                            keras==2.9.0\n33                                                                                                              Keras-Preprocessing==1.1.2\n34                                                                                                                        libclang==14.0.1\n35                                                                                                                         Markdown==3.3.7\n36                              matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1631080358261/work\n37                                        nest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1648959695634/work\n38                                                              numpy @ file:///Users/runner/miniforge3/conda-bld/numpy_1653325830837/work\n39                                                                                                                         oauthlib==3.2.0\n40                                                                                                                       opt-einsum==3.3.0\n41                                              packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1637239678211/work\n42                                                      parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\n43                                                  pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1602535608087/work\n44                                          pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n45                                                                                                                           Pillow==9.1.1\n46                                                                                                                            promise==2.3\n47                                    prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1649130487073/work\n48                                                                                                                        protobuf==3.19.4\n49                                                            psutil @ file:///Users/runner/miniforge3/conda-bld/psutil_1653089386834/work\n50 ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n51                                              pure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\n52                                                                                                                           pyasn1==0.4.8\n53                                                                                                                   pyasn1-modules==0.2.8\n54                                                              pydot @ file:///Users/runner/miniforge3/conda-bld/pydot_1636047909408/work\n55                                                Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1650904496387/work\n56                                              pyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1652235407899/work\n57                                  python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\n58                                                              pyzmq @ file:///Users/runner/miniforge3/conda-bld/pyzmq_1654181479158/work\n59                                                                                                                        requests==2.28.0\n60                                                                                                                requests-oauthlib==1.3.1\n61                                                                                                                                rsa==4.8\n62                                                              scipy @ file:///Users/runner/miniforge3/conda-bld/scipy_1653074091860/work\n63                                                          six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\n64                                            stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1644872665635/work\n65                                                                                                                      tensorboard==2.9.1\n66                                                                                                          tensorboard-data-server==0.6.1\n67                                                                                                           tensorboard-plugin-wit==1.8.1\n68                                                                                                                       tensorflow==2.9.1\n69                                                                                                              tensorflow-datasets==4.6.0\n70                                                                                                             tensorflow-estimator==2.9.0\n71                                                                                                                  tensorflow-hub==0.12.0\n72                                                                                                    tensorflow-io-gcs-filesystem==0.26.0\n73                                                                                                              tensorflow-metadata==1.8.0\n74                                                                                                                        termcolor==1.1.0\n75                                                                                                                            toml==0.10.2\n76                                                          tornado @ file:///Users/runner/miniforge3/conda-bld/tornado_1648827543297/work\n77                                                                                                                            tqdm==4.64.0\n78                                              traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1654067514780/work\n79                                                                                                                typing_extensions==4.2.0\n80                                                                                                                         urllib3==1.26.9\n81                                                  wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\n82                                                                                                                         Werkzeug==2.1.2\n83                                                                                                                           wrapt==1.14.1\n84                                                                                                                             zipp==3.8.0\n\n\n\nSystem Information\nWarning in system(\"nvidia-smi\"): error in running command\nTF Devices: - :PhysicalDevice(name=‘/physical_device:CPU:0’, device_type=‘CPU’) CPU cores: 8 Page render time: and 9 seconds"
  },
  {
    "objectID": "guides/keras/serialization_and_saving.html",
    "href": "guides/keras/serialization_and_saving.html",
    "title": "Serialization and saving",
    "section": "",
    "text": "A Keras model consists of multiple components:\n\nThe architecture, or configuration, which specifies what layers the model contain, and how they’re connected.\nA set of weights values (the “state of the model”).\nAn optimizer (defined by compiling the model).\nA set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric()).\n\nThe Keras API makes it possible to save all of these pieces to disk at once, or to only selectively save some of them:\n\nSaving everything into a single archive in the TensorFlow SavedModel format (or in the older Keras H5 format). This is the standard practice.\nSaving the architecture / configuration only, typically as a JSON file.\nSaving the weights values only. This is generally used when training the model.\n\nLet’s take a look at each of these options. When would you use one or the other, and how do they work?"
  },
  {
    "objectID": "guides/keras/serialization_and_saving.html#how-to-save-and-load-a-model",
    "href": "guides/keras/serialization_and_saving.html#how-to-save-and-load-a-model",
    "title": "Serialization and saving",
    "section": "How to save and load a model",
    "text": "How to save and load a model\nIf you only have 10 seconds to read this guide, here’s what you need to know.\nSaving a Keras model:\n\nmodel <- ...  # Get model (Sequential, Functional Model, or Model subclass)\nsave_model_tf(\"path/to/location\")\n\nLoading the model back:\n\nlibrary(keras)\nmodel <- load_model_tf(\"path/to/location\")\n\nNow, let’s look at the details."
  },
  {
    "objectID": "guides/keras/serialization_and_saving.html#setup",
    "href": "guides/keras/serialization_and_saving.html#setup",
    "title": "Serialization and saving",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/serialization_and_saving.html#whole-model-saving-loading",
    "href": "guides/keras/serialization_and_saving.html#whole-model-saving-loading",
    "title": "Serialization and saving",
    "section": "Whole-model saving & loading",
    "text": "Whole-model saving & loading\nYou can save an entire model to a single artifact. It will include:\n\nThe model’s architecture/config\nThe model’s weight values (which were learned during training)\nThe model’s compilation information (if compile() was called)\nThe optimizer and its state, if any (this enables you to restart training where you left)\n\n\nAPIs\n\nmodel$save() or save_model_tf()\nload_model_tf()\n\nThere are two formats you can use to save an entire model to disk: the TensorFlow SavedModel format, and the older Keras H5 format. The recommended format is SavedModel. It is the default when you use model$save().\nYou can switch to the H5 format by:\n\nPassing save_format = 'h5' to save_model_hdf5().\nPassing a filename that ends in .h5 or .keras to $save().\n\n\n\nSavedModel format\nSavedModel is the more comprehensive save format that saves the model architecture, weights, and the traced Tensorflow subgraphs of the call functions. This enables Keras to restore both built-in layers as well as custom objects.\nExample:\n\nget_model <- function() {\n  # Create a simple model.\n  inputs <- layer_input(shape = shape(32))\n  outputs <- layer_dense(inputs, 1)\n  model <- keras_model(inputs, outputs)\n  model %>% compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n  model\n}\nmodel <- get_model()\n\nLoaded Tensorflow version 2.9.1\n\n# Train the model.\ntest_input <- array(runif(128*32), dim = c(128, 32))\ntest_target <- array(runif(128), dim = c(128, 1))\nmodel %>% fit(test_input, test_target)\n# Calling `save('my_model')` creates a SavedModel folder `my_model`.\nsave_model_tf(model, \"my_model\")\n# It can be used to reconstruct the model identically.\nreconstructed_model <- load_model_tf(\"my_model\")\n# Let's check:\nall.equal(\n  predict(model, test_input),\n  predict(reconstructed_model, test_input)\n)\n\n[1] TRUE\n\n# The reconstructed model is already compiled and has retained the optimizer\n# state, so training can resume:\nreconstructed_model %>% fit(test_input, test_target)\n\n\nWhat the SavedModel contains\nCalling save_model_tf(model, 'my_model') creates a folder named my_model, containing the following:\n\nls my_model\n\nassets\nkeras_metadata.pb\nsaved_model.pb\nvariables\n\n\nThe model architecture, and training configuration (including the optimizer, losses, and metrics) are stored in saved_model.pb. The weights are saved in the variables/ directory.\nFor detailed information on the SavedModel format, see the SavedModel guide (The SavedModel format on disk).\n\n\nHow SavedModel handles custom objects\nWhen saving the model and its layers, the SavedModel format stores the class name, call function, losses, and weights (and the config, if implemented). The call function defines the computation graph of the model/layer.\nIn the absence of the model/layer config, the call function is used to create a model that exists like the original model which can be trained, evaluated, and used for inference.\nNevertheless, it is always a good practice to define the get_config and from_config methods when writing a custom model or layer class. This allows you to easily update the computation later if needed. See the section about Custom objects for more information.\n\n\n\n\n\n\nNote\n\n\n\nThe default from_config definition in R is something similar just calls the initialize method with the config lsit using do.call. That way you don’t need to implement a from_config method unless get_config() dictionary names don’t match the initialize arguments.\n\n\nExample:\n\ncustom_model <- new_model_class(\n  \"custom_model\",\n  initialize = function(hidden_units) {\n    super()$`__init__`()\n    self$hidden_units <- hidden_units\n    self$dense_layers <- lapply(hidden_units, function(x) layer_dense(units = x))\n  },\n  call = function(inputs) {\n    x <- inputs\n    for (layer in self$dense_layers) {\n      x <- layer(x)\n    }\n    x\n  },\n  get_config = function() {\n    list(hidden_units = self$hidden_units)\n  }\n)\nmodel <- custom_model(c(16, 16, 10))\n# Build the model by calling it\ninput_arr <- tf$random$uniform(shape(1, 5))\noutputs <- model(input_arr)\nsave_model_tf(model, \"my_model\")\n# Option 1: Load with the custom_object argument.\nloaded_1 <- load_model_tf(\n    \"my_model\", custom_objects = list(\"custom_model\" = custom_model)\n)\n# Option 2: Load without the CustomModel class.\n# Delete the custom-defined model class to ensure that the loader does not have\n# access to it.\nrm(custom_model); gc();\n\n          used (Mb) gc trigger  (Mb) limit (Mb) max used  (Mb)\nNcells 1861943 99.5    3665865 195.8         NA  2534025 135.4\nVcells 3287266 25.1    8388608  64.0     102400  5238666  40.0\n\nloaded_2 <- load_model_tf(\"my_model\")\nall.equal(predict(loaded_1, input_arr), as.array(outputs))\n\n[1] TRUE\n\nall.equal(predict(loaded_2, input_arr), as.array(outputs))\n\n[1] TRUE\n\n\nThe first loaded model is loaded using the config and custom_model class. The second model is loaded by dynamically creating the model class that acts like the original model.\n\n\nConfiguring the SavedModel\nNew in TensoFlow 2.4\nThe argument save_traces has been added to model$save, which allows you to toggle SavedModel function tracing. Functions are saved to allow the Keras to re-load custom objects without the original class definitons, so when save_traces = FALSE, all custom objects must have defined get_config/from_config methods. When loading, the custom objects must be passed to the custom_objects argument. save_traces = FALSE reduces the disk space used by the SavedModel and saving time.\n\n\n\nKeras H5 format\nKeras also supports saving a single HDF5 file containing the model’s architecture, weights values, and compile() information. It is a light-weight alternative to SavedModel.\nExample:\n\nmodel <- get_model()\n# Train the model.\ntest_input <- array(runif(128*32), dim = c(128, 32))\ntest_target <- array(runif(128), dim = c(128, 1))\nmodel %>% fit(test_input, test_target)\n# Calling `save_model_hdf5('my_model.h5')` creates a h5 file `my_model.h5`.\nsave_model_hdf5(model, \"my_h5_model.h5\")\n# It can be used to reconstruct the model identically.\nreconstructed_model <- load_model_hdf5(\"my_h5_model.h5\")\n# Let's check:\nall.equal(\n  predict(model, test_input), \n  predict(reconstructed_model, test_input)\n)\n\n[1] TRUE\n\n# The reconstructed model is already compiled and has retained the optimizer\n# state, so training can resume:\nreconstructed_model %>% fit(test_input, test_target)\n\n\n\nFormat Limitations\nKeras SavedModel format limitations:\nThe tracing done by SavedModel to produce the graphs of the layer call functions allows SavedModel be more portable than H5, but it comes with drawbacks.\n\nCan be slower and bulkier than H5.\nCannot serialize the ops generated from the mask argument (i$e. if a layer is called with layer(..., mask = mask_value), the mask argument is not saved to SavedModel).\nDoes not save the overridden train_step() in subclassed models.\n\nCustom objects that use masks or have a custom training loop can still be saved and loaded from SavedModel, except they must override get_config()/from_config(), and the classes must be passed to the custom_objects argument when loading.\nH5 limitations:\n\nExternal losses & metrics added via model$add_loss() & model$add_metric() are not saved (unlike SavedModel). If you have such losses & metrics on your model and you want to resume training, you need to add these losses back yourself after loading the model. Note that this does not apply to losses/metrics created inside layers via self$add_loss() & self$add_metric(). As long as the layer gets loaded, these losses & metrics are kept, since they are part of the call method of the layer.\nThe computation graph of custom objects such as custom layers is not included in the saved file. At loading time, Keras will need access to the Python classes/functions of these objects in order to reconstruct the model. See Custom objects.\nDoes not support preprocessing layers."
  },
  {
    "objectID": "guides/keras/serialization_and_saving.html#saving-the-architecture",
    "href": "guides/keras/serialization_and_saving.html#saving-the-architecture",
    "title": "Serialization and saving",
    "section": "Saving the architecture",
    "text": "Saving the architecture\nThe model’s configuration (or architecture) specifies what layers the model contains, and how these layers are connected*. If you have the configuration of a model, then the model can be created with a freshly initialized state for the weights and no compilation information.\n*Note this only applies to models defined using the functional or Sequential apis not subclassed models.\n\nConfiguration of a Sequential model or Functional API model\nThese types of models are explicit graphs of layers: their configuration is always available in a structured form.\n\nAPIs\n\nget_config() and from_config()\nmodel_to_json() and model_from_json()\n\n\n\nget_config() and from_config()\nCalling config = model$get_config() will return a Python dict containing the configuration of the model. The same model can then be reconstructed via Sequential$from_config(config) (for a Sequential model) or Model$from_config(config) (for a Functional API model).\nThe same workflow also works for any serializable layer.\nLayer example:\n\nlayer <- layer_dense(units = 3, activation = \"relu\")\nlayer_config <- get_config(layer)\nnew_layer <- from_config(config = layer_config)\n\nSequential model example:\n\nmodel <- keras_model_sequential(list(\n  layer_input(shape = 32), \n  layer_dense(units = 1)\n))\nconfig <- get_config(model)\nnew_model <- from_config(config)\n\nFunctional model example:\n\ninputs <- layer_input(shape = 32)\noutputs <- layer_dense(inputs, 1)\nmodel <- keras_model(inputs, outputs)\nconfig <- get_config(model)\nnew_model <- from_config(config)\n\n\n\nmodel_to_json() and model_from_json()\nThis is similar to get_config / from_config, except it turns the model into a JSON string, which can then be loaded without the original model class. It is also specific to models, it isn’t meant for layers.\nExample:\n\nmodel <- keras_model_sequential(list(\n  layer_input(shape = 32), \n  layer_dense(units = 1)\n))\njson_config <- model_to_json(model)\nnew_model <- model_from_json(json_config)\n\n\n\n\nCustom objects\nModels and layers\nThe architecture of subclassed models and layers are defined in the methods initialize and call. They are considered R bytecode, which cannot be serialized into a JSON-compatible config – you could try serializing the bytecode (e.g. via saveRDS), but it’s completely unsafe and means your model cannot be loaded on a different system.\nIn order to save/load a model with custom-defined layers, or a subclassed model, you should overwrite the get_config and optionally from_config methods. Additionally, you should use register the custom object so that Keras is aware of it.\nCustom functions\nCustom-defined functions (e.g. activation loss or initialization) do not need a get_config method. The function name is sufficient for loading as long as it is registered as a custom object.\nLoading the TensorFlow graph only\nIt’s possible to load the TensorFlow graph generated by the Keras. If you do so, you won’t need to provide any custom_objects. You can do so like this:\n\nsave_model_tf(model, \"my_model\")\ntensorflow_graph <- tf$saved_model$load(\"my_model\")\nx <- as_tensor(array(runif(4*32), dim = c(4, 32)), \"float32\")\npredicted <- tensorflow_graph(x)$numpy()\n\nNote that this method has several drawbacks: * For traceability reasons, you should always have access to the custom objects that were used. You wouldn’t want to put in production a model that you cannot re-create. * The object returned by tf$saved_model$load isn’t a Keras model. So it’s not as easy to use. For example, you won’t have access to predict() or fit()\nEven if its use is discouraged, it can help you if you’re in a tight spot, for example, if you lost the code of your custom objects or have issues loading the model with load_model_tf().\nYou can find out more in the page about tf$saved_model$load\n\nDefining the config methods\nSpecifications:\n\nget_config should return a JSON-serializable dictionary in order to be compatible with the Keras architecture - and model-saving APIs.\nfrom_config(config) (classmethod) should return a new layer or model object that is created from the config. The default implementation returns do.call(cls, config).\n\nExample:\n\ncustom_layer <- new_layer_class(\n  \"custom_layer\",\n  initialize = function(a) {\n    self$var <- tf$Variable(a, name = \"var_a\")\n  },\n  call = function(inputs, training = FALSE) {\n    if(training) {\n      inputs*self$var\n    } else {\n      inputs\n    }\n  },\n  get_config = function() {\n    list(\"a\" = as.array(self$var))\n  }\n)\n\nlayer <- custom_layer(a = 5)\nlayer$var$assign(2)\n\n<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=2.0>\n\nserialized_layer <- keras$layers$serialize(layer)\nnew_layer <- keras$layers$deserialize(\n    serialized_layer, custom_objects = list(\"custom_layer\" = custom_layer)\n)\n\n\n\nRegistering the custom object\nKeras keeps a note of which class generated the config. From the example above, tf$keras$layers$serialize generates a serialized form of the custom layer:\n\n\nlist(class_name = \"custom_layer\", config = list(a = 2))\n\n\nKeras keeps a master list of all built-in layer, model, optimizer, and metric classes, which is used to find the correct class to call from_config. If the class can’t be found, then an error is raised (Value Error: Unknown layer). There are a few ways to register custom classes to this list: 1. Setting custom_objects argument in the loading function. (see the example in section above “Defining the config methods”) 2. tf$keras$utils$custom_object_scope or tf$keras$utils$CustomObjectScope 3. tf$keras$utils$register_keras_serializable\n\n\nCustom layer and function example\n\ncustom_layer <- new_layer_class(\n  \"custom_layer\",\n  initialize = function(units = 32, ...) {\n    super()$`__init__`(...)\n    self$units <- units\n  },\n  build = function(input_shape) {\n    self$w <- self$add_weight(\n      shape = shape(tail(input_shape, 1), self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n    self$b <- self$add_weight(\n      shape = shape(self$units),\n      initializer = \"random_normal\",\n      trainable = TRUE\n    )\n  },\n  call = function(inputs) {\n    tf$matmul(inputs, self$w) + self$b\n  },\n  get_config = function() {\n    config <- super()$get_config()\n    config$units <- self$units\n    config\n  }\n)\n\ncustom_activation <- function(x) {\n  tf$nn$tanh(x)^2\n}\n\n# Make a model with the custom_layer and custom_activation\ninputs <- layer_input(shape = shape(32))\nx <- custom_layer(inputs, 32)\noutputs <- layer_activation(x, custom_activation)\nmodel <- keras_model(inputs, outputs)\n\n# Retrieve the config\nconfig <- get_config(model)\n\n# At loading time, register the custom objects with a `custom_object_scope`:\ncustom_objects <- list(\n  \"custom_layer\" = custom_layer,\n  \"python_function\" = custom_activation\n)\n\nwith(tf$keras$utils$custom_object_scope(custom_objects), {\n  new_model <- keras$Model$from_config(config)\n})\n\n\n\n\nIn-memory model cloning\nYou can also do in-memory cloning of a model via tf$keras$models$clone_model(). This is equivalent to getting the config then recreating the model from its config (so it does not preserve compilation information or layer weights values).\nExample:\n\nwith(tf$keras$utils$custom_object_scope(custom_objects), {\n  new_model <- clone_model(model)\n})"
  },
  {
    "objectID": "guides/keras/serialization_and_saving.html#saving-loading-only-the-models-weights-values",
    "href": "guides/keras/serialization_and_saving.html#saving-loading-only-the-models-weights-values",
    "title": "Serialization and saving",
    "section": "Saving & loading only the model’s weights values",
    "text": "Saving & loading only the model’s weights values\nYou can choose to only save & load a model’s weights. This can be useful if: - You only need the model for inference: in this case you won’t need to restart training, so you don’t need the compilation information or optimizer state. - You are doing transfer learning: in this case you will be training a new model reusing the state of a prior model, so you don’t need the compilation information of the prior model.\n\nAPIs for in-memory weight transfer\nWeights can be copied between different objects by using get_weights and set_weights:\n\nget_weights(): Returns a list of arrays.\nset_weights(): Sets the model weights to the values in the weights argument.\n\nExamples below.\nTransfering weights from one layer to another, in memory\n\ncreate_layer <- function() {\n  layer <- layer_dense(units = 64, activation = \"relu\", name = \"dense_2\")\n  layer$build(shape(NULL, 784))\n  layer\n}\n    \nlayer_1 <- create_layer()\nlayer_2 <- create_layer()\n\n# Copy weights from layer 1 to layer 2\nset_weights(layer_2, get_weights(layer_1))\n\nTransfering weights from one model to another model with a compatible architecture, in memory"
  },
  {
    "objectID": "guides/keras/serialization_and_saving.html#environment-details",
    "href": "guides/keras/serialization_and_saving.html#environment-details",
    "title": "Serialization and saving",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html",
    "href": "guides/keras/training_with_built_in_methods.html",
    "title": "Training & evaluation with the built-in methods",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#introduction",
    "href": "guides/keras/training_with_built_in_methods.html#introduction",
    "title": "Training & evaluation with the built-in methods",
    "section": "Introduction",
    "text": "Introduction\nThis guide covers training, evaluation, and prediction (inference) models when using built-in APIs for training & validation.\nIf you are interested in leveraging fit() while specifying your own training step function, see the Customizing what happens in fit() guide.\nIf you are interested in writing your own training & evaluation loops from scratch, see the guide “writing a training loop from scratch”.\nIn general, whether you are using built-in loops or writing your own, model training & evaluation works strictly in the same way across every kind of Keras model – Sequential models, models built with the Functional API, and models written from scratch via model subclassing.\nThis guide doesn’t cover distributed training, which is covered in our guide to multi-GPU & distributed training."
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#api-overview-a-first-end-to-end-example",
    "href": "guides/keras/training_with_built_in_methods.html#api-overview-a-first-end-to-end-example",
    "title": "Training & evaluation with the built-in methods",
    "section": "API overview: a first end-to-end example",
    "text": "API overview: a first end-to-end example\nWhen passing data to the built-in training loops of a model, you should either use NumPy arrays (if your data is small and fits in memory) or tf$data Dataset objects. In the next few paragraphs, we’ll use the MNIST dataset as NumPy arrays, in order to demonstrate how to use optimizers, losses, and metrics.\nLet’s consider the following model (here, we build in with the Functional API, but it could be a Sequential model or a subclassed model as well):\n\ninputs <- layer_input(shape = shape(784), name = \"digits\")\n\nLoaded Tensorflow version 2.9.1\n\nx <- inputs %>% \n  layer_dense(units = 64, activation = \"relu\", name = \"dense_1\") %>% \n  layer_dense(units = 64, activation = \"relu\", name = \"dense_2\")\noutputs <- x %>% \n  layer_dense(units = 10, activation = \"softmax\", name = \"predictions\")\nmodel <- keras_model(inputs = inputs, outputs = outputs)\n\nHere’s what the typical end-to-end workflow looks like, consisting of:\n\nTraining\nValidation on a holdout set generated from the original training data\nEvaluation on the test data\n\nWe’ll use MNIST data for this example.\n\nc(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()\n\nx_train <- array_reshape(x_train, c(nrow(x_train), 784))\nx_test <- array_reshape(x_test, c(nrow(x_test), 784))\n\n# Transform RGB values into [0,1] range\nx_train <- x_train / 255\nx_test <- x_test / 255\n\n# Reserve 10,000 samples for validation\nx_val <- tail(x_train, 10000)\ny_val <- tail(y_train, 10000)\nx_train <- head(x_train, 50000)\ny_train <- head(y_train, 50000)\n\nWe specify the training configuration (optimizer, loss, metrics):\n\nmodel %>% compile(\n    optimizer = optimizer_rmsprop(),  # Optimizer\n    # Loss function to minimize\n    loss = loss_sparse_categorical_crossentropy(),\n    # List of metrics to monitor\n    metrics = list(metric_sparse_categorical_accuracy()),\n)\n\nWe call fit(), which will train the model by slicing the data into “batches” of size batch_size, and repeatedly iterating over the entire dataset for a given number of epochs.\n\nhistory <- model %>% fit(\n    x_train,\n    y_train,\n    batch_size = 64,\n    epochs = 2,\n    # We pass some validation for\n    # monitoring validation loss and metrics\n    # at the end of each epoch\n    validation_data = list(x_val, y_val),\n)\n\nThe returned history object holds a record of the loss values and metric values during training:\n\nhistory\n\n\nFinal epoch (plot to see history):\n                           loss: 0.155\n    sparse_categorical_accuracy: 0.9544\n                       val_loss: 0.1476\nval_sparse_categorical_accuracy: 0.9576 \n\n\nWe evaluate the model on the test data via evaluate():\n\n# Evaluate the model on the test data using `evaluate`\nresults <- model %>% evaluate(x_test, y_test, batch_size = 128)\ncat(\"test loss, test acc:\", results)\n\ntest loss, test acc: 0.1497131 0.9563\n\n# Generate predictions (probabilities -- the output of the last layer)\n\n# on new data using `predict`\n\npredictions <- predict(model, x_test[1:3,])\ndim(predictions)\n\n[1]  3 10\n\n\nNow, let’s review each piece of this workflow in detail."
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#the-compile-method-specifying-a-loss-metrics-and-an-optimizer",
    "href": "guides/keras/training_with_built_in_methods.html#the-compile-method-specifying-a-loss-metrics-and-an-optimizer",
    "title": "Training & evaluation with the built-in methods",
    "section": "The compile() method: specifying a loss, metrics, and an optimizer",
    "text": "The compile() method: specifying a loss, metrics, and an optimizer\nTo train a model with fit(), you need to specify a loss function, an optimizer, and optionally, some metrics to monitor.\nYou pass these to the model as arguments to the compile() method:\n\nmodel %>% compile(\n    optimizer = optimizer_rmsprop(learning_rate = 1e-3),\n    loss = loss_categorical_crossentropy(),\n    metrics = list(metric_sparse_categorical_accuracy())\n)\n\nThe metrics argument should be a list – your model can have any number of metrics.\nIf your model has multiple outputs, you can specify different losses and metrics for each output, and you can modulate the contribution of each output to the total loss of the model. You will find more details about this in the Passing data to multi-input, multi-output models section.\nNote that if you’re satisfied with the default settings, in many cases the optimizer, loss, and metrics can be specified via string identifiers as a shortcut:\n\nmodel %>% compile(\n    optimizer = \"rmsprop\",\n    loss = \"sparse_categorical_crossentropy\",\n    metrics = list(\"sparse_categorical_accuracy\")\n)\n\nFor later reuse, let’s put our model definition and compile step in functions; we will call them several times across different examples in this guide.\n\nget_uncompiled_model <- function() {\n  inputs <- layer_input(shape = shape(784), name = \"digits\")\n  x <- inputs %>% \n    layer_dense(units = 64, activation = \"relu\", name = \"dense_1\") %>% \n    layer_dense(units = 64, activation = \"relu\", name = \"dense_2\")\n  outputs <- x %>% \n    layer_dense(units = 10, activation = \"softmax\", name = \"predictions\")\n  model <- keras_model(inputs = inputs, outputs = outputs)\n  model\n}\n\nget_compiled_model <- function() {\n  model <- get_uncompiled_model()\n  model %>% compile(\n    optimizer = \"rmsprop\",\n    loss = \"sparse_categorical_crossentropy\",\n    metrics = list(\"sparse_categorical_accuracy\"),\n  )\n  model\n}\n\n\nMany built-in optimizers, losses, and metrics are available\nIn general, you won’t have to create your own losses, metrics, or optimizers from scratch, because what you need is likely to be already part of the Keras API:\nOptimizers:\n\noptimizer_sgd() (with or without momentum)\noptimizer_rmsprop()\noptimizer_adam()\netc.\n\nLosses:\n\nloss_mean_squared_error()\nloss_kl_divergence()\nloss_cosine_similarity()\netc.\n\nMetrics:\n\nmetric_auc()\nmetric_precision()\nmetric_recall()\netc.\n\n\n\nCustom losses\nIf you need to create a custom loss, Keras provides two ways to do so.\nThe first method involves creating a function that accepts inputs y_true and y_pred. The following example shows a loss function that computes the mean squared error between the real data and the predictions:\n\ncustom_mean_squared_error <- function(y_true, y_pred) {\n  tf$math$reduce_mean(tf$square(y_true - y_pred))\n}\n\n\nmodel <- get_uncompiled_model()\nmodel %>% compile(optimizer = optimizer_adam(), loss = custom_mean_squared_error)\n\n# We need to one-hot encode the labels to use MSE\n\ny_train_one_hot <- tf$one_hot(y_train, depth = 10L)\nmodel %>% fit(x_train, y_train_one_hot, batch_size = 64, epochs = 1)\n\nIf you need a loss function that takes in parameters beside y_true and y_pred, you can subclass the tf$keras$losses$Loss class and implement the following two methods:\n\ninitialize(): accept parameters to pass during the call of your loss function\ncall(y_true, y_pred): use the targets (y_true) and the model predictions (y_pred) to compute the model’s loss\n\nLet’s say you want to use mean squared error, but with an added term that will de-incentivize prediction values far from 0.5 (we assume that the categorical targets are one-hot encoded and take values between 0 and 1). This creates an incentive for the model not to be too confident, which may help reduce overfitting (we won’t know if it works until we try!).\nHere’s how you would do it:\n\ncustom_mse <- new_loss_class(\n  classname = \"custom_mse\",\n  initialize = function(regularization_factor = 0.1, name = \"custom_mse\") {\n    super()$`__init__`(name = name)\n    self$regularization_factor <- regularization_factor\n  },\n  call = function(y_true, y_pred) {\n    mse <- tf$math$reduce_mean(tf$square(y_true - y_pred))\n    reg <- tf$math$reduce_mean(tf$square(0.5 - y_pred))\n    mse + reg * self$regularization_factor\n  }\n)\n\nmodel <- get_uncompiled_model()\nmodel %>% compile(optimizer = optimizer_adam(), loss = custom_mse())\n\ny_train_one_hot <- tf$one_hot(y_train, depth = 10L)\nmodel %>% fit(x_train, y_train_one_hot, batch_size = 64, epochs = 1)\n\n\n\nCustom metrics\nIf you need a metric that isn’t part of the API, you can easily create custom metrics by subclassing the tf$keras$metrics$Metric class. You will need to implement 4 methods:\n\ninitialize(), in which you will create state variables for your metric.\nupdate_state(y_true, y_pred, sample_weight = NULL), which uses the targets y_true and the model predictions y_pred to update the state variables.\nresult(), which uses the state variables to compute the final results.\nreset_state(), which reinitializes the state of the metric.\n\nState update and results computation are kept separate (in update_state() and result(), respectively) because in some cases, the results computation might be very expensive and would only be done periodically.\nHere’s a simple example showing how to implement a CategoricalTRUEPositives metric that counts how many samples were correctly classified as belonging to a given class:\n\ncategorical_true_positives <- new_metric_class(\n  classname = \"categorical_true_positives\",\n  initialize = function(name = \"categorical_true_positives\", ...) {\n    super()$`__init__`(name, ...)\n    self$true_positives <- self$add_weight(name = \"ctp\", initializer = \"zeros\")\n  },\n  update_state = function(y_true, y_pred, sample_weight = NULL) {\n    y_pred <- tf$reshape(tf$argmax(y_pred, axis = 1L), shape = c(-1L,1L))\n    values <- tf$cast(y_true, \"int32\") == tf$cast(y_pred, \"int32\")\n    values <- tf$cast(values, \"float32\")\n    if (!is.null(sample_weight)) {\n      sample_weight <- tf$cast(sample_weight, \"float32\")\n      values <- tf$multiply(values, sample_weight)\n    }\n\n    self$true_positives$assign_add(tf$reduce_sum(values))\n  },\n  result = function() {\n    self$true_positives\n  },\n  reset_state = function() {\n    self$true_positives$assign(0.0)\n  }\n)\n\nmodel <- get_uncompiled_model()\nmodel %>% compile(\n    optimizer = optimizer_rmsprop(learning_rate = 1e-3),\n    loss = loss_sparse_categorical_crossentropy(),\n    metrics = list(categorical_true_positives()),\n)\nmodel %>% fit(x_train, y_train, batch_size = 64, epochs = 3)\n\n\n\nHandling losses and metrics that don’t fit the standard signature\nThe overwhelming majority of losses and metrics can be computed from y_true and y_pred, where y_pred is an output of your model – but not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output.\nIn such cases, you can call self$add_loss(loss_value) from inside the call method of a custom layer. Losses added in this way get added to the “main” loss during training (the one passed to compile()). Here’s a simple example that adds activity regularization (note that activity regularization is built-in in all Keras layers – this layer is just for the sake of providing a concrete example):\n\nlayer_activity_regularization <- new_layer_class(\n  classname = \"activity_regularization\",\n  call = function(inputs) {\n    self$add_loss(tf$reduce_sum(inputs) * 0.1)\n    inputs # Pass-through layer.\n  }\n)\n\ninputs <- layer_input(shape = shape(784), name = \"digits\")\nx <- layer_dense(inputs, 64, activation = \"relu\", name = \"dense_1\")\n# Insert activity regularization as a layer\nx <- layer_activity_regularization(x)\nx <- layer_dense(x, 64, activation = \"relu\", name = \"dense_2\")\noutputs <- layer_dense(x, 10, name = \"predictions\")\n\nmodel <- keras_model(inputs = inputs, outputs = outputs)\nmodel %>% compile(\n    optimizer = optimizer_rmsprop(learning_rate = 1e-3),\n    loss = loss_sparse_categorical_crossentropy(from_logits = TRUE)\n)\n\n# The displayed loss will be much higher than before\n# due to the regularization component.\nmodel %>% fit(x_train, y_train, batch_size = 64, epochs = 1)\n\nYou can do the same for logging metric values, using add_metric():\n\nlayer_metric_logging <- new_layer_class(\n  \"metric_logging\",\n  call = function(inputs) {\n    self$add_metric(\n      keras$backend$std(inputs), \n      name = \"std_of_activation\", \n      aggregation = \"mean\"\n    )\n    inputs\n  }\n)\n\ninputs <- layer_input(shape = shape(784), name = \"digits\")\nx <- layer_dense(inputs, 64, activation = \"relu\", name = \"dense_1\")\n\n# Insert std logging as a layer.\nx <- layer_metric_logging(x)\nx <- layer_dense(x, 64, activation = \"relu\", name = \"dense_2\")\noutputs <- layer_dense(x, 10, name = \"predictions\")\n\nmodel <- keras_model(inputs = inputs, outputs = outputs)\nmodel %>% compile(\n    optimizer = optimizer_rmsprop(learning_rate = 1e-3),\n    loss = loss_sparse_categorical_crossentropy(from_logits = TRUE)\n)\nmodel %>% fit(x_train, y_train, batch_size = 64, epochs = 1)\n\nIn the Functional API, you can also call model$add_loss(loss_tensor), or model$add_metric(metric_tensor, name, aggregation).\nHere’s a simple example:\n\ninputs <- layer_input(shape = shape(784), name = \"digits\")\nx1 <- layer_dense(inputs, 64, activation = \"relu\", name = \"dense_1\")\nx2 <- layer_dense(x1, 64, activation = \"relu\", name = \"dense_2\")\noutputs <- layer_dense(x2, 10, name = \"predictions\")\nmodel <- keras_model(inputs = inputs, outputs = outputs)\n\nmodel$add_loss(tf$reduce_sum(x1) * 0.1)\nmodel$add_metric(\n  keras$backend$std(x1), \n  name = \"std_of_activation\", \n  aggregation = \"mean\"\n)\n\nmodel %>% compile(\n    optimizer = optimizer_rmsprop(learning_rate = 1e-3),\n    loss = loss_sparse_categorical_crossentropy(from_logits = TRUE)\n)\nmodel %>% fit(x_train, y_train, batch_size = 64, epochs = 1)\n\nNote that when you pass losses via add_loss(), it becomes possible to call compile() without a loss function, since the model already has a loss to minimize.\nConsider the following LogisticEndpoint layer: it takes as inputs targets & logits, and it tracks a crossentropy loss via add_loss(). It also tracks classification accuracy via add_metric().\n\nlayer_logistic_endpoint <- new_layer_class(\n  \"logistic_endpoint\",\n  initialize = function(name = NULL) {\n    super()$`__init__`(name = name)\n    self$loss_fn <- loss_binary_crossentropy(from_logits = TRUE)\n    self$accuracy_fn <- metric_binary_accuracy()\n  },\n  call = function(targets, logits, sample_weights = NULL) {\n    # Compute the training-time loss value and add it\n    # to the layer using `self$add_loss()`.\n    loss <- self$loss_fn(targets, logits, sample_weights)\n    self$add_loss(loss)\n    \n    # Log accuracy as a metric and add it\n    # to the layer using `self$add_metric()`.\n    acc <- self$accuracy_fn(targets, logits, sample_weights)\n    self$add_metric(acc, name = \"accuracy\")\n    \n    # Return the inference-time prediction tensor (for `.predict()`).\n    tf$nn$softmax(logits)\n  }\n)\n\nYou can use it in a model with two inputs (input data & targets), compiled without a loss argument, like this:\n\ninputs <- layer_input(shape = shape(3), name = \"inputs\")\ntargets <- layer_input(shape = shape(10), name = \"targets\")\nlogits <- layer_dense(inputs, 10)\npredictions <- layer_logistic_endpoint(name = \"predictions\")(logits, targets)\n\nmodel <- keras_model(inputs = list(inputs, targets), outputs = predictions)\nmodel %>% compile(optimizer = \"adam\")  # No loss argument!\n\ndata <- list(\n    \"inputs\" = array(runif(3*3), dim = c(3,3)),\n    \"targets\" = array(runif(3*10), dim = c(3, 10))\n)\nmodel %>% fit(data, epochs = 1)\n\nFor more information about training multi-input models, see the section Passing data to multi-input, multi-output models.\n\n\nAutomatically setting apart a validation holdout set\nIn the first end-to-end example you saw, we used the validation_data argument to pass a listy of arrays (x_val, y_val) to the model for evaluating a validation loss and validation metrics at the end of each epoch.\nHere’s another option: the argument validation_split allows you to automatically reserve part of your training data for validation. The argument value represents the fraction of the data to be reserved for validation, so it should be set to a number higher than 0 and lower than 1. For instance, validation_split = 0.2 means “use 20% of the data for validation”, and validation_split = 0.6 means “use 60% of the data for validation”.\nThe way the validation is computed is by taking the last x% samples of the arrays received by the fit() call, before any shuffling.\nNote that you can only use validation_split when training with array data.\n\nmodel <- get_compiled_model()\nmodel %>% fit(x_train, y_train, batch_size = 64, validation_split = 0.2, epochs = 1)"
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#training-evaluation-from-tensorflow-datasets",
    "href": "guides/keras/training_with_built_in_methods.html#training-evaluation-from-tensorflow-datasets",
    "title": "Training & evaluation with the built-in methods",
    "section": "Training & evaluation from TensorFlow Datasets",
    "text": "Training & evaluation from TensorFlow Datasets\nIn the past few paragraphs, you’ve seen how to handle losses, metrics, and optimizers, and you’ve seen how to use the validation_data and validation_split arguments in fit(), when your data is passed as R arrays.\nLet’s now take a look at the case where your data comes in the form of a TensorFlow dataset object.\n\n\n\n\n\n\nNote\n\n\n\nThe tfdatasets package in R is an interface for the tf.data module in Python.\n\n\nThe tf.data API is a set of utilities in TensorFlow 2.0 for loading and preprocessing data in a way that’s fast and scalable.\nFor a complete guide about creating Datasets, see the tf.data documentation.\nYou can pass a Dataset instance directly to the methods fit(), evaluate(), and predict():\n\nlibrary(tfdatasets)\nmodel <- get_compiled_model()\n\n# First, let's create a training Dataset instance.\n# For the sake of our example, we'll use the same MNIST data as before.\ntrain_dataset <- tensor_slices_dataset(list(x_train, y_train))\n# Shuffle and slice the dataset.\ntrain_dataset <- train_dataset %>% \n  dataset_shuffle(1024) %>% \n  dataset_batch(64)\n\n# Now we get a test dataset.\ntest_dataset <- list(x_test, y_test) %>% \n  tensor_slices_dataset() %>% \n  dataset_batch(64)\n\n# Since the dataset already takes care of batching,\n# we don't pass a `batch_size` argument.\nmodel %>% fit(train_dataset, epochs = 3)\n\n# You can also evaluate or predict on a dataset.\nresult <- model %>% evaluate(test_dataset)\nprint(result)\n\n                       loss sparse_categorical_accuracy \n                  0.1161979                   0.9644000 \n\n\nNote that the Dataset is reset at the end of each epoch, so it can be reused of the next epoch.\nIf you want to run training only on a specific number of batches from this Dataset, you can pass the steps_per_epoch argument, which specifies how many training steps the model should run using this Dataset before moving on to the next epoch.\nIf you do this, the dataset is not reset at the end of each epoch, instead we just keep drawing the next batches. The dataset will eventually run out of data (unless it is an infinitely-looping dataset).\n\nmodel <- get_compiled_model()\n\n# Prepare the training dataset\ntrain_dataset <- list(x_train, y_train) %>% \n  tensor_slices_dataset() %>% \n  dataset_shuffle(1024) %>% \n  dataset_batch(64)\n\n# Only use the 100 batches per epoch (that's 64 * 100 samples)\nmodel %>% fit(train_dataset, epochs = 3, steps_per_epoch = 100)\n\n\nUsing a validation dataset\nYou can pass a Dataset instance as the validation_data argument in fit():\n\nmodel <- get_compiled_model()\n\n# Prepare the training dataset\ntrain_dataset <- list(x_train, y_train) %>% \n  tensor_slices_dataset() %>% \n  dataset_shuffle(1024) %>% \n  dataset_batch(64)\n\n# Prepare the validation dataset\nval_dataset <- list(x_val, y_val) %>% \n  tensor_slices_dataset() %>% \n  dataset_batch(64)\n\nmodel %>% fit(train_dataset, epochs = 1, validation_data = val_dataset)\n\nAt the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\nIf you want to run validation only on a specific number of batches from this dataset, you can pass the validation_steps argument, which specifies how many validation steps the model should run with the validation dataset before interrupting validation and moving on to the next epoch:\n\nmodel <- get_compiled_model()\n\n# Prepare the training dataset\ntrain_dataset <- list(x_train, y_train) %>% \n  tensor_slices_dataset() %>% \n  dataset_shuffle(1024) %>% \n  dataset_batch(64)\n\n# Prepare the validation dataset\nval_dataset <- list(x_val, y_val) %>% \n  tensor_slices_dataset() %>% \n  dataset_batch(64)\n\nmodel %>% fit(\n    train_dataset,\n    epochs = 1,\n    # Only run validation using the first 10 batches of the dataset\n    # using the `validation_steps` argument\n    validation_data = val_dataset,\n    validation_steps = 10,\n)\n\nNote that the validation dataset will be reset after each use (so that you will always be evaluating on the same samples from epoch to epoch).\nThe argument validation_split (generating a holdout set from the training data) is not supported when training from Dataset objects, since this feature requires the ability to index the samples of the datasets, which is not possible in general with the Dataset API."
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#using-sample-weighting-and-class-weighting",
    "href": "guides/keras/training_with_built_in_methods.html#using-sample-weighting-and-class-weighting",
    "title": "Training & evaluation with the built-in methods",
    "section": "Using sample weighting and class weighting",
    "text": "Using sample weighting and class weighting\nWith the default settings the weight of a sample is decided by its frequency in the dataset. There are two methods to weight the data, independent of sample frequency:\n\nClass weights\nSample weights\n\n\nClass weights\nThis is set by passing a dictionary to the class_weight argument to Model %>% fit(). This dictionary maps class indices to the weight that should be used for samples belonging to this class.\nThis can be used to balance classes without resampling, or to train a model that gives more importance to a particular class.\nFor instance, if class “0” is half as represented as class “1” in your data, you could use Model %>% fit(..., class_weight = list(0= 1., 1= 0.5)).\nHere’s an example where we use class weights or sample weights to give more importance to the correct classification of class #5 (which is the digit “5” in the MNIST dataset).\n\nclass_weight <- list(\n    \"0\" = 1.0,\n    \"1\" = 1.0,\n    \"2\" = 1.0,\n    \"3\" = 1.0,\n    \"4\" = 1.0,\n    # Set weight \"2\" for class \"5\",\n    # making this class 2x more important\n    \"5\" = 2.0,\n    \"6\" = 1.0,\n    \"7\" = 1.0,\n    \"8\" = 1.0,\n    \"9\" = 1.0\n)\n\nmodel <- get_compiled_model()\nmodel %>% fit(x_train, y_train, class_weight = class_weight, batch_size = 64, epochs = 1)\n\n\n\nSample weights\nFor fine grained control, or if you are not building a classifier, you can use “sample weights”.\n\nWhen training from R data: Pass the sample_weight argument to Model %>% fit().\nWhen training from tfdatasets or any other sort of iterator: Yield (input_batch, label_batch, sample_weight_batch) tuples.\n\nA “sample weights” array is an array of numbers that specify how much weight each sample in a batch should have in computing the total loss. It is commonly used in imbalanced classification problems (the idea being to give more weight to rarely-seen classes).\nWhen the weights used are ones and zeros, the array can be used as a mask for the loss function (entirely discarding the contribution of certain samples to the total loss).\n\nsample_weight <- rep(1, length(y_train))\nsample_weight[y_train == 5] <- 2.0\n\nmodel <- get_compiled_model()\nmodel %>% fit(x_train, y_train, sample_weight = sample_weight, batch_size = 64, epochs = 1)\n\nHere’s a matching Dataset example:\n\nsample_weight <- rep(1, length(y_train))\nsample_weight[y_train == 5] <- 2.0\n\n# Create a Dataset that includes sample weights\n# (3rd element in the return tuple).\ntrain_dataset <- list(x_train, y_train, sample_weight) %>% \n  tensor_slices_dataset()\n\n# Shuffle and slice the dataset.\ntrain_dataset <- train_dataset %>% \n  dataset_shuffle(1024) %>% \n  dataset_batch(64)\n\nmodel <- get_compiled_model()\nmodel %>% fit(train_dataset, epochs = 1)"
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#passing-data-to-multi-input-multi-output-models",
    "href": "guides/keras/training_with_built_in_methods.html#passing-data-to-multi-input-multi-output-models",
    "title": "Training & evaluation with the built-in methods",
    "section": "Passing data to multi-input, multi-output models",
    "text": "Passing data to multi-input, multi-output models\nIn the previous examples, we were considering a model with a single input (a tensor of shape (764)) and a single output (a prediction tensor of shape (10)). But what about models that have multiple inputs or outputs?\nConsider the following model, which has an image input of shape (32, 32, 3) (that’s (height, width, channels)) and a time series input of shape (NULL, 10) (that’s (timesteps, features)). Our model will have two outputs computed from the combination of these inputs: a “score” (of shape (1)) and a probability distribution over five classes (of shape (5)).\n\nimage_input <- layer_input(shape = shape(32, 32, 3), name = \"img_input\")\ntimeseries_input <- layer_input(shape = shape(NULL, 10), name = \"ts_input\")\n\nx1 <- layer_conv_2d(image_input, 3, 3)\nx1 <- layer_global_max_pooling_2d(x1)\n\nx2 <- layer_conv_1d(timeseries_input, 3, 3)\nx2 <- layer_global_max_pooling_1d(x2)\n\nx <- layer_concatenate(list(x1, x2))\n\nscore_output <- layer_dense(x, 1, name = \"score_output\")\nclass_output <- layer_dense(x, 5, name = \"class_output\")\n\nmodel <- keras_model(\n    inputs = list(image_input, timeseries_input), \n    outputs = list(score_output, class_output)\n)\n\nLet’s plot this model, so you can clearly see what we’re doing here (note that the shapes shown in the plot are batch shapes, rather than per-sample shapes).\n\nkeras$utils$plot_model(\n  model, \"img/multi_input_and_output_model.png\", \n  show_shapes = TRUE\n)\n\n<IPython.core.display.Image object>\n\n\n\nAt compilation time, we can specify different losses to different outputs, by passing the loss functions as a list:\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    loss_mean_squared_error(),\n    loss_categorical_crossentropy()\n  )\n)\n\nIf we only passed a single loss function to the model, the same loss function would be applied to every output (which is not appropriate here).\nLikewise for metrics:\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    loss_mean_squared_error(),\n    loss_categorical_crossentropy()\n  ),\n  metrics = list(\n    list(\n      metric_mean_absolute_percentage_error(),\n      metric_mean_absolute_error()\n    ),\n    list(\n      metric_categorical_accuracy()\n    )\n  )\n)\n\nSince we gave names to our output layers, we could also specify per-output losses and metrics via a dict:\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    score_output = loss_mean_squared_error(),\n    class_output = loss_categorical_crossentropy()\n  ),\n  metrics = list(\n    class_output = list(\n      metric_categorical_accuracy()\n    ),\n    score_output = list(\n      metric_mean_absolute_percentage_error(),\n      metric_mean_absolute_error()\n    )\n  )\n)\n\nWe recommend the use of explicit names and dicts if you have more than 2 outputs.\nIt’s possible to give different weights to different output-specific losses (for instance, one might wish to privilege the “score” loss in our example, by giving to 2x the importance of the class loss), using the loss_weights argument:\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    score_output = loss_mean_squared_error(),\n    class_output = loss_categorical_crossentropy()\n  ),\n  metrics = list(\n    class_output = list(\n      metric_categorical_accuracy()\n    ),\n    score_output = list(\n      metric_mean_absolute_percentage_error(),\n      metric_mean_absolute_error()\n    )\n  ),\n  loss_weights = list(score_output = 2.0, class_output = 1.0)\n)\n\nYou could also choose not to compute a loss for certain outputs, if these outputs are meant for prediction but not for training:\n\n# List loss version\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    NULL,\n    loss_categorical_crossentropy()\n  )\n)\n\n# Or dict loss version\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    class_output = loss_categorical_crossentropy()\n  )\n)\n\nPassing data to a multi-input or multi-output model in fit() works in a similar way as specifying a loss function in compile: you can pass lists of R arrays (with 1:1 mapping to the outputs that received a loss function) or named list mapping output names to R arrays.\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(1e-3),\n  loss = list(\n    loss_mean_squared_error(),\n    loss_categorical_crossentropy()\n  )\n)\n# Generate dummy NumPy data\n\nimg_data <- array(runif(100*32*32*3), dim = c(100, 32, 32, 3))\nts_data <- array(runif(100*20*10), dim = c(100, 20, 10))\nscore_targets <- array(runif(100), dim = c(100, 1))\nclass_targets <- array(runif(100*5), dim = c(100, 5))\n\n# Fit on lists\nmodel %>% fit(\n  list(img_data, ts_data), \n  list(score_targets, class_targets), \n  batch_size = 32, \n  epochs = 1\n)\n\n# Alternatively, fit on named lists\nmodel %>% fit(\n    list(\"img_input\" = img_data, \"ts_input\" = ts_data),\n    list(\"score_output\" = score_targets, \"class_output\" = class_targets),\n    batch_size = 32,\n    epochs = 1\n)\n\nHere’s the Dataset use case: similarly as what we did for R arrays, the Dataset should return a tuple of dicts.\n\ntrain_dataset <- list(\n  list(\"img_input\" = img_data, \"ts_input\" = ts_data),\n  list(\"score_output\" = score_targets, \"class_output\" = class_targets)\n) %>% \n  tensor_slices_dataset() %>% \n  dataset_shuffle(1024) %>% \n  dataset_batch(64)\n\nmodel %>% fit(train_dataset, epochs = 1)"
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#using-callbacks",
    "href": "guides/keras/training_with_built_in_methods.html#using-callbacks",
    "title": "Training & evaluation with the built-in methods",
    "section": "Using callbacks",
    "text": "Using callbacks\nCallbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.). They can be used to implement certain behaviors, such as:\n\nDoing validation at different points during training (beyond the built-in per-epoch validation)\nCheckpointing the model at regular intervals or when it exceeds a certain accuracy threshold\nChanging the learning rate of the model when training seems to be plateauing\nDoing fine-tuning of the top layers when training seems to be plateauing\nSending email or instant message notifications when training ends or where a certain performance threshold is exceeded\nEtc.\n\nCallbacks can be passed as a list to your call to fit():\n\nmodel <- get_compiled_model()\n\ncallbacks <- list(\n  callback_early_stopping(\n    # Stop training when `val_loss` is no longer improving\n    monitor = \"val_loss\",\n    # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n    min_delta = 1e-2,\n    # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n    patience = 2,\n    verbose = 1,\n  )\n)\n\nmodel %>% fit(\n    x_train,\n    y_train,\n    epochs = 20,\n    batch_size = 64,\n    callbacks = callbacks,\n    validation_split = 0.2,\n)\n\n\nMany built-in callbacks are available\nThere are many built-in callbacks already available in Keras, such as:\n\ncallback_model_checkpoint(): Periodically save the model.\ncallback_early_stopping(): Stop training when training is no longer improving the validation metrics.\ncallback_tensorboard(): periodically write model logs that can be visualized in TensorBoard (more details in the section “Visualization”).\ncallback_csv_logger(): streams loss and metrics data to a CSV file.\netc.\n\nSee the callbacks documentation for the complete list.\n\n\nWriting your own callback\nYou can create a custom callback by extending the base class keras$callbacks$Callback. A callback has access to its associated model through the class property self$model.\nMake sure to read the complete guide to writing custom callbacks.\nHere’s a simple example saving a list of per-batch loss values during training:\n\ncallback_loss_history <- new_callback_class(\n  \"loss_history\",\n  on_train_begin = function(logs) {\n    self$per_batch_losses <- list()\n  },\n  on_batch_end = function(batch, logs) {\n    self$per_batch_losses <- c(\n      self$per_batch_losses,\n      logs$get(\"loss\")\n    )\n  }\n)"
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#checkpointing-models",
    "href": "guides/keras/training_with_built_in_methods.html#checkpointing-models",
    "title": "Training & evaluation with the built-in methods",
    "section": "Checkpointing models",
    "text": "Checkpointing models\nWhen you’re training model on relatively large datasets, it’s crucial to save checkpoints of your model at frequent intervals.\nThe easiest way to achieve this is with the callback_model_checkpoint() callback:\n\nmodel <- get_compiled_model()\n\ncallbacks <- list(\n  callback_model_checkpoint(\n    # Path where to save the model\n    # The two parameters below mean that we will overwrite\n    # the current checkpoint if and only if\n    # the `val_loss` score has improved.\n    # The saved model name will include the current epoch.\n    filepath = \"mymodel_{epoch}\",\n    save_best_only = TRUE,  # Only save a model if `val_loss` has improved.\n    monitor = \"val_loss\",\n    verbose = 1,\n  )\n)\n\nmodel %>% fit(\n    x_train, \n    y_train, \n    epochs = 2, \n    batch_size = 64, \n    callbacks = callbacks, \n    validation_split = 0.2\n)\n\nThe callback_model_checkpoint() callback can be used to implement fault-tolerance: the ability to restart training from the last saved state of the model in case training gets randomly interrupted. Here’s a basic example:\n\n# Prepare a directory to store all the checkpoints.\ncheckpoint_dir <- \"./ckpt\"\ndir.create(checkpoint_dir, showWarnings = FALSE)\n\n\nmake_or_restore_model <- function() {\n  # Either restore the latest model, or create a fresh one\n  # if there is no checkpoint available.\n  checkpoints <- list.files(checkpoint_dir, full.names = TRUE)\n  details <- file.info(checkpoints)\n  if (length(checkpoints) > 0) {\n    latest_checkpoint <- checkpoints[which.max(as.POSIXct(details$mtime))]\n    cat(\"Restoring from\", latest_checkpoint)\n    return(load_model_tf(latest_checkpoint))\n  }\n  \n  cat(\"Creating a new model\")\n  get_compiled_model()\n}\n\nmodel <- make_or_restore_model()\n\nCreating a new model\n\ncallbacks <- list(\n    # This callback saves a SavedModel every 100 batches.\n    # We include the training loss in the saved model name.\n    callback_model_checkpoint(\n        filepath = paste0(checkpoint_dir, \"/ckpt-loss={loss:.2f}\"), \n        save_freq = 100\n    )\n)\nmodel %>% fit(x_train, y_train, epochs = 1, callbacks = callbacks)\n\nYou call also write your own callback for saving and restoring models.\nFor a complete guide on serialization and saving, see the guide to saving and serializing Models."
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#using-learning-rate-schedules",
    "href": "guides/keras/training_with_built_in_methods.html#using-learning-rate-schedules",
    "title": "Training & evaluation with the built-in methods",
    "section": "Using learning rate schedules",
    "text": "Using learning rate schedules\nA common pattern when training deep learning models is to gradually reduce the learning as training progresses. This is generally known as “learning rate decay”.\nThe learning decay schedule could be static (fixed in advance, as a function of the current epoch or the current batch index), or dynamic (responding to the current behavior of the model, in particular the validation loss).\n\nPassing a schedule to an optimizer\nYou can easily use a static learning rate decay schedule by passing a schedule object as the learning_rate argument in your optimizer:\n\ninitial_learning_rate <- 0.1\nlr_schedule <- learning_rate_schedule_exponential_decay(\n  initial_learning_rate = initial_learning_rate,\n  decay_steps = 100000, \n  decay_rate = 0.96, \n  staircase = TRUE\n)\n\noptimizer <- keras$optimizers$RMSprop(learning_rate = lr_schedule)\n\nSeveral built-in schedules are available: learning_rate_schedule_cosine_decay, learning_rate_schedule_cosine_decay_restarts, learning_rate_schedule_exponential_decay, learning_rate_schedule_inverse_time_decay, learning_rate_schedule_piecewise_constant_decay, learning_rate_schedule_polynomial_decay\n\n\nUsing callbacks to implement a dynamic learning rate schedule\nA dynamic learning rate schedule (for instance, decreasing the learning rate when the validation loss is no longer improving) cannot be achieved with these schedule objects, since the optimizer does not have access to validation metrics.\nHowever, callbacks do have access to all metrics, including validation metrics! You can thus achieve this pattern by using a callback that modifies the current learning rate on the optimizer. In fact, this is even built-in as the callback_reduce_lr_on_plateau() callback."
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#visualizing-loss-and-metrics-during-training",
    "href": "guides/keras/training_with_built_in_methods.html#visualizing-loss-and-metrics-during-training",
    "title": "Training & evaluation with the built-in methods",
    "section": "Visualizing loss and metrics during training",
    "text": "Visualizing loss and metrics during training\nThe best way to keep an eye on your model during training is to use TensorBoard – a browser-based application that you can run locally that provides you with:\n\nLive plots of the loss and metrics for training and evaluation\n(optionally) Visualizations of the histograms of your layer activations\n(optionally) 3D visualizations of the embedding spaces learned by your Embedding layers\n\nIf you have installed TensorFlow with pip, you should be able to launch TensorBoard from R with:\n\ntensorflow::tensorboard(log_dir = \"/full_path_to_your_logs\")\n\n\nUsing the TensorBoard callback\nThe easiest way to use TensorBoard with a Keras model and the fit() method is the TensorBoard callback.\nIn the simplest case, just specify where you want the callback to write logs, and you’re good to go:\n\ncallback_tensorboard(\n    log_dir = \"/full_path_to_your_logs\",\n    histogram_freq = 0,  # How often to log histogram visualizations\n    embeddings_freq = 0,  # How often to log embedding visualizations\n    update_freq = \"epoch\" # How often to write logs (default: once per epoch)\n)  \n\n<keras.callbacks.TensorBoard object at 0x7fea244b90a0>\n\n\nFor more information, see the documentation for the TensorBoard callback."
  },
  {
    "objectID": "guides/keras/training_with_built_in_methods.html#environment-details",
    "href": "guides/keras/training_with_built_in_methods.html#environment-details",
    "title": "Training & evaluation with the built-in methods",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/transfer_learning.html",
    "href": "guides/keras/transfer_learning.html",
    "title": "Transfer learning and fine-tuning",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)\nprintf <- function(...) writeLines(sprintf(...))"
  },
  {
    "objectID": "guides/keras/transfer_learning.html#introduction",
    "href": "guides/keras/transfer_learning.html#introduction",
    "title": "Transfer learning and fine-tuning",
    "section": "Introduction",
    "text": "Introduction\nTransfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify skunks.\nTransfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\nThe most common incarnation of transfer learning in the context of deep learning is the following workflow:\n\nTake layers from a previously trained model.\nFreeze them, so as to avoid destroying any of the information they contain during future training rounds.\nAdd some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\nTrain the new layers on your dataset.\n\nA last, optional step, is fine-tuning, which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate. This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data.\nFirst, we will go over the Keras trainable API in detail, which underlies most transfer learning and fine-tuning workflows.\nThen, we’ll demonstrate the typical workflow by taking a model pretrained on the ImageNet dataset, and retraining it on the Kaggle “cats vs dogs” classification dataset.\nThis is adapted from Deep Learning with R and the 2016 blog post “building powerful image classification models using very little data”."
  },
  {
    "objectID": "guides/keras/transfer_learning.html#freezing-layers-understanding-the-trainable-attribute",
    "href": "guides/keras/transfer_learning.html#freezing-layers-understanding-the-trainable-attribute",
    "title": "Transfer learning and fine-tuning",
    "section": "Freezing layers: understanding the trainable attribute",
    "text": "Freezing layers: understanding the trainable attribute\nLayers and models have three weight attributes:\n\nweights is the list of all weights variables of the layer.\ntrainable_weights is the list of those that are meant to be updated (via gradient descent) to minimize the loss during training.\nnon_trainable_weights is the list of those that aren’t meant to be trained. Typically they are updated by the model during the forward pass.\n\nExample: the Dense layer has 2 trainable weights (kernel and bias)\n\nlayer <- layer_dense(units = 3)\n\nLoaded Tensorflow version 2.9.1\n\nlayer$build(shape(NULL, 4))\n\nprintf(\"weights: %s\", length(layer$weights))\n\nweights: 2\n\nprintf(\"trainable_weights: %s\", length(layer$trainable_weights))\n\ntrainable_weights: 2\n\nprintf(\"non_trainable_weights: %s\", length(layer$non_trainable_weights))\n\nnon_trainable_weights: 0\n\n\nIn general, all weights are trainable weights. The only built-in layer that has non-trainable weights is layer_batch_normalization(). It uses non-trainable weights to keep track of the mean and variance of its inputs during training. To learn how to use non-trainable weights in your own custom layers, see the guide to writing new layers from scratch.\nExample: The layer instance returned by layer_batch_normalization() has 2 trainable weights and 2 non-trainable weights\n\nlayer <- layer_batch_normalization()\nlayer$build(shape(NULL, 4))\n\nprintf(\"weights: %s\", length(layer$weights))\n\nweights: 4\n\nprintf(\"trainable_weights: %s\", length(layer$trainable_weights))\n\ntrainable_weights: 2\n\nprintf(\"non_trainable_weights: %s\", length(layer$non_trainable_weights))\n\nnon_trainable_weights: 2\n\n\nLayers and models also feature a boolean attribute trainable. Its value can be changed. Setting layer$trainable to FALSE moves all the layer’s weights from trainable to non-trainable. This is called “freezing” the layer: the state of a frozen layer won’t be updated during training (either when training with fit() or when training with any custom loop that relies on trainable_weights to apply gradient updates).\nExample: setting trainable to False\n\nlayer = layer_dense(units = 3)\nlayer$build(shape(NULL, 4))  # Create the weights\nlayer$trainable <- FALSE     # Freeze the layer\n\nprintf(\"weights: %s\", length(layer$weights))\n\nweights: 2\n\nprintf(\"trainable_weights: %s\", length(layer$trainable_weights))\n\ntrainable_weights: 0\n\nprintf(\"non_trainable_weights: %s\", length(layer$non_trainable_weights))\n\nnon_trainable_weights: 2\n\n\nWhen a trainable weight becomes non-trainable, its value is no longer updated during training.\n\n# Make a model with 2 layers\nlayer1 <- layer_dense(units = 3, activation = \"relu\")\nlayer2 <- layer_dense(units = 3, activation = \"sigmoid\")\nmodel <- keras_model_sequential(input_shape = c(3)) %>%\n  layer1() %>%\n  layer2()\n\n# Freeze the first layer\nlayer1$trainable <- FALSE\n\n# Keep a copy of the weights of layer1 for later reference\ninitial_layer1_weights_values <- get_weights(layer1)\n\n# Train the model\nmodel %>% compile(optimizer = \"adam\", loss = \"mse\")\nmodel %>% fit(k_random_normal(c(2, 3)), k_random_normal(c(2, 3)))\n\n# Check that the weights of layer1 have not changed during training\nfinal_layer1_weights_values <- get_weights(layer1)\nstopifnot(all.equal(initial_layer1_weights_values, final_layer1_weights_values))\n\nDo not confuse the layer$trainable attribute with the training argument in a layer instance’s call signature layer(training =) (which controls whether the layer should run its forward pass in inference mode or training mode). For more information, see the Keras FAQ."
  },
  {
    "objectID": "guides/keras/transfer_learning.html#recursive-setting-of-the-trainable-attribute",
    "href": "guides/keras/transfer_learning.html#recursive-setting-of-the-trainable-attribute",
    "title": "Transfer learning and fine-tuning",
    "section": "Recursive setting of the trainable attribute",
    "text": "Recursive setting of the trainable attribute\nIf you set trainable = FALSE on a model or on any layer that has sublayers, all child layers become non-trainable as well.\nExample:\n\ninner_model <- keras_model_sequential(input_shape = c(3)) %>%\n  layer_dense(3, activation = \"relu\") %>%\n  layer_dense(3, activation = \"relu\")\n\nmodel <- keras_model_sequential(input_shape = c(3)) %>%\n  inner_model() %>%\n  layer_dense(3, activation = \"sigmoid\")\n\n\nmodel$trainable <- FALSE  # Freeze the outer model\n\nstopifnot(inner_model$trainable == FALSE)             # All layers in `model` are now frozen\nstopifnot(inner_model$layers[[1]]$trainable == FALSE)  # `trainable` is propagated recursively"
  },
  {
    "objectID": "guides/keras/transfer_learning.html#the-typical-transfer-learning-workflow",
    "href": "guides/keras/transfer_learning.html#the-typical-transfer-learning-workflow",
    "title": "Transfer learning and fine-tuning",
    "section": "The typical transfer-learning workflow",
    "text": "The typical transfer-learning workflow\nThis leads us to how a typical transfer learning workflow can be implemented in Keras:\n\nInstantiate a base model and load pre-trained weights into it.\nFreeze all layers in the base model by setting trainable = FALSE.\nCreate a new model on top of the output of one (or several) layers from the base model.\nTrain your new model on your new dataset.\n\nNote that an alternative, more lightweight workflow could also be:\n\nInstantiate a base model and load pre-trained weights into it.\nRun your new dataset through it and record the output of one (or several) layers from the base model. This is called feature extraction.\nUse that output as input data for a new, smaller model.\n\nA key advantage of that second workflow is that you only run the base model once on your data, rather than once per epoch of training. So it’s a lot faster and cheaper.\nAn issue with that second workflow, though, is that it doesn’t allow you to dynamically modify the input data of your new model during training, which is required when doing data augmentation, for instance. Transfer learning is typically used for tasks when your new dataset has too little data to train a full-scale model from scratch, and in such scenarios data augmentation is very important. So in what follows, we will focus on the first workflow.\nHere’s what the first workflow looks like in Keras:\nFirst, instantiate a base model with pre-trained weights.\n\nbase_model <- application_xception(\n  weights = 'imagenet', # Load weights pre-trained on ImageNet.\n  input_shape = c(150, 150, 3),\n  include_top = FALSE # Do not include the ImageNet classifier at the top.\n)\n\nThen, freeze the base model.\n\nbase_model$trainable <- FALSE\n\nCreate a new model on top.\n\ninputs <- layer_input(c(150, 150, 3))\n\noutputs <- inputs %>%\n  # We make sure that the base_model is running in inference mode here,\n  # by passing `training=FALSE`. This is important for fine-tuning, as you will\n  # learn in a few paragraphs.\n  base_model(training=FALSE) %>%\n\n  # Convert features of shape `base_model$output_shape[-1]` to vectors\n  layer_global_average_pooling_2d() %>%\n\n  # A Dense classifier with a single unit (binary classification)\n  layer_dense(1)\n\nmodel <- keras_model(inputs, outputs)\n\nTrain the model on new data.\n\nmodel %>%\n  compile(optimizer = optimizer_adam(),\n          loss = loss_binary_crossentropy(from_logits = TRUE),\n          metrics = metric_binary_accuracy()) %>%\n  fit(new_dataset, epochs = 20, callbacks = ..., validation_data = ...)"
  },
  {
    "objectID": "guides/keras/transfer_learning.html#fine-tuning",
    "href": "guides/keras/transfer_learning.html#fine-tuning",
    "title": "Transfer learning and fine-tuning",
    "section": "Fine-tuning",
    "text": "Fine-tuning\nOnce your model has converged on the new data, you can try to unfreeze all or part of the base model and retrain the whole model end-to-end with a very low learning rate.\nThis is an optional last step that can potentially give you incremental improvements. It could also potentially lead to quick overfitting – keep that in mind.\nIt is critical to only do this step after the model with frozen layers has been trained to convergence. If you mix randomly-initialized trainable layers with trainable layers that hold pre-trained features, the randomly-initialized layers will cause very large gradient updates during training, which will destroy your pre-trained features.\nIt’s also critical to use a very low learning rate at this stage, because you are training a much larger model than in the first round of training, on a dataset that is typically very small. As a result, you are at risk of overfitting very quickly if you apply large weight updates. Here, you only want to re-adapt the pretrained weights in an incremental way.\nThis is how to implement fine-tuning of the whole base model:\n\n# Unfreeze the base model\nbase_model$trainable <- TRUE\n\n# It's important to recompile your model after you make any changes\n# to the `trainable` attribute of any inner layer, so that your changes\n# are taken into account\nmodel %>% compile(\n  optimizer = optimizer_adam(1e-5), # Very low learning rate\n  loss = loss_binary_crossentropy(from_logits = TRUE),\n  metrics = metric_binary_accuracy()\n)\n\n# Train end-to-end. Be careful to stop before you overfit!\nmodel %>% fit(new_dataset, epochs=10, callbacks=..., validation_data=...)\n\nImportant note about compile() and trainable\nCalling compile() on a model is meant to “freeze” the behavior of that model. This implies that the trainable attribute values at the time the model is compiled should be preserved throughout the lifetime of that model, until compile is called again. Hence, if you change any trainable value, make sure to call compile() again on your model for your changes to be taken into account.\nImportant notes about layer_batch_normalization()\nMany image models contain BatchNormalization layers. That layer is a special case on every imaginable count. Here are a few things to keep in mind.\n\nBatchNormalization contains 2 non-trainable weights that get updated during training. These are the variables tracking the mean and variance of the inputs.\nWhen you set bn_layer$trainable = FALSE, the BatchNormalization layer will run in inference mode, and will not update its mean and variance statistics. This is not the case for other layers in general, as weight trainability and inference/training modes are two orthogonal concepts. But the two are tied in the case of the BatchNormalization layer.\nWhen you unfreeze a model that contains BatchNormalization layers in order to do fine-tuning, you should keep the BatchNormalization layers in inference mode by passing training = FALSE when calling the base model. Otherwise the updates applied to the non-trainable weights will suddenly destroy what the model has learned.\n\nYou’ll see this pattern in action in the end-to-end example at the end of this guide."
  },
  {
    "objectID": "guides/keras/transfer_learning.html#transfer-learning-and-fine-tuning-with-a-custom-training-loop",
    "href": "guides/keras/transfer_learning.html#transfer-learning-and-fine-tuning-with-a-custom-training-loop",
    "title": "Transfer learning and fine-tuning",
    "section": "Transfer learning and fine-tuning with a custom training loop",
    "text": "Transfer learning and fine-tuning with a custom training loop\nIf instead of fit(), you are using your own low-level training loop, the workflow stays essentially the same. You should be careful to only take into account the list model$trainable_weights when applying gradient updates:\n\n# Create base model\nbase_model = application_xception(\n  weights = 'imagenet',\n  input_shape = c(150, 150, 3),\n  include_top = FALSE\n)\n\n# Freeze base model\nbase_model$trainable = FALSE\n\n# Create new model on top.\ninputs <- layer_input(shape = c(150, 150, 3))\noutputs <- inputs %>%\n  base_model(training = FALSE) %>%\n  layer_global_average_pooling_2d() %>%\n  layer_dense(1)\nmodel <- keras_model(inputs, outputs)\n\nloss_fn <- loss_binary_crossentropy(from_logits = TRUE)\noptimizer <- optimizer_adam()\n\n# helper to zip gradients with weights\nxyz <- function(...) .mapply(c, list(...), NULL)\n\n# Iterate over the batches of a dataset.\nlibrary(tfdatasets)\nnew_dataset <- ...\n\nwhile(!is.null(batch <- iter_next(new_dataset))) {\n  c(inputs, targets) %<-% batch\n  # Open a GradientTape.\n  with(tf$GradientTape() %as% tape, {\n    # Forward pass.\n    predictions = model(inputs)\n    # Compute the loss value for this batch.\n    loss_value = loss_fn(targets, predictions)\n  })\n  # Get gradients of loss w.r.t. the *trainable* weights.\n  gradients <- tape$gradient(loss_value, model$trainable_weights)\n  # Update the weights of the model.\n  optimizer$apply_gradients(xyz(gradients, model$trainable_weights))\n}\n\nLikewise for fine-tuning."
  },
  {
    "objectID": "guides/keras/transfer_learning.html#an-end-to-end-example-fine-tuning-an-image-classification-model-on-a-cats-vs.-dogs-dataset",
    "href": "guides/keras/transfer_learning.html#an-end-to-end-example-fine-tuning-an-image-classification-model-on-a-cats-vs.-dogs-dataset",
    "title": "Transfer learning and fine-tuning",
    "section": "An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset",
    "text": "An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset\nTo solidify these concepts, let’s walk you through a concrete end-to-end transfer learning and fine-tuning example. We will load the Xception model, pre-trained on ImageNet, and use it on the Kaggle “cats vs. dogs” classification dataset.\n\nGetting the data\nFirst, let’s fetch the cats vs. dogs dataset using TFDS. If you have your own dataset, you’ll probably want to use the utility image_dataset_from_directory() to generate similar labeled dataset objects from a set of images on disk filed into class-specific folders.\nTransfer learning is most useful when working with very small datasets. To keep our dataset small, we will use 40% of the original training data (25,000 images) for training, 10% for validation, and 10% for testing.\n\n# reticulate::py_install(\"tensorflow_datasets\", pip = TRUE)\ntfds <- reticulate::import(\"tensorflow_datasets\")\n\nc(train_ds, validation_ds, test_ds) %<-% tfds$load(\n    \"cats_vs_dogs\",\n    # Reserve 10% for validation and 10% for test\n    split = c(\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"),\n    as_supervised=TRUE  # Include labels\n)\n\nprintf(\"Number of training samples: %d\", length(train_ds))\n\nNumber of training samples: 9305\n\nprintf(\"Number of validation samples: %d\", length(validation_ds) )\n\nNumber of validation samples: 2326\n\nprintf(\"Number of test samples: %d\", length(test_ds))\n\nNumber of test samples: 2326\n\n\nThese are the first 9 images in the training dataset – as you can see, they’re all different sizes.\n\nlibrary(tfdatasets)\n\npar(mfrow = c(3, 3), mar = c(1,0,1.5,0))\ntrain_ds %>%\n  dataset_take(9) %>%\n  as_array_iterator() %>%\n  iterate(function(batch) {\n    c(image, label) %<-% batch\n    plot(as.raster(image, max = 255))\n    title(sprintf(\"label: %s   size: %s\",\n                  label, paste(dim(image), collapse = \" x \")))\n  })\n\n\n\n\nWe can also see that label 1 is “dog” and label 0 is “cat”.\n\n\nStandardizing the data\nOur raw images have a variety of sizes. In addition, each pixel consists of 3 integer values between 0 and 255 (RGB level values). This isn’t a great fit for feeding a neural network. We need to do 2 things:\n\nStandardize to a fixed image size. We pick 150x150.\nNormalize pixel values between -1 and 1. We’ll do this using a layer_normalization() as part of the model itself.\n\nIn general, it’s a good practice to develop models that take raw data as input, as opposed to models that take already-preprocessed data. The reason being that, if your model expects preprocessed data, any time you export your model to use it elsewhere (in a web browser, in a mobile app), you’ll need to reimplement the exact same preprocessing pipeline. This gets very tricky very quickly. So we should do the least possible amount of preprocessing before hitting the model.\nHere, we’ll do image resizing in the data pipeline (because a deep neural network can only process contiguous batches of data), and we’ll do the input value scaling as part of the model, when we create it.\nLet’s resize images to 150x150:\n\nlibrary(magrittr, include.only = \"%<>%\")\n\nWarning: package 'magrittr' was built under R version 4.1.2\n\nsize <- as.integer(c(150, 150))\ntrain_ds      %<>% dataset_map(function(x, y) list(tf$image$resize(x, size), y))\nvalidation_ds %<>% dataset_map(function(x, y) list(tf$image$resize(x, size), y))\ntest_ds       %<>% dataset_map(function(x, y) list(tf$image$resize(x, size), y))\n\nBesides, let’s batch the data and use caching and prefetching to optimize loading speed.\n\ndataset_cache_batch_prefetch <- function(dataset, batch_size = 32, buffer_size = 10) {\n  dataset %>%\n    dataset_cache() %>%\n    dataset_batch(batch_size) %>%\n    dataset_prefetch(buffer_size)\n}\n\ntrain_ds      %<>% dataset_cache_batch_prefetch()\nvalidation_ds %<>% dataset_cache_batch_prefetch()\ntest_ds       %<>% dataset_cache_batch_prefetch()\n\n\n\nUsing random data augmentation\nWhen you don’t have a large image dataset, it’s a good practice to artificially introduce sample diversity by applying random yet realistic transformations to the training images, such as random horizontal flipping or small random rotations. This helps expose the model to different aspects of the training data while slowing down overfitting.\n\ndata_augmentation <- keras_model_sequential() %>%\n  layer_random_flip(\"horizontal\") %>%\n  layer_random_rotation(.1)\n\nLet’s visualize what the first image of the first batch looks like after various random transformations:\n\nbatch <- train_ds %>%\n  dataset_take(1) %>%\n  as_iterator() %>% iter_next()\n\nc(images, labels) %<-% batch\nfirst_image <- images[1, all_dims(), drop = FALSE]\naugmented_image <- data_augmentation(first_image, training = TRUE)\n\nplot_image <- function(image, main = deparse1(substitute(image))) {\n  image %>%\n    k_squeeze(1) %>% # drop batch dim\n    as.array() %>%   # convert from tensor to R array\n    as.raster(max = 255) %>%\n    plot()\n\n  if(!is.null(main))\n    title(main)\n}\n\npar(mfrow = c(2, 2), mar = c(1, 1, 1.5, 1))\nplot_image(first_image)\nplot_image(augmented_image)\nplot_image(data_augmentation(first_image, training = TRUE), \"augmented 2\")\nplot_image(data_augmentation(first_image, training = TRUE), \"augmented 3\")"
  },
  {
    "objectID": "guides/keras/transfer_learning.html#build-a-model",
    "href": "guides/keras/transfer_learning.html#build-a-model",
    "title": "Transfer learning and fine-tuning",
    "section": "Build a model",
    "text": "Build a model\nNow let’s build a model that follows the blueprint we’ve explained earlier.\nNote that:\n\nWe add layer_rescaling() to scale input values (initially in the [0, 255] range) to the [-1, 1] range.\nWe add a layer_dropout() before the classification layer, for regularization.\nWe make sure to pass training = FALSE when calling the base model, so that it runs in inference mode, so that batchnorm statistics don’t get updated even after we unfreeze the base model for fine-tuning.\n\n\nbase_model = application_xception(\n  weights = \"imagenet\", # Load weights pre-trained on ImageNet.\n  input_shape = c(150, 150, 3),\n  include_top = FALSE # Do not include the ImageNet classifier at the top.\n)\n\n# Freeze the base_model\nbase_model$trainable <- FALSE\n\n# Create new model on top\ninputs <- layer_input(shape = c(150, 150, 3))\n\noutputs <- inputs %>%\n  data_augmentation() %>%   # Apply random data augmentation\n\n  # Pre-trained Xception weights requires that input be scaled\n  # from (0, 255) to a range of (-1., +1.), the rescaling layer\n  # outputs: `(inputs * scale) + offset`\n  layer_rescaling(scale = 1 / 127.5, offset = -1) %>%\n\n  # The base model contains batchnorm layers. We want to keep them in inference mode\n  # when we unfreeze the base model for fine-tuning, so we make sure that the\n  # base_model is running in inference mode here.\n  base_model(training = FALSE) %>%\n  layer_global_average_pooling_2d() %>%\n  layer_dropout(.2) %>%\n  layer_dense(1)\n\nmodel <- keras_model(inputs, outputs)\nmodel\n\nModel: \"model_1\"\n____________________________________________________________________________\n Layer (type)                Output Shape              Param #   Trainable  \n============================================================================\n input_7 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n sequential_3 (Sequential)   (None, 150, 150, 3)       0         Y          \n rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n xception (Functional)       (None, 5, 5, 2048)        20861480  N          \n global_average_pooling2d_1   (None, 2048)             0         Y          \n (GlobalAveragePooling2D)                                                   \n dropout (Dropout)           (None, 2048)              0         Y          \n dense_8 (Dense)             (None, 1)                 2049      Y          \n============================================================================\nTotal params: 20,863,529\nTrainable params: 2,049\nNon-trainable params: 20,861,480\n____________________________________________________________________________"
  },
  {
    "objectID": "guides/keras/transfer_learning.html#train-the-top-layer",
    "href": "guides/keras/transfer_learning.html#train-the-top-layer",
    "title": "Transfer learning and fine-tuning",
    "section": "Train the top layer",
    "text": "Train the top layer\n\nmodel %>% compile(\n  optimizer = optimizer_adam(),\n  loss = loss_binary_crossentropy(from_logits = TRUE),\n  metrics = metric_binary_accuracy()\n)\n\nepochs <- 2\nmodel %>% fit(train_ds, epochs = epochs, validation_data = validation_ds)"
  },
  {
    "objectID": "guides/keras/transfer_learning.html#do-a-round-of-fine-tuning-of-the-entire-model",
    "href": "guides/keras/transfer_learning.html#do-a-round-of-fine-tuning-of-the-entire-model",
    "title": "Transfer learning and fine-tuning",
    "section": "Do a round of fine-tuning of the entire model",
    "text": "Do a round of fine-tuning of the entire model\nFinally, let’s unfreeze the base model and train the entire model end-to-end with a low learning rate.\nImportantly, although the base model becomes trainable, it is still running in inference mode since we passed training = FALSE when calling it when we built the model. This means that the batch normalization layers inside won’t update their batch statistics. If they did, they would wreck havoc on the representations learned by the model so far.\n\n# Unfreeze the base_model. Note that it keeps running in inference mode\n# since we passed `training = FALSE` when calling it. This means that\n# the batchnorm layers will not update their batch statistics.\n# This prevents the batchnorm layers from undoing all the training\n# we've done so far.\nbase_model$trainable <- TRUE\nmodel\n\nModel: \"model_1\"\n____________________________________________________________________________\n Layer (type)                Output Shape              Param #   Trainable  \n============================================================================\n input_7 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n sequential_3 (Sequential)   (None, 150, 150, 3)       0         Y          \n rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n xception (Functional)       (None, 5, 5, 2048)        20861480  Y          \n global_average_pooling2d_1   (None, 2048)             0         Y          \n (GlobalAveragePooling2D)                                                   \n dropout (Dropout)           (None, 2048)              0         Y          \n dense_8 (Dense)             (None, 1)                 2049      Y          \n============================================================================\nTotal params: 20,863,529\nTrainable params: 20,809,001\nNon-trainable params: 54,528\n____________________________________________________________________________\n\nmodel %>% compile(\n  optimizer = optimizer_adam(1e-5),\n  loss = loss_binary_crossentropy(from_logits = TRUE),\n  metrics = metric_binary_accuracy()\n)\n\nepochs <- 1\nmodel %>% fit(train_ds, epochs = epochs, validation_data = validation_ds)\n\nAfter 10 epochs, fine-tuning gains us a nice improvement here."
  },
  {
    "objectID": "guides/keras/transfer_learning.html#environment-details",
    "href": "guides/keras/transfer_learning.html#environment-details",
    "title": "Transfer learning and fine-tuning",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html",
    "href": "guides/keras/understanding_masking_and_padding.html",
    "title": "Understanding masking & padding",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#introduction",
    "href": "guides/keras/understanding_masking_and_padding.html#introduction",
    "title": "Understanding masking & padding",
    "section": "Introduction",
    "text": "Introduction\nMasking is a way to tell sequence-processing layers that certain timesteps in an input are missing, and thus should be skipped when processing the data.\nPadding is a special form of masking where the masked steps are at the start or the end of a sequence. Padding comes from the need to encode sequence data into contiguous batches: in order to make all sequences in a batch fit a given standard length, it is necessary to pad or truncate some sequences.\nLet’s take a close look."
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#padding-sequence-data",
    "href": "guides/keras/understanding_masking_and_padding.html#padding-sequence-data",
    "title": "Understanding masking & padding",
    "section": "Padding sequence data",
    "text": "Padding sequence data\nWhen processing sequence data, it is very common for individual samples to have different lengths. Consider the following example (text tokenized as words):\n\nlist(\n  c(\"Hello\", \"world\", \"!\"),\n  c(\"How\", \"are\", \"you\", \"doing\", \"today\"),\n  c(\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\")\n)\n\n[[1]]\n[1] \"Hello\" \"world\" \"!\"    \n\n[[2]]\n[1] \"How\"   \"are\"   \"you\"   \"doing\" \"today\"\n\n[[3]]\n[1] \"The\"      \"weather\"  \"will\"     \"be\"       \"nice\"     \"tomorrow\"\n\n\nAfter vocabulary lookup, the data might be vectorized as integers, e.g.:\n\nlist(\n  c(71, 1331, 4231),\n  c(73, 8, 3215, 55, 927),\n  c(83, 91, 1, 645, 1253, 927)\n)\n\n[[1]]\n[1]   71 1331 4231\n\n[[2]]\n[1]   73    8 3215   55  927\n\n[[3]]\n[1]   83   91    1  645 1253  927\n\n\nThe data is a nested list where individual samples have length 3, 5, and 6, respectively. Since the input data for a deep learning model must be a single tensor (of shape e.g. (batch_size, 6, vocab_size) in this case), samples that are shorter than the longest item need to be padded with some placeholder value (alternatively, one might also truncate long samples before padding short samples).\nKeras provides a utility function to truncate and pad lists to a common length: pad_sequences().\n\nraw_inputs <- list(\n  c(711, 632, 71),\n  c(73, 8, 3215, 55, 927),\n  c(83, 91, 1, 645, 1253, 927)\n)\n\n# By default, this will pad using 0s; it is configurable via the\n# \"value\" parameter.\n# Note that you could use \"pre\" padding (at the beginning) or\n# \"post\" padding (at the end).\n# We recommend using \"post\" padding when working with RNN layers\n# (in order to be able to use the\n# CuDNN implementation of the layers).\n\npadded_inputs <- pad_sequences(raw_inputs, padding = \"post\")\n\nLoaded Tensorflow version 2.9.1\n\nprint(padded_inputs)\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]  711  632   71    0    0    0\n[2,]   73    8 3215   55  927    0\n[3,]   83   91    1  645 1253  927"
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#masking",
    "href": "guides/keras/understanding_masking_and_padding.html#masking",
    "title": "Understanding masking & padding",
    "section": "Masking",
    "text": "Masking\nNow that all samples have a uniform length, the model must be informed that some part of the data is actually padding and should be ignored. That mechanism is masking.\nThere are three ways to introduce input masks in Keras models:\n\nAdd a layer_masking() layer.\nConfigure a layer_embedding() layer with mask_zero = TRUE.\nPass a mask argument manually when calling layers that support this argument (e.g. RNN layers)."
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#mask-generating-layers-embedding-and-masking",
    "href": "guides/keras/understanding_masking_and_padding.html#mask-generating-layers-embedding-and-masking",
    "title": "Understanding masking & padding",
    "section": "Mask-generating layers: embedding and masking",
    "text": "Mask-generating layers: embedding and masking\nUnder the hood, these layers will create a mask tensor (2D tensor with shape (batch, sequence_length)), and attach it to the tensor output returned by the layer_masking() or layer_embedding() layer.\n\nembedding <- layer_embedding(input_dim = 5000, output_dim = 16, mask_zero = TRUE)\nmasked_output <- embedding(padded_inputs)\n\nprint(masked_output$`_keras_mask`)\n\ntf.Tensor(\n[[ True  True  True False False False]\n [ True  True  True  True  True False]\n [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n\nmasking_layer <- layer_masking()\n# Simulate the embedding lookup by expanding the 2D input to 3D,\n# with embedding dimension of 10.\nunmasked_embedding <- tf$cast(\n    tf$tile(tf$expand_dims(padded_inputs, axis = -1L), c(1L, 1L, 10L)), tf$float32\n)\nmasked_embedding <- masking_layer(unmasked_embedding)\nprint(masked_embedding$`_keras_mask`)\n\ntf.Tensor(\n[[ True  True  True False False False]\n [ True  True  True  True  True False]\n [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n\n\nAs you can see from the printed result, the mask is a 2D boolean tensor with shape (batch_size, sequence_length), where each individual FALSE entry indicates that the corresponding timestep should be ignored during processing."
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#mask-propagation-in-the-functional-api-and-sequential-api",
    "href": "guides/keras/understanding_masking_and_padding.html#mask-propagation-in-the-functional-api-and-sequential-api",
    "title": "Understanding masking & padding",
    "section": "Mask propagation in the Functional API and Sequential API",
    "text": "Mask propagation in the Functional API and Sequential API\nWhen using the Functional API or the Sequential API, a mask generated by an layer_embedding() or layer_masking() will be propagated through the network for any layer that is capable of using them (for example, RNN layers). Keras will automatically fetch the mask corresponding to an input and pass it to any layer that knows how to use it.\nFor instance, in the following Sequential model, the LSTM layer will automatically receive a mask, which means it will ignore padded values:\n\nmodel <- keras_model_sequential() %>% \n  layer_embedding(input_dim = 5000, output_dim = 16, mask_zero = TRUE) %>% \n  layer_lstm(32)\n\nThis is also the case for the following Functional API model:\n\ninputs <- layer_input(shape = shape(NULL), dtype = \"int32\")\noutputs <- inputs %>% \n  layer_embedding(input_dim = 5000, output_dim = 16, mask_zero = TRUE) %>% \n  layer_lstm(units = 32)\nmodel <- keras_model(inputs, outputs)"
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#passing-mask-tensors-directly-to-layers",
    "href": "guides/keras/understanding_masking_and_padding.html#passing-mask-tensors-directly-to-layers",
    "title": "Understanding masking & padding",
    "section": "Passing mask tensors directly to layers",
    "text": "Passing mask tensors directly to layers\nLayers that can handle masks (such as the LSTM layer) have a mask argument in their call method.\nMeanwhile, layers that produce a mask (e.g. Embedding) expose a compute_mask(input, previous_mask) method which you can call.\nThus, you can pass the output of the compute_mask() method of a mask-producing layer to the call method of a mask-consuming layer, like this:\n\nmy_layer <- new_layer_class(\n  \"my_layer\",\n  initialize = function(...) {\n    super()$`__init__`(...)\n    self$embedding <- layer_embedding(\n      input_dim = 5000, \n      output_dim = 16, \n      mask_zero = TRUE\n    )\n    self$lstm <- layer_lstm(units = 32)\n  },\n  call = function(inputs) {\n    x <- self$embedding(inputs)\n    # Note that you could also prepare a `mask` tensor manually.\n    # It only needs to be a boolean tensor\n    # with the right shape, i$e. (batch_size, timesteps).\n    mask <- self$embedding$compute_mask(inputs)\n    output <- self$lstm(x, mask = mask)  # The layer will ignore the masked values\n    output\n  }\n)\n\n\nlayer <- my_layer()\nx <- array(as.integer(runif(32*10)*100), dim = c(32, 10))\nlayer(x)\n\ntf.Tensor(\n[[-0.00205488  0.00106485  0.0013517  ... -0.00200369 -0.00046926\n   0.00044221]\n [-0.01361378 -0.0092069  -0.0084025  ...  0.00248097 -0.00110209\n  -0.00467769]\n [-0.00342713  0.00777482 -0.00901797 ... -0.00059411  0.00423267\n   0.000895  ]\n ...\n [ 0.00578892  0.00677103  0.00049386 ... -0.00435947  0.00212847\n   0.00391663]\n [ 0.00251169 -0.00628054 -0.00592228 ... -0.00285684 -0.00215456\n   0.00113647]\n [ 0.00398869 -0.00239744  0.00408143 ... -0.0066454   0.00028073\n  -0.00198999]], shape=(32, 32), dtype=float32)"
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#supporting-masking-in-your-custom-layers",
    "href": "guides/keras/understanding_masking_and_padding.html#supporting-masking-in-your-custom-layers",
    "title": "Understanding masking & padding",
    "section": "Supporting masking in your custom layers",
    "text": "Supporting masking in your custom layers\nSometimes, you may need to write layers that generate a mask (like Embedding), or layers that need to modify the current mask.\nFor instance, any layer that produces a tensor with a different time dimension than its input, such as a Concatenate layer that concatenates on the time dimension, will need to modify the current mask so that downstream layers will be able to properly take masked timesteps into account.\nTo do this, your layer should implement the layer$compute_mask() method, which produces a new mask given the input and the current mask.\nHere is an example of a temporal_split layer that needs to modify the current mask.\n\nlayer_temporal_split <- new_layer_class(\n  \"temporal_split\",\n  call = function(inputs) {\n    # Expect the input to be 3D and mask to be 2D, split the input tensor into 2\n    # subtensors along the time axis (axis 1).\n    tf$split(inputs, 2L, axis = 1L)\n  },\n  compute_mask = function(inputs, mask = NULL) {\n    # Also split the mask into 2 if it presents.\n    if (is.null(mask)) return(NULL)\n    tf$split(mask, 2L, axis = 1L)\n  }\n)\n\nc(first_half, second_half) %<-% layer_temporal_split()(masked_embedding)\nprint(first_half$`_keras_mask`)\n\ntf.Tensor(\n[[ True  True  True]\n [ True  True  True]\n [ True  True  True]], shape=(3, 3), dtype=bool)\n\nprint(second_half$`_keras_mask`)\n\ntf.Tensor(\n[[False False False]\n [ True  True False]\n [ True  True  True]], shape=(3, 3), dtype=bool)\n\n\nHere is another example of a custom_embedding layer that is capable of generating a mask from input values:\n\nlayer_custom_embedding <- new_layer_class(\n  \"custom_embedding\",\n  initialize = function(input_dim, output_dim, mask_zero = FALSE, ...) {\n    super()$ `__init__`(...)\n    self$input_dim <- input_dim\n    self$output_dim <- output_dim\n    self$mask_zero <- mask_zero  \n  },\n  build = function(input_shape) {\n    self$embeddings <- self$add_weight(\n      shape = shape(self$input_dim, self$output_dim),\n      initializer = \"random_normal\",\n      dtype = \"float32\"\n    )\n  },\n  call = function(inputs) {\n    tf$nn$embedding_lookup(self$embeddings, inputs)\n  },\n  compute_mask = function(inputs, mask = NULL) {\n    if (!self$mask_zero) return(NULL)\n    tf$not_equal(inputs, 0L)\n  }\n)\n\nlayer <- layer_custom_embedding(\n  input_dim = 10, \n  output_dim = 32, \n  mask_zero = TRUE\n)\n\nx <- array(as.integer(runif(3*10)*9), dim = c(3, 10))\ny <- layer(x)\nmask <- layer$compute_mask(x)\n\nprint(mask)\n\ntf.Tensor(\n[[ True  True False  True False False  True  True  True  True]\n [ True  True  True False  True False  True  True  True  True]\n [ True  True  True  True  True  True False  True  True  True]], shape=(3, 10), dtype=bool)\n\n\nNote: For more details about format limitations related to masking, see the serialization guide."
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#opting-in-to-mask-propagation-on-compatible-layers",
    "href": "guides/keras/understanding_masking_and_padding.html#opting-in-to-mask-propagation-on-compatible-layers",
    "title": "Understanding masking & padding",
    "section": "Opting-in to mask propagation on compatible layers",
    "text": "Opting-in to mask propagation on compatible layers\nMost layers don’t modify the time dimension, so don’t need to modify the current mask. However, they may still want to be able to propagate the current mask, unchanged, to the next layer. This is an opt-in behavior. By default, a custom layer will destroy the current mask (since the framework has no way to tell whether propagating the mask is safe to do).\nIf you have a custom layer that does not modify the time dimension, and if you want it to be able to propagate the current input mask, you should set self$supports_masking = TRUE in the layer constructor. In this case, the default behavior of compute_mask() is to just pass the current mask through.\nHere’s an example of a layer that is whitelisted for mask propagation:\n\nlayer_my_activation <- new_layer_class(\n  \"my_activation\",\n  initialize = function(...) {\n    super()$`__init__`(...)\n    self$supports_masking <- TRUE\n  },\n  call = function(inputs) {\n    tf$nn$relu(inputs)\n  }\n)\n\nYou can now use this custom layer in-between a mask-generating layer (like Embedding) and a mask-consuming layer (like LSTM), and it will pass the mask along so that it reaches the mask-consuming layer.\n\ninputs <- layer_input(shape = shape(NULL), dtype = \"int32\")\nx <- inputs %>% \n  layer_embedding(input_dim = 5000, output_dim = 16, mask_zero = TRUE) %>% \n  layer_my_activation() # Will pass the mask along\nprint(x$`_keras_mask`)\n\nKerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.bool, name=None), name='Placeholder_1:0')\n\noutputs <- layer_lstm(x, 32)# Will receive the mask\nmodel <- keras_model(inputs, outputs)"
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#writing-layers-that-need-mask-information",
    "href": "guides/keras/understanding_masking_and_padding.html#writing-layers-that-need-mask-information",
    "title": "Understanding masking & padding",
    "section": "Writing layers that need mask information",
    "text": "Writing layers that need mask information\nSome layers are mask consumers: they accept a mask argument in call and use it to determine whether to skip certain time steps.\nTo write such a layer, you can simply add a mask = NULL argument in your call signature. The mask associated with the inputs will be passed to your layer whenever it is available.\nHere’s a simple example below: a layer that computes a softmax over the time dimension (axis 1) of an input sequence, while discarding masked timesteps.\n\nlayer_temporal_softmax <- new_layer_class(\n  \"temporal_softmax\",\n  call = function(inputs, mask = NULL) {\n   broadcast_float_mask <- tf$expand_dims(tf$cast(mask, \"float32\"), -1L)\n   inputs_exp <- tf$exp(inputs) * broadcast_float_mask\n   inputs_sum <- tf$reduce_sum(\n     inputs_exp * broadcast_float_mask, \n     axis = -1L, \n     keepdims = TRUE\n   )\n   inputs_exp / inputs_sum \n  }\n)\n\ninputs <- layer_input(shape = shape(NULL), dtype = \"int32\")\noutputs <- inputs %>% \n  layer_embedding(input_dim = 10, output_dim = 32, mask_zero = TRUE) %>% \n  layer_dense(1) %>% \n  layer_temporal_softmax()\n\nmodel <- keras_model(inputs, outputs)\ny <- model(\n  array(sample.int(9, 32*100, replace = TRUE), dim = c(32, 100)),\n  array(runif(32*100), dim = c(32, 100, 1))\n)"
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#summary",
    "href": "guides/keras/understanding_masking_and_padding.html#summary",
    "title": "Understanding masking & padding",
    "section": "Summary",
    "text": "Summary\nThat is all you need to know about padding & masking in Keras. To recap:\n\n“Masking” is how layers are able to know when to skip / ignore certain timesteps in sequence inputs.\nSome layers are mask-generators: Embedding can generate a mask from input values (if mask_zero = TRUE), and so can the Masking layer.\nSome layers are mask-consumers: they expose a mask argument in their __call__ method. This is the case for RNN layers.\nIn the Functional API and Sequential API, mask information is propagated automatically.\nWhen using layers in a standalone way, you can pass the mask arguments to layers manually.\nYou can easily write layers that modify the current mask, that generate a new mask, or that consume the mask associated with the inputs."
  },
  {
    "objectID": "guides/keras/understanding_masking_and_padding.html#environment-details",
    "href": "guides/keras/understanding_masking_and_padding.html#environment-details",
    "title": "Understanding masking & padding",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/working_with_rnns.html",
    "href": "guides/keras/working_with_rnns.html",
    "title": "Working with RNNs",
    "section": "",
    "text": "Recurrent neural networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language.\nSchematically, a RNN layer uses a for loop to iterate over the timesteps of a sequence, while maintaining an internal state that encodes information about the timesteps it has seen so far.\nThe Keras RNN API is designed with a focus on:\n\nEase of use: the built-in layer_rnn(), layer_lstm(), layer_gru() layers enable you to quickly build recurrent models without having to make difficult configuration choices.\nEase of customization: You can also define your own RNN cell layer (the inner part of the for loop) with custom behavior, and use it with the generic layer_rnn layer (the for loop itself). This allows you to quickly prototype different research ideas in a flexible way with minimal code."
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#setup",
    "href": "guides/keras/working_with_rnns.html#setup",
    "title": "Working with RNNs",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#built-in-rnn-layers-a-simple-example",
    "href": "guides/keras/working_with_rnns.html#built-in-rnn-layers-a-simple-example",
    "title": "Working with RNNs",
    "section": "Built-in RNN layers: a simple example",
    "text": "Built-in RNN layers: a simple example\nThere are three built-in RNN layers in Keras:\n\nlayer_simple_rnn(), a fully-connected RNN where the output from the previous timestep is to be fed to the next timestep.\nlayer_gru(), first proposed in Cho et al., 2014.\nlayer_lstm(), first proposed in Hochreiter & Schmidhuber, 1997.\n\nHere is a simple example of a sequential model that processes sequences of integers, embeds each integer into a 64-dimensional vector, then processes the sequence of vectors using a layer_lstm().\n\nmodel <- keras_model_sequential() %>%\n\n  # Add an Embedding layer expecting input vocab of size 1000, and\n  # output embedding dimension of size 64.\n  layer_embedding(input_dim = 1000, output_dim = 64) %>%\n\n  # Add a LSTM layer with 128 internal units.\n  layer_lstm(128) %>%\n\n  # Add a Dense layer with 10 units.\n  layer_dense(10)\n\nLoaded Tensorflow version 2.9.1\n\nmodel\n\nModel: \"sequential\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n embedding (Embedding)            (None, None, 64)              64000       \n lstm (LSTM)                      (None, 128)                   98816       \n dense (Dense)                    (None, 10)                    1290        \n============================================================================\nTotal params: 164,106\nTrainable params: 164,106\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nBuilt-in RNNs support a number of useful features:\n\nRecurrent dropout, via the dropout and recurrent_dropout arguments\nAbility to process an input sequence in reverse, via the go_backwards argument\nLoop unrolling (which can lead to a large speedup when processing short sequences on CPU), via the unroll argument\n…and more.\n\nFor more information, see the RNN API documentation."
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#outputs-and-states",
    "href": "guides/keras/working_with_rnns.html#outputs-and-states",
    "title": "Working with RNNs",
    "section": "Outputs and states",
    "text": "Outputs and states\nBy default, the output of a RNN layer contains a single vector per sample. This vector is the RNN cell output corresponding to the last timestep, containing information about the entire input sequence. The shape of this output is (batch_size, units) where units corresponds to the units argument passed to the layer’s constructor.\nA RNN layer can also return the entire sequence of outputs for each sample (one vector per timestep per sample), if you set return_sequences = TRUE. The shape of this output is (batch_size, timesteps, units).\n\nmodel <- keras_model_sequential() %>%\n  layer_embedding(input_dim = 1000, output_dim = 64) %>%\n\n  # The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n  layer_gru(256, return_sequences = TRUE) %>%\n\n  # The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n  layer_simple_rnn(128) %>%\n\n  layer_dense(10)\n\nmodel\n\nModel: \"sequential_1\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n embedding_1 (Embedding)          (None, None, 64)              64000       \n gru (GRU)                        (None, None, 256)             247296      \n simple_rnn (SimpleRNN)           (None, 128)                   49280       \n dense_1 (Dense)                  (None, 10)                    1290        \n============================================================================\nTotal params: 361,866\nTrainable params: 361,866\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nIn addition, a RNN layer can return its final internal state(s). The returned states can be used to resume the RNN execution later, or to initialize another RNN. This setting is commonly used in the encoder-decoder sequence-to-sequence model, where the encoder final state is used as the initial state of the decoder.\nTo configure a RNN layer to return its internal state, set return_state = TRUE when creating the layer. Note that LSTM has 2 state tensors, but GRU only has one.\nTo configure the initial state of the layer, call the layer instance with the additional named argument initial_state. Note that the shape of the state needs to match the unit size of the layer, like in the example below.\n\nencoder_vocab <- 1000\ndecoder_vocab <- 2000\n\nencoder_input <- layer_input(shape(NULL))\nencoder_embedded <- encoder_input %>%\n  layer_embedding(input_dim=encoder_vocab, output_dim=64)\n\n\n# Return states in addition to output\nc(output, state_h, state_c) %<-%\n  layer_lstm(encoder_embedded, units = 64, return_state=TRUE, name=\"encoder\")\n\nencoder_state <- list(state_h, state_c)\n\ndecoder_input <- layer_input(shape(NULL))\ndecoder_embedded <- decoder_input %>%\n  layer_embedding(input_dim = decoder_vocab, output_dim = 64)\n\n# Pass the 2 states to a new LSTM layer, as initial state\ndecoder_lstm_layer <- layer_lstm(units = 64, name = \"decoder\")\ndecoder_output <- decoder_lstm_layer(decoder_embedded, initial_state = encoder_state)\n\noutput <- decoder_output %>% layer_dense(10)\n\nmodel <- keras_model(inputs = list(encoder_input, decoder_input),\n                     outputs = output)\nmodel\n\nModel: \"model\"\n____________________________________________________________________________\n Layer (type)            Output Shape    Param #  Connected to              \n============================================================================\n input_1 (InputLayer)    [(None, None)]  0        []                        \n input_2 (InputLayer)    [(None, None)]  0        []                        \n embedding_2 (Embedding)  (None, None, 6  64000   ['input_1[0][0]']         \n                         4)                                                 \n embedding_3 (Embedding)  (None, None, 6  128000  ['input_2[0][0]']         \n                         4)                                                 \n encoder (LSTM)          [(None, 64),    33024    ['embedding_2[0][0]']     \n                          (None, 64),                                       \n                          (None, 64)]                                       \n decoder (LSTM)          (None, 64)      33024    ['embedding_3[0][0]',     \n                                                   'encoder[0][1]',         \n                                                   'encoder[0][2]']         \n dense_2 (Dense)         (None, 10)      650      ['decoder[0][0]']         \n============================================================================\nTotal params: 258,698\nTrainable params: 258,698\nNon-trainable params: 0\n____________________________________________________________________________"
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#rnn-layers-and-rnn-cells",
    "href": "guides/keras/working_with_rnns.html#rnn-layers-and-rnn-cells",
    "title": "Working with RNNs",
    "section": "RNN layers and RNN cells",
    "text": "RNN layers and RNN cells\nIn addition to the built-in RNN layers, the RNN API also provides cell-level APIs. Unlike RNN layers, which process whole batches of input sequences, the RNN cell only processes a single timestep.\nThe cell is the inside of the for loop of a RNN layer. Wrapping a cell inside a layer_rnn() layer gives you a layer capable of processing a sequence, e.g. layer_rnn(layer_lstm_cell(10)).\nMathematically, layer_rnn(layer_lstm_cell(10)) produces the same result as layer_lstm(10). In fact, the implementation of this layer in TF v1.x was just creating the corresponding RNN cell and wrapping it in a RNN layer. However using the built-in layer_gru() and layer_lstm() layers enable the use of CuDNN and you may see better performance.\nThere are three built-in RNN cells, each of them corresponding to the matching RNN layer.\n\nlayer_simple_rnn_cell() corresponds to the layer_simple_rnn() layer.\nlayer_gru_cell corresponds to the layer_gru layer.\nlayer_lstm_cell corresponds to the layer_lstm layer.\n\nThe cell abstraction, together with the generic layer_rnn() class, makes it very easy to implement custom RNN architectures for your research."
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#cross-batch-statefulness",
    "href": "guides/keras/working_with_rnns.html#cross-batch-statefulness",
    "title": "Working with RNNs",
    "section": "Cross-batch statefulness",
    "text": "Cross-batch statefulness\nWhen processing very long (possibly infinite) sequences, you may want to use the pattern of cross-batch statefulness.\nNormally, the internal state of a RNN layer is reset every time it sees a new batch (i.e. every sample seen by the layer is assumed to be independent of the past). The layer will only maintain a state while processing a given sample.\nIf you have very long sequences though, it is useful to break them into shorter sequences, and to feed these shorter sequences sequentially into a RNN layer without resetting the layer’s state. That way, the layer can retain information about the entirety of the sequence, even though it’s only seeing one sub-sequence at a time.\nYou can do this by setting stateful = TRUE in the constructor.\nIf you have a sequence s = c(t0, t1, ... t1546, t1547), you would split it into e.g.\n\ns1 = c(t0, t1, ..., t100)\ns2 = c(t101, ..., t201)\n...\ns16 = c(t1501, ..., t1547)\n\nThen you would process it via:\n\nlstm_layer <- layer_lstm(units = 64, stateful = TRUE)\nfor(s in sub_sequences)\n  output <- lstm_layer(s)\n\nWhen you want to clear the state, you can use layer$reset_states().\n\nNote: In this setup, sample i in a given batch is assumed to be the continuation of sample i in the previous batch. This means that all batches should contain the same number of samples (batch size). E.g. if a batch contains [sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100], the next batch should contain [sequence_A_from_t101_to_t200,  sequence_B_from_t101_to_t200].\n\nHere is a complete example:\n\nparagraph1 <- k_random_uniform(c(20, 10, 50), dtype = \"float32\")\nparagraph2 <- k_random_uniform(c(20, 10, 50), dtype = \"float32\")\nparagraph3 <- k_random_uniform(c(20, 10, 50), dtype = \"float32\")\n\nlstm_layer <- layer_lstm(units = 64, stateful = TRUE)\noutput <- lstm_layer(paragraph1)\noutput <- lstm_layer(paragraph2)\noutput <- lstm_layer(paragraph3)\n\n# reset_states() will reset the cached state to the original initial_state.\n# If no initial_state was provided, zero-states will be used by default.\nlstm_layer$reset_states()\n\n\nRNN State Reuse\nThe recorded states of the RNN layer are not included in the layer$weights(). If you would like to reuse the state from a RNN layer, you can retrieve the states value by layer$states and use it as the initial state of a new layer instance via the Keras functional API like new_layer(inputs, initial_state = layer$states), or model subclassing.\nPlease also note that a sequential model cannot be used in this case since it only supports layers with single input and output. The extra input of initial state makes it impossible to use here.\n\nparagraph1 <- k_random_uniform(c(20, 10, 50), dtype = \"float32\")\nparagraph2 <- k_random_uniform(c(20, 10, 50), dtype = \"float32\")\nparagraph3 <- k_random_uniform(c(20, 10, 50), dtype = \"float32\")\n\nlstm_layer <- layer_lstm(units = 64, stateful = TRUE)\noutput <- lstm_layer(paragraph1)\noutput <- lstm_layer(paragraph2)\n\nexisting_state <- lstm_layer$states\n\nnew_lstm_layer <- layer_lstm(units = 64)\nnew_output <- new_lstm_layer(paragraph3, initial_state = existing_state)"
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#bidirectional-rnns",
    "href": "guides/keras/working_with_rnns.html#bidirectional-rnns",
    "title": "Working with RNNs",
    "section": "Bidirectional RNNs",
    "text": "Bidirectional RNNs\nFor sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards. For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\nKeras provides an easy API for you to build such bidirectional RNNs: the bidirectional() wrapper.\n\nmodel <- keras_model_sequential(input_shape = shape(5, 10)) %>%\n  bidirectional(layer_lstm(units = 64, return_sequences = TRUE)) %>%\n  bidirectional(layer_lstm(units = 32)) %>%\n  layer_dense(10)\n\nmodel\n\nModel: \"sequential_2\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n bidirectional_1 (Bidirectional)  (None, 5, 128)                38400       \n bidirectional (Bidirectional)    (None, 64)                    41216       \n dense_3 (Dense)                  (None, 10)                    650         \n============================================================================\nTotal params: 80,266\nTrainable params: 80,266\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nUnder the hood, bidirectional() will copy the RNN layer passed in, and flip the go_backwards field of the newly copied layer, so that it will process the inputs in reverse order.\nThe output of the bidirectional RNN will be, by default, the concatenation of the forward layer output and the backward layer output. If you need a different merging behavior, e.g. averaging, change the merge_mode parameter in the bidirectional wrapper constructor. For more details about bidirectional, please check the API docs."
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#performance-optimization-and-cudnn-kernels",
    "href": "guides/keras/working_with_rnns.html#performance-optimization-and-cudnn-kernels",
    "title": "Working with RNNs",
    "section": "Performance optimization and CuDNN kernels",
    "text": "Performance optimization and CuDNN kernels\nIn TensorFlow 2.0, the built-in LSTM and GRU layers have been updated to leverage CuDNN kernels by default when a GPU is available. With this change, the prior layer_cudnn_gru/layer_cudnn_lstm layers have been deprecated, and you can build your model without worrying about the hardware it will run on.\nSince the CuDNN kernel is built with certain assumptions, this means the layer will not be able to use the CuDNN kernel if you change the defaults of the built-in LSTM or GRU layers. E.g.:\n\nChanging the activation function from \"tanh\" to something else.\nChanging the recurrent_activation function from \"sigmoid\" to something else.\nUsing recurrent_dropout > 0.\nSetting unroll to TRUE, which forces LSTM/GRU to decompose the inner tf$while_loop into an unrolled for loop.\nSetting use_bias to FALSE.\nUsing masking when the input data is not strictly right padded (if the mask corresponds to strictly right padded data, CuDNN can still be used. This is the most common case).\n\nFor the detailed list of constraints, please see the documentation for the LSTM and GRU layers.\n\nUsing CuDNN kernels when available\nLet’s build a simple LSTM model to demonstrate the performance difference.\nWe’ll use as input sequences the sequence of rows of MNIST digits (treating each row of pixels as a timestep), and we’ll predict the digit’s label.\n\nbatch_size <- 64\n# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n# Each input sequence will be of size (28, 28) (height is treated like time).\ninput_dim <- 28\n\nunits <- 64\noutput_size <- 10  # labels are from 0 to 9\n\n# Build the RNN model\nbuild_model <- function(allow_cudnn_kernel = TRUE) {\n  # CuDNN is only available at the layer level, and not at the cell level.\n  # This means `layer_lstm(units = units)` will use the CuDNN kernel,\n  # while layer_rnn(cell = layer_lstm_cell(units)) will run on non-CuDNN kernel.\n  if (allow_cudnn_kernel)\n    # The LSTM layer with default options uses CuDNN.\n    lstm_layer <- layer_lstm(units = units)\n  else\n    # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n    lstm_layer <- layer_rnn(cell = layer_lstm_cell(units = units))\n\n  model <-\n    keras_model_sequential(input_shape = shape(NULL, input_dim)) %>%\n    lstm_layer() %>%\n    layer_batch_normalization() %>%\n    layer_dense(output_size)\n\n  model\n}\n\nLet’s load the MNIST dataset:\n\nmnist <- dataset_mnist()\nmnist$train$x <- mnist$train$x / 255\nmnist$test$x <- mnist$test$x / 255\nc(sample, sample_label) %<-% with(mnist$train, list(x[1,,], y[1]))\n\nLet’s create a model instance and train it.\nWe choose sparse_categorical_crossentropy() as the loss function for the model. The output of the model has shape of (batch_size, 10). The target for the model is an integer vector, each of the integer is in the range of 0 to 9.\n\nmodel <- build_model(allow_cudnn_kernel = TRUE) %>%\n  compile(\n    loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),\n    optimizer = \"sgd\",\n    metrics = \"accuracy\"\n  )\n\nmodel %>% fit(\n  mnist$train$x,\n  mnist$train$y,\n  validation_data = with(mnist$test, list(x, y)),\n  batch_size = batch_size,\n  epochs = 1\n)\n\nNow, let’s compare to a model that does not use the CuDNN kernel:\n\nnoncudnn_model <- build_model(allow_cudnn_kernel=FALSE)\nnoncudnn_model$set_weights(model$get_weights())\nnoncudnn_model %>% compile(\n    loss=loss_sparse_categorical_crossentropy(from_logits=TRUE),\n    optimizer=\"sgd\",\n    metrics=\"accuracy\",\n)\n\nnoncudnn_model %>% fit(\n  mnist$train$x,\n  mnist$train$y,\n  validation_data = with(mnist$test, list(x, y)),\n  batch_size = batch_size,\n  epochs = 1\n)\n\nWhen running on a machine with a NVIDIA GPU and CuDNN installed, the model built with CuDNN is much faster to train compared to the model that uses the regular TensorFlow kernel.\nThe same CuDNN-enabled model can also be used to run inference in a CPU-only environment. The tf$device() annotation below is just forcing the device placement. The model will run on CPU by default if no GPU is available.\nYou simply don’t have to worry about the hardware you’re running on anymore. Isn’t that pretty cool?\n\nwith(tf$device(\"CPU:0\"), {\n    cpu_model <- build_model(allow_cudnn_kernel=TRUE)\n    cpu_model$set_weights(model$get_weights())\n\n    result <- cpu_model %>%\n      predict_on_batch(k_expand_dims(sample, 1)) %>%\n      k_argmax(axis = 2)\n\n    cat(sprintf(\n        \"Predicted result is: %s, target result is: %s\\n\", as.numeric(result), sample_label))\n\n    # show mnist image\n    sample %>%\n      apply(2, rev) %>% # flip\n      t() %>%           # rotate\n      image(axes = FALSE, asp = 1, col = grey(seq(0, 1, length.out = 256)))\n})\n\nPredicted result is: 3, target result is: 5"
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#rnns-with-listdict-inputs-or-nested-inputs",
    "href": "guides/keras/working_with_rnns.html#rnns-with-listdict-inputs-or-nested-inputs",
    "title": "Working with RNNs",
    "section": "RNNs with list/dict inputs, or nested inputs",
    "text": "RNNs with list/dict inputs, or nested inputs\nNested structures allow implementers to include more information within a single timestep. For example, a video frame could have audio and video input at the same time. The data shape in this case could be:\n[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]\nIn another example, handwriting data could have both coordinates x and y for the current position of the pen, as well as pressure information. So the data representation could be:\n[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]\nThe following code provides an example of how to build a custom RNN cell that accepts such structured inputs.\n\nDefine a custom cell that supports nested input/output\nSee Making new Layers & Models via subclassing for details on writing your own layers.\n\nNestedCell(keras$layers$Layer) %py_class% {\n\n  initialize <- function(unit_1, unit_2, unit_3, ...) {\n    self$unit_1 <- unit_1\n    self$unit_2 <- unit_2\n    self$unit_3 <- unit_3\n    self$state_size <- list(shape(unit_1), shape(unit_2, unit_3))\n    self$output_size <- list(shape(unit_1), shape(unit_2, unit_3))\n    super$initialize(...)\n  }\n\n  build <- function(self, input_shapes) {\n    # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n    # dput(input_shapes) gives: list(list(NULL, 32L), list(NULL, 64L, 32L))\n    i1 <- input_shapes[[c(1, 2)]] # 32\n    i2 <- input_shapes[[c(2, 2)]] # 64\n    i3 <- input_shapes[[c(2, 3)]] # 32\n\n    self$kernel_1 = self$add_weight(\n      shape = shape(i1, self$unit_1),\n      initializer = \"uniform\",\n      name = \"kernel_1\"\n    )\n    self$kernel_2_3 = self$add_weight(\n      shape = shape(i2, i3, self$unit_2, self$unit_3),\n      initializer = \"uniform\",\n      name = \"kernel_2_3\"\n    )\n  }\n\n  call <- function(inputs, states) {\n    # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n    # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n    # Don't forget you can call `browser()` here while the layer is being traced!\n    c(input_1, input_2) %<-% tf$nest$flatten(inputs)\n    c(s1, s2) %<-% states\n\n    output_1 <- tf$matmul(input_1, self$kernel_1)\n    output_2_3 <- tf$einsum(\"bij,ijkl->bkl\", input_2, self$kernel_2_3)\n    state_1 <- s1 + output_1\n    state_2_3 <- s2 + output_2_3\n\n    output <- tuple(output_1, output_2_3)\n    new_states <- tuple(state_1, state_2_3)\n\n    tuple(output, new_states)\n  }\n\n  get_config <- function() {\n    list(\"unit_1\" = self$unit_1,\n         \"unit_2\" = self$unit_2,\n         \"unit_3\" = self$unit_3)\n  }\n}\n\n\n\nBuild a RNN model with nested input/output\nLet’s build a Keras model that uses a layer_rnn layer and the custom cell we just defined.\n\nunit_1 <- 10\nunit_2 <- 20\nunit_3 <- 30\n\ni1 <- 32\ni2 <- 64\ni3 <- 32\nbatch_size <- 64\nnum_batches <- 10\ntimestep <- 50\n\ncell <- NestedCell(unit_1, unit_2, unit_3)\nrnn <- layer_rnn(cell = cell)\n\ninput_1 = layer_input(shape(NULL, i1))\ninput_2 = layer_input(shape(NULL, i2, i3))\n\noutputs = rnn(tuple(input_1, input_2))\n\nmodel = keras_model(list(input_1, input_2), outputs)\n\nmodel %>% compile(optimizer=\"adam\", loss=\"mse\", metrics=\"accuracy\")\n\n\n\nTrain the model with randomly generated data\nSince there isn’t a good candidate dataset for this model, we use random data for demonstration.\n\ninput_1_data <- k_random_uniform(c(batch_size * num_batches, timestep, i1))\ninput_2_data <- k_random_uniform(c(batch_size * num_batches, timestep, i2, i3))\ntarget_1_data <- k_random_uniform(c(batch_size * num_batches, unit_1))\ntarget_2_data <- k_random_uniform(c(batch_size * num_batches, unit_2, unit_3))\ninput_data <- list(input_1_data, input_2_data)\ntarget_data <- list(target_1_data, target_2_data)\n\nmodel %>% fit(input_data, target_data, batch_size=batch_size)\n\nWith keras::layer_rnn(), you are only expected to define the math logic for an individual step within the sequence, and the layer_rnn() will handle the sequence iteration for you. It’s an incredibly powerful way to quickly prototype new kinds of RNNs (e.g. a LSTM variant).\nFor more details, please visit the API docs."
  },
  {
    "objectID": "guides/keras/working_with_rnns.html#environment-details",
    "href": "guides/keras/working_with_rnns.html#environment-details",
    "title": "Working with RNNs",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/keras/writing_a_training_loop_from_scratch.html",
    "href": "guides/keras/writing_a_training_loop_from_scratch.html",
    "title": "Writing a training loop from scratch",
    "section": "",
    "text": "library(tensorflow)\nlibrary(keras)\nlibrary(tfdatasets)"
  },
  {
    "objectID": "guides/keras/writing_a_training_loop_from_scratch.html#introduction",
    "href": "guides/keras/writing_a_training_loop_from_scratch.html#introduction",
    "title": "Writing a training loop from scratch",
    "section": "Introduction",
    "text": "Introduction\nKeras provides default training and evaluation loops, fit() and evaluate(). Their usage is covered in the guide Training & evaluation with the built-in methods.\nIf you want to customize the learning algorithm of your model while still leveraging the convenience of fit() (for instance, to train a GAN using fit()), you can subclass the Model class and implement your own train_step() method, which is called repeatedly during fit(). This is covered in the guide Customizing what happens in fit().\nNow, if you want very low-level control over training & evaluation, you should write your own training & evaluation loops from scratch. This is what this guide is about."
  },
  {
    "objectID": "guides/keras/writing_a_training_loop_from_scratch.html#using-the-gradienttape-a-first-end-to-end-example",
    "href": "guides/keras/writing_a_training_loop_from_scratch.html#using-the-gradienttape-a-first-end-to-end-example",
    "title": "Writing a training loop from scratch",
    "section": "Using the GradientTape: a first end-to-end example",
    "text": "Using the GradientTape: a first end-to-end example\nCalling a model inside a GradientTape scope enables you to retrieve the gradients of the trainable weights of the layer with respect to a loss value. Using an optimizer instance, you can use these gradients to update these variables (which you can retrieve using model$trainable_weights).\nLet’s consider a simple MNIST model:\n\ninputs <- layer_input(shape = shape(784), name = \"digits\")\n\nLoaded Tensorflow version 2.9.1\n\noutputs <- inputs %>% \n  layer_dense(64, activation = \"relu\") %>% \n  layer_dense(64, activation = \"relu\") %>% \n  layer_dense(10, name = \"predictions\")\nmodel <- keras_model(inputs = inputs, outputs = outputs)\n\nLet’s train it using mini-batch gradient with a custom training loop. First, we’re going to need an optimizer, a loss function, and a dataset:\n\n# Instantiate an optimizer.\noptimizer <- optimizer_sgd(learning_rate = 1e-3)\n\n# Instantiate a loss function.\nloss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)\n\n# Prepare the training dataset.\nbatch_size <- 64\nc(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()\nx_train <- x_train %>% array_reshape(dim = c(60000, 784))/255\nx_test <- x_test %>% array_reshape(dim = c(10000, 784))/255\n\n# Reserve 10,000 samples for validation.\nx_val <- x_train[-(1:50000),]\ny_val <- y_train[-(1:50000)]\nx_train <- x_train[(1:50000),]\ny_train <- y_train[(1:50000)]\n\n# Prepare the training dataset.\ntrain_dataset <- list(x_train, y_train) %>% \n  tensor_slices_dataset() %>% \n  dataset_shuffle(buffer_size = 1024) %>% \n  dataset_batch(batch_size)\n\n# Prepare the validation dataset.\nval_dataset <- list(x_val, y_val) %>% \n  tensor_slices_dataset() %>% \n  dataset_batch(batch_size)\n\nHere’s our training loop:\n\nWe open a for loop that iterates over epochs\nFor each epoch, we open a for loop that iterates over the dataset, in batches\nFor each batch, we open a GradientTape() scope\nInside this scope, we call the model (forward pass) and compute the loss\nOutside the scope, we retrieve the gradients of the weights of the model with regard to the loss\nFinally, we use the optimizer to update the weights of the model based on the gradients\n\n\n\n\n\n\n\nNote\n\n\n\nIn the example train_dataset is a TensorFlow Dataset, thus it can’t be iterated in normal R for loops. That’s why we wrap the second loop into a autograph call. autograph will compile the expression into efficient TensorFlow code to quickly evaluate the loop.\n\n\n\nepochs <- 2\nfor(epoch in seq_len(epochs)) {\n  cat(\"Start of epoch \", epoch, \"\\n\")\n  # Iterate over the batches of the dataset.\n  tfautograph::autograph(for (batch in train_dataset) {\n    # Open a GradientTape to record the operations run\n    # during the forward pass, which enables auto-differentiation.\n    with(tf$GradientTape() %as% tape, {\n      # Run the forward pass of the layer.\n      # The operations that the layer applies\n      # to its inputs are going to be recorded\n      # on the GradientTape.\n      logits <- model(batch[[1]], training = TRUE)  # Logits for this minibatch\n      \n      # Compute the loss value for this minibatch.\n      loss_value <- loss_fn(batch[[2]], logits)\n    })\n    \n    # Use the gradient tape to automatically retrieve\n    # the gradients of the trainable variables with respect to the loss.\n    grads <- tape$gradient(loss_value, model$trainable_weights)\n    \n    # Run one step of gradient descent by updating\n    # the value of the variables to minimize the loss.\n    optimizer$apply_gradients(zip_lists(grads, model$trainable_weights))\n    \n  })\n}\n\nStart of epoch  1 \nStart of epoch  2"
  },
  {
    "objectID": "guides/keras/writing_a_training_loop_from_scratch.html#low-level-handling-of-metrics",
    "href": "guides/keras/writing_a_training_loop_from_scratch.html#low-level-handling-of-metrics",
    "title": "Writing a training loop from scratch",
    "section": "Low-level handling of metrics",
    "text": "Low-level handling of metrics\nLet’s add metrics monitoring to this basic loop.\nYou can readily reuse the built-in metrics (or custom ones you wrote) in such training loops written from scratch. Here’s the flow:\n\nInstantiate the metric at the start of the loop\nCall metric$update_state() after each batch\nCall metric$result() when you need to display the current value of the metric\nCall metric$reset_states() when you need to clear the state of the metric (typically at the end of an epoch)\n\nLet’s use this knowledge to compute sparse_categorical_accuracy on validation data at the end of each epoch:\n\n# Get model\ninputs <- layer_input(shape = shape(784), name = \"digits\")\noutputs <- inputs %>% \n  layer_dense(64, activation = \"relu\") %>% \n  layer_dense(64, activation = \"relu\") %>% \n  layer_dense(10, name = \"predictions\")\nmodel <- keras_model(inputs = inputs, outputs = outputs)\n\n# Instantiate an optimizer.\noptimizer <- optimizer_sgd(learning_rate = 1e-3)\n\n# Instantiate a loss function.\nloss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)\n\n# Prepare the metrics.\ntrain_acc_metric <- metric_sparse_categorical_accuracy()\nval_acc_metric <- metric_sparse_categorical_accuracy()\n\nHere’s our training & evaluation loop:\n\nepochs <- 2\nfor(epoch in seq_len(epochs)) {\n  cat(\"Start of epoch \", epoch, \"\\n\")\n  tfautograph::autograph(for (batch in train_dataset) {\n    with(tf$GradientTape() %as% tape, {\n      logits <- model(batch[[1]], training = TRUE)\n      loss_value <- loss_fn(batch[[2]], logits)\n    })\n    grads <- tape$gradient(loss_value, model$trainable_weights)\n    optimizer$apply_gradients(zip_lists(grads, model$trainable_weights))\n\n    # Update training metric.\n    train_acc_metric$update_state(batch[[2]], logits)\n  })\n  \n  train_acc <- as.numeric(train_acc_metric$result())\n  cat(\"Training acc over epoch: \", train_acc, \"\\n\")\n  train_acc_metric$reset_states()\n\n  # Run a validation loop at the end of each epoch.\n  tfautograph::autograph(for(batch in val_dataset) {\n    val_logits <- model(batch[[1]], training = FALSE)\n    # Update val metrics\n    val_acc_metric$update_state(batch[[2]], val_logits)\n  })\n  \n  val_acc <- as.numeric(val_acc_metric$result())\n  cat(\"Validation acc over epoch: \", val_acc, \"\\n\")\n  val_acc_metric$reset_states()\n}\n\nStart of epoch  1 \nTraining acc over epoch:  0.27868 \nValidation acc over epoch:  0.4074 \nStart of epoch  2 \nTraining acc over epoch:  0.52598 \nValidation acc over epoch:  0.6312 \n\n\nIt’s common to extract out the expressin inside the second loop into a new function called train_step. For example:\n\ntrain_step <- function(batch) {\n  with(tf$GradientTape() %as% tape, {\n      logits <- model(batch[[1]], training = TRUE)\n      loss_value <- loss_fn(batch[[2]], logits)\n  })\n  grads <- tape$gradient(loss_value, model$trainable_weights)\n  optimizer$apply_gradients(zip_lists(grads, model$trainable_weights))\n  \n  # Update training metric.\n  train_acc_metric$update_state(batch[[2]], logits)\n}"
  },
  {
    "objectID": "guides/keras/writing_a_training_loop_from_scratch.html#low-level-handling-of-losses-tracked-by-the-model",
    "href": "guides/keras/writing_a_training_loop_from_scratch.html#low-level-handling-of-losses-tracked-by-the-model",
    "title": "Writing a training loop from scratch",
    "section": "Low-level handling of losses tracked by the model",
    "text": "Low-level handling of losses tracked by the model\nLayers & models recursively track any losses created during the forward pass by layers that call self$add_loss(value). The resulting list of scalar loss values are available via the property model$losses at the end of the forward pass.\nIf you want to be using these loss components, you should sum them and add them to the main loss in your training step.\nConsider this layer, that creates an activity regularization loss:\n\nlayer_activity_regularization <- new_layer_class(\n  \"activity_regularization\",\n  call = function(inputs) {\n    self$add_loss(1e-2 * tf$reduce_sum(inputs))\n    inputs\n  }\n)\n\nLet’s build a really simple model that uses it:\n\ninputs <- layer_input(shape = shape(784), name = \"digits\")\noutputs <- inputs %>% \n  layer_dense(64, activation = \"relu\") %>% \n  # Insert activity regularization as a layer\n  layer_activity_regularization() %>% \n  layer_dense(64, activation = \"relu\") %>% \n  layer_dense(10, name = \"predictions\")\nmodel <- keras_model(inputs = inputs, outputs = outputs)\n\nHere’s what our training step should look like now:\n\ntrain_step <- function(batch) {\n  with(tf$GradientTape() %as% tape, {    \n    logits <- model(batch[[1]], training = TRUE)\n    loss_value <- loss_fn(batch[[2]], logits)\n    # Add any extra losses created during the forward pass.\n    loss_value <- loss_value + do.call(sum, model$losses)\n  })\n  grads <- tape$gradient(loss_value, model$trainable_weights)\n  optimizer$apply_gradients(zip_lists(grads, model$trainable_weights))\n  train_acc_metric$update_state(batch[[2]], logits)\n  loss_value\n}"
  },
  {
    "objectID": "guides/keras/writing_a_training_loop_from_scratch.html#summary",
    "href": "guides/keras/writing_a_training_loop_from_scratch.html#summary",
    "title": "Writing a training loop from scratch",
    "section": "Summary",
    "text": "Summary\nNow you know everything there is to know about using built-in training loops and writing your own from scratch.\nTo conclude, here’s a simple end-to-end example that ties together everything you’ve learned in this guide: a DCGAN trained on MNIST digits."
  },
  {
    "objectID": "guides/keras/writing_a_training_loop_from_scratch.html#end-to-end-example-a-gan-training-loop-from-scratch",
    "href": "guides/keras/writing_a_training_loop_from_scratch.html#end-to-end-example-a-gan-training-loop-from-scratch",
    "title": "Writing a training loop from scratch",
    "section": "End-to-end example: a GAN training loop from scratch",
    "text": "End-to-end example: a GAN training loop from scratch\nYou may be familiar with Generative Adversarial Networks (GANs). GANs can generate new images that look almost real, by learning the latent distribution of a training dataset of images (the “latent space” of the images).\nA GAN is made of two parts: a “generator” model that maps points in the latent space to points in image space, a “discriminator” model, a classifier that can tell the difference between real images (from the training dataset) and fake images (the output of the generator network).\nA GAN training loop looks like this:\n\nTrain the discriminator.\n\n\nSample a batch of random points in the latent space.\nTurn the points into fake images via the “generator” model.\nGet a batch of real images and combine them with the generated images.\nTrain the “discriminator” model to classify generated vs. real images.\n\n\nTrain the generator.\n\n\nSample random points in the latent space.\nTurn the points into fake images via the “generator” network.\nGet a batch of real images and combine them with the generated images.\nTrain the “generator” model to “fool” the discriminator and classify the fake images as real.\n\nFor a much more detailed overview of how GANs works, see Deep Learning with Python.\nLet’s implement this training loop. First, create the discriminator meant to classify fake vs real digits:\n\ndiscriminator <- keras_model_sequential(\n  name = \"discriminator\", \n  input_shape = shape(28, 28, 1)\n) %>% \n  layer_conv_2d(64, c(3, 3), strides = c(2, 2), padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d(128, c(3, 3), strides = c(2, 2), padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_global_max_pooling_2d() %>% \n  layer_dense(1)\nsummary(discriminator)\n\nModel: \"discriminator\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n conv2d_1 (Conv2D)                (None, 14, 14, 64)            640         \n leaky_re_lu_1 (LeakyReLU)        (None, 14, 14, 64)            0           \n conv2d (Conv2D)                  (None, 7, 7, 128)             73856       \n leaky_re_lu (LeakyReLU)          (None, 7, 7, 128)             0           \n global_max_pooling2d (GlobalMaxP  (None, 128)                  0           \n ooling2D)                                                                  \n dense_6 (Dense)                  (None, 1)                     129         \n============================================================================\nTotal params: 74,625\nTrainable params: 74,625\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nThen let’s create a generator network, that turns latent vectors into outputs of shape (28, 28, 1) (representing MNIST digits):\n\nlatent_dim <- 128\ngenerator <- keras_model_sequential(\n  input_shape = shape(latent_dim), \n  name = \"generator\"\n) %>% \n  # We want to generate 128 coefficients to reshape into a 7x7x128 map\n  layer_dense(7 * 7 * 128) %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_reshape(c(7, 7, 128)) %>% \n  layer_conv_2d_transpose(128, c(4, 4), strides = c(2, 2), padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d_transpose(128, c(4, 4), strides = c(2, 2), padding = \"same\") %>% \n  layer_activation_leaky_relu(alpha = 0.2) %>% \n  layer_conv_2d(1, c(7, 7), padding = \"same\", activation = \"sigmoid\")\n\nHere’s the key bit: the training loop. As you can see it is quite straightforward. The training step function only takes 17 lines.\n\n# Instantiate one optimizer for the discriminator and another for the generator.\nd_optimizer <- optimizer_adam(learning_rate = 0.0003)\ng_optimizer <- optimizer_adam(learning_rate = 0.0004)\n\n# Instantiate a loss function.\nloss_fn <- loss_binary_crossentropy(from_logits = TRUE)\n\ntrain_step <- function(real_images) {\n  # Sample random points in the latent space\n  random_latent_vectors <- tf$random$normal(shape = shape(batch_size, latent_dim))\n  # Decode them to fake images\n  generated_images <- generator(random_latent_vectors)\n  # Combine them with real images\n  combined_images <- tf$concat(list(generated_images, real_images), axis = 0L)\n  \n  # Assemble labels discriminating real from fake images\\\n  labels <- tf$concat(list(\n    tf$ones(shape(batch_size, 1)), \n    tf$zeros(shape(real_images$shape[[1]], 1))), \n    axis = 0L\n  )\n  # Add random noise to the labels - important trick!\n  labels <- labels + 0.05 * tf$random$uniform(labels$shape)\n  \n  # Train the discriminator\n  with(tf$GradientTape() %as% tape, {    \n    predictions <- discriminator(combined_images)\n    d_loss <- loss_fn(labels, predictions)  \n  })\n  \n  grads <- tape$gradient(d_loss, discriminator$trainable_weights)\n  d_optimizer$apply_gradients(zip_lists(grads, discriminator$trainable_weights))\n  \n  # Sample random points in the latent space\n  random_latent_vectors <- tf$random$normal(shape = shape(batch_size, latent_dim))\n  # Assemble labels that say \"all real images\"\n  misleading_labels <- tf$zeros(shape(batch_size, 1))\n  \n  # Train the generator (note that we should *not* update the weights\n  # of the discriminator)!\n  with(tf$GradientTape() %as% tape, {    \n    predictions <- discriminator(generator(random_latent_vectors))\n    g_loss <- loss_fn(misleading_labels, predictions)\n  })\n  \n  grads <- tape$gradient(g_loss, generator$trainable_weights)\n  g_optimizer$apply_gradients(zip_lists(grads, generator$trainable_weights))\n  list(d_loss, g_loss, generated_images)\n}\n\nLet’s train our GAN, by repeatedly calling train_step on batches of images. Since our discriminator and generator are convnets, you’re going to want to run this code on a GPU.\n\n# Prepare the dataset. We use both the training & test MNIST digits.\nbatch_size <- 64\nc(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()\nx_train[] <- x_train/255\nx_test[] <- x_test/255\n\ndataset <- tensor_slices_dataset(x_train) %>% \n  dataset_concatenate(tensor_slices_dataset(x_test)) %>% \n  dataset_map(function(x) {\n    tf$cast(tf$expand_dims(x, -1L), tf$float32)\n  }) %>% \n  dataset_shuffle(1024) %>% \n  dataset_batch(batch_size)\n\nepochs <- 1  # In practice you need at least 20 epochs to generate nice digits.\nsave_dir <- \"./\"\nfor (epoch in seq_len(epochs)) {\n  cat(\"\\nStart epoch \", epoch, \"\\n\")\n  tfautograph::autograph(for (real_images in dataset) {\n    c(d_loss, g_loss, generated_images) %<-% train_step(real_images)\n  })\n}\n\n\nStart epoch  1 \n\ngenerated_images[1,,,] %>% \n  image_array_save(path = \"generated_img.png\")\n\n\nThat’s it! You’ll get nice-looking fake MNIST digits after just ~30s of training on the Colab GPU."
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html",
    "href": "guides/keras/writing_your_own_callbacks.html",
    "title": "Writing your own callbacks",
    "section": "",
    "text": "A callback is a powerful tool to customize the behavior of a Keras model during training, evaluation, or inference. Examples include callback_tensorboard() to visualize training progress and results with TensorBoard, or callback_model_checkpoint() to periodically save your model during training.\nIn this guide, you will learn what a Keras callback is, what it can do, and how you can build your own. We provide a few demos of simple callback applications to get you started."
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html#setup",
    "href": "guides/keras/writing_your_own_callbacks.html#setup",
    "title": "Writing your own callbacks",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)\nlibrary(keras)\nenvir::import_from(magrittr, `%<>%`)\nenvir::import_from(dplyr, last)\n\ntf_version()"
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html#keras-callbacks-overview",
    "href": "guides/keras/writing_your_own_callbacks.html#keras-callbacks-overview",
    "title": "Writing your own callbacks",
    "section": "Keras callbacks overview",
    "text": "Keras callbacks overview\nAll callbacks subclass the keras$callbacks$Callback class, and override a set of methods called at various stages of training, testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training.\nYou can pass a list of callbacks (as a named argument callbacks) to the following keras model methods:\n\nfit()\nevaluate()\npredict()"
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html#an-overview-of-callback-methods",
    "href": "guides/keras/writing_your_own_callbacks.html#an-overview-of-callback-methods",
    "title": "Writing your own callbacks",
    "section": "An overview of callback methods",
    "text": "An overview of callback methods\n\nGlobal methods\n\non_(train|test|predict)_begin(self, logs=None)\nCalled at the beginning of fit/evaluate/predict.\n\n\non_(train|test|predict)_end(self, logs=None)\nCalled at the end of fit/evaluate/predict.\n\n\n\nBatch-level methods for training/testing/predicting\n\non_(train|test|predict)_batch_begin(self, batch, logs=None)\nCalled right before processing a batch during training/testing/predicting.\n\n\non_(train|test|predict)_batch_end(self, batch, logs=None)\nCalled at the end of training/testing/predicting a batch. Within this method, logs is a dict containing the metrics results.\n\n\n\nEpoch-level methods (training only)\n\non_epoch_begin(self, epoch, logs=None)\nCalled at the beginning of an epoch during training.\n\n\non_epoch_end(self, epoch, logs=None)\nCalled at the end of an epoch during training."
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html#a-basic-example",
    "href": "guides/keras/writing_your_own_callbacks.html#a-basic-example",
    "title": "Writing your own callbacks",
    "section": "A basic example",
    "text": "A basic example\nLet’s take a look at a concrete example. To get started, let’s import tensorflow and define a simple Sequential Keras model:\n\nget_model <- function() {\n  model <- keras_model_sequential() %>%\n    layer_dense(1, input_shape = 784) %>%\n    compile(\n      optimizer = optimizer_rmsprop(learning_rate=0.1),\n      loss = \"mean_squared_error\",\n      metrics = \"mean_absolute_error\"\n    )\n  model\n}\n\nThen, load the MNIST data for training and testing from Keras datasets API:\n\nmnist <- dataset_mnist()\n\nflatten_and_rescale <- function(x) {\n  x <- array_reshape(x, c(-1, 784))\n  x <- x / 255\n  x\n}\n\nmnist$train$x <- flatten_and_rescale(mnist$train$x)\nmnist$test$x  <- flatten_and_rescale(mnist$test$x)\n\n# limit to 500 samples\nmnist$train$x <- mnist$train$x[1:500,]\nmnist$train$y <- mnist$train$y[1:500]\nmnist$test$x  <- mnist$test$x[1:500,]\nmnist$test$y  <- mnist$test$y[1:500]\n\nNow, define a simple custom callback that logs:\n\nWhen fit/evaluate/predict starts & ends\nWhen each epoch starts & ends\nWhen each training batch starts & ends\nWhen each evaluation (test) batch starts & ends\nWhen each inference (prediction) batch starts & ends\n\n\nshow <- function(msg, logs) {\n  cat(glue::glue(msg, .envir = parent.frame()),\n      \"got logs: \", sep = \"; \")\n  str(logs); cat(\"\\n\")\n}\n\nCustomCallback(keras$callbacks$Callback) %py_class% {\n  on_train_begin <- function(logs = NULL)\n    show(\"Starting training\", logs)\n\n  on_train_end <- function(logs = NULL)\n    show(\"Stop training\", logs)\n\n  on_epoch_begin <- function(epoch, logs = NULL)\n    show(\"Start epoch {epoch} of training\", logs)\n\n  on_epoch_end <- function(epoch, logs = NULL)\n    show(\"End epoch {epoch} of training\", logs)\n\n  on_test_begin <- function(logs = NULL)\n    show(\"Start testing\", logs)\n\n  on_test_end <- function(logs = NULL)\n    show(\"Stop testing\", logs)\n\n  on_predict_begin <- function(logs = NULL)\n    show(\"Start predicting\", logs)\n\n  on_predict_end <- function(logs = NULL)\n    show(\"Stop predicting\", logs)\n\n  on_train_batch_begin <- function(batch, logs = NULL)\n    show(\"...Training: start of batch {batch}\", logs)\n\n  on_train_batch_end <- function(batch, logs = NULL)\n    show(\"...Training: end of batch {batch}\",  logs)\n\n  on_test_batch_begin <- function(batch, logs = NULL)\n    show(\"...Evaluating: start of batch {batch}\", logs)\n\n  on_test_batch_end <- function(batch, logs = NULL)\n    show(\"...Evaluating: end of batch {batch}\", logs)\n\n  on_predict_batch_begin <- function(batch, logs = NULL)\n    show(\"...Predicting: start of batch {batch}\", logs)\n\n  on_predict_batch_end <- function(batch, logs = NULL)\n    show(\"...Predicting: end of batch {batch}\", logs)\n}\n\nLet’s try it out:\n\nmodel <- get_model()\nmodel %>% fit(\n  mnist$train$x,\n  mnist$train$y,\n  batch_size = 128,\n  epochs = 2,\n  verbose = 0,\n  validation_split = 0.5,\n  callbacks = list(CustomCallback())\n)\n\n\nres <- model %>%\n  evaluate(\n    mnist$test$x,\n    mnist$test$y,\n    batch_size = 128,\n    verbose = 0,\n    callbacks = list(CustomCallback())\n  )\n\n\nres <- model %>%\n  predict(mnist$test$x,\n          batch_size = 128,\n          callbacks = list(CustomCallback()))\n\n\nUsage of logs dict\nThe logs dict contains the loss value, and all the metrics at the end of a batch or epoch. Example includes the loss and mean absolute error.\n\nLossAndErrorPrintingCallback(keras$callbacks$Callback) %py_class% {\n  on_train_batch_end <- function(batch, logs = NULL)\n    cat(sprintf(\"Up to batch %i, the average loss is %7.2f.\\n\",\n                batch,  logs$loss))\n\n  on_test_batch_end <- function(batch, logs = NULL)\n    cat(sprintf(\"Up to batch %i, the average loss is %7.2f.\\n\",\n                batch, logs$loss))\n\n  on_epoch_end <- function(epoch, logs = NULL)\n    cat(sprintf(\n      \"The average loss for epoch %2i is %9.2f and mean absolute error is %7.2f.\\n\",\n      epoch, logs$loss, logs$mean_absolute_error\n    ))\n}\n\nmodel <- get_model()\nmodel %>% fit(\n  mnist$train$x,\n  mnist$train$y,\n  batch_size = 128,\n  epochs = 2,\n  verbose = 0,\n  callbacks = list(LossAndErrorPrintingCallback())\n)\n\nres = model %>% evaluate(\n  mnist$test$x,\n  mnist$test$y,\n  batch_size = 128,\n  verbose = 0,\n  callbacks = list(LossAndErrorPrintingCallback())\n)"
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html#usage-of-selfmodel-attribute",
    "href": "guides/keras/writing_your_own_callbacks.html#usage-of-selfmodel-attribute",
    "title": "Writing your own callbacks",
    "section": "Usage of self$model attribute",
    "text": "Usage of self$model attribute\nIn addition to receiving log information when one of their methods is called, callbacks have access to the model associated with the current round of training/evaluation/inference: self$model.\nHere are of few of the things you can do with self$model in a callback:\n\nSet self$model$stop_training <- TRUE to immediately interrupt training.\nMutate hyperparameters of the optimizer (available as self$model$optimizer), such as self$model$optimizer$learning_rate.\nSave the model at period intervals.\nRecord the output of predict(model) on a few test samples at the end of each epoch, to use as a sanity check during training.\nExtract visualizations of intermediate features at the end of each epoch, to monitor what the model is learning over time.\netc.\n\nLet’s see this in action in a couple of examples."
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html#examples-of-keras-callback-applications",
    "href": "guides/keras/writing_your_own_callbacks.html#examples-of-keras-callback-applications",
    "title": "Writing your own callbacks",
    "section": "Examples of Keras callback applications",
    "text": "Examples of Keras callback applications\n\nEarly stopping at minimum loss\nThis first example shows the creation of a Callback that stops training when the minimum of loss has been reached, by setting the attribute self$model$stop_training (boolean). Optionally, you can provide an argument patience to specify how many epochs we should wait before stopping after having reached a local minimum.\nkeras$callbacks$EarlyStopping provides a more complete and general implementation.\n\nEarlyStoppingAtMinLoss(keras$callbacks$Callback) %py_class% {\n  \"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n\n  Arguments:\n      patience: Number of epochs to wait after min has been hit. After this\n        number of no improvement, training stops.\n  \"\n\n  initialize <- function(patience = 0) {\n    # call keras$callbacks$Callback$__init__(), so it can setup `self`\n    super$initialize()\n    self$patience <- patience\n    # best_weights to store the weights at which the minimum loss occurs.\n    self$best_weights <- NULL\n  }\n\n  on_train_begin <- function(logs = NULL) {\n    # The number of epoch it has waited when loss is no longer minimum.\n    self$wait <- 0\n    # The epoch the training stops at.\n    self$stopped_epoch <- 0\n    # Initialize the best as infinity.\n    self$best <- Inf\n  }\n\n  on_epoch_end <- function(epoch, logs = NULL) {\n    current <- logs$loss\n    if (current < self$best) {\n      self$best <- current\n      self$wait <- 0\n      # Record the best weights if current results is better (less).\n      self$best_weights <- self$model$get_weights()\n    } else {\n      self$wait %<>% `+`(1)\n      if (self$wait >= self$patience) {\n        self$stopped_epoch <- epoch\n        self$model$stop_training <- TRUE\n        cat(\"Restoring model weights from the end of the best epoch.\\n\")\n        self$model$set_weights(self$best_weights)\n      }\n    }\n  }\n\n  on_train_end <- function(logs = NULL)\n    if (self$stopped_epoch > 0)\n      cat(sprintf(\"Epoch %05d: early stopping\\n\", self$stopped_epoch + 1))\n\n}\n\n\nmodel <- get_model()\nmodel %>% fit(\n  mnist$train$x,\n  mnist$train$y,\n  batch_size = 64,\n  steps_per_epoch = 5,\n  epochs = 30,\n  verbose = 0,\n  callbacks = list(LossAndErrorPrintingCallback(),\n                   EarlyStoppingAtMinLoss())\n)\n\n\n\nLearning rate scheduling\nIn this example, we show how a custom Callback can be used to dynamically change the learning rate of the optimizer during the course of training.\nSee keras$callbacks$LearningRateScheduler for a more general implementations (in RStudio, press F1 while the cursor is over LearningRateScheduler and a browser will open to this page).\n\nCustomLearningRateScheduler(keras$callbacks$Callback) %py_class% {\n  \"Learning rate scheduler which sets the learning rate according to schedule.\n\n  Arguments:\n      schedule: a function that takes an epoch index\n          (integer, indexed from 0) and current learning rate\n          as inputs and returns a new learning rate as output (float).\n  \"\n\n  `__init__` <- function(schedule) {\n    super()$`__init__`()\n    self$schedule <- schedule\n  }\n\n  on_epoch_begin <- function(epoch, logs = NULL) {\n    ## When in doubt about what types of objects are in scope (e.g., self$model)\n    ## use a debugger to interact with the actual objects at the console!\n    # browser()\n\n    if (!\"learning_rate\" %in% names(self$model$optimizer))\n      stop('Optimizer must have a \"learning_rate\" attribute.')\n\n    # # Get the current learning rate from model's optimizer.\n    # use as.numeric() to convert the tf.Variable to an R numeric\n    lr <- as.numeric(self$model$optimizer$learning_rate)\n    # # Call schedule function to get the scheduled learning rate.\n    scheduled_lr <- self$schedule(epoch, lr)\n    # # Set the value back to the optimizer before this epoch starts\n    self$model$optimizer$learning_rate <- scheduled_lr\n    cat(sprintf(\"\\nEpoch %05d: Learning rate is %6.4f.\\n\", epoch, scheduled_lr))\n  }\n}\n\n\nLR_SCHEDULE <- tibble::tribble(~ start_epoch, ~ learning_rate,\n                               0, .1,\n                               3, 0.05,\n                               6, 0.01,\n                               9, 0.005,\n                               12, 0.001)\n\n\nlr_schedule <- function(epoch, learning_rate) {\n  \"Helper function to retrieve the scheduled learning rate based on epoch.\"\n  if (epoch <= last(LR_SCHEDULE$start_epoch))\n    with(LR_SCHEDULE, learning_rate[which.min(epoch > start_epoch)])\n  else\n    learning_rate\n}\n\n\nmodel <- get_model()\nmodel %>% fit(\n  mnist$train$x,\n  mnist$train$y,\n  batch_size = 64,\n  steps_per_epoch = 5,\n  epochs = 15,\n  verbose = 0,\n  callbacks = list(\n    LossAndErrorPrintingCallback(),\n    CustomLearningRateScheduler(lr_schedule)\n  )\n)\n\n\n\nBuilt-in Keras callbacks\nBe sure to check out the existing Keras callbacks by reading the API docs. Applications include logging to CSV, saving the model, visualizing metrics in TensorBoard, and a lot more!"
  },
  {
    "objectID": "guides/keras/writing_your_own_callbacks.html#environment-details",
    "href": "guides/keras/writing_your_own_callbacks.html#environment-details",
    "title": "Writing your own callbacks",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html",
    "href": "guides/tensorflow/autodiff.html",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "",
    "text": "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License."
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#automatic-differentiation-and-gradients",
    "href": "guides/tensorflow/autodiff.html#automatic-differentiation-and-gradients",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Automatic Differentiation and Gradients",
    "text": "Automatic Differentiation and Gradients\nAutomatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks.\nIn this guide, you will explore ways to compute gradients with TensorFlow, especially in eager execution."
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#setup",
    "href": "guides/tensorflow/autodiff.html#setup",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#computing-gradients",
    "href": "guides/tensorflow/autodiff.html#computing-gradients",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Computing gradients",
    "text": "Computing gradients\nTo differentiate automatically, TensorFlow needs to remember what operations happen in what order during the forward pass. Then, during the backward pass, TensorFlow traverses this list of operations in reverse order to compute gradients."
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#gradient-tapes",
    "href": "guides/tensorflow/autodiff.html#gradient-tapes",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Gradient tapes",
    "text": "Gradient tapes\nTensorFlow provides the tf$GradientTape() API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf$Variables. TensorFlow “records” relevant operations executed inside the context of a tf$GradientTape() onto a “tape”. TensorFlow then uses that tape to compute the gradients of a “recorded” computation using reverse mode differentiation.\nHere is a simple example:\n\nx <- tf$Variable(3)\n\nLoaded Tensorflow version 2.9.1\n\nwith(tf$GradientTape() %as% tape, {\n  y <- x ^ 2\n})\n\nOnce you’ve recorded some operations, use GradientTape$gradient(target, sources) to calculate the gradient of some target (often a loss) relative to some source (often the model’s variables):\n\n# dy = 2x * dx\n\ndy_dx <- tape$gradient(y, x)\ndy_dx\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\nThe above example uses scalars, but tf$GradientTape works as easily on any tensor:\n\nw <- tf$Variable(tf$random$normal(c(3L, 2L)), name = 'w')\nb <- tf$Variable(tf$zeros(2L, dtype = tf$float32), name = 'b')\nx <- as_tensor(1:3, \"float32\", shape = c(1, 3))\n\nwith(tf$GradientTape(persistent = TRUE) %as% tape, {\n  y <- tf$matmul(x, w) + b\n  loss <- mean(y ^ 2)\n})\n\nTo get the gradient of loss with respect to both variables, you can pass both as sources to the gradient method. The tape is flexible about how sources are passed and will accept any nested combination of lists or dictionaries and return the gradient structured the same way (see tf$nest).\n\nc(dl_dw, dl_db) %<-% tape$gradient(loss, c(w, b))\n\nThe gradient with respect to each source has the shape of the source:\n\nw$shape\n\nTensorShape([3, 2])\n\ndl_dw$shape\n\nTensorShape([3, 2])\n\n\nHere is the gradient calculation again, this time passing a named list of variables:\n\nmy_vars <- list(w = w,\n                b = b)\n\ngrad <- tape$gradient(loss, my_vars)\ngrad$b\n\ntf.Tensor([-3.2715926 -2.462634 ], shape=(2), dtype=float32)"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#gradients-with-respect-to-a-model",
    "href": "guides/tensorflow/autodiff.html#gradients-with-respect-to-a-model",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Gradients with respect to a model",
    "text": "Gradients with respect to a model\nIt’s common to collect tf$Variables into a tf$Module or one of its subclasses (tf$keras$layers$Layer, tf$keras$Model) for checkpointing and exporting.\nIn most cases, you will want to calculate gradients with respect to a model’s trainable variables. Since all subclasses of tf$Module aggregate their variables in the Module$trainable_variables property, you can calculate these gradients in a few lines of code:\n\nlayer <- layer_dense(units = 2, activation = 'relu')\nx <- as_tensor(1:3, \"float32\", shape = c(1, -1))\n\nwith(tf$GradientTape() %as% tape, {\n  # Forward pass\n  y <- layer(x)\n  loss <- mean(y ^ 2)\n})\n\n# Calculate gradients with respect to every trainable variable\ngrad <- tape$gradient(loss, layer$trainable_variables)\n\n\nfor (pair in zip_lists(layer$trainable_variables, grad)) {\n  c(var, g) %<-% pair\n  print(glue::glue('{var$name}, shape: {format(g$shape)}'))\n}\n\ndense/kernel:0, shape: (3, 2)\ndense/bias:0, shape: (2)"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#controlling-what-the-tape-watches",
    "href": "guides/tensorflow/autodiff.html#controlling-what-the-tape-watches",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Controlling what the tape watches",
    "text": "Controlling what the tape watches\nThe default behavior is to record all operations after accessing a trainable tf$Variable. The reasons for this are:\n\nThe tape needs to know which operations to record in the forward pass to calculate the gradients in the backwards pass.\nThe tape holds references to intermediate outputs, so you don’t want to record unnecessary operations.\nThe most common use case involves calculating the gradient of a loss with respect to all a model’s trainable variables.\n\nFor example, the following fails to calculate a gradient because the tf$Tensor is not “watched” by default, and the tf$Variable is not trainable:\n\n# A trainable variable\nx0 <- tf$Variable(3.0, name = 'x0')\n\n# Not trainable\nx1 <- tf$Variable(3.0, name = 'x1', trainable = FALSE)\n\n# Not a Variable: A variable + tensor returns a tensor.\nx2 <- tf$Variable(2.0, name = 'x2') + 1.0\n\n# Not a variable\nx3 <- as_tensor(3.0, name = 'x3')\n\nwith(tf$GradientTape() %as% tape, {\n  y <- (x0 ^ 2) + (x1 ^ 2) + (x2 ^ 2)\n})\n\ngrad <- tape$gradient(y, list(x0, x1, x2, x3))\n\nstr(grad)\n\nList of 4\n $ :<tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n $ : NULL\n $ : NULL\n $ : NULL\n\n\nYou can list the variables being watched by the tape using the GradientTape$watched_variables method:\n\ntape$watched_variables()\n\n[[1]]\n<tf.Variable 'x0:0' shape=() dtype=float32, numpy=3.0>\n\n\ntf$GradientTape provides hooks that give the user control over what is or is not watched.\nTo record gradients with respect to a tf$Tensor, you need to call GradientTape$watch(x):\n\nx <- as_tensor(3.0)\nwith(tf$GradientTape() %as% tape, {\n  tape$watch(x)\n  y <- x ^ 2\n})\n\n# dy = 2x * dx\ndy_dx <- tape$gradient(y, x)\nas.array(dy_dx)\n\n[1] 6\n\n\nConversely, to disable the default behavior of watching all tf$Variables, set watch_accessed_variables = FALSE when creating the gradient tape. This calculation uses two variables, but only connects the gradient for one of the variables:\n\nx0 <- tf$Variable(0.0)\nx1 <- tf$Variable(10.0)\n\nwith(tf$GradientTape(watch_accessed_variables = FALSE) %as% tape, {\n  tape$watch(x1)\n  y0 <- sin(x0)\n  y1 <- tf$nn$softplus(x1)\n  y <- y0 + y1\n  ys <- sum(y)\n})\n\nSince GradientTape$watch was not called on x0, no gradient is computed with respect to it:\n\n# dys/dx1 = exp(x1) / (1 + exp(x1)) = sigmoid(x1)\ngrad <- tape$gradient(ys, list(x0 = x0, x1 = x1))\n\ncat('dy/dx0: ', grad$x0)\n\ndy/dx0: \n\ncat('dy/dx1: ', as.array(grad$x1))\n\ndy/dx1:  0.9999546"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#intermediate-results",
    "href": "guides/tensorflow/autodiff.html#intermediate-results",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Intermediate results",
    "text": "Intermediate results\nYou can also request gradients of the output with respect to intermediate values computed inside the tf$GradientTape context.\n\nx <- as_tensor(3.0)\n\nwith(tf$GradientTape() %as% tape, {\n  tape$watch(x)\n  y <- x * x\n  z <- y * y\n})\n\n# Use the tape to compute the gradient of z with respect to the\n# intermediate value y.\n# dz_dy = 2 * y and y = x ^ 2 = 9\ntape$gradient(z, y) |> as.array()\n\n[1] 18\n\n\nBy default, the resources held by a GradientTape are released as soon as the GradientTape$gradient method is called. To compute multiple gradients over the same computation, create a gradient tape with persistent = TRUE. This allows multiple calls to the gradient method as resources are released when the tape object is garbage collected. For example:\n\nx <- as_tensor(c(1, 3.0))\nwith(tf$GradientTape(persistent = TRUE) %as% tape, {\n\n  tape$watch(x)\n  y <- x * x\n  z <- y * y\n})\n\nas.array(tape$gradient(z, x))  # c(4.0, 108.0); (4 * x^3 at x = c(1.0, 3.0)\n\n[1]   4 108\n\nas.array(tape$gradient(y, x))  # c(2.0, 6.0);   (2 * x at x = c(1.0, 3.0)\n\n[1] 2 6\n\n\n\nrm(tape)   # Drop the reference to the tape"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#notes-on-performance",
    "href": "guides/tensorflow/autodiff.html#notes-on-performance",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Notes on performance",
    "text": "Notes on performance\n\nThere is a tiny overhead associated with doing operations inside a gradient tape context. For most eager execution this will not be a noticeable cost, but you should still use tape context around the areas only where it is required.\nGradient tapes use memory to store intermediate results, including inputs and outputs, for use during the backwards pass.\nFor efficiency, some ops (like ReLU) don’t need to keep their intermediate results and they are pruned during the forward pass. However, if you use persistent = TRUE on your tape, nothing is discarded and your peak memory usage will be higher."
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#gradients-of-non-scalar-targets",
    "href": "guides/tensorflow/autodiff.html#gradients-of-non-scalar-targets",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Gradients of non-scalar targets",
    "text": "Gradients of non-scalar targets\nA gradient is fundamentally an operation on a scalar.\n\nx <- tf$Variable(2.0)\nwith(tf$GradientTape(persistent = TRUE) %as% tape, {\n  y0 <- x ^ 2\n  y1 <- 1 / x\n})\n\nas.array(tape$gradient(y0, x))\n\n[1] 4\n\nas.array(tape$gradient(y1, x))\n\n[1] -0.25\n\n\nThus, if you ask for the gradient of multiple targets, the result for each source is:\n\nThe gradient of the sum of the targets, or equivalently\nThe sum of the gradients of each target.\n\n\nx <- tf$Variable(2.0)\nwith(tf$GradientTape() %as% tape, {\n  y0 <- x^2\n  y1 <- 1 / x\n})\n\nas.array(tape$gradient(list(y0 = y0, y1 = y1), x))\n\n[1] 3.75\n\n\nSimilarly, if the target(s) are not scalar the gradient of the sum is calculated:\n\nx <- tf$Variable(2)\n\nwith(tf$GradientTape() %as% tape, {\n  y <- x * c(3, 4)\n})\n\nas.array(tape$gradient(y, x))\n\n[1] 7\n\n\nThis makes it simple to take the gradient of the sum of a collection of losses, or the gradient of the sum of an element-wise loss calculation.\nIf you need a separate gradient for each item, refer to Jacobians.\nIn some cases you can skip the Jacobian. For an element-wise calculation, the gradient of the sum gives the derivative of each element with respect to its input-element, since each element is independent:\n\nx <- tf$linspace(-10.0, 10.0, as.integer(200+1))\n\nwith(tf$GradientTape() %as% tape, {\n  tape$watch(x)\n  y <- tf$nn$sigmoid(x)\n})\n\ndy_dx <- tape$gradient(y, x)\n\n\nfor(var in alist(x, y, dy_dx))\n  eval(bquote(.(var) <- as.array(.(var))))\nplot(NULL, xlim = range(x), ylim = range(y), ann=F, frame.plot = F)\nlines(x, y, col = \"royalblue\", lwd = 2)\nlines(x, dy_dx, col = \"coral\", lwd=2)\nlegend(\"topleft\", inset = .05,\n       expression(y, dy/dx),\n       col = c(\"royalblue\", \"coral\"), lwd = 2)"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#control-flow",
    "href": "guides/tensorflow/autodiff.html#control-flow",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Control flow",
    "text": "Control flow\nBecause a gradient tape records operations as they are executed, Python control flow is naturally handled (for example, if and while statements).\nHere a different variable is used on each branch of an if. The gradient only connects to the variable that was used:\n\nx <- as_tensor(1.0)\n\nv0 <- tf$Variable(2.0)\nv1 <- tf$Variable(2.0)\n\nwith(tf$GradientTape(persistent = TRUE) %as% tape, {\n  tape$watch(x)\n  if (as.logical(x > 0.0))\n    result <- v0\n  else\n    result <- v1 ^ 2\n})\n\nc(dv0, dv1) %<-% tape$gradient(result, list(v0, v1))\n\ndv0\n\ntf.Tensor(1.0, shape=(), dtype=float32)\n\ndv1\n\nNULL\n\n\nJust remember that the control statements themselves are not differentiable, so they are invisible to gradient-based optimizers.\nDepending on the value of x in the above example, the tape either records result = v0 or result = v1 ^ 2. The gradient with respect to x is always NULL.\n\n(dx <- tape$gradient(result, x))\n\nNULL"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#getting-a-gradient-of-null",
    "href": "guides/tensorflow/autodiff.html#getting-a-gradient-of-null",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Getting a gradient of NULL",
    "text": "Getting a gradient of NULL\nWhen a target is not connected to a source you will get a gradient of NULL.\n\nx <- tf$Variable(2)\ny <- tf$Variable(3)\n\nwith(tf$GradientTape() %as% tape, {\n  z <- y * y\n})\ntape$gradient(z, x)\n\nHere z is obviously not connected to x, but there are several less-obvious ways that a gradient can be disconnected.\n\n1. Replaced a variable with a tensor\nIn the section on “controlling what the tape watches” you saw that the tape will automatically watch a tf$Variable but not a tf$Tensor.\nOne common error is to inadvertently replace a tf$Variable with a tf$Tensor, instead of using Variable$assign to update the tf$Variable. Here is an example:\n\nx <- tf$Variable(2.0)\n\nfor (epoch in seq(2)) {\n\n  with(tf$GradientTape() %as% tape,\n       {  y <- x+1 })\n\n  cat(x$`__class__`$`__name__`, \": \")\n  print(tape$gradient(y, x))\n  x <- x + 1   # This should be `x$assign_add(1)`\n}\n\nResourceVariable : tf.Tensor(1.0, shape=(), dtype=float32)\nEagerTensor : NULL\n\n\n\n\n2. Did calculations outside of TensorFlow\nThe tape can’t record the gradient path if the calculation exits TensorFlow. For example:\n\nnp <- reticulate::import(\"numpy\", convert = FALSE)\nx <- tf$Variable(as_tensor(1:4, dtype=tf$float32, shape = c(2, 2)))\n\nwith(tf$GradientTape() %as% tape, {\n  x2 <- x ^ 2\n\n  # This step is calculated with NumPy\n  y <- np$mean(x2, axis = 0L)\n\n  # Like most tf ops, reduce_mean will cast the NumPy array to a constant tensor\n  # using `tf$convert_to_tensor`.\n  y <- tf$reduce_mean(y, axis = 0L)\n})\n\nprint(tape$gradient(y, x))\n\nNULL\n\n\n\n\n3. Took gradients through an integer or string\nIntegers and strings are not differentiable. If a calculation path uses these data types there will be no gradient.\nNobody expects strings to be differentiable, but it’s easy to accidentally create an int constant or variable if you don’t specify the dtype.\n\nx <- as_tensor(10L)\n\nwith(tf$GradientTape() %as% g, {\n  g$watch(x)\n  y <- x * x\n})\n\ng$gradient(y, x)\n\nWARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\nWARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\nWARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\nTensorFlow doesn’t automatically cast between types, so, in practice, you’ll often get a type error instead of a missing gradient.\n\n\n4. Took gradients through a stateful object\nState stops gradients. When you read from a stateful object, the tape can only observe the current state, not the history that lead to it.\nA tf$Tensor is immutable. You can’t change a tensor once it’s created. It has a value, but no state. All the operations discussed so far are also stateless: the output of a tf$matmul only depends on its inputs.\nA tf$Variable has internal state—its value. When you use the variable, the state is read. It’s normal to calculate a gradient with respect to a variable, but the variable’s state blocks gradient calculations from going farther back. For example:\n\nx0 <- tf$Variable(3.0)\nx1 <- tf$Variable(0.0)\n\nwith(tf$GradientTape() %as% tape, {\n  # Update x1 <- x1 + x0.\n  x1$assign_add(x0)\n  # The tape starts recording from x1.\n  y <- x1^2   # y = (x1 + x0)^2\n})\n\n# This doesn't work.\nprint(tape$gradient(y, x0))  #dy/dx0 = 2*(x1 + x0)\n\nNULL\n\n\nSimilarly, tf$data$Dataset iterators and tf$queues are stateful, and will stop all gradients on tensors that pass through them."
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#no-gradient-registered",
    "href": "guides/tensorflow/autodiff.html#no-gradient-registered",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "No gradient registered",
    "text": "No gradient registered\nSome tf$Operations are registered as being non-differentiable* and will return NULL. Others have no gradient registered**.\nThe tf$raw_ops page shows which low-level ops have gradients registered.\nIf you attempt to take a gradient through a float op that has no gradient registered the tape will throw an error instead of silently returning NULL. This way you know something has gone wrong.\nFor example, the tf$image$adjust_contrast function wraps raw_ops$AdjustContrastv2, which could have a gradient but the gradient is not implemented:\n\nimage <- tf$Variable(array(c(0.5, 0, 0), c(1,1,1)))\ndelta <- tf$Variable(0.1)\n\nwith(tf$GradientTape() %as% tape, {\n  new_image <- tf$image$adjust_contrast(image, delta)\n})\n\ntry(print(tape$gradient(new_image, list(image, delta))))\n\nError in py_call_impl(callable, dots$args, dots$keywords) : \n  LookupError: gradient registry has no entry for: AdjustContrastv2\n\n\nIf you need to differentiate through this op, you’ll either need to implement the gradient and register it (using tf$RegisterGradient) or re-implement the function using other ops."
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#zeros-instead-of-null",
    "href": "guides/tensorflow/autodiff.html#zeros-instead-of-null",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Zeros instead of NULL",
    "text": "Zeros instead of NULL\nIn some cases it would be convenient to get 0 instead of NULL for unconnected gradients. You can decide what to return when you have unconnected gradients using the unconnected_gradients argument:\n\nx <- tf$Variable(c(2, 2))\ny <- tf$Variable(3)\n\nwith(tf$GradientTape() %as% tape, {\n  z <- y^2\n})\ntape$gradient(z, x, unconnected_gradients = tf$UnconnectedGradients$ZERO)\n\ntf.Tensor([0. 0.], shape=(2), dtype=float32)"
  },
  {
    "objectID": "guides/tensorflow/autodiff.html#environment-details",
    "href": "guides/tensorflow/autodiff.html#environment-details",
    "title": "Introduction to gradients and automatic differentiation",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/tensorflow/basics.html",
    "href": "guides/tensorflow/basics.html",
    "title": "Tensorflow Basics",
    "section": "",
    "text": "This guide provides a quick overview of TensorFlow basics. Each section of this doc is an overview of a larger topic—you can find links to full guides at the end of each section.\nTensorFlow is an end-to-end platform for machine learning. It supports the following:\n\nMultidimensional-array based numeric computation (similar to Numpy\nGPU and distributed processing\nAutomatic differentiation\nModel construction, training, and export\nAnd more"
  },
  {
    "objectID": "guides/tensorflow/basics.html#tensors",
    "href": "guides/tensorflow/basics.html#tensors",
    "title": "Tensorflow Basics",
    "section": "Tensors",
    "text": "Tensors\nTensorFlow operates on multidimensional arrays or tensors represented as tensorflow.tensor objects. Here is a two-dimensional tensor:\n\nlibrary(tensorflow)\n\nx <- as_tensor(1:6, dtype = \"float32\", shape = c(2, 3))\n\nLoaded Tensorflow version 2.9.1\n\nx\n\ntf.Tensor(\n[[1. 2. 3.]\n [4. 5. 6.]], shape=(2, 3), dtype=float32)\n\nx$shape\n\nTensorShape([2, 3])\n\nx$dtype\n\ntf.float32\n\n\nThe most important attributes of a tensor are its shape and dtype:\n\ntensor$shape: tells you the size of the tensor along each of its axes.\ntensor$dtype: tells you the type of all the elements in the tensor.\n\nTensorFlow implements standard mathematical operations on tensors, as well as many operations specialized for machine learning.\nFor example:\n\nx + x\n\ntf.Tensor(\n[[ 2.  4.  6.]\n [ 8. 10. 12.]], shape=(2, 3), dtype=float32)\n\n\n\n5 * x\n\ntf.Tensor(\n[[ 5. 10. 15.]\n [20. 25. 30.]], shape=(2, 3), dtype=float32)\n\n\n\ntf$matmul(x, t(x)) \n\ntf.Tensor(\n[[14. 32.]\n [32. 77.]], shape=(2, 2), dtype=float32)\n\n\n\ntf$concat(list(x, x, x), axis = 0L)\n\ntf.Tensor(\n[[1. 2. 3.]\n [4. 5. 6.]\n [1. 2. 3.]\n [4. 5. 6.]\n [1. 2. 3.]\n [4. 5. 6.]], shape=(6, 3), dtype=float32)\n\n\n\ntf$nn$softmax(x, axis = -1L)\n\ntf.Tensor(\n[[0.09003057 0.24472848 0.66524094]\n [0.09003057 0.24472848 0.66524094]], shape=(2, 3), dtype=float32)\n\n\n\nsum(x) # same as tf$reduce_sum(x)\n\ntf.Tensor(21.0, shape=(), dtype=float32)\n\n\nRunning large calculations on CPU can be slow. When properly configured, TensorFlow can use accelerator hardware like GPUs to execute operations very quickly.\n\nif (length(tf$config$list_physical_devices('GPU')))\n  message(\"TensorFlow **IS** using the GPU\") else\n  message(\"TensorFlow **IS NOT** using the GPU\")\n\nTensorFlow **IS NOT** using the GPU\n\n\nRefer to the Tensor guide for details."
  },
  {
    "objectID": "guides/tensorflow/basics.html#variables",
    "href": "guides/tensorflow/basics.html#variables",
    "title": "Tensorflow Basics",
    "section": "Variables",
    "text": "Variables\nNormal tensor objects are immutable. To store model weights (or other mutable state) in TensorFlow use a tf$Variable.\n\nvar <- tf$Variable(c(0, 0, 0))\nvar\n\n<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n\n\n\nvar$assign(c(1, 2, 3))\n\n<tf.Variable 'UnreadVariable' shape=(3,) dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>\n\n\n\nvar$assign_add(c(1, 1, 1))\n\n<tf.Variable 'UnreadVariable' shape=(3,) dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>\n\n\nRefer to the Variables guide for details."
  },
  {
    "objectID": "guides/tensorflow/basics.html#automatic-differentiation",
    "href": "guides/tensorflow/basics.html#automatic-differentiation",
    "title": "Tensorflow Basics",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\nGradient descent and related algorithms are a cornerstone of modern machine learning.\nTo enable this, TensorFlow implements automatic differentiation (autodiff), which uses calculus to compute gradients. Typically you’ll use this to calculate the gradient of a model’s error or loss with respect to its weights.\n\nx <- tf$Variable(1.0)\n\nf <- function(x)\n  x^2 + 2*x - 5\n\n\nf(x)\n\ntf.Tensor(-2.0, shape=(), dtype=float32)\n\n\nAt x = 1.0, y = f(x) = (1^2 + 2*1 - 5) = -2.\nThe derivative of y is y' = f'(x) = (2*x + 2) = 4. TensorFlow can calculate this automatically:\n\nwith(tf$GradientTape() %as% tape, {\n  y <- f(x)\n})\n\ng_x <- tape$gradient(y, x)  # g(x) = dy/dx\n\ng_x\n\ntf.Tensor(4.0, shape=(), dtype=float32)\n\n\nThis simplified example only takes the derivative with respect to a single scalar (x), but TensorFlow can compute the gradient with respect to any number of non-scalar tensors simultaneously.\nRefer to the Autodiff guide for details."
  },
  {
    "objectID": "guides/tensorflow/basics.html#graphs-and-tf_function",
    "href": "guides/tensorflow/basics.html#graphs-and-tf_function",
    "title": "Tensorflow Basics",
    "section": "Graphs and tf_function",
    "text": "Graphs and tf_function\nWhile you can use TensorFlow interactively like any R library, TensorFlow also provides tools for:\n\nPerformance optimization: to speed up training and inference.\nExport: so you can save your model when it’s done training.\n\nThese require that you use tf_function() to separate your pure-TensorFlow code from R.\n\nmy_func <- tf_function(function(x) {\n  message('Tracing.')\n  tf$reduce_sum(x)\n})\n\nThe first time you run the tf_function, although it executes in R, it captures a complete, optimized graph representing the TensorFlow computations done within the function.\n\nx <- as_tensor(1:3)\nmy_func(x)\n\nTracing.\n\n\ntf.Tensor(6, shape=(), dtype=int32)\n\n\nOn subsequent calls TensorFlow only executes the optimized graph, skipping any non-TensorFlow steps. Below, note that my_func doesn’t print \"Tracing.\" since message is an R function, not a TensorFlow function.\n\nx <- as_tensor(10:8)\nmy_func(x)\n\ntf.Tensor(27, shape=(), dtype=int32)\n\n\nA graph may not be reusable for inputs with a different signature (shape and dtype), so a new graph is generated instead:\n\nx <- as_tensor(c(10.0, 9.1, 8.2), dtype=tf$dtypes$float32)\nmy_func(x)\n\nTracing.\n\n\ntf.Tensor(27.3, shape=(), dtype=float32)\n\n\nThese captured graphs provide two benefits:\n\nIn many cases they provide a significant speedup in execution (though not this trivial example).\nYou can export these graphs, using tf$saved_model, to run on other systems like a server or a mobile device, no Python installation required.\n\nRefer to Intro to graphs for more details."
  },
  {
    "objectID": "guides/tensorflow/basics.html#modules-layers-and-models",
    "href": "guides/tensorflow/basics.html#modules-layers-and-models",
    "title": "Tensorflow Basics",
    "section": "Modules, layers, and models",
    "text": "Modules, layers, and models\ntf$Module is a class for managing your tf$Variable objects, and the tf_function objects that operate on them. The tf$Module class is necessary to support two significant features:\n\nYou can save and restore the values of your variables using tf$train$Checkpoint. This is useful during training as it is quick to save and restore a model’s state.\nYou can import and export the tf$Variable values and the tf$function graphs using tf$saved_model. This allows you to run your model independently of the Python program that created it.\n\nHere is a complete example exporting a simple tf$Module object:\n\nlibrary(keras) # %py_class% is exported by the keras package at this time\nMyModule(tf$Module) %py_class% {\n  initialize <- function(self, value) {\n    self$weight <- tf$Variable(value)\n  }\n  \n  multiply <- tf_function(function(self, x) {\n    x * self$weight\n  })\n}\n\n\nmod <- MyModule(3)\nmod$multiply(as_tensor(c(1, 2, 3), \"float32\"))\n\ntf.Tensor([3. 6. 9.], shape=(3), dtype=float32)\n\n\nSave the Module:\n\nsave_path <- tempfile()\ntf$saved_model$save(mod, save_path)\n\nThe resulting SavedModel is independent of the code that created it. You can load a SavedModel from R, Python, other language bindings, or TensorFlow Serving. You can also convert it to run with TensorFlow Lite or TensorFlow JS.\n\nreloaded <- tf$saved_model$load(save_path)\nreloaded$multiply(as_tensor(c(1, 2, 3), \"float32\"))\n\ntf.Tensor([3. 6. 9.], shape=(3), dtype=float32)\n\n\nThe tf$keras$layers$Layer and tf$keras$Model classes build on tf$Module providing additional functionality and convenience methods for building, training, and saving models. Some of these are demonstrated in the next section.\nRefer to Intro to modules for details."
  },
  {
    "objectID": "guides/tensorflow/basics.html#training-loops",
    "href": "guides/tensorflow/basics.html#training-loops",
    "title": "Tensorflow Basics",
    "section": "Training loops",
    "text": "Training loops\nNow put this all together to build a basic model and train it from scratch.\nFirst, create some example data. This generates a cloud of points that loosely follows a quadratic curve:\n\nx <- as_tensor(seq(-2, 2, length.out = 201), \"float32\")\n\nf <- function(x)\n  x^2 + 2*x - 5\n\nground_truth <- f(x) \ny <- ground_truth + tf$random$normal(shape(201))\n\nx %<>% as.array()\ny %<>% as.array()\nground_truth %<>% as.array()\n\nplot(x, y, type = 'p', col = \"deepskyblue2\", pch = 19)\nlines(x, ground_truth, col = \"tomato2\", lwd = 3)\nlegend(\"topleft\", \n       col = c(\"deepskyblue2\", \"tomato2\"),\n       lty = c(NA, 1), lwd = 3,\n       pch = c(19, NA), \n       legend = c(\"Data\", \"Ground Truth\"))\n\n\n\n\nCreate a model:\n\nModel(tf$keras$Model) %py_class% {\n  initialize <- function(units) {\n    super$initialize()\n    self$dense1 <- layer_dense(\n      units = units,\n      activation = tf$nn$relu,\n      kernel_initializer = tf$random$normal,\n      bias_initializer = tf$random$normal\n    )\n    self$dense2 <- layer_dense(units = 1)\n  }\n  \n  call <- function(x, training = TRUE) {\n    x %>% \n      .[, tf$newaxis] %>% \n      self$dense1() %>% \n      self$dense2() %>% \n      .[, 1] \n  }\n}\n\n\nmodel <- Model(64)\n\n\nuntrained_predictions <- model(as_tensor(x))\n\nplot(x, y, type = 'p', col = \"deepskyblue2\", pch = 19)\nlines(x, ground_truth, col = \"tomato2\", lwd = 3)\nlines(x, untrained_predictions, col = \"forestgreen\", lwd = 3)\nlegend(\"topleft\", \n       col = c(\"deepskyblue2\", \"tomato2\", \"forestgreen\"),\n       lty = c(NA, 1, 1), lwd = 3,\n       pch = c(19, NA), \n       legend = c(\"Data\", \"Ground Truth\", \"Untrained predictions\"))\ntitle(\"Before training\")\n\n\n\n\nWrite a basic training loop:\n\nvariables <- model$variables\n\noptimizer <- tf$optimizers$SGD(learning_rate=0.01)\n\nfor (step in seq(1000)) {\n  \n  with(tf$GradientTape() %as% tape, {\n    prediction <- model(x)\n    error <- (y - prediction) ^ 2\n    mean_error <- mean(error)\n  })\n  gradient <- tape$gradient(mean_error, variables)\n  optimizer$apply_gradients(zip_lists(gradient, variables))\n\n  if (step %% 100 == 0)\n    message(sprintf('Mean squared error: %.3f', as.array(mean_error)))\n}\n\nMean squared error: 1.168\n\n\nMean squared error: 1.143\n\n\nMean squared error: 1.126\n\n\nMean squared error: 1.112\n\n\nMean squared error: 1.100\n\n\nMean squared error: 1.090\n\n\nMean squared error: 1.081\n\n\nMean squared error: 1.074\n\n\nMean squared error: 1.068\n\n\nMean squared error: 1.063\n\n\n\ntrained_predictions <- model(x)\nplot(x, y, type = 'p', col = \"deepskyblue2\", pch = 19)\nlines(x, ground_truth, col = \"tomato2\", lwd = 3)\nlines(x, trained_predictions, col = \"forestgreen\", lwd = 3)\nlegend(\"topleft\", \n       col = c(\"deepskyblue2\", \"tomato2\", \"forestgreen\"),\n       lty = c(NA, 1, 1), lwd = 3,\n       pch = c(19, NA), \n       legend = c(\"Data\", \"Ground Truth\", \"Trained predictions\"))\ntitle(\"After training\")\n\n\n\n\nThat’s working, but remember that implementations of common training utilities are available in the tf$keras module. So consider using those before writing your own. To start with, the compile and fit methods for Keras Models implement a training loop for you:\n\nnew_model <- Model(64)\n\n\nnew_model %>% compile(\n  loss = tf$keras$losses$MSE,\n  optimizer = tf$optimizers$SGD(learning_rate = 0.01)\n)\n\nhistory <- new_model %>% \n  fit(x, y,\n      epochs = 100,\n      batch_size = 32,\n      verbose = 0)\n\nmodel$save('./my_model')\n\n\n\n\n\nplot(history, metrics = 'loss', method = \"base\") \n\n\n\n# see ?plot.keras_training_history for more options.\n\nRefer to Basic training loops and the Keras guide for more details."
  },
  {
    "objectID": "guides/tensorflow/basics.html#environment-details",
    "href": "guides/tensorflow/basics.html#environment-details",
    "title": "Tensorflow Basics",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html",
    "href": "guides/tensorflow/intro_to_graphs.html",
    "title": "Introduction to graphs",
    "section": "",
    "text": "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License."
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#overview",
    "href": "guides/tensorflow/intro_to_graphs.html#overview",
    "title": "Introduction to graphs",
    "section": "Overview",
    "text": "Overview\nThis guide goes beneath the surface of TensorFlow and Keras to demonstrate how TensorFlow works. If you instead want to immediately get started with Keras, check out the collection of Keras guides.\nIn this guide, you’ll learn how TensorFlow allows you to make simple changes to your code to get graphs, how graphs are stored and represented, and how you can use them to accelerate your models.\nNote: For those of you who are only familiar with TensorFlow 1.x, this guide demonstrates a very different view of graphs.\nThis is a big-picture overview that covers how tf_function() allows you to switch from eager execution to graph execution. For a more complete specification of tf_function(), go to the tf_function() guide.\n\nWhat are graphs?\nIn the previous three guides, you ran TensorFlow eagerly. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.\nWhile eager execution has several unique advantages, graph execution enables portability outside Python and tends to offer better performance. Graph execution means that tensor computations are executed as a TensorFlow graph, sometimes referred to as a tf$Graph or simply a “graph.”\nGraphs are data structures that contain a set of tf$Operation objects, which represent units of computation; and tf$Tensor objects, which represent the units of data that flow between operations. They are defined in a tf$Graph context. Since these graphs are data structures, they can be saved, run, and restored all without the original R code.\nThis is what a TensorFlow graph representing a two-layer neural network looks like when visualized in TensorBoard.\n\n\n\nA simple TensorFlow g\n\n\n\n\nThe benefits of graphs\nWith a graph, you have a great deal of flexibility. You can use your TensorFlow graph in environments that don’t have an R interpreter, like mobile applications, embedded devices, and backend servers. TensorFlow uses graphs as the format for saved models when it exports them from R.\nGraphs are also easily optimized, allowing the compiler to do transformations like:\n\nStatically infer the value of tensors by folding constant nodes in your computation (“constant folding”).\nSeparate sub-parts of a computation that are independent and split them between threads or devices.\nSimplify arithmetic operations by eliminating common subexpressions.\n\nThere is an entire optimization system, Grappler, to perform this and other speedups.\nIn short, graphs are extremely useful and let your TensorFlow run fast, run in parallel, and run efficiently on multiple devices.\nHowever, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them."
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#setup",
    "href": "guides/tensorflow/intro_to_graphs.html#setup",
    "title": "Introduction to graphs",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)\nlibrary(magrittr, include.only = \"%>%\")\n\nWarning: package 'magrittr' was built under R version 4.1.2"
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#taking-advantage-of-graphs",
    "href": "guides/tensorflow/intro_to_graphs.html#taking-advantage-of-graphs",
    "title": "Introduction to graphs",
    "section": "Taking advantage of graphs",
    "text": "Taking advantage of graphs\nYou create and run a graph in TensorFlow by using tf_function(), either as a direct call or as a decorator. tf_function() takes a regular function as input and returns a Function. A Function is a callable that builds TensorFlow graphs from the R function. You use a Function in the same way as its R equivalent.\n\n# Define an R function.\na_regular_function <- function(x, y, b) {\n  x %>%\n    tf$matmul(y) %>%\n    { . + b }\n}\n\n# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\na_function_that_uses_a_graph <- tf_function(a_regular_function)\n\nLoaded Tensorflow version 2.9.1\n\n# Make some tensors.\nx1 <- as_tensor(1:2, \"float64\", shape = c(1, 2))\ny1 <- as_tensor(2:3, \"float64\", shape = c(2, 1))\nb1 <- as_tensor(4)\n\norig_value <- as.array(a_regular_function(x1, y1, b1))\n# Call a `Function` like a Python function.\n\ntf_function_value <- as.array(a_function_that_uses_a_graph(x1, y1, b1))\nstopifnot(orig_value == tf_function_value)\n\nOn the outside, a Function looks like a regular function you write using TensorFlow operations. Underneath, however, it is very different. A Function encapsulates several tf$Graphs behind one API. That is how Function is able to give you the benefits of graph execution, like speed and deployability.\ntf_function applies to a function and all other functions it calls:\n\ninner_function <- function(x, y, b) {\n  tf$matmul(x, y) + b\n}\n\nouter_function <- tf_function(function(x) {\n  y <- as_tensor(2:3, \"float64\", shape = c(2, 1))\n  b <- as_tensor(4.0)\n\n  inner_function(x, y, b)\n})\n\n# Note that the callable will create a graph that\n# includes `inner_function` as well as `outer_function`.\nouter_function(as_tensor(1:2, \"float64\", shape = c(1, 2))) #%>% as.array()\n\ntf.Tensor([[12.]], shape=(1, 1), dtype=float64)\n\n\nIf you have used TensorFlow 1.x, you will notice that at no time did you need to define a Placeholder or tf$Session().\n\nConverting Python functions to graphs\nAny function you write with TensorFlow will contain a mixture of built-in TF operations and R control-flow logic, such as if-then clauses, loops, break, return, next, and more. While TensorFlow operations are easily captured by a tf$Graph, R-specific logic needs to undergo an extra step in order to become part of the graph. tf_function() uses a library called {tfautograph} to evaluate the R code in a special way so that it generates a graph.\n\nsimple_relu <- function(x) {\n  if (tf$greater(x, 0))\n    x\n  else\n    as_tensor(0, x$dtype)\n}\n\n# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\ntf_simple_relu <- tf_function(simple_relu)\n\ncat(\n  \"First branch, with graph: \", format(tf_simple_relu(as_tensor(1))), \"\\n\",\n  \"Second branch, with graph: \", format(tf_simple_relu(as_tensor(-1))), \"\\n\",\n  sep = \"\"\n)\n\nFirst branch, with graph: tf.Tensor(1.0, shape=(), dtype=float64)\nSecond branch, with graph: tf.Tensor(0.0, shape=(), dtype=float64)\n\n\nThough it is unlikely that you will need to view graphs directly, you can inspect the outputs to check the exact results. These are not easy to read, so no need to look too carefully!\n\n# This is the graph itself.\ntf_simple_relu$get_concrete_function(as_tensor(1))$graph$as_graph_def()\n\nMost of the time, tf_function() will work without special considerations. However, there are some caveats, and the tf_function guide can help here, as well as the tfautograph Getting Started vignette\n\n\nPolymorphism: one Function, many graphs\nA tf$Graph is specialized to a specific type of inputs (for example, tensors with a specific dtype or objects with the same id()) (i.e, the same memory address).\nEach time you invoke a Function with a set of arguments that can’t be handled by any of its existing graphs (such as arguments with new dtypes or incompatible shapes), Function creates a new tf$Graph specialized to those new arguments. The type specification of a tf$Graph’s inputs is known as its input signature or just a signature. For more information regarding when a new tf$Graph is generated and how that can be controlled, see the rules of retracing.\nThe Function stores the tf$Graph corresponding to that signature in a ConcreteFunction. A ConcreteFunction is a wrapper around a tf$Graph.\n\nmy_relu <- tf_function(function(x) {\n  message(\"Tracing my_relu(x) with: \", x)\n  tf$maximum(as_tensor(0), x)\n})\n\n# `my_relu` creates new graphs as it observes more signatures.\n\nmy_relu(as_tensor(5.5))\n\nTracing my_relu(x) with: Tensor(\"x:0\", shape=(), dtype=float64)\n\n\ntf.Tensor(5.5, shape=(), dtype=float64)\n\nmy_relu(c(1, -1))\n\nTracing my_relu(x) with: 1-1\n\n\ntf.Tensor([1. 0.], shape=(2), dtype=float64)\n\nmy_relu(as_tensor(c(3, -3)))\n\nTracing my_relu(x) with: Tensor(\"x:0\", shape=(2,), dtype=float64)\n\n\ntf.Tensor([3. 0.], shape=(2), dtype=float64)\n\n\nIf the Function has already been called with that signature, Function does not create a new tf$Graph.\n\n# These two calls do *not* create new graphs.\nmy_relu(as_tensor(-2.5)) # Signature matches `as_tensor(5.5)`.\n\ntf.Tensor(0.0, shape=(), dtype=float64)\n\nmy_relu(as_tensor(c(-1., 1.))) # Signature matches `as_tensor(c(3., -3.))`.\n\ntf.Tensor([0. 1.], shape=(2), dtype=float64)\n\n\nBecause it’s backed by multiple graphs, a Function is polymorphic. That enables it to support more input types than a single tf$Graph could represent, as well as to optimize each tf$Graph for better performance.\n\n# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n# The `ConcreteFunction` also knows the return type and shape!\ncat(my_relu$pretty_printed_concrete_signatures())\n\nfn(x)\n  Args:\n    x: float64 Tensor, shape=()\n  Returns:\n    float64 Tensor, shape=()\n\nfn(x=[1.0, -1.0])\n  Returns:\n    float64 Tensor, shape=(2,)\n\nfn(x)\n  Args:\n    x: float64 Tensor, shape=(2,)\n  Returns:\n    float64 Tensor, shape=(2,)"
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#using-tf_function",
    "href": "guides/tensorflow/intro_to_graphs.html#using-tf_function",
    "title": "Introduction to graphs",
    "section": "Using tf_function()",
    "text": "Using tf_function()\nSo far, you’ve learned how to convert a Python function into a graph simply by using tf_function() as function wrapper. But in practice, getting tf_function to work correctly can be tricky! In the following sections, you’ll learn how you can make your code work as expected with tf_function().\n\nGraph execution vs. eager execution\nThe code in a Function can be executed both eagerly and as a graph. By default, Function executes its code as a graph:\n\nget_MSE <- tf_function(function(y_true, y_pred) {\n  # if y_true and y_pred are tensors, the R generics mean`, `^`, and `-`\n  # dispatch to tf$reduce_mean(), tf$math$pow(), and tf$math$subtract()\n  mean((y_true - y_pred) ^ 2)\n})\n\n\n(y_true <- tf$random$uniform(shape(5), maxval = 10L, dtype = tf$int32))\n\ntf.Tensor([3 7 9 5 0], shape=(5), dtype=int32)\n\n(y_pred <- tf$random$uniform(shape(5), maxval = 10L, dtype = tf$int32))\n\ntf.Tensor([8 3 4 7 4], shape=(5), dtype=int32)\n\n\n\nget_MSE(y_true, y_pred)\n\ntf.Tensor(17, shape=(), dtype=int32)\n\n\nTo verify that your Function’s graph is doing the same computation as its equivalent Python function, you can make it execute eagerly with tf$config$run_functions_eagerly(TRUE). This is a switch that turns off Function’s ability to create and run graphs, instead executing the code normally.\n\ntf$config$run_functions_eagerly(TRUE)\n\n\nget_MSE(y_true, y_pred)\n\ntf.Tensor(17, shape=(), dtype=int32)\n\n\n\n# Don't forget to set it back when you are done.\ntf$config$run_functions_eagerly(FALSE)\n\nHowever, Function can behave differently under graph and eager execution. The R print() function is one example of how these two modes differ. Let’s check out what happens when you insert a print statement to your function and call it repeatedly.\n\nget_MSE <- tf_function(function(y_true, y_pred) {\n  print(\"Calculating MSE!\")\n  mean((y_true - y_pred) ^ 2)\n  })\n\nObserve what is printed:\n\nerror <- get_MSE(y_true, y_pred)\n\n[1] \"Calculating MSE!\"\n\nerror <- get_MSE(y_true, y_pred)\nerror <- get_MSE(y_true, y_pred)\n\nIs the output surprising? get_MSE only printed once even though it was called three times.\nTo explain, the print statement is executed when Function runs the original code in order to create the graph in a process known as “tracing”. Tracing captures the TensorFlow operations into a graph, and print() is not captured in the graph. That graph is then executed for all three calls without ever running the R code again.\nAs a sanity check, let’s turn off graph execution to compare:\n\n# Now, globally set everything to run eagerly to force eager execution.\ntf$config$run_functions_eagerly(TRUE)\n\n\n# Observe what is printed below.\nerror <- get_MSE(y_true, y_pred)\n\n[1] \"Calculating MSE!\"\n\nerror <- get_MSE(y_true, y_pred)\n\n[1] \"Calculating MSE!\"\n\nerror <- get_MSE(y_true, y_pred)\n\n[1] \"Calculating MSE!\"\n\n\n\ntf$config$run_functions_eagerly(FALSE)\n\nprint is an R side effect, and there are other differences that you should be aware of when converting a function into a Function. Learn more in the Limitations section of the Better performance with tf_function guide.\n\n\n\n\n\n\nNote\n\n\n\nNote: If you would like to print values in both eager and graph execution, use tf$print() instead.\n\n\n\n\nNon-strict execution\nGraph execution only executes the operations necessary to produce the observable effects, which includes:\n\nThe return value of the function\nDocumented well-known side-effects such as:\n\nInput/output operations, like tf$print()\nDebugging operations, such as the assert functions in tf$debugging() (also, stopifnot())\nMutations of tf$Variable()\n\n\nThis behavior is usually known as “Non-strict execution”, and differs from eager execution, which steps through all of the program operations, needed or not.\nIn particular, runtime error checking does not count as an observable effect. If an operation is skipped because it is unnecessary, it cannot raise any runtime errors.\nIn the following example, the “unnecessary” operation tf$gather() is skipped during graph execution, so the runtime error InvalidArgumentError is not raised as it would be in eager execution. Do not rely on an error being raised while executing a graph.\n\nunused_return_eager <- function(x) {\n  # tf$gather() will fail on a CPU device if the index is out of bounds\n  with(tf$device(\"CPU\"),\n       tf$gather(x, list(2L))) # unused\n  x\n}\n\ntry(unused_return_eager(as_tensor(0, shape = c(1))))\n\nError in py_call_impl(callable, dots$args, dots$keywords) : \n  tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 2 is not in [0, 1) [Op:GatherV2]\n\n# All operations are run during eager execution so an error is raised.\n\n\nunused_return_graph <- tf_function(function(x) {\n  with(tf$device(\"CPU\"),\n       tf$gather(x, list(2L))) # unused\n  x\n})\n\n# Only needed operations are run during graph exection. The error is not raised.\nunused_return_graph(as_tensor(0, shape = 1))\n\ntf.Tensor([0.], shape=(1), dtype=float64)\n\n\n\n\ntf_function() best practices\nIt may take some time to get used to the behavior of Function. To get started quickly, first-time users should play around with wrapping toy functions with tf_function() to get experience with going from eager to graph execution.\nDesigning for tf_function may be your best bet for writing graph-compatible TensorFlow programs. Here are some tips:\n\nToggle between eager and graph execution early and often with tf$config$run_functions_eagerly() to pinpoint if/when the two modes diverge.\nCreate tf$Variables outside the Python function and modify them on the inside. The same goes for objects that use tf$Variable, like keras$layers, keras$Models and tf$optimizers.\nAvoid writing functions that depend on outer Python variables, excluding tf$Variables and Keras objects.\nPrefer to write functions which take tensors and other TensorFlow types as input. You can pass in other object types but be careful!\nInclude as much computation as possible under a tf_function to maximize the performance gain. For example, wrap a whole training step or the entire training loop."
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#seeing-the-speed-up",
    "href": "guides/tensorflow/intro_to_graphs.html#seeing-the-speed-up",
    "title": "Introduction to graphs",
    "section": "Seeing the speed-up",
    "text": "Seeing the speed-up\ntf_function usually improves the performance of your code, but the amount of speed-up depends on the kind of computation you run. Small computations can be dominated by the overhead of calling a graph. You can measure the difference in performance like so:\n\nx <- tf$random$uniform(shape(10, 10),\n                       minval = -1L, maxval = 2L,\n                       dtype = tf$dtypes$int32)\n\npower <- function(x, y) {\n  result <- tf$eye(10L, dtype = tf$dtypes$int32)\n  for (. in seq_len(y))\n    result <- tf$matmul(x, result)\n  result\n}\npower_as_graph <- tf_function(power)\n\n\nplot(bench::mark(\n  \"Eager execution\" = power(x, 100),\n  \"Graph execution\" = power_as_graph(x, 100)))\n\nLoading required namespace: tidyr\n\n\n\n\n\ntf_function is commonly used to speed up training loops, and you can learn more about it in Writing a training loop from scratch with Keras.\nNote: You can also try tf_function(jit_compile = TRUE) for a more significant performance boost, especially if your code is heavy on TF control flow and uses many small tensors.\n\nPerformance and trade-offs\nGraphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. This investment is usually quickly paid back with the performance boost of subsequent executions, but it’s important to be aware that the first few steps of any large model training can be slower due to tracing.\nNo matter how large your model, you want to avoid tracing frequently. The tf_function() guide discusses how to set input specifications and use tensor arguments to avoid retracing. If you find you are getting unusually poor performance, it’s a good idea to check if you are retracing accidentally."
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#when-is-a-function-tracing",
    "href": "guides/tensorflow/intro_to_graphs.html#when-is-a-function-tracing",
    "title": "Introduction to graphs",
    "section": "When is a Function tracing?",
    "text": "When is a Function tracing?\nTo figure out when your Function is tracing, add a print or message() statement to its code. As a rule of thumb, Function will execute the message statement every time it traces.\n\na_function_with_r_side_effect <- tf_function(function(x) {\n  message(\"Tracing!\") # An eager-only side effect.\n  (x * x) + 2\n})\n\n# This is traced the first time.\na_function_with_r_side_effect(as_tensor(2))\n\nTracing!\n\n\ntf.Tensor(6.0, shape=(), dtype=float64)\n\n# The second time through, you won't see the side effect.\na_function_with_r_side_effect(as_tensor(3))\n\ntf.Tensor(11.0, shape=(), dtype=float64)\n\n\n\n# This retraces each time the Python argument changes,\n# as a Python argument could be an epoch count or other\n# hyperparameter.\n\na_function_with_r_side_effect(2)\n\nTracing!\n\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\na_function_with_r_side_effect(3)\n\nTracing!\n\n\ntf.Tensor(11.0, shape=(), dtype=float32)\n\n\nNew (non-tensor) R arguments always trigger the creation of a new graph, hence the extra tracing."
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#next-steps",
    "href": "guides/tensorflow/intro_to_graphs.html#next-steps",
    "title": "Introduction to graphs",
    "section": "Next steps",
    "text": "Next steps\nYou can learn more about tf_function() on the API reference page and by following the Better performance with tf_function guide."
  },
  {
    "objectID": "guides/tensorflow/intro_to_graphs.html#environment-details",
    "href": "guides/tensorflow/intro_to_graphs.html#environment-details",
    "title": "Introduction to graphs",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/tensorflow/tensor.html",
    "href": "guides/tensorflow/tensor.html",
    "title": "Introduction to Tensors",
    "section": "",
    "text": "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nlibrary(tensorflow)\n\nTensors are multi-dimensional arrays with a uniform type (called a dtype). You can see all supported dtypes with names(tf$dtypes).\nIf you’re familiar with R array or NumPy, tensors are (kind of) like R or NumPy arrays.\nAll tensors are immutable: you can never update the contents of a tensor, only create a new one."
  },
  {
    "objectID": "guides/tensorflow/tensor.html#basics",
    "href": "guides/tensorflow/tensor.html#basics",
    "title": "Introduction to Tensors",
    "section": "Basics",
    "text": "Basics\nLet’s create some basic tensors.\nHere is a “scalar” or “rank-0” tensor . A scalar contains a single value, and no “axes”.\n\n# This will be an float64 tensor by default; see \"dtypes\" below.\nrank_0_tensor <- as_tensor(4)\n\nLoaded Tensorflow version 2.9.1\n\nprint(rank_0_tensor)\n\ntf.Tensor(4.0, shape=(), dtype=float64)\n\n\nA “vector” or “rank-1” tensor is like a list of values. A vector has one axis:\n\nrank_1_tensor <- as_tensor(c(2, 3, 4))\nprint(rank_1_tensor)\n\ntf.Tensor([2. 3. 4.], shape=(3), dtype=float64)\n\n\nA “matrix” or “rank-2” tensor has two axes:\n\n# If you want to be specific, you can set the dtype (see below) at creation time\nrank_2_tensor <- \n  as_tensor(rbind(c(1, 2), \n                  c(3, 4), \n                  c(5, 6)), \n            dtype=tf$float16)\nprint(rank_2_tensor)\n\ntf.Tensor(\n[[1. 2.]\n [3. 4.]\n [5. 6.]], shape=(3, 2), dtype=float16)\n\n\n\n\n\n\n\n\n\n\nA scalar, shape: []\nA vector, shape: [3]\nA matrix, shape: [3, 2]\n\n\n\n\n\n\n\n\n\n\nTensors may have more axes; here is a tensor with three axes:\n\n# There can be an arbitrary number of\n# axes (sometimes called \"dimensions\")\n\nrank_3_tensor <- as_tensor(0:29, shape = c(3, 2, 5))\nrank_3_tensor\n\ntf.Tensor(\n[[[ 0  1  2  3  4]\n  [ 5  6  7  8  9]]\n\n [[10 11 12 13 14]\n  [15 16 17 18 19]]\n\n [[20 21 22 23 24]\n  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n\n\nThere are many ways you might visualize a tensor with more than two axes.\n\n\n\n\n\n\nA 3-axis tensor, shape: [3, 2, 5]\n\n\n\n\n\n\n\n!  \n\n\n\nYou can convert a tensor to an R array using as.array():\n\nas.array(rank_2_tensor)\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\n\nTensors often contain floats and ints, but have many other types, including:\n\ncomplex numbers\nstrings\n\nThe base tf$Tensor class requires tensors to be “rectangular”—that is, along each axis, every element is the same size. However, there are specialized types of tensors that can handle different shapes:\n\nRagged tensors (see RaggedTensor below)\nSparse tensors (see SparseTensor below)\n\nYou can do basic math on tensors, including addition, element-wise multiplication, and matrix multiplication.\n\na <- as_tensor(1:4, shape = c(2, 2)) \nb <- as_tensor(1L, shape = c(2, 2))\n\na + b # element-wise addition, same as tf$add(a, b)\n\ntf.Tensor(\n[[2 3]\n [4 5]], shape=(2, 2), dtype=int32)\n\na * b # element-wise multiplication, same as tf$multiply(a, b)\n\ntf.Tensor(\n[[1 2]\n [3 4]], shape=(2, 2), dtype=int32)\n\ntf$matmul(a, b) # matrix multiplication\n\ntf.Tensor(\n[[3 3]\n [7 7]], shape=(2, 2), dtype=int32)\n\n\nTensors are used in all kinds of operations (ops).\n\nx <- as_tensor(rbind(c(4, 5), c(10, 1)))\n\n# Find the largest value\n\n# Find the largest value\ntf$reduce_max(x) # can also just call max(c)\n\ntf.Tensor(10.0, shape=(), dtype=float64)\n\n# Find the index of the largest value\ntf$math$argmax(x) \n\ntf.Tensor([1 0], shape=(2), dtype=int64)\n\ntf$nn$softmax(x) # Compute the softmax\n\ntf.Tensor(\n[[2.68941421e-01 7.31058579e-01]\n [9.99876605e-01 1.23394576e-04]], shape=(2, 2), dtype=float64)"
  },
  {
    "objectID": "guides/tensorflow/tensor.html#about-shapes",
    "href": "guides/tensorflow/tensor.html#about-shapes",
    "title": "Introduction to Tensors",
    "section": "About shapes",
    "text": "About shapes\nTensors have shapes. Some vocabulary:\n\nShape: The length (number of elements) of each of the axes of a tensor.\nRank: Number of tensor axes. A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\nAxis or Dimension: A particular dimension of a tensor.\nSize: The total number of items in the tensor, the product of the shape vector’s elements.\n\nNote: Although you may see reference to a “tensor of two dimensions”, a rank-2 tensor does not usually describe a 2D space.\nTensors and tf$TensorShape objects have convenient properties for accessing these:\n\nrank_4_tensor <- tf$zeros(shape(3, 2, 4, 5))\n\n\n\n\nA rank-4 tensor, shape: [3, 2, 4, 5]\n\n\n\n\n\n\n\n\n\nmessage(\"Type of every element: \", rank_4_tensor$dtype)\n\nType of every element: <dtype: 'float32'>\n\nmessage(\"Number of axes: \", length(dim(rank_4_tensor)))\n\nNumber of axes: 4\n\nmessage(\"Shape of tensor: \", dim(rank_4_tensor)) # can also access via rank_4_tensor$shape\n\nShape of tensor: 3245\n\nmessage(\"Elements along axis 0 of tensor: \", dim(rank_4_tensor)[1])\n\nElements along axis 0 of tensor: 3\n\nmessage(\"Elements along the last axis of tensor: \", dim(rank_4_tensor) |> tail(1)) \n\nElements along the last axis of tensor: 5\n\nmessage(\"Total number of elements (3*2*4*5): \", length(rank_4_tensor)) # can also call tf$size()\n\nTotal number of elements (3*2*4*5): 120\n\n\nWhile axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory.\n\n\n\n\n\n\nTypical axis order"
  },
  {
    "objectID": "guides/tensorflow/tensor.html#indexing",
    "href": "guides/tensorflow/tensor.html#indexing",
    "title": "Introduction to Tensors",
    "section": "Indexing",
    "text": "Indexing\n\nSingle-axis indexing\nSee ?`[.tensorflow.tensor` for details\n\n\nMulti-axis indexing\nHigher rank tensors are indexed by passing multiple indices.\nThe exact same rules as in the single-axis case apply to each axis independently.\nRead the tensor slicing guide to learn how you can apply indexing to manipulate individual elements in your tensors."
  },
  {
    "objectID": "guides/tensorflow/tensor.html#manipulating-shapes",
    "href": "guides/tensorflow/tensor.html#manipulating-shapes",
    "title": "Introduction to Tensors",
    "section": "Manipulating Shapes",
    "text": "Manipulating Shapes\nReshaping a tensor is of great utility.\n\n# Shape returns a `TensorShape` object that shows the size along each axis\n\nx <- as_tensor(1:3, shape = c(1, -1)) \nx$shape\n\nTensorShape([1, 3])\n\n\n\n# You can convert this object into an R vector too\nas.integer(x$shape)\n\n[1] 1 3\n\n\nYou can reshape a tensor into a new shape. The tf$reshape operation is fast and cheap as the underlying data does not need to be duplicated.\n\n# You can reshape a tensor to a new shape.\n# Note that you're passing in integers\n\nreshaped <- tf$reshape(x, c(1L, 3L))\n\n\nx$shape\n\nTensorShape([1, 3])\n\nreshaped$shape\n\nTensorShape([1, 3])\n\n\nThe data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style “row-major” memory ordering, where incrementing the rightmost index corresponds to a single step in memory.\n\nrank_3_tensor\n\ntf.Tensor(\n[[[ 0  1  2  3  4]\n  [ 5  6  7  8  9]]\n\n [[10 11 12 13 14]\n  [15 16 17 18 19]]\n\n [[20 21 22 23 24]\n  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n\n\nIf you flatten a tensor you can see what order it is laid out in memory.\n\n# A `-1` passed in the `shape` argument says \"Whatever fits\".\ntf$reshape(rank_3_tensor, c(-1L))\n\ntf.Tensor(\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29], shape=(30), dtype=int32)\n\n\nA typical and reasonable use of tf$reshape is to combine or split adjacent axes (or add/remove 1s).\nFor this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:\n\ntf$reshape(rank_3_tensor, as.integer(c(3*2, 5)))\n\ntf.Tensor(\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]\n [25 26 27 28 29]], shape=(6, 5), dtype=int32)\n\ntf$reshape(rank_3_tensor, as.integer(c(3L, -1L)))\n\ntf.Tensor(\n[[ 0  1  2  3  4  5  6  7  8  9]\n [10 11 12 13 14 15 16 17 18 19]\n [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n\n\n\n\n\n\n\n\nSome good reshapes.\n\n\n\n\n  \n\n\n\nhttps://www.tensorflow.org/guide/images/tensor/reshape-before.png https://www.tensorflow.org/guide/ https://www.tensorflow.org/guide/images/tensor/reshape-good2.png\nReshaping will “work” for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.\nSwapping axes in tf$reshape does not work; you need tf$transpose for that.\n\n# Bad examples: don't do this\n\n# You can't reorder axes with reshape.\ntf$reshape(rank_3_tensor, as.integer(c(2, 3, 5)))\n\ntf.Tensor(\n[[[ 0  1  2  3  4]\n  [ 5  6  7  8  9]\n  [10 11 12 13 14]]\n\n [[15 16 17 18 19]\n  [20 21 22 23 24]\n  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)\n\n# This is a mess\ntf$reshape(rank_3_tensor, as.integer(c(5, 6)))\n\ntf.Tensor(\n[[ 0  1  2  3  4  5]\n [ 6  7  8  9 10 11]\n [12 13 14 15 16 17]\n [18 19 20 21 22 23]\n [24 25 26 27 28 29]], shape=(5, 6), dtype=int32)\n\n# This doesn't work at all\ntry(tf$reshape(rank_3_tensor, as.integer(c(7, -1))))\n\nError in py_call_impl(callable, dots$args, dots$keywords) : \n  tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n\n\n\n\n\n\n\n\nSome bad reshapes.\n\n\n\n\n  \n\n\n\nYou may run across not-fully-specified shapes. Either the shape contains a NULL (an axis-length is unknown) or the whole shape is NULL (the rank of the tensor is unknown).\nExcept for tf$RaggedTensor, such shapes will only occur in the context of TensorFlow’s symbolic, graph-building APIs:\n\ntf_function\nThe keras functional API."
  },
  {
    "objectID": "guides/tensorflow/tensor.html#more-on-dtypes",
    "href": "guides/tensorflow/tensor.html#more-on-dtypes",
    "title": "Introduction to Tensors",
    "section": "More on DTypes",
    "text": "More on DTypes\nTo inspect a tf$Tensor’s data type use the Tensor$dtype property.\nWhen creating a tf$Tensor from a Python object you may optionally specify the datatype.\nIf you don’t, TensorFlow chooses a datatype that can represent your data. TensorFlow converts R integers to tf$int32 and R floating point numbers to tf$float64.\nYou can cast from type to type.\n\nthe_f64_tensor <- as_tensor(c(2.2, 3.3, 4.4), dtype = tf$float64)\nthe_f16_tensor <- tf$cast(the_f64_tensor, dtype = tf$float16)\n# Now, cast to an uint8 and lose the decimal precision\n\nthe_u8_tensor <- tf$cast(the_f16_tensor, dtype = tf$uint8)\nthe_u8_tensor\n\ntf.Tensor([2 3 4], shape=(3), dtype=uint8)"
  },
  {
    "objectID": "guides/tensorflow/tensor.html#broadcasting",
    "href": "guides/tensorflow/tensor.html#broadcasting",
    "title": "Introduction to Tensors",
    "section": "Broadcasting",
    "text": "Broadcasting\nBroadcasting is a concept borrowed from the equivalent feature in NumPy. In short, under certain conditions, smaller tensors are recycled automatically to fit larger tensors when running combined operations on them.\nThe simplest and most common case is when you attempt to multiply or add a tensor to a scalar. In that case, the scalar is broadcast to be the same shape as the other argument.\n\nx <- as_tensor(c(1, 2, 3))\n\ny <- as_tensor(2)\nz <- as_tensor(c(2, 2, 2))\n\n# All of these are the same computation\ntf$multiply(x, 2)\n\ntf.Tensor([2. 4. 6.], shape=(3), dtype=float64)\n\nx * y\n\ntf.Tensor([2. 4. 6.], shape=(3), dtype=float64)\n\nx * z\n\ntf.Tensor([2. 4. 6.], shape=(3), dtype=float64)\n\n\nLikewise, axes with length 1 can be stretched out to match the other arguments. Both arguments can be stretched in the same computation.\nIn this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is [4].\n\n# These are the same computations\n(x <- tf$reshape(x, as.integer(c(3, 1))))\n\ntf.Tensor(\n[[1.]\n [2.]\n [3.]], shape=(3, 1), dtype=float64)\n\n(y <- tf$range(1, 5,  dtype = \"float64\"))\n\ntf.Tensor([1. 2. 3. 4.], shape=(4), dtype=float64)\n\nx * y\n\ntf.Tensor(\n[[ 1.  2.  3.  4.]\n [ 2.  4.  6.  8.]\n [ 3.  6.  9. 12.]], shape=(3, 4), dtype=float64)\n\n\n\n\n\n\n\n\nA broadcasted add: a [3, 1] times a [1, 4] gives a [3,4]\n\n\n\n\n\\\n\n\n\nHere is the same operation without broadcasting:\n\nx_stretch <- as_tensor(rbind(c(1, 1, 1, 1),\n                             c(2, 2, 2, 2),\n                             c(3, 3, 3, 3)))\n\ny_stretch <- as_tensor(rbind(c(1, 2, 3, 4),\n                             c(1, 2, 3, 4),\n                             c(1, 2, 3, 4)))\n\nx_stretch * y_stretch  \n\ntf.Tensor(\n[[ 1.  2.  3.  4.]\n [ 2.  4.  6.  8.]\n [ 3.  6.  9. 12.]], shape=(3, 4), dtype=float64)\n\n\nMost of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory.\nYou see what broadcasting looks like using tf$broadcast_to.\n\ntf$broadcast_to(as_tensor(c(1, 2, 3)), c(3L, 3L))\n\ntf.Tensor(\n[[1. 2. 3.]\n [1. 2. 3.]\n [1. 2. 3.]], shape=(3, 3), dtype=float64)\n\n\nUnlike a mathematical op, for example, broadcast_to does nothing special to save memory. Here, you are materializing the tensor.\nIt can get even more complicated. This section of Jake VanderPlas’s book Python Data Science Handbook shows more broadcasting tricks (again in NumPy)."
  },
  {
    "objectID": "guides/tensorflow/tensor.html#tfconvert_to_tensor",
    "href": "guides/tensorflow/tensor.html#tfconvert_to_tensor",
    "title": "Introduction to Tensors",
    "section": "tf$convert_to_tensor",
    "text": "tf$convert_to_tensor\nMost ops, like tf$matmul and tf$reshape take arguments of class tf$Tensor. However, you’ll notice in the above case, objects shaped like tensors are also accepted.\nMost, but not all, ops call convert_to_tensor on non-tensor arguments. There is a registry of conversions, and most object classes like NumPy’s ndarray, TensorShape, Python lists, and tf$Variable will all convert automatically.\nSee tf$register_tensor_conversion_function for more details, and if you have your own type you’d like to automatically convert to a tensor."
  },
  {
    "objectID": "guides/tensorflow/tensor.html#ragged-tensors",
    "href": "guides/tensorflow/tensor.html#ragged-tensors",
    "title": "Introduction to Tensors",
    "section": "Ragged Tensors",
    "text": "Ragged Tensors\nA tensor with variable numbers of elements along some axis is called “ragged”. Use tf$ragged$RaggedTensor for ragged data.\nFor example, This cannot be represented as a regular tensor:\n\n\n\n\n\n\nA tf$RaggedTensor, shape: [4, NULL]\n\n\n\n\n\n\n\n\n\nragged_list <- list(list(0, 1, 2, 3),\n                    list(4, 5),\n                    list(6, 7, 8),\n                    list(9))\n\n\ntry(tensor <- as_tensor(ragged_list))\n\nError in py_call_impl(callable, dots$args, dots$keywords) : \n  ValueError: Can't convert non-rectangular Python sequence to Tensor.\n\n\nInstead create a tf$RaggedTensor using tf$ragged$constant:\n\n(ragged_tensor <- tf$ragged$constant(ragged_list))\n\n<tf.RaggedTensor [[0.0, 1.0, 2.0, 3.0], [4.0, 5.0], [6.0, 7.0, 8.0], [9.0]]>\n\n\nThe shape of a tf$RaggedTensor will contain some axes with unknown lengths:\n\nprint(ragged_tensor$shape)\n\nTensorShape([4, None])"
  },
  {
    "objectID": "guides/tensorflow/tensor.html#string-tensors",
    "href": "guides/tensorflow/tensor.html#string-tensors",
    "title": "Introduction to Tensors",
    "section": "String tensors",
    "text": "String tensors\ntf$string is a dtype, which is to say you can represent data as strings (variable-length byte arrays) in tensors.\nThe length of the string is not one of the axes of the tensor. See tf$strings for functions to manipulate them.\nHere is a scalar string tensor:\n\n# Tensors can be strings, too here is a scalar string.\n\n(scalar_string_tensor <- as_tensor(\"Gray wolf\"))\n\ntf.Tensor(b'Gray wolf', shape=(), dtype=string)\n\n\nAnd a vector of strings:\n\n\n\n\n\n\nA vector of strings, shape: [3,]\n\n\n\n\n\n\n\n\n\ntensor_of_strings <- as_tensor(c(\"Gray wolf\",\n                                 \"Quick brown fox\",\n                                 \"Lazy dog\"))\n# Note that the shape is (3). The string length is not included.\n\ntensor_of_strings\n\ntf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3), dtype=string)\n\n\nIn the above printout the b prefix indicates that tf$string dtype is not a unicode string, but a byte-string. See the Unicode Tutorial for more about working with unicode text in TensorFlow.\nIf you pass unicode characters they are utf-8 encoded.\n\nas_tensor(\"🥳👍\")\n\ntf.Tensor(b'\\xf0\\x9f\\xa5\\xb3\\xf0\\x9f\\x91\\x8d', shape=(), dtype=string)\n\n\nSome basic functions with strings can be found in tf$strings, including tf$strings$split.\n\n# You can use split to split a string into a set of tensors\ntf$strings$split(scalar_string_tensor, sep=\" \")\n\ntf.Tensor([b'Gray' b'wolf'], shape=(2), dtype=string)\n\n\n\n# ...and it turns into a `RaggedTensor` if you split up a tensor of strings,\n# as each string might be split into a different number of parts.\ntf$strings$split(tensor_of_strings)\n\n<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n\n\n\n\n\n\n\n\nThree strings split, shape: [3, NULL]\n\n\n\n\n\n\n\n\nAnd tf$string$to_number:\n\ntext <- as_tensor(\"1 10 100\")\ntf$strings$to_number(tf$strings$split(text, \" \"))\n\ntf.Tensor([  1.  10. 100.], shape=(3), dtype=float32)\n\n\nAlthough you can’t use tf$cast to turn a string tensor into numbers, you can convert it into bytes, and then into numbers.\n\nbyte_strings <- tf$strings$bytes_split(as_tensor(\"Duck\"))\nbyte_ints <- tf$io$decode_raw(as_tensor(\"Duck\"), tf$uint8)\ncat(\"Byte strings: \"); print(byte_strings)\n\nByte strings: \n\n\ntf.Tensor([b'D' b'u' b'c' b'k'], shape=(4), dtype=string)\n\ncat(\"Bytes: \"); print(byte_ints)\n\nBytes: \n\n\ntf.Tensor([ 68 117  99 107], shape=(4), dtype=uint8)\n\n\n\n# Or split it up as unicode and then decode it\nunicode_bytes <- as_tensor(\"アヒル 🦆\")\nunicode_char_bytes <- tf$strings$unicode_split(unicode_bytes, \"UTF-8\")\nunicode_values <- tf$strings$unicode_decode(unicode_bytes, \"UTF-8\")\n\ncat(\"Unicode bytes: \"); unicode_bytes\n\nUnicode bytes: \n\n\ntf.Tensor(b'\\xe3\\x82\\xa2\\xe3\\x83\\x92\\xe3\\x83\\xab \\xf0\\x9f\\xa6\\x86', shape=(), dtype=string)\n\ncat(\"Unicode chars: \"); unicode_char_bytes\n\nUnicode chars: \n\n\ntf.Tensor([b'\\xe3\\x82\\xa2' b'\\xe3\\x83\\x92' b'\\xe3\\x83\\xab' b' ' b'\\xf0\\x9f\\xa6\\x86'], shape=(5), dtype=string)\n\ncat(\"Unicode values: \"); unicode_values\n\nUnicode values: \n\n\ntf.Tensor([ 12450  12498  12523     32 129414], shape=(5), dtype=int32)\n\n\nThe tf$string dtype is used for all raw bytes data in TensorFlow. The tf$io module contains functions for converting data to and from bytes, including decoding images and parsing csv."
  },
  {
    "objectID": "guides/tensorflow/tensor.html#sparse-tensors",
    "href": "guides/tensorflow/tensor.html#sparse-tensors",
    "title": "Introduction to Tensors",
    "section": "Sparse tensors",
    "text": "Sparse tensors\nSometimes, your data is sparse, like a very wide embedding space. TensorFlow supports tf$sparse$SparseTensor and related operations to store sparse data efficiently.\n\n\n\n\n\n\nA tf$SparseTensor, shape: [3, 4]\n\n\n\n\n\n\n\n\n\n# Sparse tensors store values by index in a memory-efficient manner\nsparse_tensor <- tf$sparse$SparseTensor(\n  indices = rbind(c(0L, 0L),\n                  c(1L, 2L)),\n  values = c(1, 2),\n  dense_shape = as.integer(c(3, 4))\n)\n\nsparse_tensor\n\nSparseTensor(indices=tf.Tensor(\n[[0 0]\n [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2), dtype=int64))\n\n# You can convert sparse tensors to dense\ntf$sparse$to_dense(sparse_tensor)\n\ntf.Tensor(\n[[1. 0. 0. 0.]\n [0. 0. 2. 0.]\n [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)"
  },
  {
    "objectID": "guides/tensorflow/tensor.html#environment-details",
    "href": "guides/tensorflow/tensor.html#environment-details",
    "title": "Introduction to Tensors",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/tensorflow/tensor_slicing.html",
    "href": "guides/tensorflow/tensor_slicing.html",
    "title": "Tensor Slicing",
    "section": "",
    "text": "# Copyright 2020 The TensorFlow Authors.\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License."
  },
  {
    "objectID": "guides/tensorflow/tensor_slicing.html#setup",
    "href": "guides/tensorflow/tensor_slicing.html#setup",
    "title": "Tensor Slicing",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)"
  },
  {
    "objectID": "guides/tensorflow/tensor_slicing.html#extract-tensor-slices",
    "href": "guides/tensorflow/tensor_slicing.html#extract-tensor-slices",
    "title": "Tensor Slicing",
    "section": "Extract tensor slices",
    "text": "Extract tensor slices\nPerform slicing using the [ operator:\n\nt1 <- as_tensor(c(1, 2, 3, 4, 5, 6, 7))\n\nLoaded Tensorflow version 2.9.1\n\nt1[1:3]\n\ntf.Tensor([1. 2. 3.], shape=(3), dtype=float64)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike base R’s [ operator, TensorFlow’s [ uses negative indexes for selecting starting from the end.\nNULL can be used instead of the last dimension or first, depending if it appears before or after the :.\n\n\n\nt1[-3:NULL]\n\nWarning: Negative numbers are interpreted python-style when subsetting tensorflow tensors.\nSee: ?`[.tensorflow.tensor` for details.\nTo turn off this warning, set `options(tensorflow.extract.warn_negatives_pythonic = FALSE)`\n\n\ntf.Tensor([5. 6. 7.], shape=(3), dtype=float64)\n\n\n\nFor 2-dimensional tensors,you can use something like:\n\nt2 <- as_tensor(rbind(c(0, 1, 2, 3, 4),\n                      c(5, 6, 7, 8, 9),\n                      c(10, 11, 12, 13, 14),\n                      c(15, 16, 17, 18, 19)))\n\nt2[NULL:-1, 2:3]\n\ntf.Tensor(\n[[ 1.  2.]\n [ 6.  7.]\n [11. 12.]\n [16. 17.]], shape=(4, 2), dtype=float64)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ntf$slice can be used instead of the [ operator. However, not that when using functions directly from the tf module, dimensions and indexes will start from 0, unlike in R.\nYou also need to make sure that indexes are passed to TensorFlow with the integer type, for example using the L suffix notation.\n\n\nYou can use tf$slice on higher dimensional tensors as well.\n\nt3 <- as_tensor(array(seq(from=1, to = 31, by = 2), dim = c(2,2,4)))\ntf$slice(\n  t3,\n  begin = list(1L, 1L, 0L),\n  size = list(1L, 1L, 2L)\n)\n\ntf.Tensor([[[ 7. 15.]]], shape=(1, 1, 2), dtype=float64)\n\n\nYou can also use tf$strided_slice to extract slices of tensors by ‘striding’ over the tensor dimensions.\nUse tf$gather to extract specific indices from a single axis of a tensor.\n\ntf$gather(t1, indices = c(0L, 3L, 6L))\n\ntf.Tensor([1. 4. 7.], shape=(3), dtype=float64)\n\n\n\ntf$gather does not require indices to be evenly spaced.\n\nalphabet <- as_tensor(strsplit(\"abcdefghijklmnopqrstuvwxyz\", \"\")[[1]])\ntf$gather(alphabet, indices = c(2L, 0L, 19L, 18L))\n\ntf.Tensor([b'c' b'a' b't' b's'], shape=(4), dtype=string)\n\n\n\nTo extract slices from multiple axes of a tensor, use tf$gather_nd. This is useful when you want to gather the elements of a matrix as opposed to just its rows or columns.\n\nt4 <- as_tensor(rbind(c(0, 5),\n                      c(1, 6),\n                      c(2, 7),\n                      c(3, 8),\n                      c(4, 9)))\n\ntf$gather_nd(t4, indices = list(list(2L), list(3L), list(0L)))\n\ntf.Tensor(\n[[2. 7.]\n [3. 8.]\n [0. 5.]], shape=(3, 2), dtype=float64)\n\n\n\n\nt5 <- array(1:18, dim = c(2,3,3))\ntf$gather_nd(t5, indices = list(c(0L, 0L, 0L), c(1L, 2L, 1L)))\n\ntf.Tensor([ 1 12], shape=(2), dtype=int32)\n\n\n\n# Return a list of two matrices\ntf$gather_nd(\n  t5,\n  indices = list(\n    list(c(0L, 0L), c(0L, 2L)), \n    list(c(1L, 0L), c(1L, 2L)))\n)\n\ntf.Tensor(\n[[[ 1  7 13]\n  [ 5 11 17]]\n\n [[ 2  8 14]\n  [ 6 12 18]]], shape=(2, 2, 3), dtype=int32)\n\n\n\n# Return one matrix\ntf$gather_nd(\n  t5,\n  indices = list(c(0L, 0L), c(0L, 2L), c(1L, 0L), c(1L, 2L))\n)\n\ntf.Tensor(\n[[ 1  7 13]\n [ 5 11 17]\n [ 2  8 14]\n [ 6 12 18]], shape=(4, 3), dtype=int32)"
  },
  {
    "objectID": "guides/tensorflow/tensor_slicing.html#insert-data-into-tensors",
    "href": "guides/tensorflow/tensor_slicing.html#insert-data-into-tensors",
    "title": "Tensor Slicing",
    "section": "Insert data into tensors",
    "text": "Insert data into tensors\nUse tf$scatter_nd to insert data at specific slices/indices of a tensor. Note that the tensor into which you insert values is zero-initialized.\n\nt6 <- as_tensor(list(10L))\nindices <- as_tensor(list(list(1L), list(3L), list(5L), list(7L), list(9L)))\ndata <- as_tensor(c(2, 4, 6, 8, 10))\n\ntf$scatter_nd(\n  indices = indices,\n  updates = data,\n  shape = t6\n)\n\ntf.Tensor([ 0.  2.  0.  4.  0.  6.  0.  8.  0. 10.], shape=(10), dtype=float64)\n\n\nMethods like tf$scatter_nd which require zero-initialized tensors are similar to sparse tensor initializers. You can use tf$gather_nd and tf$scatter_nd to mimic the behavior of sparse tensor ops.\nConsider an example where you construct a sparse tensor using these two methods in conjunction.\n\n# Gather values from one tensor by specifying indices\nnew_indices <- as_tensor(rbind(c(0L, 2L), c(2L, 1L), c(3L, 3L)))\nt7 <- tf$gather_nd(t2, indices = new_indices)\n\n\n\n# Add these values into a new tensor\nt8 <- tf$scatter_nd(\n  indices = new_indices, \n  updates = t7, \n  shape = as_tensor(c(4L, 5L))\n)\nt8\n\ntf.Tensor(\n[[ 0.  0.  2.  0.  0.]\n [ 0.  0.  0.  0.  0.]\n [ 0. 11.  0.  0.  0.]\n [ 0.  0.  0. 18.  0.]], shape=(4, 5), dtype=float64)\n\n\nThis is similar to:\n\nt9 <- tf$SparseTensor(\n  indices = list(c(0L, 2L), c(2L, 1L), c(3L, 3L)),\n  values = c(2, 11, 18),\n  dense_shape = c(4L, 5L)\n)\nt9\n\nSparseTensor(indices=tf.Tensor(\n[[0 2]\n [2 1]\n [3 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 2. 11. 18.], shape=(3), dtype=float32), dense_shape=tf.Tensor([4 5], shape=(2), dtype=int64))\n\n\n\n# Convert the sparse tensor into a dense tensor\nt10 <- tf$sparse$to_dense(t9)\nt10\n\ntf.Tensor(\n[[ 0.  0.  2.  0.  0.]\n [ 0.  0.  0.  0.  0.]\n [ 0. 11.  0.  0.  0.]\n [ 0.  0.  0. 18.  0.]], shape=(4, 5), dtype=float32)\n\n\nTo insert data into a tensor with pre-existing values, use tf$tensor_scatter_nd_add.\n\nt11 <- as_tensor(rbind(c(2, 7, 0),\n                       c(9, 0, 1),\n                       c(0, 3, 8)))\n\n# Convert the tensor into a magic square by inserting numbers at appropriate indices\nt12 <- tf$tensor_scatter_nd_add(\n  t11,\n  indices = list(c(0L, 2L), c(1L, 1L), c(2L, 0L)),\n  updates = c(6, 5, 4)\n)\nt12\n\ntf.Tensor(\n[[2. 7. 6.]\n [9. 5. 1.]\n [4. 3. 8.]], shape=(3, 3), dtype=float64)\n\n\nSimilarly, use tf$tensor_scatter_nd_sub to subtract values from a tensor with pre-existing values.\n\n# Convert the tensor into an identity matrix\nt13 <- tf$tensor_scatter_nd_sub(\n  t11,\n  indices = list(c(0L, 0L), c(0L, 1L), c(1L, 0L), c(1L, 1L), c(1L, 2L), c(2L, 1L), c(2L, 2L)),\n  updates = c(1, 7, 9, -1, 1, 3, 7)\n)\n\nprint(t13)\n\ntf.Tensor(\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]], shape=(3, 3), dtype=float64)\n\n\nUse tf$tensor_scatter_nd_min to copy element-wise minimum values from one tensor to another.\n\nt14 <- as_tensor(rbind(c(-2, -7, 0),\n                       c(-9, 0, 1),\n                       c(0, -3, -8)))\n\nt15 <- tf$tensor_scatter_nd_min(\n  t14,\n  indices = list(c(0L, 2L), c(1L, 1L), c(2L, 0L)),\n  updates = c(-6, -5, -4)\n)\nt15\n\ntf.Tensor(\n[[-2. -7. -6.]\n [-9. -5.  1.]\n [-4. -3. -8.]], shape=(3, 3), dtype=float64)\n\n\nSimilarly, use tf$tensor_scatter_nd_max to copy element-wise maximum values from one tensor to another.\n\nt16 <- tf$tensor_scatter_nd_max(\n  t14,\n  indices = list(c(0L, 2L), c(1L, 1L), c(2L, 0L)),\n  updates = c(6, 5, 4)\n)\nt16\n\ntf.Tensor(\n[[-2. -7.  6.]\n [-9.  5.  1.]\n [ 4. -3. -8.]], shape=(3, 3), dtype=float64)"
  },
  {
    "objectID": "guides/tensorflow/tensor_slicing.html#further-reading-and-resources",
    "href": "guides/tensorflow/tensor_slicing.html#further-reading-and-resources",
    "title": "Tensor Slicing",
    "section": "Further reading and resources",
    "text": "Further reading and resources\nIn this guide, you learned how to use the tensor slicing ops available with TensorFlow to exert finer control over the elements in your tensors.\n\nCheck out the slicing ops available with TensorFlow NumPy such as tf$experimental$numpy$take_along_axis and tf$experimental$numpy$take.\nAlso check out the Tensor guide and the Variable guide."
  },
  {
    "objectID": "guides/tensorflow/tensor_slicing.html#environment-details",
    "href": "guides/tensorflow/tensor_slicing.html#environment-details",
    "title": "Tensor Slicing",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "guides/tensorflow/variable.html",
    "href": "guides/tensorflow/variable.html",
    "title": "Introduction to Variables",
    "section": "",
    "text": "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nA TensorFlow variable is the recommended way to represent shared, persistent state your program manipulates. This guide covers how to create, update, and manage instances of tf$Variable in TensorFlow.\nVariables are created and tracked via the tf$Variable class. A tf$Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like tf$keras use tf$Variable to store model parameters."
  },
  {
    "objectID": "guides/tensorflow/variable.html#setup",
    "href": "guides/tensorflow/variable.html#setup",
    "title": "Introduction to Variables",
    "section": "Setup",
    "text": "Setup\nThis notebook discusses variable placement. If you want to see on what device your variables are placed, uncomment this line.\n\nlibrary(tensorflow)\n\n# Uncomment to see where your variables get placed (see below)\n# tf$debugging$set_log_device_placement(TRUE)"
  },
  {
    "objectID": "guides/tensorflow/variable.html#create-a-variable",
    "href": "guides/tensorflow/variable.html#create-a-variable",
    "title": "Introduction to Variables",
    "section": "Create a variable",
    "text": "Create a variable\nTo create a variable, provide an initial value. The tf$Variable will have the same dtype as the initialization value.\n\nmy_tensor <- as_tensor(1:4, \"float32\", shape = c(2, 2))\n\nLoaded Tensorflow version 2.9.1\n\n(my_variable <- tf$Variable(my_tensor))\n\n<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\narray([[1., 2.],\n       [3., 4.]], dtype=float32)>\n\n# Variables can be all kinds of types, just like tensors\n\n(bool_variable <- tf$Variable(c(FALSE, FALSE, FALSE, TRUE)))\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=bool, numpy=array([False, False, False,  True])>\n\n(complex_variable <- tf$Variable(c(5 + 4i, 6 + 1i)))\n\n<tf.Variable 'Variable:0' shape=(2,) dtype=complex128, numpy=array([5.+4.j, 6.+1.j])>\n\n\nA variable looks and acts like a tensor, and, in fact, is a data structure backed by a tf$Tensor. Like tensors, they have a dtype and a shape, and can be exported to regular R arrays.\n\ncat(\"Shape: \"); my_variable$shape\n\nShape: \n\n\nTensorShape([2, 2])\n\ncat(\"DType: \"); my_variable$dtype\n\nDType: \n\n\ntf.float32\n\ncat(\"As R array: \"); str(as.array(my_variable))\n\nAs R array: \n\n\n num [1:2, 1:2] 1 3 2 4\n\n\nMost tensor operations work on variables as expected, although variables cannot be reshaped.\n\nmessage(\"A variable: \")\n\nA variable: \n\nmy_variable\n\n<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\narray([[1., 2.],\n       [3., 4.]], dtype=float32)>\n\nmessage(\"Viewed as a tensor: \")\n\nViewed as a tensor: \n\nas_tensor(my_variable)\n\ntf.Tensor(\n[[1. 2.]\n [3. 4.]], shape=(2, 2), dtype=float32)\n\nmessage(\"Index of highest value: \")\n\nIndex of highest value: \n\ntf$math$argmax(my_variable)\n\ntf.Tensor([1 1], shape=(2), dtype=int64)\n\n# This creates a new tensor; it does not reshape the variable.\nmessage(\"Copying and reshaping: \") \n\nCopying and reshaping: \n\ntf$reshape(my_variable, c(1L, 4L))\n\ntf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n\n\nAs noted above, variables are backed by tensors. You can reassign the tensor using tf$Variable$assign. Calling assign does not (usually) allocate a new tensor; instead, the existing tensor’s memory is reused.\n\na <- tf$Variable(c(2, 3))\n\n# assigning allowed, input is automatically \n# cast to the dtype of the Variable, float32\na$assign(as.integer(c(1, 2)))\n\n<tf.Variable 'UnreadVariable' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n\n# resize the variable is not allowed\ntry(a$assign(c(1.0, 2.0, 3.0)))\n\nError in py_call_impl(callable, dots$args, dots$keywords) : \n  ValueError: Cannot assign value to variable ' Variable:0': Shape mismatch.The variable shape (2,), and the assigned value shape (3,) are incompatible.\n\n\nIf you use a variable like a tensor in operations, you will usually operate on the backing tensor.\nCreating new variables from existing variables duplicates the backing tensors. Two variables will not share the same memory.\n\na <- tf$Variable(c(2, 3))\n# Create b based on the value of a\n\nb <- tf$Variable(a)\na$assign(c(5, 6))\n\n<tf.Variable 'UnreadVariable' shape=(2,) dtype=float32, numpy=array([5., 6.], dtype=float32)>\n\n# a and b are different\n\nas.array(a)\n\n[1] 5 6\n\nas.array(b)\n\n[1] 2 3\n\n# There are other versions of assign\n\nas.array(a$assign_add(c(2,3))) # c(7, 9)\n\n[1] 7 9\n\nas.array(a$assign_sub(c(7,9))) # c(0, 0)\n\n[1] 0 0"
  },
  {
    "objectID": "guides/tensorflow/variable.html#lifecycles-naming-and-watching",
    "href": "guides/tensorflow/variable.html#lifecycles-naming-and-watching",
    "title": "Introduction to Variables",
    "section": "Lifecycles, naming, and watching",
    "text": "Lifecycles, naming, and watching\nIn TensorFlow, tf$Variable instance have the same lifecycle as other R objects. When there are no references to a variable it is automatically deallocated (garbage-collected).\nVariables can also be named which can help you track and debug them. You can give two variables the same name.\n\n# Create a and b; they will have the same name but will be backed by\n# different tensors.\n\na <- tf$Variable(my_tensor, name = \"Mark\")\n# A new variable with the same name, but different value\n\n# Note that the scalar add `+` is broadcast\nb <- tf$Variable(my_tensor + 1, name = \"Mark\")\n\n# These are elementwise-unequal, despite having the same name\nprint(a == b)\n\ntf.Tensor(\n[[False False]\n [False False]], shape=(2, 2), dtype=bool)\n\n\nVariable names are preserved when saving and loading models. By default, variables in models will acquire unique variable names automatically, so you don’t need to assign them yourself unless you want to.\nAlthough variables are important for differentiation, some variables will not need to be differentiated. You can turn off gradients for a variable by setting trainable to false at creation. An example of a variable that would not need gradients is a training step counter.\n\n(step_counter <- tf$Variable(1L, trainable = FALSE))\n\n<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>"
  },
  {
    "objectID": "guides/tensorflow/variable.html#placing-variables-and-tensors",
    "href": "guides/tensorflow/variable.html#placing-variables-and-tensors",
    "title": "Introduction to Variables",
    "section": "Placing variables and tensors",
    "text": "Placing variables and tensors\nFor better performance, TensorFlow will attempt to place tensors and variables on the fastest device compatible with its dtype. This means most variables are placed on a GPU if one is available.\nHowever, you can override this. In this snippet, place a float tensor and a variable on the CPU, even if a GPU is available. By turning on device placement logging (see above), you can see where the variable is placed.\nNote: Although manual placement works, using distribution strategies can be a more convenient and scalable way to optimize your computation.\nIf you run this notebook on different backends with and without a GPU you will see different logging. Note that logging device placement must be turned on at the start of the session.\n\nwith(tf$device('CPU:0'), {\n  # Create some tensors\n  a <- tf$Variable(array(1:6, c(2, 3)), dtype = \"float32\")\n  b <- as_tensor(array(1:6, c(3, 2)), dtype = \"float32\")\n  c <- tf$matmul(a, b)\n})\n\nc\n\ntf.Tensor(\n[[22. 49.]\n [28. 64.]], shape=(2, 2), dtype=float32)\n\n\nIt’s possible to set the location of a variable or tensor on one device and do the computation on another device. This will introduce delay, as data needs to be copied between the devices.\nYou might do this, however, if you had multiple GPU workers but only want one copy of the variables.\n\nwith(tf$device('CPU:0'), {\n  a <- tf$Variable(array(1:6, c(2, 3)), dtype = \"float32\")\n  b <- tf$Variable(array(1:3, c(1, 3)), dtype = \"float32\")\n})\n\nwith(tf$device('GPU:0'), {\n  # Element-wise multiply\n  k <- a * b\n})\n\nk\n\ntf.Tensor(\n[[ 1.  6. 15.]\n [ 2.  8. 18.]], shape=(2, 3), dtype=float32)\n\n\nNote: Because tf$config$set_soft_device_placement() is turned on by default, even if you run this code on a device without a GPU, it will still run. The multiplication step will happen on the CPU.\nFor more on distributed training, refer to the guide."
  },
  {
    "objectID": "guides/tensorflow/variable.html#next-steps",
    "href": "guides/tensorflow/variable.html#next-steps",
    "title": "Introduction to Variables",
    "section": "Next steps",
    "text": "Next steps\nTo understand how variables are typically used, see our guide on automatic differentiation."
  },
  {
    "objectID": "guides/tensorflow/variable.html#environment-details",
    "href": "guides/tensorflow/variable.html#environment-details",
    "title": "Introduction to Variables",
    "section": "Environment Details",
    "text": "Environment Details\n\n\n\n\n\n\nTensorflow Version\n\n\n\n\n\n\ntensorflow::tf_version()\n\n[1] '2.9'\n\n\n\n\n\n\n\n\n\n\n\nR Environment Information\n\n\n\n\n\n\nSys.info()\n\n                                                                                           sysname \n                                                                                          \"Darwin\" \n                                                                                           release \n                                                                                          \"21.4.0\" \n                                                                                           version \n\"Darwin Kernel Version 21.4.0: Mon Feb 21 20:34:37 PST 2022; root:xnu-8020.101.4~2/RELEASE_X86_64\" \n                                                                                          nodename \n                                                                       \"Daniels-MacBook-Pro.local\" \n                                                                                           machine \n                                                                                          \"x86_64\" \n                                                                                             login \n                                                                                            \"root\" \n                                                                                              user \n                                                                                         \"dfalbel\" \n                                                                                    effective_user \n                                                                                         \"dfalbel\""
  },
  {
    "objectID": "install/custom.html",
    "href": "install/custom.html",
    "title": "Custom Installation",
    "section": "",
    "text": "The install_tensorflow() function is provided as a convenient way to get started, but is not required. If you have an existing installation of TensorFlow or just prefer your own custom installation that’s fine too.\nThe full instructions for installing TensorFlow on various platforms are here: https://www.tensorflow.org/install/. After installing, please refer to the sections below on locating TensorFlow and meeting additional dependencies to ensure that the tensorflow for R package functions correctly with your installation."
  },
  {
    "objectID": "install/custom.html#supported-platforms",
    "href": "install/custom.html#supported-platforms",
    "title": "Custom Installation",
    "section": "Supported Platforms",
    "text": "Supported Platforms\nNote that binary installations of TensorFlow are provided for Windows, OS X, and Ubuntu 16.04 or higher. It’s possible that binary installations will work on other Linux variants but Ubuntu is the only platform tested and supported.\nIn particular, if you are running on RedHat or CentOS you will need to install from source then follow the instructions in the [Custom Installation] section to ensure that your installation of TensorFlow can be used with the tensorflow R package."
  },
  {
    "objectID": "install/gpu/cloud_desktop_gpu/index.html",
    "href": "install/gpu/cloud_desktop_gpu/index.html",
    "title": "Cloud Desktop GPUs",
    "section": "",
    "text": "Cloud desktops with various GPU configurations are available from Paperspace. With Paperspace, you can access a full Linux desktop running Ubuntu 16.04 all from within a web browser. An SSH interface is also available, as is a browser based RStudio Server interface (via SSH tunnel).\nPaperspace offers an RStudio TensorFlow template with NVIDIA GPU libraries (CUDA 8.0 and cuDNN 6.0) pre-installed, along with the GPU version of TensorFlow v1.4 and the R keras, tfestimators, and tensorflow packages. Follow the instructions below to get started with using RStudio on Paperspace."
  },
  {
    "objectID": "install/gpu/cloud_desktop_gpu/index.html#getting-started",
    "href": "install/gpu/cloud_desktop_gpu/index.html#getting-started",
    "title": "Cloud Desktop GPUs",
    "section": "Getting Started",
    "text": "Getting Started\nTo get started, sign up for a Paperspace account here: https://www.paperspace.com/account/signup (you can use the RSTUDIO promo code when you sign up to receive a $5 account credit).\n\nAfter you’ve signed up and verified your account email, you will be taken to a Create Machine page. Here you’ll select various options including your compute region and machine template. You should select the RStudio template:\n\nBe sure to select one of the GPU instances (as opposed to the CPU instances). For example, here we select the P4000 machine type which includes an NVIDIA Quadro P4000 GPU:\n\nAfter your machine is provisioned (this can take a few minutes) you are ready to access it via a web browser. Hover over the machine in the Paperspace Console and click the “Launch” link:\n\nAfter the machine is launched you’ll see your Linux desktop within the browser you launched it from. You may need to use the Scaling Settings to adjust the desktop to a comfortable resolution:\n\nYou should also change your default password using the passwd utility (your default password should have been sent to you in an email titled “Your new Paperspace Linux machine is ready”):\n\nYou now have a Linux desktop equipped ready to use with TensorFlow for R! Go ahead and run RStudio from the application bar:\n\nNVIDIA GPU libraries (CUDA 9 and cuDNN 7) are pre-installed, along with the GPU version of TensorFlow v1.7. The R keras, tfestimators, and tensorflow packages are also pre-installed, as are all of the packages from the [tidyverse[(https://www.tidyverse.org/)] (dplyr, ggplot2, etc.).\nAn important note about the pre-installed dependencies: Since the NVIDIA CUDA libraries, TensorFlow, and Keras are all pre-installed on the Paperspace instances, you should not use the install_tensorflow() or install_keras() functions, but rather rely on the existing, pre-configured versions of these libraries. Installing or updating other versions of these libraries will likely not work at all!"
  },
  {
    "objectID": "install/gpu/cloud_desktop_gpu/index.html#automatic-shutdown",
    "href": "install/gpu/cloud_desktop_gpu/index.html#automatic-shutdown",
    "title": "Cloud Desktop GPUs",
    "section": "Automatic Shutdown",
    "text": "Automatic Shutdown\nYou can set Paperspace machines to automatically shutdown when they have not been used for a set period of time (this is especially important since machine time is billed by the hour). You can access this setting from the Paperspace console for your machine:\n\nHere the auto-shutdown time is set to 1 day, however you can also choose shorter or longer intervals."
  },
  {
    "objectID": "install/gpu/cloud_desktop_gpu/index.html#terminal-access",
    "href": "install/gpu/cloud_desktop_gpu/index.html#terminal-access",
    "title": "Cloud Desktop GPUs",
    "section": "Terminal Access",
    "text": "Terminal Access\n\nWeb Terminal\nYou can use the Open Terminal command on the Paperspace console for your machine to open a web based terminal to your machine:\n\nYou’ll need to login using either the default password emailed to you when you created the machine or to the new password which you subsequently created.\n\n\nSSH Login\nYou can also login to your Paperspace instance using a standard SSH client. This requires that you first Assign a public IP address to your machine (note that public IP addresses cost an additional $3/month).\nOnce you have your public IP address, you can SSH into your machine as follows:\n$ ssh paperspace@<public IP>\nYou’ll need to login using either the default password emailed to you when you created the machine or to the new password which you subsequently created."
  },
  {
    "objectID": "install/gpu/cloud_desktop_gpu/index.html#rstudio-server",
    "href": "install/gpu/cloud_desktop_gpu/index.html#rstudio-server",
    "title": "Cloud Desktop GPUs",
    "section": "RStudio Server",
    "text": "RStudio Server\nYou may prefer using the RStudio Server browser-based interface to the virtual Linux desktop provided by Paperspace (especially when on slower internet connections). This section describes how to access your Paperspace machine using an SSH tunnel.\nTo start with, follow the instructions for SSH Login immediately above and ensure that you can login to your machine remotely via SSH.\nOnce you’ve verified this, you should also be able to setup an SSH tunnel to RStudio Server as follows:\n$ ssh -N -L 8787:127.0.0.1:8787 paperspace@<public-ip>\nYou can access RStudio Server by navigating to port 8787 on your local machine and logging in using the paperspace account and either the default password emailed to you when you created the machine or to the new password which you subsequently created.\nhttp://localhost:8787"
  },
  {
    "objectID": "install/gpu/cloud_server_gpu/index.html",
    "href": "install/gpu/cloud_server_gpu/index.html",
    "title": "Cloud Server GPUs",
    "section": "",
    "text": "Cloud server instances with GPUs are available from services like Amazon EC2 and Google Compute Engine. You can use RStudio Server on these instances, making the development experience nearly identical to working locally."
  },
  {
    "objectID": "install/gpu/cloud_server_gpu/index.html#amazon-ec2",
    "href": "install/gpu/cloud_server_gpu/index.html#amazon-ec2",
    "title": "Cloud Server GPUs",
    "section": "Amazon EC2",
    "text": "Amazon EC2\nRStudio has AWS Marketplace offerings that are designed to provide stable, secure, and high performance execution environments for deep learning applications running on Amazon EC2. The tensorflow, tfestimators, and keras R packages (along with their pre-requisites, including the GPU version of TensorFlow) are installed as part of the image.\n\nLaunching the Server\nThere are AMIs on the Amazon Cloud Marketplace for both the open-source and Professional versions of RStudio Server. You can find them here:\n\nOpen Source: https://aws.amazon.com/marketplace/pp/B0785SXYB2\nProfessional: https://aws.amazon.com/marketplace/pp/B07B8G3FZP\n\nYou should launch these AMIs on the p2.xlarge instance type. This type includes a single GPU whereas other GPU-based images include up to 16 GPUs (however they are commensurately much more expensive). Note that you may need to select a different region than your default to be able to launch p2.xlarge instances (for example, selecting “US East (Ohio)” rather than “US East (N Virginia)”).\n\n\n\nAccessing the Server\nAfter you’ve launched the server you can access an instance of RStudio Server running on port 8787. For example:\nhttp://ec2-18-217-204-43.us-east-2.compute.amazonaws.com:8787\nNote that the above server address needs to be substituted for the public IP of the server you launched, which you can find in the EC2 Dashboard.\nThe first time you access the server you will be presented with a login screen:\n\nLogin with user id “rstudio-user” and password the instance ID of your AWS server (for example “i-0a8ea329c18892dfa”, your specific ID is available via the EC2 dashboard).\nThen, use the RStudio Terminal to change the default password using the passwd utility:\n\nYour EC2 deep learning instance is now ready to use (the tensorflow, tfestimators, and keras R packages along with their pre-requisites, including the GPU version of TensorFlow, are installed as part of the image).\nSee the sections below for discussion of various ways in which you can make your EC2 instance more secure.\n\n\nLimiting Inbound Traffic\nThe EC2 instance is by default configured to allow access to SSH and HTTP traffic from all IP addresses on the internet, whereas it would be more desirable to restrict this to IP addresses that you know you will access the server from (this can however be challenging if you plan on accessing the server from a variety of public networks).\nYou can see these settings in the Security Group of your EC2 instance:\n\nEdit the Source for the SSH and HTTP protocols to limit access to specific blocks of IP addresses.\n\n\nUsing HTTPS\nBy default the EC2 instance which you launched is accessed over HTTP, a non-encrypted channel. This means that data transmitted to the instance (including your username and password) can potentially be compromised during transmission.\nThere are many ways to add HTTPS support to a server including AWS Elastic Load Balancing, CloudFlare SSL, and setting up reverse proxy from an Nginx or Apache web server configured with SSL support.\nThe details of adding HTTPS support to your server are beyond the scope of this article (see the links above to learn more). An alternative to this is to prohibit external HTTP connections entirely and access the server over an SSH Tunnel, this option is covered in the next section.\n\n\nSSH Tunnel\nUsing an SSH Tunnel to access your EC2 instance provides a number of benefits, including:\n\nUse of the SSH authentication protocol to identify and authorize remote users\nEncrypting traffic that would otherwise be sent in the clear\n\nNote that SSH tunnel access as described below works only for Linux and OS X clients.\n\nSecurity Group\nTo use an SSH Tunnel with your EC2 instance, first configure the Security Group of your instance to only accept SSH traffic (removing any HTTP entry that existed previously):\n\nNote that you may also want to restrict the Source of SSH traffic to the specific block of IP addresses you plan to access the server from.\n\n\nServer Configuration\nNext, connect to your instance over SSH (click the Connect button in the EC2 console for instructions specific to your server):\nssh -i \"my-security-key.pem\" ubuntu@my-ec2-server-address\nNote that if you copied and pasted the command from the EC2 console you may see this error message:\nPlease login as the user \"ubuntu\" rather than the user \"root\".\nIn that case be sure that you use ubuntu@my-ec2-server-address rather than root@my-ec2-server-address.\nExecute the following commands to configure RStudio Server to only accept local connections:\n# Configure RStudio to only allow local connections \nsudo /bin/bash -c \"echo 'www-address=127.0.0.1' >> /etc/rstudio/rserver.conf\"\n\n# Restart RStudio with new settings\nsudo rstudio-server restart\n\n\nConnecting to the Server\nYou should now be able to connect to the server via SSH tunnel as follows:\nssh -N -L 8787:localhost:8787 -i my-security-key.pem ubuntu@my-ec2-server-address\n(where my-security-key.pem and my-ec2-server-address are specific to your server configuration).\nOnce the SSH connection is established, RStudio Server will be available at http://localhost:8787/"
  },
  {
    "objectID": "install/gpu/index.html",
    "href": "install/gpu/index.html",
    "title": "Overview",
    "section": "",
    "text": "If your local workstation doesn’t already have a GPU that you can use for deep learning (a recent, high-end NVIDIA GPU), then running deep learning experiments in the cloud is a simple, low-cost way for you to get started without having to buy any additional hardware. See the documentation below for details on using both local and cloud GPUs.\n\n\n\n\n\n\n\nLocal GPU\nFor systems that have a recent, high-end NVIDIA® GPU, TensorFlow is available in a GPU version that takes advantage of the CUDA and cuDNN libraries to accelerate training performance. Note that the GPU version of TensorFlow is currently only supported on Windows and Linux (there is no GPU version available for Mac OS X since NVIDIA GPUs are not commonly available on that platform).\n\n\nCloudML\nGoogle CloudML is a managed service that provides on-demand access to training on GPUs, including the new Tesla P100 GPUs from NVIDIA. CloudML also provides hyperparameter tuning to optmize key attributes of model architectures in order to maximize predictive accuracy.\n\n\nCloud Server\nCloud server instances with GPUs are available from services like Amazon EC2 and Google Compute Engine. You can use RStudio Server on these instances, making the development experience nearly identical to working locally.\n\n\nCloud Desktop\nVirtual cloud desktops with GPUs are available from Paperspace. This provides an Ubuntu 16.04 desktop environment that you can access entirely within a web browser (note that this requires a reasonbly fast internet connection to be usable)."
  },
  {
    "objectID": "install/gpu/local_gpu/index.html",
    "href": "install/gpu/local_gpu/index.html",
    "title": "Local GPU",
    "section": "",
    "text": "TensorFlow can be configured to run on either CPUs or GPUs. The CPU version is much easier to install and configure so is the best starting place especially when you are first learning how to use TensorFlow. Here’s the guidance on CPU vs. GPU versions from the TensorFlow website:\n\nTensorFlow with CPU support only. If your system does not have a NVIDIA® GPU, you must install this version. Note that this version of TensorFlow is typically much easier to install (typically, in 5 or 10 minutes), so even if you have an NVIDIA GPU, we recommend installing this version first.\nTensorFlow with GPU support. TensorFlow programs typically run significantly faster on a GPU than on a CPU. Therefore, if your system has a NVIDIA® GPU meeting the prerequisites shown below and you need to run performance-critical applications, you should ultimately install this version.\n\nSo if you are just getting started with TensorFlow you may want to stick with the CPU version to start out, then install the GPU version once your training becomes more computationally demanding.\nThe prerequisites for the GPU version of TensorFlow on each platform are covered below. Once you’ve met the prerequisites installing the GPU version in a single-user / desktop environment is as simple as:\n\nlibrary(tensorflow)\ninstall_tensorflow(version = \"gpu\")\n\nIf you are using Keras you can install both Keras and the GPU version of TensorFlow with:\n\nlibrary(keras)\ninstall_keras(tensorflow = \"gpu\")\n\nNote that on all platforms you must be running an NVIDIA® GPU with CUDA® Compute Capability 3.5 or higher in order to run the GPU version of TensorFlow. See the list of CUDA-enabled GPU cards."
  },
  {
    "objectID": "install/gpu/local_gpu/index.html#prerequisties",
    "href": "install/gpu/local_gpu/index.html#prerequisties",
    "title": "Local GPU",
    "section": "Prerequisties",
    "text": "Prerequisties\n\nWindows\nThis article describes how to detect whether your graphics card uses an NVIDIA® GPU:\nhttp://nvidia.custhelp.com/app/answers/detail/a_id/2040/~/identifying-the-graphics-card-model-and-device-id-in-a-pc\nOnce you’ve confirmed that you have an NVIDIA® GPU, the following article describes how to install required software components including the CUDA Toolkit v10.0, required NVIDIA® drivers, and cuDNN >= v7.4.1:\nhttps://www.tensorflow.org/install/gpu#hardware_requirements\nNote that the documentation on installation of the last component (cuDNN v7.4.1) is a bit sparse. Once you join the NVIDIA® developer program and download the zip file containing cuDNN you need to extract the zip file and add the location where you extracted it to your system PATH.\n\n\nUbuntu\nThis article describes how to install required software components including the CUDA Toolkit v10.0, required NVIDIA® drivers, and cuDNN >= v7.4.1:\nhttps://www.tensorflow.org/install/install_linux#nvidia_requirements_to_run_tensorflow_with_gpu_support\nThe specifics of installing required software differ by Linux version so please review the NVIDIA® documentation carefully to ensure you install everything correctly.\nThe following section provides as example of the installation commands you might use on Ubuntu 16.04.\n\nUbuntu 16.04 Example\nFirst, install the NVIDIA drivers:\n# Add NVIDIA package repositories\n# Add HTTPS support for apt-key\nsudo apt-get install gnupg-curl\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.0.130-1_amd64.deb\nsudo dpkg -i cuda-repo-ubuntu1604_10.0.130-1_amd64.deb\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\nsudo apt-get update\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\nsudo apt-get update\n\n# Install NVIDIA driver\n# Issue with driver install requires creating /usr/lib/nvidia\nsudo mkdir /usr/lib/nvidia\nsudo apt-get install --no-install-recommends nvidia-410\n# Reboot. Check that GPUs are visible using the command: nvidia-smi\nNext install CUDA Toolkit v10.0 and cuDNN v7.4.1 with:\n# Install development and runtime libraries (~4GB)\nsudo apt-get install --no-install-recommends \\\n    cuda-10-0 \\\n    libcudnn7=7.4.1.5-1+cuda10.0  \\\n    libcudnn7-dev=7.4.1.5-1+cuda10.0\nNote that it’s important to download CUDA 10.0 (rather than CUDA 10.1, which may be the choice initially presented) as v10.0 is what TensorFlow is built against.\nYou can see more for the installation here.\n\n\nEnvironment Variables\nOn Linux, part of the setup for CUDA libraries is adding the path to the CUDA binaries to your PATH and LD_LIBRARY_PATH as well as setting the CUDA_HOME environment variable. You will set these variables in distinct ways depending on whether you are installing TensorFlow on a single-user workstation or on a multi-user server. If you are running RStudio Server there is some additional setup required which is also covered below.\nIn all cases these are the environment variables that need to be set/modified in order for TensorFlow to find the required CUDA libraries. For example (paths will change depending on your specific installation of CUDA):\nexport CUDA_HOME=/usr/local/cuda\nexport LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${CUDA_HOME}/lib64 \nPATH=${CUDA_HOME}/bin:${PATH} \nexport PATH\n\n\nSingle-User Installation\nIn a single-user environment (e.g. a desktop system) you should define the environment variables within your ~/.profile file. It’s necessary to use ~/.profile rather than ~/.bashrc, because ~/.profile is read by desktop applications (e.g. RStudio) as well as terminal sessions whereas ~/.bashrc applies only to terminal sessions.\nNote that you need to restart your system after editing the ~/.profile file for the changes to take effect. Note also that the ~/.profile file will not be read by bash if you have either a ~/.bash_profile or ~/.bash_login file.\nTo summarize the recommendations above:\n\nDefine CUDA related environment variables in ~/.profile rather than ~/.bashrc;\nEnsure that you don’t have either a ~/.bash_profile or ~/.bash_login file (as these will prevent bash from seeing the variables you’ve added into ~/.profile);\nRestart your system after editing ~/.profile so that the changes take effect.\n\n\n\nMulti-User Installation\nIn a multi-user installation (e.g. a server) you should define the environment variables within the system-wide bash startup file (/etc/profile) so all users have access to them.\nIf you are running RStudio Server you need to also provide these variable definitions in an R / RStudio specific fashion (as RStudio Server doesn’t execute system profile scripts for R sessions).\nTo modify the LD_LIBRARY_PATH you use the rsession-ld-library-path in the /etc/rstudio/rserver.conf configuration file\n/etc/rstudio/rserver.conf\nrsession-ld-library-path=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\nYou should set the CUDA_HOME and PATH variables in the /usr/lib/R/etc/Rprofile.site configuration file:\n/usr/lib/R/etc/Rprofile.site\nSys.setenv(CUDA_HOME=\"/usr/local/cuda\")\nSys.setenv(PATH=paste(Sys.getenv(\"PATH\"), \"/usr/local/cuda/bin\", sep = \":\"))\nIn a server environment you might also find it more convenient to install TensorFlow into a system-wide location where all users of the server can share access to it. Details on doing this are covered in the multi-user installation section below.\n\n\n\nMac OS X\nAs of version 1.2 of TensorFlow, GPU support is no longer available on Mac OS X. If you want to use a GPU on Mac OS X you will need to install TensorFlow v1.1 as follows:\n\nlibrary(tensorflow)\ninstall_tensorflow(version = \"1.1-gpu\")\n\nHowever, before you install you should ensure that you have an NVIDIA® GPU and that you have the required CUDA libraries on your system.\nWhile some older Macs include NVIDIA® GPU’s, most Macs (especially newer ones) do not, so you should check the type of graphics card you have in your Mac before proceeding.\nHere is a list of Mac systems which include built in NVIDIA GPU’s:\nhttps://support.apple.com/en-us/HT204349\nYou can check which graphics card your Mac has via the System Report button found within the About This Mac dialog:\n\nThe MacBook Pro system displayed above does not have an NVIDIA® GPU installed (rather it has an Intel Iris Pro).\nIf you do have an NVIDIA® GPU, the following article describes how to install the base CUDA libraries:\nhttp://docs.nvidia.com/cuda/cuda-installation-guide-mac-os-x/index.html\nYou also need to intall the cuDNN library 5.1 library for OS X from here:\nhttps://developer.nvidia.com/cudnn\nAfter installing these components, you need to ensure that both CUDA and cuDNN are available to your R session via the DYLD_LIBRARY_PATH. This typically involves setting environment variables in your .bash_profile as described in the NVIDIA documentation for CUDA and cuDNN.\nNote that environment variables set in .bash_profile will not be available by default to OS X desktop applications like R GUI and RStudio. To use CUDA within those environments you should start the application from a system terminal as follows:\nopen -a R         # R GUI\nopen -a RStudio   # RStudio"
  },
  {
    "objectID": "install/gpu/local_gpu/index.html#installation",
    "href": "install/gpu/local_gpu/index.html#installation",
    "title": "Local GPU",
    "section": "Installation",
    "text": "Installation\n\nSingle User\nIn a single-user desktop environment you can install TensorFlow with GPU support via:\n\nlibrary(tensorflow)\ninstall_tensorflow(version = \"gpu\")\n\nIf this version doesn’t load successfully you should review the prerequisites above and ensure that you’ve provided definitions of CUDA environment variables as recommended above.\nSee the main installation article for details on other available options (e.g. virtualenv vs. conda installation, installing development versions, etc.).\n\n\nMultiple Users\nIn a multi-user server environment you may want to install a system-wide version of TensorFlow with GPU support so all users can share the same configuration. To do this, start by following the directions for native pip installation of the GPU version of TensorFlow here:\nhttps://www.tensorflow.org/install/install_linux#InstallingNativePip\nThere are some components of TensorFlow (e.g. the Keras library) which have dependencies on additional Python packages.\nYou can install Keras and it’s optional dependencies with the following command (ensuring you have the correct privilege to write to system library locations as required via sudo, etc.):\npip install keras h5py pyyaml requests Pillow scipy\nIf you have any trouble with locating the system-wide version of TensorFlow from within R please see the section on locating TensorFlow."
  },
  {
    "objectID": "install/index.html",
    "href": "install/index.html",
    "title": "Quick start",
    "section": "",
    "text": "Prior to using the tensorflow R package you need to install a version of TensorFlow on your system. Below we describe how to install TensorFlow as well the various options available for customizing your installation.\nNote that this article principally covers the use of the R install_tensorflow() function, which provides an easy to use wrapper for the various steps required to install TensorFlow.\nYou can also choose to install TensorFlow manually (as described at https://www.tensorflow.org/install/). In that case the Custom Installation section covers how to arrange for the tensorflow R package to use the version you installed.\nTensorFlow is tested and supported on the following 64-bit systems:"
  },
  {
    "objectID": "install/index.html#installation",
    "href": "install/index.html#installation",
    "title": "Quick start",
    "section": "Installation",
    "text": "Installation\nFirst, install the tensorflow R package from GitHub as follows:\n\ninstall.packages(\"tensorflow\")\n\nNext, configure R (reticulate) with a Python installation it can use, like this:\n\nlibrary(reticulate)\npath_to_python <- install_python()\nvirtualenv_create(\"r-reticulate\", python = path_to_python)\n\nThen, use the install_tensorflow() function to install TensorFlow.\n\nlibrary(tensorflow)\ninstall_tensorflow(envname = \"r-reticulate\")\n\nYou can confirm that the installation succeeded with:\n\nlibrary(tensorflow)\ntf$constant(\"Hello Tensorflow\")\n\nLoaded Tensorflow version 2.9.1\n\n\ntf.Tensor(b'Hello Tensorflow', shape=(), dtype=string)\n\n\nThis will provide you with a default installation of TensorFlow suitable for use with the tensorflow R package. Read on if you want to learn about additional installation options, including installing a version of TensorFlow that takes advantage of Nvidia GPUs if you have the correct CUDA libraries installed."
  },
  {
    "objectID": "install/index.html#installation-methods",
    "href": "install/index.html#installation-methods",
    "title": "Quick start",
    "section": "Installation methods",
    "text": "Installation methods\nTensorFlow is distributed as a Python package and so needs to be installed within a Python environment on your system. By default, the install_tensorflow() function attempts to install TensorFlow within an isolated Python environment (“r-reticulate”).\nThese are the available methods and their behavior:\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nauto\nAutomatically choose an appropriate default for the current platform.\n\n\nvirtualenv\nInstall into a Python virtual environment at ~/.virtualenvs/r-reticulate\n\n\nconda\nInstall into an Anaconda Python environment named r-reticulate\n\n\nsystem\nInstall into the system Python environment\n\n\n\ninstall_tensorflow is a wrapper around reticulate::py_install. Please refer to ‘Installing Python Packages’ for more information."
  },
  {
    "objectID": "install/index.html#alternate-versions",
    "href": "install/index.html#alternate-versions",
    "title": "Quick start",
    "section": "Alternate Versions",
    "text": "Alternate Versions\nBy default, install_tensorflow() install the latest release version of TensorFlow. You can override this behavior by specifying the version parameter. For example:\n\ninstall_tensorflow(version = \"2.7\")\n\nNote that you can provide a full major.minor.patch version specification, or just a major.minor specification, in which case the latest patch is automatically selected.\nYou can install the nightly build of TensorFlow (CPU or GPU version) with:\n\ninstall_tensorflow(version = \"nightly\")      # cpu+gpu version\ninstall_tensorflow(version = \"nightly-cpu\")  # cpu version\n\nYou can install any other build of TensorFlow by specifying a URL to a TensorFlow binary. For example:\n\ninstall_tensorflow(version = \"https://files.pythonhosted.org/packages/c2/c1/a035e377cf5a5b90eff27f096448fa5c5a90cbcf13b7eb0673df888f2c2d/tf_nightly-1.12.0.dev20180918-cp36-cp36m-manylinux1_x86_64.whl\")"
  },
  {
    "objectID": "tutorials/keras/classification.html",
    "href": "tutorials/keras/classification.html",
    "title": "Basic Image Classification",
    "section": "",
    "text": "In this guide, we will train a neural network model to classify images of clothing, like sneakers and shirts. It’s fine if you don’t understand all the details, this is a fast-paced overview of a complete Keras program with the details explained as we go."
  },
  {
    "objectID": "tutorials/keras/classification.html#import-the-fashion-mnist-dataset",
    "href": "tutorials/keras/classification.html#import-the-fashion-mnist-dataset",
    "title": "Basic Image Classification",
    "section": "Import the Fashion MNIST dataset",
    "text": "Import the Fashion MNIST dataset\nThis guide uses the Fashion MNIST dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n\n\n\nFigure 1. Fashion-MNIST samples (by Zalando, MIT License).\n\n\nFashion MNIST is intended as a drop-in replacement for the classic MNIST dataset—often used as the “Hello, World” of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we’ll use here.\nThis guide uses Fashion MNIST for variety, and because it’s a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They’re good starting points to test and debug code.\nWe will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from Keras.\n\nfashion_mnist <- dataset_fashion_mnist()\n\nLoaded Tensorflow version 2.9.1\n\nc(train_images, train_labels) %<-% fashion_mnist$train\nc(test_images, test_labels) %<-% fashion_mnist$test\n\nAt this point we have four arrays: The train_images and train_labels arrays are the training set — the data the model uses to learn. The model is tested against the test set: the test_images, and test_labels arrays.\nThe images each are 28 x 28 arrays, with pixel values ranging between 0 and 255. The labels are arrays of integers, ranging from 0 to 9. These correspond to the class of clothing the image represents:\n\n\n\nDigit\nClass\n\n\n\n\n0\nT-shirt/top\n\n\n1\nTrouser\n\n\n2\nPullover\n\n\n3\nDress\n\n\n4\nCoat\n\n\n5\nSandal\n\n\n6\nShirt\n\n\n7\nSneaker\n\n\n8\nBag\n\n\n9\nAnkle boot\n\n\n\nEach image is mapped to a single label. Since the class names are not included with the dataset, we’ll store them in a vector to use later when plotting the images.\n\nclass_names = c('T-shirt/top',\n                'Trouser',\n                'Pullover',\n                'Dress',\n                'Coat', \n                'Sandal',\n                'Shirt',\n                'Sneaker',\n                'Bag',\n                'Ankle boot')"
  },
  {
    "objectID": "tutorials/keras/classification.html#explore-the-data",
    "href": "tutorials/keras/classification.html#explore-the-data",
    "title": "Basic Image Classification",
    "section": "Explore the data",
    "text": "Explore the data\nLet’s explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels:\n\ndim(train_images)\n\n[1] 60000    28    28\n\n\n[1] 60000    28    28\nLikewise, there are 60,000 labels in the training set:\n\ndim(train_labels)\n\n[1] 60000\n\n\n[1] 60000\nEach label is an integer between 0 and 9:\n\ntrain_labels[1:20]\n\n [1] 9 0 0 3 0 2 7 2 5 5 0 9 5 5 7 9 1 0 6 4\n\n\n[1] 9 0 0 3 0 2 7 2 5 5 0 9 5 5 7 9 1 0 6 4\nThere are 10,000 images in the test set. Again, each image is represented as 28 x 28 pixels:\n\ndim(test_images)\n\n[1] 10000    28    28\n\n\n[1] 10000    28    28\nAnd the test set contains 10,000 images labels:\n\ndim(test_labels)\n\n[1] 10000\n\n\n[1] 10000"
  },
  {
    "objectID": "tutorials/keras/classification.html#preprocess-the-data",
    "href": "tutorials/keras/classification.html#preprocess-the-data",
    "title": "Basic Image Classification",
    "section": "Preprocess the data",
    "text": "Preprocess the data\nThe data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:\n\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\nlibrary(ggplot2)\n\nimage_1 <- as.data.frame(train_images[1, , ])\ncolnames(image_1) <- seq_len(ncol(image_1))\nimage_1$y <- seq_len(nrow(image_1))\nimage_1 <- gather(image_1, \"x\", \"value\", -y)\nimage_1$x <- as.integer(image_1$x)\n\nggplot(image_1, aes(x = x, y = y, fill = value)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"black\", na.value = NA) +\n  scale_y_reverse() +\n  theme_minimal() +\n  theme(panel.grid = element_blank())   +\n  theme(aspect.ratio = 1) +\n  xlab(\"\") +\n  ylab(\"\")\n\n\n\n\nWe scale these values to a range of 0 to 1 before feeding to the neural network model. For this, we simply divide by 255.\nIt’s important that the training set and the testing set are preprocessed in the same way:\n\ntrain_images <- train_images / 255\ntest_images <- test_images / 255\n\nDisplay the first 25 images from the training set and display the class name below each image. Verify that the data is in the correct format and we’re ready to build and train the network.\n\npar(mfcol=c(5,5))\npar(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')\nfor (i in 1:25) { \n  img <- train_images[i, , ]\n  img <- t(apply(img, 2, rev)) \n  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',\n        main = paste(class_names[train_labels[i] + 1]))\n}"
  },
  {
    "objectID": "tutorials/keras/classification.html#build-the-model",
    "href": "tutorials/keras/classification.html#build-the-model",
    "title": "Basic Image Classification",
    "section": "Build the model",
    "text": "Build the model\nBuilding the neural network requires configuring the layers of the model, then compiling the model.\n\nSetup the layers\nThe basic building block of a neural network is the layer. Layers extract representations from the data fed into them. And, hopefully, these representations are more meaningful for the problem at hand.\nMost of deep learning consists of chaining together simple layers. Most layers, like layer_dense, have parameters that are learned during training.\n\nmodel <- keras_model_sequential()\nmodel %>%\n  layer_flatten(input_shape = c(28, 28)) %>%\n  layer_dense(units = 128, activation = 'relu') %>%\n  layer_dense(units = 10, activation = 'softmax')\n\nThe first layer in this network, layer_flatten, transforms the format of the images from a 2d-array (of 28 by 28 pixels), to a 1d-array of 28 * 28 = 784 pixels. Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\nAfter the pixels are flattened, the network consists of a sequence of two dense layers. These are densely-connected, or fully-connected, neural layers. The first dense layer has 128 nodes (or neurons). The second (and last) layer is a 10-node softmax layer —this returns an array of 10 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 10 digit classes.\n\n\nCompile the model\nBefore the model is ready for training, it needs a few more settings. These are added during the model’s compile step:\n\nLoss function — This measures how accurate the model is during training. We want to minimize this function to “steer” the model in the right direction.\nOptimizer — This is how the model is updated based on the data it sees and its loss function.\nMetrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.\n\n\nmodel %>% compile(\n  optimizer = 'adam', \n  loss = 'sparse_categorical_crossentropy',\n  metrics = c('accuracy')\n)\n\n\n\nTrain the model\nTraining the neural network model requires the following steps:\n\nFeed the training data to the model — in this example, the train_images and train_labels arrays.\nThe model learns to associate images and labels.\nWe ask the model to make predictions about a test set — in this example, the test_images array. We verify that the predictions match the labels from the test_labels array.\n\nTo start training, call the fit method — the model is “fit” to the training data:\n\nmodel %>% fit(train_images, train_labels, epochs = 5, verbose = 2)\n\nAs the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.88 (or 88%) on the training data.\n\n\nEvaluate accuracy\nNext, compare how the model performs on the test dataset:\n\nscore <- model %>% evaluate(test_images, test_labels, verbose = 0)\n\ncat('Test loss:', score[\"loss\"], \"\\n\")\n\nTest loss: 0.3504261 \n\ncat('Test accuracy:', score[\"acc\"], \"\\n\")\n\nTest accuracy: NA \n\n\nIt turns out, the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy is an example of overfitting. Overfitting is when a machine learning model performs worse on new data than on their training data.\n\n\nMake predictions\nWith the model trained, we can use it to make predictions about some images.\n\npredictions <- model %>% predict(test_images)\n\nHere, the model has predicted the label for each image in the testing set. Let’s take a look at the first prediction:\n\npredictions[1, ]\n\n [1] 0.0000047085869 0.0000001454795 0.0000011415185 0.0000016535852\n [5] 0.0000084582016 0.0116209536791 0.0000306908732 0.1333010792732\n [9] 0.0007113508182 0.8543198108673\n\n\nA prediction is an array of 10 numbers. These describe the “confidence” of the model that the image corresponds to each of the 10 different articles of clothing. We can see which label has the highest confidence value:\n\nwhich.max(predictions[1, ])\n\n[1] 10\n\n\nAs the labels are 0-based, this actually means a predicted label of 9 (to be found in class_names[9]). So the model is most confident that this image is an ankle boot. And we can check the test label to see this is correct:\n\ntest_labels[1]\n\n[1] 9\n\n\nLet’s plot several images with their predictions. Correct prediction labels are green and incorrect prediction labels are red.\n\npar(mfcol=c(5,5))\npar(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')\nfor (i in 1:25) { \n  img <- test_images[i, , ]\n  img <- t(apply(img, 2, rev)) \n  # subtract 1 as labels go from 0 to 9\n  predicted_label <- which.max(predictions[i, ]) - 1\n  true_label <- test_labels[i]\n  if (predicted_label == true_label) {\n    color <- '#008800' \n  } else {\n    color <- '#bb0000'\n  }\n  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',\n        main = paste0(class_names[predicted_label + 1], \" (\",\n                      class_names[true_label + 1], \")\"),\n        col.main = color)\n}\n\n\n\n\nFinally, use the trained model to make a prediction about a single image.\n\n# Grab an image from the test dataset\n# take care to keep the batch dimension, as this is expected by the model\nimg <- test_images[1, , , drop = FALSE]\ndim(img)\n\n[1]  1 28 28\n\n\nNow predict the image:\n\npredictions <- model %>% predict(img)\npredictions\n\n               [,1]            [,2]           [,3]           [,4]\n[1,] 0.000004708587 0.0000001454792 0.000001141517 0.000001653585\n               [,5]       [,6]          [,7]      [,8]         [,9]\n[1,] 0.000008458202 0.01162093 0.00003069084 0.1333011 0.0007113498\n         [,10]\n[1,] 0.8543198\n\n\npredict returns a list of lists, one for each image in the batch of data. Grab the predictions for our (only) image in the batch:\n\n# subtract 1 as labels are 0-based\nprediction <- predictions[1, ] - 1\nwhich.max(prediction)\n\n[1] 10\n\n\nAnd, as before, the model predicts a label of 9."
  },
  {
    "objectID": "tutorials/keras/overfit_and_underfit.html",
    "href": "tutorials/keras/overfit_and_underfit.html",
    "title": "Overfit and underfit",
    "section": "",
    "text": "As always, the code in this example will use the Keras API, which you can learn more about in the TensorFlow Keras guide.\nIn both of the previous examples — classifying text and predicting fuel efficiency — the accuracy of models on the validation data would peak after training for a number of epochs and then stagnate or start decreasing.\nIn other words, your model would overfit to the training data. Learning how to deal with overfitting is important. Although it’s often possible to achieve high accuracy on the training set, what you really want is to develop models that generalize well to a testing set (or data they haven’t seen before).\nThe opposite of overfitting is underfitting. Underfitting occurs when there is still room for improvement on the train data. This can happen for a number of reasons: If the model is not powerful enough, is over-regularized, or has simply not been trained long enough. This means the network has not learned the relevant patterns in the training data.\nIf you train for too long though, the model will start to overfit and learn patterns from the training data that don’t generalize to the test data. You need to strike a balance. Understanding how to train for an appropriate number of epochs as you’ll explore below is a useful skill.\nTo prevent overfitting, the best solution is to use more complete training data. The dataset should cover the full range of inputs that the model is expected to handle. Additional data may only be useful if it covers new and interesting cases.\nA model trained on more complete data will naturally generalize better. When that is no longer possible, the next best solution is to use techniques like regularization. These place constraints on the quantity and type of information your model can store. If a network can only afford to memorize a small number of patterns, the optimization process will force it to focus on the most prominent patterns, which have a better chance of generalizing well.\nIn this notebook, you’ll explore several common regularization techniques, and use them to improve on a classification model."
  },
  {
    "objectID": "tutorials/keras/overfit_and_underfit.html#setup",
    "href": "tutorials/keras/overfit_and_underfit.html#setup",
    "title": "Overfit and underfit",
    "section": "Setup",
    "text": "Setup\nBefore getting started, import the necessary packages:\n\nlibrary(tensorflow)\nlibrary(keras)\nlibrary(tfdatasets)\nlibrary(ggplot2)\n\n\nlogdir <- tempfile()"
  },
  {
    "objectID": "tutorials/keras/overfit_and_underfit.html#the-higgs-dataset",
    "href": "tutorials/keras/overfit_and_underfit.html#the-higgs-dataset",
    "title": "Overfit and underfit",
    "section": "The Higgs dataset",
    "text": "The Higgs dataset\nThe goal of this tutorial is not to do particle physics, so don’t dwell on the details of the dataset. It contains 11,000,000 examples, each with 28 features, and a binary class label.\n\ngz <- get_file(\n  'HIGGS.csv.gz', \n  'http://mlphysics.ics.uci.edu/data/higgs/HIGGS.csv.gz',\n  cache_dir = \"higgs\"\n)\n\nLoaded Tensorflow version 2.9.1\n\n\n\nFEATURES <- 28\n\nThe tf$data$experimental$CsvDataset class can be used to read csv records directly from a gzip file with no intermediate decompression step.\n\nds <- tf$data$experimental$CsvDataset(\n  gz,\n  lapply(seq_len(FEATURES + 1), function(x) tf$float32), \n  compression_type = \"GZIP\"\n)\n\nThat csv reader class returns a list of scalars for each record. The following function repacks that list of scalars into a (feature_vector, label) pair.\n\npack_row <- function(...) {\n  row <- list(...)\n  label <- row[[1]]\n  features <- tf$stack(row[2:length(row)], 1L)\n  list(features, label)\n}\n\nTensorFlow is most efficient when operating on large batches of data.\nSo, instead of repacking each row individually make a new tf$data$Dataset that takes batches of 10,000 examples, applies the pack_row function to each batch, and then splits the batches back up into individual records:\n\npacked_ds <- ds %>% \n  dataset_batch(10000) %>% \n  dataset_map(pack_row)\npacked_ds <- packed_ds$unbatch()\n\nInspect some of the records from this new packed_ds.\nThe features are not perfectly normalized, but this is sufficient for this tutorial.\n\nbatch <- packed_ds %>% \n  dataset_batch(1000) %>% \n  dataset_take(1) %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next()\nstr(batch)\n\nList of 2\n $ :<tf.Tensor: shape=(1000, 28), dtype=float32, numpy=…>\n $ :<tf.Tensor: shape=(1000), dtype=float32, numpy=…>\n\n\nTo keep this tutorial relatively short, use just the first 1,000 samples for validation, and the next 10,000 for training:\n\nN_VALIDATION <- 1e3\nN_TRAIN <- 1e4\nBUFFER_SIZE <- 1e4\nBATCH_SIZE <- 500\nSTEPS_PER_EPOCH <- N_TRAIN %/% BATCH_SIZE\n\nThe dataset_skip() and dataset_take() methods make this easy.\nAt the same time, use the dataset_cache() method to ensure that the loader doesn’t need to re-read the data from the file on each epoch:\n\nvalidate_ds <- packed_ds %>% \n  dataset_take(N_VALIDATION) %>% \n  dataset_cache()\ntrain_ds <- packed_ds %>% \n  dataset_skip(N_VALIDATION) %>% \n  dataset_take(N_TRAIN) %>% \n  dataset_cache()\n\n\ntrain_ds\n\n<CacheDataset element_spec=(TensorSpec(shape=(28,), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>\n\n\nThese datasets return individual examples. Use the dataset_batch() method to create batches of an appropriate size for training. Before batching, also remember to use dataset_shuffle() and dataset_repeat() on the training set.\n\nvalidate_ds <- validate_ds %>% dataset_batch(BATCH_SIZE)\ntrain_ds <- train_ds %>% \n  dataset_shuffle(BUFFER_SIZE) %>% \n  dataset_repeat() %>% \n  dataset_batch(BATCH_SIZE)"
  },
  {
    "objectID": "tutorials/keras/overfit_and_underfit.html#demonstrate-overfitting",
    "href": "tutorials/keras/overfit_and_underfit.html#demonstrate-overfitting",
    "title": "Overfit and underfit",
    "section": "Demonstrate overfitting",
    "text": "Demonstrate overfitting\nThe simplest way to prevent overfitting is to start with a small model. A model with a small number of learnable parameters (which is determined by the number of layers and the number of units per layer). In deep learning, the number of learnable parameters in a model is often referred to as the model’s “capacity”.\nIntuitively, a model with more parameters will have more “memorization capacity” and therefore will be able to easily learn a perfect dictionary-like mapping between training samples and their targets, a mapping without any generalization power, but this would be useless when making predictions on previously unseen data.\nAlways keep this in mind: deep learning models tend to be good at fitting to the training data, but the real challenge is generalization, not fitting.\nOn the other hand, if the network has limited memorization resources, it will not be able to learn the mapping as easily. To minimize its loss, it will have to learn compressed representations that have more predictive power. At the same time, if you make your model too small, it will have difficulty fitting to the training data. There is a balance between “too much capacity” and “not enough capacity”.\nUnfortunately, there is no magical formula to determine the right size or architecture of your model (in terms of the number of layers, or the right size for each layer). You will have to experiment using a series of different architectures.\nTo find an appropriate model size, it’s best to start with relatively few layers and parameters, then begin increasing the size of the layers or adding new layers until you see diminishing returns on the validation loss.\nStart with a simple model using only densely-connected layers (tf$keras$layers$Dense) as a baseline, then create larger models, and compare them.\n\nTraining procedure\nMany models train better if you gradually reduce the learning rate during training. Use keras::learning_rate_schedule* to reduce the learning rate over time:\n\nlr_schedule <- learning_rate_schedule_inverse_time_decay(\n  0.001,\n  decay_steps = STEPS_PER_EPOCH*1000,\n  decay_rate = 1,\n  staircase = FALSE\n)\n\nget_optimizer <- function() {\n  optimizer_adam(lr_schedule)\n}\n\nThe code above sets a learning_rate_schedule_inverse_time_decay() to hyperbolically decrease the learning rate to 1/2 of the base rate at 1,000 epochs, 1/3 at 2,000 epochs, and so on.\n\nstep <- seq(1, 100000)\nlr <- lr_schedule(step)\ndata.frame(step = as.numeric(step), lr = as.numeric(lr)) %>% \n  ggplot(aes(x = step, y = lr)) +\n  geom_line()\n\n\n\n\nEach model in this tutorial will use the same training configuration. So set these up in a reusable way, starting with the list of callbacks.\nThe training for this tutorial runs for many short epochs.\nWe include callback_early_stopping() to avoid long and unnecessary training times. Note that this callback is set to monitor the val_binary_crossentropy, not the val_loss. This difference will be important later.\nUse callback_tensorboard() to generate TensorBoard logs for the training.\n\nget_callbacks <- function(name) {\n  list(\n    callback_early_stopping(monitor = 'val_binary_crossentropy', patience = 200),\n    callback_tensorboard(file.path(logdir, name))\n  )\n}\n\nSimilarly each model will use the same compile() and fit() settings:\n\ncompile_and_fit <- function(model, name, optimizer = NULL, max_epochs = 10000) {\n  if (is.null(optimizer)) {\n    optimizer <- get_optimizer()\n  }\n  \n  model %>% compile(\n    optimizer = optimizer,\n    loss = loss_binary_crossentropy(from_logits = TRUE),\n    metrics = list(\n      loss_binary_crossentropy(from_logits = TRUE, name = \"binary_crossentropy\"),\n      \"accuracy\"\n    )\n  )\n  \n  summary(model)\n\n  history <- model %>% fit(\n    train_ds,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = max_epochs,\n    validation_data = validate_ds,\n    callbacks = get_callbacks(name),\n    verbose = 0\n  )\n  \n  history\n}\n\n\n\nTiny model\nStart by training a model:\n\ntiny_model <- keras_model_sequential() %>% \n  layer_dense(16, activation = \"elu\", input_shape = shape(FEATURES)) %>% \n  layer_dense(1)\n\n\nsize_histories <- list()\n\n\nsize_histories[['Tiny']] <- compile_and_fit(tiny_model, 'sizes/Tiny')\n\nModel: \"sequential\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_1 (Dense)                  (None, 16)                    464         \n dense (Dense)                    (None, 1)                     17          \n============================================================================\nTotal params: 481\nTrainable params: 481\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nNow check how the model did:\n\nsize_histories[[\"Tiny\"]] %>% \n  plot() +\n  coord_cartesian(xlim = c(0, 5000))\n\n\n\n\n\n\nSmall model\nTo check if you can beat the performance of the small model, progressively train some larger models. Try two hidden layers with 16 units each:\n\nsmall_model <- keras_model_sequential() %>% \n  # `input_shape` is only required here so that `.summary` works.\n  layer_dense(16, activation = 'elu', input_shape = shape(FEATURES)) %>% \n  layer_dense(16, activation = 'elu') %>% \n  layer_dense(1)\n\n\nsize_histories[['Small']] <- compile_and_fit(small_model, 'sizes/Small')\n\nModel: \"sequential_1\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_4 (Dense)                  (None, 16)                    464         \n dense_3 (Dense)                  (None, 16)                    272         \n dense_2 (Dense)                  (None, 1)                     17          \n============================================================================\nTotal params: 753\nTrainable params: 753\nNon-trainable params: 0\n____________________________________________________________________________\n\n\n\n\nMedium model\nNow try three hidden layers with 64 units each:\n\nmedium_model <- keras_model_sequential() %>% \n  layer_dense(64, activation = 'elu', input_shape = shape(FEATURES)) %>% \n  layer_dense(64, activation = 'elu') %>% \n  layer_dense(64, activation = 'elu') %>% \n  layer_dense(1)\n\nAnd train the model using the same data:\n\nsize_histories[['Medium']] <- compile_and_fit(medium_model, \"sizes/Medium\")\n\nModel: \"sequential_2\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_8 (Dense)                  (None, 64)                    1856        \n dense_7 (Dense)                  (None, 64)                    4160        \n dense_6 (Dense)                  (None, 64)                    4160        \n dense_5 (Dense)                  (None, 1)                     65          \n============================================================================\nTotal params: 10,241\nTrainable params: 10,241\nNon-trainable params: 0\n____________________________________________________________________________\n\n\n\n\nLarge model\nAs an exercise, you can create an even larger model and check how quickly it begins overfitting. Next, add to this benchmark a network that has much more capacity, far more than the problem would warrant:\n\nlarge_model <- keras_model_sequential() %>% \n  layer_dense(512, activation = 'elu', input_shape = shape(FEATURES)) %>% \n  layer_dense(512, activation = 'elu') %>% \n  layer_dense(512, activation = 'elu') %>% \n  layer_dense(512, activation = 'elu') %>% \n  layer_dense(1)\n\nAnd, again, train the model using the same data:\n\nsize_histories[['large']] <- compile_and_fit(large_model, \"sizes/large\")\n\nModel: \"sequential_3\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_13 (Dense)                 (None, 512)                   14848       \n dense_12 (Dense)                 (None, 512)                   262656      \n dense_11 (Dense)                 (None, 512)                   262656      \n dense_10 (Dense)                 (None, 512)                   262656      \n dense_9 (Dense)                  (None, 1)                     513         \n============================================================================\nTotal params: 803,329\nTrainable params: 803,329\nNon-trainable params: 0\n____________________________________________________________________________\n\n\n\n\nPlot the training and validation losses\nThe solid lines show the training loss, and the dashed lines show the validation loss (remember: a lower validation loss indicates a better model).\nWhile building a larger model gives it more power, if this power is not constrained somehow it can easily overfit to the training set.\nIn this example, typically, only the \"Tiny\" model manages to avoid overfitting altogether, and each of the larger models overfit the data more quickly. This becomes so severe for the \"large\" model that you need to switch the plot to a log-scale to really figure out what’s happening.\nThis is apparent if you plot and compare the validation metrics to the training metrics.\n\nIt’s normal for there to be a small difference.\nIf both metrics are moving in the same direction, everything is fine.\nIf the validation metric begins to stagnate while the training metric continues to improve, you are probably close to overfitting.\nIf the validation metric is going in the wrong direction, the model is clearly overfitting.\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nplot_histories <- function(histories) {\n  histories %>% \n    purrr::map_dfr(as.data.frame, .id = \"model\") %>% \n    filter(metric == \"binary_crossentropy\") %>% \n    ggplot(aes(x = epoch, y = value, color = model, linetype = data)) +\n    geom_smooth(se = FALSE) +\n    coord_cartesian(ylim = c(0.5, 0.7)) +\n    scale_x_log10()  \n}\nplot_histories(size_histories)\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nNote: All the above training runs used the callback_ealry_stopping() to end the training once it was clear the model was not making progress.\n\n\nView in TensorBoard\nThese models all wrote TensorBoard logs during training.\n\ntensorboard(log_dir = logdir)\n\nYou can view the results of a previous run of this notebook on TensorBoard.dev.\nTensorBoard.dev is a managed experience for hosting, tracking, and sharing ML experiments with everyone.\nIt’s also included in an <iframe> for convenience:\n\n\nIf you want to share TensorBoard results you can upload the logs to TensorBoard.dev by copying the following into a terminal session.\ntensorboard dev upload --logdir logdir/sizes\nCaution: This command does not terminate. It’s designed to continuously upload the results of long-running experiments. Once your data is uploaded you need to stop it using the “interrupt execution” option in your terminal tool."
  },
  {
    "objectID": "tutorials/keras/overfit_and_underfit.html#strategies-to-prevent-overfitting",
    "href": "tutorials/keras/overfit_and_underfit.html#strategies-to-prevent-overfitting",
    "title": "Overfit and underfit",
    "section": "Strategies to prevent overfitting",
    "text": "Strategies to prevent overfitting\nBefore getting into the content of this section copy the training logs from the \"Tiny\" model above, to use as a baseline for comparison.\n\nregularizer_histories <- list()\nregularizer_histories[['Tiny']] <- size_histories[['Tiny']]\n\n\nAdd weight regularization\nYou may be familiar with Occam’s Razor principle: given two explanations for something, the explanation most likely to be correct is the “simplest” one, the one that makes the least amount of assumptions. This also applies to the models learned by neural networks: given some training data and a network architecture, there are multiple sets of weights values (multiple models) that could explain the data, and simpler models are less likely to overfit than complex ones.\nA “simple model” in this context is a model where the distribution of parameter values has less entropy (or a model with fewer parameters altogether, as demonstrated in the section above). Thus a common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights only to take small values, which makes the distribution of weight values more “regular”. This is called “weight regularization”, and it is done by adding to the loss function of the network a cost associated with(having large weights. This cost comes in two flavors, { })\n\nL1 regularization, where the cost added is proportional to the absolute value of the weights coefficients (i$e. to what is called the “L1 norm” of the weights).\nL2 regularization, where the cost added is proportional to the square of the value of the weights coefficients (i$e. to what is called the squared “L2 norm” of the weights). L2 regularization is also called weight decay in the context of neural networks. Don’t let the different name confuse you: weight decay is mathematically the exact same as L2 regularization.\n\nL1 regularization pushes weights towards exactly zero, encouraging a sparse model. L2 regularization will penalize the weights parameters without making them sparse since the penalty goes to zero for small weights—one reason why L2 is more common.\nIn tf$keras, weight regularization is added by passing weight regularizer instances to layers as keyword arguments. Add L2 weight regularization:\n\nl2_model <- keras_model_sequential() %>% \n  layer_dense(512, activation = 'elu',\n              kernel_regularizer = regularizer_l2(0.001),\n              input_shape <- shape(FEATURES)) %>% \n  layer_dense(512, activation = 'elu',\n              kernel_regularizer = regularizer_l2(0.001)) %>% \n  layer_dense(512, activation = 'elu',\n              kernel_regularizer = regularizer_l2(0.001)) %>% \n  layer_dense(512, activation = 'elu',\n              kernel_regularizer = regularizer_l2(0.001)) %>% \n  layer_dense(1)\n\nregularizer_histories[['l2']] <- compile_and_fit(l2_model, \"regularizers/l2\")\n\nModel: <no summary available, model was not built>\n\n\nl2(0.001) means that every coefficient in the weight matrix of the layer will add 0.001 * weight_coefficient_value**2 to the total loss of the network.\nThat is why we’re monitoring the binary_crossentropy directly. Because it doesn’t have this regularization component mixed in.\nSo, that same \"Large\" model with an L2 regularization penalty performs much better:\n\nplot_histories(regularizer_histories)\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nAs demonstrated in the diagram above, the \"L2\" regularized model is now much more competitive with the \"Tiny\" model. This \"L2\" model is also much more resistant to overfitting than the \"Large\" model it was based on despite having the same number of parameters.\n\nMore info\nThere are two important things to note about this sort of regularization:\n\nIf you are writing your own training loop, then you need to be sure to ask the model for its regularization losses.\n\n\nresult <- l2_model(features)\nregularization_loss <- tf$add_n(l2_model$losses)\n\n\nThis implementation works by adding the weight penalties to the model’s loss, and then applying a standard optimization procedure after that.\n\nThere is a second approach that instead only runs the optimizer on the raw loss, and then while applying the calculated step the optimizer also applies some weight decay. This “decoupled weight decay” is used in optimizers like optimizer_ftrl() and optimizer_adamw().\n\n\n\nAdd dropout\nDropout is one of the most effective and most commonly used regularization techniques for neural networks, developed by Hinton and his students at the University of Toronto.\nThe intuitive explanation for dropout is that because individual nodes in the network cannot rely on the output of the others, each node must output features that are useful on their own.\nDropout, applied to a layer, consists of randomly “dropping out” (i$e. set to zero) a number of output features of the layer during training. For example, a given layer would normally have returned a vector [0.2, 0.5, 1.3, 0.8, 1.1] for a given input sample during training; after applying dropout, this vector will have a few zero entries distributed at random, e.g. [0, 0.5, 1.3, 0, 1.1].\nThe “dropout rate” is the fraction of the features that are being zeroed-out; it is usually set between 0.2 and 0.5. At test time, no units are dropped out, and instead the layer’s output values are scaled down by a factor equal to the dropout rate, so as to balance for the fact that more units are active than at training time.\nIn Keras, you can introduce dropout in a network via the tf$keras$layers$Dropout layer, which gets applied to the output of layer right before.\nAdd two dropout layers to your network to check how well they do at reducing overfitting:\n\ndropout_model <- keras_model_sequential() %>% \n  layer_dense(512, activation = 'elu', input_shape = shape(FEATURES)) %>% \n  layer_dropout(0.5) %>% \n  layer_dense(512, activation = 'elu') %>% \n  layer_dropout(0.5) %>% \n  layer_dense(512, activation = 'elu') %>% \n  layer_dropout(0.5) %>% \n  layer_dense(512, activation = 'elu') %>% \n  layer_dropout(0.5) %>% \n  layer_dense(1)\n\nregularizer_histories[['dropout']] <- compile_and_fit(dropout_model, \"regularizers/dropout\")\n\nModel: \"sequential_5\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_23 (Dense)                 (None, 512)                   14848       \n dropout_3 (Dropout)              (None, 512)                   0           \n dense_22 (Dense)                 (None, 512)                   262656      \n dropout_2 (Dropout)              (None, 512)                   0           \n dense_21 (Dense)                 (None, 512)                   262656      \n dropout_1 (Dropout)              (None, 512)                   0           \n dense_20 (Dense)                 (None, 512)                   262656      \n dropout (Dropout)                (None, 512)                   0           \n dense_19 (Dense)                 (None, 1)                     513         \n============================================================================\nTotal params: 803,329\nTrainable params: 803,329\nNon-trainable params: 0\n____________________________________________________________________________\n\n\n\nplot_histories(regularizer_histories)\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nIt’s clear from this plot that both of these regularization approaches improve the behavior of the \"Large\" model. But this still doesn’t beat even the \"Tiny\" baseline.\nNext try them both, together, and see if that does better.\n\n\nCombined L2 + dropout\n\ncombined_model <- keras_model_sequential() %>% \n  layer_dense(512, kernel_regularizer = regularizer_l2(0.0001),\n              activation = 'elu', input_shape = shape(FEATURES)) %>% \n  layer_dropout(0.5) %>% \n  layer_dense(512, kernel_regularizer = regularizer_l2(0.0001),\n              activation = 'elu') %>% \n  layer_dropout(0.5) %>% \n  layer_dense(512, kernel_regularizer = regularizer_l2(0.0001),\n              activation = 'elu') %>% \n  layer_dropout(0.5) %>% \n  layer_dense(512, kernel_regularizer = regularizer_l2(0.0001),\n              activation = 'elu') %>% \n  layer_dropout(0.5) %>% \n  layer_dense(1)\n\nregularizer_histories[['combined']] <- compile_and_fit(combined_model, \"regularizers/combined\")\n\nModel: \"sequential_6\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_28 (Dense)                 (None, 512)                   14848       \n dropout_7 (Dropout)              (None, 512)                   0           \n dense_27 (Dense)                 (None, 512)                   262656      \n dropout_6 (Dropout)              (None, 512)                   0           \n dense_26 (Dense)                 (None, 512)                   262656      \n dropout_5 (Dropout)              (None, 512)                   0           \n dense_25 (Dense)                 (None, 512)                   262656      \n dropout_4 (Dropout)              (None, 512)                   0           \n dense_24 (Dense)                 (None, 1)                     513         \n============================================================================\nTotal params: 803,329\nTrainable params: 803,329\nNon-trainable params: 0\n____________________________________________________________________________\n\n\n\nplot_histories(regularizer_histories)\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nThis model with the \"Combined\" regularization is obviously the best one so far.\n\n\nView in TensorBoard\nThese models also recorded TensorBoard logs. Use the following to visualize the tensorboard:\n\ntensorboard(file.path(logdir, \"regularizers\"))\n\nYou can view the results of a previous run of this notebook on TensorBoard.dev."
  },
  {
    "objectID": "tutorials/keras/overfit_and_underfit.html#conclusions",
    "href": "tutorials/keras/overfit_and_underfit.html#conclusions",
    "title": "Overfit and underfit",
    "section": "Conclusions",
    "text": "Conclusions\nTo recap, here are the most common ways to prevent overfitting in neural networks:\n\nGet more training data.\nReduce the capacity of the network.\nAdd weight regularization.\nAdd dropout.\n\nTwo important approaches not covered in this guide are:\n\nData augmentation\nBatch normalization (layer_batch_normalization())\n\nRemember that each method can help on its own, but often combining them can be even more effective."
  },
  {
    "objectID": "tutorials/keras/regression.html",
    "href": "tutorials/keras/regression.html",
    "title": "Regression",
    "section": "",
    "text": "In a regression problem, the aim is to predict the output of a continuous value, like a price or a probability. Contrast this with a classification problem, where the aim is to select a class from a list of classes (for example, where a picture contains an apple or an orange, recognizing which fruit is in the picture).\nThis tutorial uses the classic Auto MPG dataset and demonstrates how to build models to predict the fuel efficiency of the late-1970s and early 1980s automobiles. To do this, you will provide the models with a description of many automobiles from that time period. This description includes attributes like cylinders, displacement, horsepower, and weight.\nThis example uses the Keras API. (Visit the Keras tutorials and guides to learn more.)"
  },
  {
    "objectID": "tutorials/keras/regression.html#the-auto-mpg-dataset",
    "href": "tutorials/keras/regression.html#the-auto-mpg-dataset",
    "title": "Regression",
    "section": "The Auto MPG dataset",
    "text": "The Auto MPG dataset\nThe dataset is available from the UCI Machine Learning Repository.\n\nGet the data\nFirst download and import the dataset using pandas:\n\nurl <- \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\ncol_names <- c(\"mpg\",\"cylinders\",\"displacement\",\"horsepower\",\"weight\",\"acceleration\",\"model_year\", \"origin\",\"car_name\")\n\nraw_dataset <- read.table(\n  url, \n  header = T, \n  col.names = col_names, \n  na.strings = \"?\"\n)\n\n\ndataset <- raw_dataset %>% select(-car_name)\ntail(dataset)\n\n    mpg cylinders displacement horsepower weight acceleration model_year\n392  27         4          151         90   2950         17.3         82\n393  27         4          140         86   2790         15.6         82\n394  44         4           97         52   2130         24.6         82\n395  32         4          135         84   2295         11.6         82\n396  28         4          120         79   2625         18.6         82\n397  31         4          119         82   2720         19.4         82\n    origin\n392      1\n393      1\n394      2\n395      1\n396      1\n397      1\n\n\n\n\nClean the data\nThe dataset contains a few unknown values:\n\nlapply(dataset, function(x) sum(is.na(x))) %>% str()\n\nList of 8\n $ mpg         : int 0\n $ cylinders   : int 0\n $ displacement: int 0\n $ horsepower  : int 6\n $ weight      : int 0\n $ acceleration: int 0\n $ model_year  : int 0\n $ origin      : int 0\n\n\nDrop those rows to keep this initial tutorial simple:\n\ndataset <- na.omit(dataset)\n\nThe \"origin\" column is categorical, not numeric. So the next step is to one-hot encode the values in the column with the recipes package.\nNote: You can set up the keras_model() to do this kind of transformation for you but that’s beyond the scope of this tutorial. Check out the Classify structured data using Keras preprocessing layers or Load CSV data tutorials for examples.\n\nlibrary(recipes)\ndataset <- recipe(mpg ~ ., dataset) %>% \n  step_num2factor(origin, levels = c(\"USA\", \"Europe\", \"Japan\")) %>% \n  step_dummy(origin, one_hot = TRUE) %>% \n  prep() %>% \n  bake(new_data = NULL)\n\n\nglimpse(dataset)\n\nRows: 391\nColumns: 10\n$ cylinders     <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4…\n$ displacement  <dbl> 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34…\n$ horsepower    <dbl> 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16…\n$ weight        <dbl> 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 3850…\n$ acceleration  <dbl> 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, 1…\n$ model_year    <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, …\n$ mpg           <dbl> 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, …\n$ origin_USA    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0…\n$ origin_Europe <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ origin_Japan  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1…\n\n\n\n\nSplit the data into training and test sets\nNow, split the dataset into a training set and a test set. You will use the test set in the final evaluation of your models.\n\nsplit <- initial_split(dataset, 0.8)\ntrain_dataset <- training(split)\ntest_dataset <- testing(split)\n\n\n\nInspect the data\nReview the joint distribution of a few pairs of columns from the training set.\nThe top row suggests that the fuel efficiency (MPG) is a function of all the other parameters. The other rows indicate they are functions of each other.\n\ntrain_dataset %>% \n  select(mpg, cylinders, displacement, weight) %>% \n  GGally::ggpairs()\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\nLet’s also check the overall statistics. Note how each feature covers a very different range:\n\nskimr::skim(train_dataset)\n\n\nData summary\n\n\nName\ntrain_dataset\n\n\nNumber of rows\n312\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n10\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncylinders\n0\n1\n5.50\n1.72\n3\n4.00\n4.00\n8.0\n8.0\n▇▁▃▁▅\n\n\ndisplacement\n0\n1\n196.99\n105.81\n68\n105.00\n151.00\n302.0\n455.0\n▇▂▂▃▁\n\n\nhorsepower\n0\n1\n104.93\n38.85\n46\n76.75\n92.00\n126.0\n230.0\n▆▇▃▂▁\n\n\nweight\n0\n1\n2995.04\n844.26\n1613\n2232.50\n2849.00\n3622.5\n4997.0\n▇▇▆▅▂\n\n\nacceleration\n0\n1\n15.57\n2.83\n8\n13.88\n15.50\n17.2\n24.8\n▁▆▇▂▁\n\n\nmodel_year\n0\n1\n76.06\n3.71\n70\n73.00\n76.00\n79.0\n82.0\n▇▆▇▆▇\n\n\nmpg\n0\n1\n23.48\n7.91\n9\n17.00\n22.15\n29.0\n46.6\n▆▇▆▃▁\n\n\norigin_USA\n0\n1\n0.62\n0.48\n0\n0.00\n1.00\n1.0\n1.0\n▅▁▁▁▇\n\n\norigin_Europe\n0\n1\n0.17\n0.38\n0\n0.00\n0.00\n0.0\n1.0\n▇▁▁▁▂\n\n\norigin_Japan\n0\n1\n0.21\n0.40\n0\n0.00\n0.00\n0.0\n1.0\n▇▁▁▁▂\n\n\n\n\n\n\n\nSplit features from labels\nSeparate the target value—the “label”—from the features. This label is the value that you will train the model to predict.\n\ntrain_features <- train_dataset %>% select(-mpg)\ntest_features <- test_dataset %>% select(-mpg)\n\ntrain_labels <- train_dataset %>% select(mpg)\ntest_labels <- test_dataset %>% select(mpg)"
  },
  {
    "objectID": "tutorials/keras/regression.html#normalization",
    "href": "tutorials/keras/regression.html#normalization",
    "title": "Regression",
    "section": "Normalization",
    "text": "Normalization\nIn the table of statistics it’s easy to see how different the ranges of each feature are:\n\nmy_skim <- skimr::skim_with(numeric = skimr::sfl(mean, sd))\ntrain_dataset %>% \n  select(where(~is.numeric(.x))) %>% \n  pivot_longer(\n    cols = everything(), names_to = \"variable\", values_to = \"values\") %>% \n  group_by(variable) %>% \n  summarise(mean = mean(values), sd = sd(values))\n\n# A tibble: 10 × 3\n   variable          mean      sd\n   <chr>            <dbl>   <dbl>\n 1 acceleration    15.6     2.83 \n 2 cylinders        5.5     1.72 \n 3 displacement   197.    106.   \n 4 horsepower     105.     38.9  \n 5 model_year      76.1     3.71 \n 6 mpg             23.5     7.91 \n 7 origin_Europe    0.170   0.376\n 8 origin_Japan     0.205   0.404\n 9 origin_USA       0.625   0.485\n10 weight        2995.    844.   \n\n\nIt is good practice to normalize features that use different scales and ranges.\nOne reason this is important is because the features are multiplied by the model weights. So, the scale of the outputs and the scale of the gradients are affected by the scale of the inputs.\nAlthough a model might converge without feature normalization, normalization makes training much more stable.\nNote: There is no advantage to normalizing the one-hot features—it is done here for simplicity. For more details on how to use the preprocessing layers, refer to the Working with preprocessing layers guide and the Classify structured data using Keras preprocessing layers tutorial.\n\nThe Normalization layer\nThe layer_normalization() is a clean and simple way to add feature normalization into your model.\nThe first step is to create the layer:\n\nnormalizer <- layer_normalization(axis = -1L)\n\nLoaded Tensorflow version 2.9.1\n\n\nThen, fit the state of the preprocessing layer to the data by calling adapt():\n\nnormalizer %>% adapt(as.matrix(train_features))\n\nCalculate the mean and variance, and store them in the layer:\n\nprint(normalizer$mean)\n\ntf.Tensor(\n[[5.5000000e+00 1.9699361e+02 1.0493270e+02 2.9950388e+03 1.5573077e+01\n  7.6060890e+01 6.2500000e-01 1.6987181e-01 2.0512822e-01]], shape=(1, 9), dtype=float32)\n\n\nWhen the layer is called, it returns the input data, with each feature independently normalized.\n\nfirst <- as.matrix(train_features[1,])\n\ncat('First example:', first)\n\nFirst example: 8 318 150 4077 14 72 1 0 0\n\ncat('Normalized:', as.matrix(normalizer(first)))\n\nNormalized: 1.452718 1.145492 1.161751 1.283603 -0.5567052 -1.095416 0.7745966 -0.452364 -0.5080005"
  },
  {
    "objectID": "tutorials/keras/regression.html#linear-regression",
    "href": "tutorials/keras/regression.html#linear-regression",
    "title": "Regression",
    "section": "Linear regression",
    "text": "Linear regression\nBefore building a deep neural network model, start with linear regression using one and several variables.\n\nLinear regression with one variable\nBegin with a single-variable linear regression to predict 'mpg' from 'horsepower'.\nTraining a model with Keras typically starts by defining the model architecture. Use a Sequential model, which represents a sequence of steps.\nThere are two steps in your single-variable linear regression model:\n\nNormalize the 'horsepower' input features using the normalization preprocessing layer.\nApply a linear transformation (\\(y = mx+b\\)) to produce 1 output using a linear layer (dense).\n\nThe number of inputs can either be set by the input_shape argument, or automatically when the model is run for the first time.\nFirst, create a matrix made of the 'horsepower' features. Then, instantiate the layer_normalization and fit its state to the horsepower data:\n\nhorsepower <- matrix(train_features$horsepower)\nhorsepower_normalizer <- layer_normalization(input_shape = shape(1), axis = NULL)\nhorsepower_normalizer %>% adapt(horsepower)\n\nBuild the Keras Sequential model:\n\nhorsepower_model <- keras_model_sequential() %>% \n  horsepower_normalizer() %>% \n  layer_dense(units = 1)\n\nsummary(horsepower_model)\n\nModel: \"sequential\"\n____________________________________________________________________________\n Layer (type)                Output Shape              Param #   Trainable  \n============================================================================\n normalization_1 (Normalizat  (None, 1)                3         Y          \n ion)                                                                       \n dense (Dense)               (None, 1)                 2         Y          \n============================================================================\nTotal params: 5\nTrainable params: 2\nNon-trainable params: 3\n____________________________________________________________________________\n\n\nThis model will predict 'mpg' from 'horsepower'.\nRun the untrained model on the first 10 ‘horsepower’ values. The output won’t be good, but notice that it has the expected shape of (10, 1):\n\npredict(horsepower_model, horsepower[1:10,])\n\n              [,1]\n [1,]  0.918656170\n [2,]  0.918656170\n [3,] -0.182085037\n [4,] -0.222853214\n [5,] -0.610151052\n [6,] -0.161700934\n [7,]  0.001371827\n [8,]  0.103292309\n [9,]  0.103292309\n[10,] -0.447078258\n\n\nOnce the model is built, configure the training procedure using the Keras compile() method. The most important arguments to compile are the loss and the optimizer, since these define what will be optimized (mean_absolute_error) and how (using the optimizer_adam).\n\nhorsepower_model %>% compile(\n  optimizer = optimizer_adam(learning_rate = 0.1),\n  loss = 'mean_absolute_error'\n)\n\nUse Keras fit() to execute the training for 100 epochs:\n\nhistory <- horsepower_model %>% fit(\n  as.matrix(train_features$horsepower),\n  as.matrix(train_labels),\n  epochs = 100,\n  # Suppress logging.\n  verbose = 0,\n  # Calculate validation results on 20% of the training data.\n  validation_split = 0.2\n)\n\nVisualize the model’s training progress using the stats stored in the history object:\n\nplot(history)\n\n\n\n\nCollect the results on the test set for later:\n\ntest_results <- list()\ntest_results[[\"horsepower_model\"]] <- horsepower_model %>% evaluate(\n  as.matrix(test_features$horsepower),\n  as.matrix(test_labels), \n  verbose = 0\n)\n\nSince this is a single variable regression, it’s easy to view the model’s predictions as a function of the input:\n\nx <- seq(0, 250, length.out = 251)\ny <- predict(horsepower_model, x)\n\n\nggplot(train_dataset) +\n  geom_point(aes(x = horsepower, y = mpg, color = \"data\")) +\n  geom_line(data = data.frame(x, y), aes(x = x, y = y, color = \"prediction\"))\n\n\n\n\n\n\nLinear regression with multiple inputs\nYou can use an almost identical setup to make predictions based on multiple inputs. This model still does the same \\(y = mx+b\\) except that \\(m\\) is a matrix and \\(b\\) is a vector.\nCreate a two-step Keras Sequential model again with the first layer being normalizer (layer_normalization(axis = -1)) you defined earlier and adapted to the whole dataset:\n\nlinear_model <- keras_model_sequential() %>% \n  normalizer() %>% \n  layer_dense(units = 1)\n\nWhen you call predict() on a batch of inputs, it produces units = 1 outputs for each example:\n\npredict(linear_model, as.matrix(train_features[1:10, ]))\n\n            [,1]\n [1,] -2.9093571\n [2,] -3.0792081\n [3,]  1.2285657\n [4,]  1.3383932\n [5,]  2.0067687\n [6,]  0.9256226\n [7,] -0.9580150\n [8,] -0.7418302\n [9,] -0.5034288\n[10,]  0.2313302\n\n\nWhen you call the model, its weight matrices will be built—check that the kernel weights (the \\(m\\) in \\(y = mx+b\\)) have a shape of (9, 1):\n\nlinear_model$layers[[2]]$kernel\n\n<tf.Variable 'dense_1/kernel:0' shape=(9, 1) dtype=float32, numpy=\narray([[ 0.09463781],\n       [-0.04923761],\n       [-0.73521256],\n       [-0.61125565],\n       [ 0.66817605],\n       [ 0.3159597 ],\n       [-0.6834484 ],\n       [ 0.23534286],\n       [-0.00442344]], dtype=float32)>\n\n\nConfigure the model with Keras compile() and train with fit() for 100 epochs:\n\nlinear_model %>% compile(\n  optimizer = optimizer_adam(learning_rate = 0.1),\n  loss = 'mean_absolute_error'\n)\n\n\nhistory <- linear_model %>% fit(\n  as.matrix(train_features),\n  as.matrix(train_labels),\n  epochs = 100,\n  # Suppress logging.\n  verbose = 0,\n  # Calculate validation results on 20% of the training data.\n  validation_split = 0.2\n)\n\nUsing all the inputs in this regression model achieves a much lower training and validation error than the horsepower_model, which had one input:\n\nplot(history)\n\n\n\n\nCollect the results on the test set for later:\n\ntest_results[['linear_model']] <- linear_model %>% \n  evaluate(\n    as.matrix(test_features), \n    as.matrix(test_labels), \n    verbose = 0\n  )"
  },
  {
    "objectID": "tutorials/keras/regression.html#regression-with-a-deep-neural-network-dnn",
    "href": "tutorials/keras/regression.html#regression-with-a-deep-neural-network-dnn",
    "title": "Regression",
    "section": "Regression with a deep neural network (DNN)",
    "text": "Regression with a deep neural network (DNN)\nIn the previous section, you implemented two linear models for single and multiple inputs.\nHere, you will implement single-input and multiple-input DNN models.\nThe code is basically the same except the model is expanded to include some “hidden” non-linear layers. The name “hidden” here just means not directly connected to the inputs or outputs.\nThese models will contain a few more layers than the linear model:\n\nThe normalization layer, as before (with horsepower_normalizer for a single-input model and normalizer for a multiple-input model).\nTwo hidden, non-linear, Dense layers with the ReLU (relu) activation function nonlinearity.\nA linear Dense single-output layer.\n\nBoth models will use the same training procedure so the compile method is included in the build_and_compile_model function below.\n\nbuild_and_compile_model <- function(norm) {\n  model <- keras_model_sequential() %>% \n    norm() %>% \n    layer_dense(64, activation = 'relu') %>% \n    layer_dense(64, activation = 'relu') %>% \n    layer_dense(1)\n\n  model %>% compile(\n    loss = 'mean_absolute_error',\n    optimizer = optimizer_adam(0.001)\n  )\n  \n  model\n}\n\n\nRegression using a DNN and a single input\nCreate a DNN model with only 'Horsepower' as input and horsepower_normalizer (defined earlier) as the normalization layer:\n\ndnn_horsepower_model <- build_and_compile_model(horsepower_normalizer)\n\nThis model has quite a few more trainable parameters than the linear models:\n\nsummary(dnn_horsepower_model)\n\nModel: \"sequential_2\"\n____________________________________________________________________________\n Layer (type)                Output Shape              Param #   Trainable  \n============================================================================\n normalization_1 (Normalizat  (None, 1)                3         Y          \n ion)                                                                       \n dense_4 (Dense)             (None, 64)                128       Y          \n dense_3 (Dense)             (None, 64)                4160      Y          \n dense_2 (Dense)             (None, 1)                 65        Y          \n============================================================================\nTotal params: 4,356\nTrainable params: 4,353\nNon-trainable params: 3\n____________________________________________________________________________\n\n\nTrain the model with Keras Model$fit:\n\nhistory <- dnn_horsepower_model %>% fit(\n  as.matrix(train_features$horsepower),\n  as.matrix(train_labels),\n  validation_split = 0.2,\n  verbose = 0, \n  epochs = 100\n)\n\nThis model does slightly better than the linear single-input horsepower_model:\n\nplot(history)\n\n\n\n\nIf you plot the predictions as a function of 'horsepower', you should notice how this model takes advantage of the nonlinearity provided by the hidden layers:\n\nx <- seq(0.0, 250, length.out = 251)\ny <- predict(dnn_horsepower_model, x)\n\n\nggplot(train_dataset) +\n  geom_point(aes(x = horsepower, y = mpg, color = \"data\")) +\n  geom_line(data = data.frame(x, y), aes(x = x, y = y, color = \"prediction\"))\n\n\n\n\nCollect the results on the test set for later:\n\ntest_results[['dnn_horsepower_model']] <- dnn_horsepower_model %>% evaluate(\n  as.matrix(test_features$horsepower), \n  as.matrix(test_labels),\n  verbose = 0\n)\n\n\n\nRegression using a DNN and multiple inputs\nRepeat the previous process using all the inputs. The model’s performance slightly improves on the validation dataset.\n\ndnn_model <- build_and_compile_model(normalizer)\nsummary(dnn_model)\n\nModel: \"sequential_3\"\n____________________________________________________________________________\n Layer (type)                Output Shape              Param #   Trainable  \n============================================================================\n normalization (Normalizatio  (None, 9)                19        Y          \n n)                                                                         \n dense_7 (Dense)             (None, 64)                640       Y          \n dense_6 (Dense)             (None, 64)                4160      Y          \n dense_5 (Dense)             (None, 1)                 65        Y          \n============================================================================\nTotal params: 4,884\nTrainable params: 4,865\nNon-trainable params: 19\n____________________________________________________________________________\n\n\n\nhistory <- dnn_model %>% fit(\n  as.matrix(train_features),\n  as.matrix(train_labels),\n  validation_split = 0.2,\n  verbose = 0, \n  epochs = 100\n)\n\n\nplot(history)\n\n\n\n\nCollect the results on the test set:\n\ntest_results[['dnn_model']] <- dnn_model %>% evaluate(\n  as.matrix(test_features), \n  as.matrix(test_labels), \n  verbose = 0\n)"
  },
  {
    "objectID": "tutorials/keras/regression.html#performance",
    "href": "tutorials/keras/regression.html#performance",
    "title": "Regression",
    "section": "Performance",
    "text": "Performance\nSince all models have been trained, you can review their test set performance:\n\nsapply(test_results, function(x) x)\n\n    horsepower_model.loss         linear_model.loss \n                 3.575989                  2.465263 \ndnn_horsepower_model.loss            dnn_model.loss \n                 3.201861                  1.801497 \n\n\nThese results match the validation error observed during training.\n\nMake predictions\nYou can now make predictions with the dnn_model on the test set using Keras predict() and review the loss:\n\ntest_predictions <- predict(dnn_model, as.matrix(test_features))\nggplot(data.frame(pred = as.numeric(test_predictions), mpg = test_labels$mpg)) +\n  geom_point(aes(x = pred, y = mpg)) +\n  geom_abline(intercept = 0, slope = 1, color = \"blue\")\n\n\n\n\nIt appears that the model predicts reasonably well.\nNow, check the error distribution:\n\nqplot(test_predictions - test_labels$mpg, geom = \"density\")\n\n\n\nerror <- test_predictions - test_labels\n\nIf you’re happy with the model, save it for later use with Model$save:\n\nsave_model_tf(dnn_model, 'dnn_model')\n\nIf you reload the model, it gives identical output:\n\nreloaded <- load_model_tf('dnn_model')\n\ntest_results[['reloaded']] <- reloaded %>% evaluate(\n  as.matrix(test_features), \n  as.matrix(test_labels), \n  verbose = 0\n)\n\n\nsapply(test_results, function(x) x)\n\n    horsepower_model.loss         linear_model.loss \n                 3.575989                  2.465263 \ndnn_horsepower_model.loss            dnn_model.loss \n                 3.201861                  1.801497 \n            reloaded.loss \n                 1.801497"
  },
  {
    "objectID": "tutorials/keras/regression.html#conclusion",
    "href": "tutorials/keras/regression.html#conclusion",
    "title": "Regression",
    "section": "Conclusion",
    "text": "Conclusion\nThis notebook introduced a few techniques to handle a regression problem. Here are a few more tips that may help:\n\nMean squared error (MSE) (loss_mean_squared_error()) and mean absolute error (MAE) (loss_mean_absolute_error()) are common loss functions used for regression problems. MAE is less sensitive to outliers. Different loss functions are used for classification problems.\nSimilarly, evaluation metrics used for regression differ from classification.\nWhen numeric input data features have values with different ranges, each feature should be scaled independently to the same range.\nOverfitting is a common problem for DNN models, though it wasn’t a problem for this tutorial. Visit the Overfit and underfit tutorial for more help with this."
  },
  {
    "objectID": "tutorials/keras/save_and_load.html",
    "href": "tutorials/keras/save_and_load.html",
    "title": "Save and load",
    "section": "",
    "text": "Model progress can be saved during and after training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work. When publishing research models and techniques, most machine learning practitioners share:\nSharing this data helps others understand how the model works and try it themselves with new data.\nCaution: TensorFlow models are code and it is important to be careful with untrusted code. See Using TensorFlow Securely for details."
  },
  {
    "objectID": "tutorials/keras/save_and_load.html#setup",
    "href": "tutorials/keras/save_and_load.html#setup",
    "title": "Save and load",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tensorflow)\nlibrary(keras)\n\n\nGet an example dataset\nTo demonstrate how to save and load weights, you’ll use the MNIST dataset. To speed up these runs, use the first 1000 examples:\n\nc(c(train_images, train_labels), c(test_images, test_labels)) %<-% dataset_mnist()\n\nLoaded Tensorflow version 2.9.1\n\ntrain_labels <- train_labels[1:1000]\ntest_labels <- test_labels[1:1000]\n\ntrain_images <- train_images[1:1000,,] %>% array_reshape(dim = c(1000, 784))/255\ntest_images <- test_images[1:1000,,] %>% array_reshape(dim = c(1000, 784))/255\n\n\n\nDefine a model\nStart by building a simple sequential model:\n\n# Define a simple sequential model\ncreate_model <- function() {\n  model <- keras_model_sequential() %>% \n    layer_dense(512, activation = 'relu', input_shape = shape(784)) %>% \n    layer_dropout(0.2) %>% \n    layer_dense(10)\n  \n  model %>% compile(\n    optimizer = 'adam',\n    loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),\n    metrics = list(metric_sparse_categorical_accuracy())\n  )\n  \n  model\n}\n\n# Create a basic model instance\nmodel <- create_model()\n\n# Display the model's architecture\nsummary(model)\n\nModel: \"sequential\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_1 (Dense)                  (None, 512)                   401920      \n dropout (Dropout)                (None, 512)                   0           \n dense (Dense)                    (None, 10)                    5130        \n============================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n____________________________________________________________________________"
  },
  {
    "objectID": "tutorials/keras/save_and_load.html#save-checkpoints-during-training",
    "href": "tutorials/keras/save_and_load.html#save-checkpoints-during-training",
    "title": "Save and load",
    "section": "Save checkpoints during training",
    "text": "Save checkpoints during training\nYou can use a trained model without having to retrain it, or pick-up training where you left off in case the training process was interrupted. The callback_model_checkpoint() callback allows you to continually save the model both during and at the end of training.\n\nCheckpoint callback usage\nCreate a callback_model_checkpoint() callback that saves weights only during training:\n\ncheckpoint_path <- \"training_1/cp.ckpt\"\ncheckpoint_dir <- fs::path_dir(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback <- callback_model_checkpoint(\n  filepath = checkpoint_path,\n  save_weights_only = TRUE,\n  verbose = 1\n)\n\n# Train the model with the new callback\nmodel %>% fit(\n  train_images, \n  train_labels,  \n  epochs = 10,\n  validation_data = list(test_images, test_labels),\n  callbacks = list(cp_callback) # Pass callback to training\n)  \n\n# This may generate warnings related to saving the state of the optimizer.\n# These warnings (and similar warnings throughout this notebook)\n# are in place to discourage outdated usage, and can be ignored.\n\nThis creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch:\n\nfs::dir_tree(checkpoint_dir)\n\ntraining_1\n├── checkpoint\n├── cp.ckpt.data-00000-of-00001\n└── cp.ckpt.index\n\n\nAs long as two models share the same architecture you can share weights between them. So, when restoring a model from weights-only, create a model with the same architecture as the original model and then set its weights.\nNow rebuild a fresh, untrained model and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):\n\n# Create a basic model instance\nmodel <- create_model()\n\n# Evaluate the model\nuntrained_results <- model %>% evaluate(test_images, test_labels, verbose = 2)\ncat(\"Untrained model results: \\n\")\n\nUntrained model results: \n\nuntrained_results\n\n                       loss sparse_categorical_accuracy \n                   2.314683                    0.122000 \n\n\nThen load the weights from the checkpoint and re-evaluate:\n\n# Loads the weights\nload_model_weights_tf(model, checkpoint_path)\n\n# Re-evaluate the model\nrestored_model <- model %>% evaluate(test_images, test_labels, verbose = 2)\ncat(\"Restored model results: \\n\")\n\nRestored model results: \n\nrestored_model\n\n                       loss sparse_categorical_accuracy \n                  0.4228736                   0.8610000 \n\n\n\n\nCheckpoint callback options\nThe callback provides several options to provide unique names for checkpoints and adjust the checkpointing frequency. Train a new model, and save uniquely named checkpoints once every five epochs:\n\n# Include the epoch in the file name \ncheckpoint_path <- \"training_2/cp-list{epoch:04d}.ckpt\"\ncheckpoint_dir <- fs::path_dir(checkpoint_path)\n\nbatch_size <- 32\n\n# Create a callback that saves the model's weights every 5 epochs\ncp_callback <- callback_model_checkpoint(\n  filepath = checkpoint_path,\n  verbose = 1,\n  save_weights_only = TRUE,\n  save_freq = 5*batch_size\n)\n\n# Create a new model instance\nmodel <- create_model()\n\n# Train the model with the new callback\nmodel %>% fit(\n  train_images, \n  train_labels,\n  epochs = 50, \n  batch_size = batch_size, \n  callbacks = list(cp_callback),\n  validation_data = list(test_images, test_labels),\n  verbose = 0\n)\n\nNow, look at the resulting checkpoints and choose the latest one:\n\nfs::dir_tree(checkpoint_dir)\n\ntraining_2\n├── checkpoint\n├── cp-list0005.ckpt.data-00000-of-00001\n├── cp-list0005.ckpt.index\n├── cp-list0010.ckpt.data-00000-of-00001\n├── cp-list0010.ckpt.index\n├── cp-list0015.ckpt.data-00000-of-00001\n├── cp-list0015.ckpt.index\n├── cp-list0020.ckpt.data-00000-of-00001\n├── cp-list0020.ckpt.index\n├── cp-list0025.ckpt.data-00000-of-00001\n├── cp-list0025.ckpt.index\n├── cp-list0030.ckpt.data-00000-of-00001\n├── cp-list0030.ckpt.index\n├── cp-list0035.ckpt.data-00000-of-00001\n├── cp-list0035.ckpt.index\n├── cp-list0040.ckpt.data-00000-of-00001\n├── cp-list0040.ckpt.index\n├── cp-list0045.ckpt.data-00000-of-00001\n├── cp-list0045.ckpt.index\n├── cp-list0050.ckpt.data-00000-of-00001\n└── cp-list0050.ckpt.index\n\n\n\nlatest <- tf$train$latest_checkpoint(checkpoint_dir)\nlatest\n\n[1] \"training_2/cp-list0050.ckpt\"\n\n\nNote: the default TensorFlow format only saves the 5 most recent checkpoints. To test, reset the model and load the latest checkpoint:\n\n# Create a new model instance\nmodel <- create_model()\n\n# Load the previously saved weights\nload_model_weights_tf(model, latest)\n\n# Re-evaluate the model\nmodel %>% evaluate(test_images, test_labels, verbose = 0)\n\n                       loss sparse_categorical_accuracy \n                  0.4657353                   0.8810000"
  },
  {
    "objectID": "tutorials/keras/save_and_load.html#what-are-these-files",
    "href": "tutorials/keras/save_and_load.html#what-are-these-files",
    "title": "Save and load",
    "section": "What are these files?",
    "text": "What are these files?\nThe above code stores the weights to a collection of checkpoint-formatted files that contain only the trained weights in a binary format. Checkpoints contain: * One or more shards that contain your model’s weights. * An index file that indicates which weights are stored in which shard.\nIf you are training a model on a single machine, you’ll have one shard with(the suffix, { }) .data-00000-of-00001"
  },
  {
    "objectID": "tutorials/keras/save_and_load.html#manually-save-weights",
    "href": "tutorials/keras/save_and_load.html#manually-save-weights",
    "title": "Save and load",
    "section": "Manually save weights",
    "text": "Manually save weights\nTo save weights manually, use save_model_weights_tf(). By default, Keras —and the save_model_weights_tf() method in particular—uses the TensorFlow Checkpoint format with a .ckpt extension. To save in the HDF5 format with a .h5 extension, refer to the Save and load models guide.\n\n# Save the weights\nsave_model_weights_tf(model, './checkpoints/my_checkpoint')\n\n# Create a new model instance\nmodel <- create_model()\n\n# Restore the weights\nload_model_weights_tf(model, './checkpoints/my_checkpoint')\n\n# Evaluate the model\nrestored_model <- model %>% evaluate(test_images, test_labels, verbose = 2)\ncat(\"Restored model results: \\n\")\n\nRestored model results: \n\nrestored_model\n\n                       loss sparse_categorical_accuracy \n                  0.4657353                   0.8810000"
  },
  {
    "objectID": "tutorials/keras/save_and_load.html#save-the-entire-model",
    "href": "tutorials/keras/save_and_load.html#save-the-entire-model",
    "title": "Save and load",
    "section": "Save the entire model",
    "text": "Save the entire model\nCall save_model_tf() to save a model’s architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code*. Since the optimizer-state is recovered, you can resume training from exactly where you left off.\nAn entire model can be saved in two different file formats (SavedModel and HDF5). The TensorFlow SavedModel format is the default file format in TF2$x. However, models can be saved in HDF5 format. More details on saving entire models in the two file formats is described below.\nSaving a fully-functional model is very useful—you can load them in TensorFlow.js (Saved Model, HDF5) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite (Saved Model, HDF5)\n*Custom objects (e.g. subclassed models or layers) require special attention when saving and loading. See the Saving custom objects section below\n\nSavedModel format\nThe SavedModel format is another way to serialize models. Models saved in this format can be restored using load_model_tf() and are compatible with TensorFlow Serving. The SavedModel guide goes into detail about how to serve/inspect the SavedModel. The section below illustrates the steps to save and restore the model.\n\n# Create and train a new model instance.\nmodel <- create_model()\nmodel %>% fit(train_images, train_labels, epochs = 5)\n\n# Save the entire model as a SavedModel.\nsave_model_tf(model, \"saved_model/my_model\")\n\nThe SavedModel format is a directory containing a protobuf binary and a TensorFlow checkpoint. Inspect the saved model directory:\n\n# my_model directory\n# Contains an assets folder, saved_model.pb, and variables folder.\nfs::dir_tree(\"saved_model/\")\n\nsaved_model/\n└── my_model\n    ├── assets\n    ├── keras_metadata.pb\n    ├── saved_model.pb\n    └── variables\n        ├── variables.data-00000-of-00001\n        └── variables.index\n\n\nReload a fresh Keras model from the saved model:\n\nnew_model <- load_model_tf('saved_model/my_model')\n\n# Check its architecture\nsummary(new_model)\n\nModel: \"sequential_5\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_11 (Dense)                 (None, 512)                   401920      \n dropout_5 (Dropout)              (None, 512)                   0           \n dense_10 (Dense)                 (None, 10)                    5130        \n============================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nThe restored model is compiled with the same arguments as the original model. Try running evaluate and predict with the loaded model.\n\n# Evaluate the restored model\nrestored_model <- new_model %>% evaluate(test_images, test_labels, verbose = 2)\nrestored_model\n\n                       loss sparse_categorical_accuracy \n                  0.4132914                   0.8640000 \n\ndim(predict(new_model, test_images))\n\n[1] 1000   10\n\n\n\n\nHDF5 format\nKeras provides a basic save format using the HDF5 standard.\n\n# Create and train a new model instance.\nmodel <- create_model()\nmodel %>% fit(train_images, train_labels, epochs = 5)\n\n# Save the entire model to a HDF5 file.\n# The '.h5' extension indicates that the model should be saved to HDF5.\nsave_model_hdf5(model, 'my_model.h5') \n\nNow, recreate the model from that file:\n\n# Recreate the exact same model, including its weights and the optimizer\nnew_model <- load_model_hdf5('my_model.h5')\n\n# Show the model architecture\nsummary(new_model)\n\nModel: \"sequential_6\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n dense_13 (Dense)                 (None, 512)                   401920      \n dropout_6 (Dropout)              (None, 512)                   0           \n dense_12 (Dense)                 (None, 10)                    5130        \n============================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nCheck its accuracy:\n\nnew_model %>% evaluate(test_images, test_labels, verbose = 0)\n\n                       loss sparse_categorical_accuracy \n                  0.4181948                   0.8630000 \n\n\nKeras saves models by inspecting their architectures. This technique saves everything:\n\nThe weight values\nThe model’s architecture\nThe model’s training configuration (what you pass to the compile() method)\nThe optimizer and its state, if any (this enables you to restart training where you left off)\n\nKeras is not able to save the v1$x optimizers (from tf.compat$v1$train) since they aren’t compatible with checkpoints. For v1$x optimizers, you need to re-compile the model after loading—losing the state of the optimizer.\n\n\nSaving custom objects\nIf you are using the SavedModel format, you can skip this section. The key difference between HDF5 and SavedModel is that HDF5 uses object configs to save the model architecture, while SavedModel saves the execution graph. Thus, SavedModels are able to save custom objects like subclassed models and custom layers without requiring the original code.\nTo save custom objects to HDF5, you must do the following:\n\nDefine a get_config method in your object, and optionally a from_config classmethod.\n\n\nget_config(self) returns a JSON-serializable dictionary of parameters needed to recreate the object.\nfrom_config(cls, config) uses the returned config from get_config to create a new object. By default, this function will use the config as initialization kwargs (return do.call(cls, config)).\n\n\nPass the object to the custom_objects argument when loading the model. The argument must be a dictionary mapping the string class name to the Python class. Eg. load_model_tf(path, custom_objects = list('CustomLayer'= CustomLayer))\n\nSee the Writing layers and models from scratch tutorial for examples of custom objects and get_config."
  },
  {
    "objectID": "tutorials/keras/text_classification.html",
    "href": "tutorials/keras/text_classification.html",
    "title": "Basic text classification",
    "section": "",
    "text": "This tutorial demonstrates text classification starting from plain text files stored on disk. You’ll train a binary classifier to perform sentiment analysis on an IMDB dataset. At the end of the notebook, there is an exercise for you to try, in which you’ll train a multi-class classifier to predict the tag for a programming question on Stack Overflow."
  },
  {
    "objectID": "tutorials/keras/text_classification.html#sentiment-analysis",
    "href": "tutorials/keras/text_classification.html#sentiment-analysis",
    "title": "Basic text classification",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\nThis notebook trains a sentiment analysis model to classify movie reviews as positive or negative, based on the text of the review. This is an example of binary—or two-class—classification, an important and widely applicable kind of machine learning problem.\nYou’ll use the Large Movie Review Dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews.\n\nDownload and explore the IMDB dataset\nLet’s download and extract the dataset, then explore the directory structure.\n\nurl <- \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n\ndataset <- get_file(\n  \"aclImdb_v1\", \n  url,\n  untar = TRUE, \n  cache_dir = '.',\n  cache_subdir = ''\n)\n\nLoaded Tensorflow version 2.9.1\n\ndataset_dir <- file.path(\"aclImdb\")\n\n\nlist.files(dataset_dir)\n\n[1] \"imdb.vocab\" \"imdbEr.txt\" \"README\"     \"test\"       \"train\"     \n\n\n\ntrain_dir <- file.path(dataset_dir, 'train')\nlist.files(train_dir)\n\n[1] \"labeledBow.feat\" \"neg\"             \"pos\"             \"unsup\"          \n[5] \"unsupBow.feat\"   \"urls_neg.txt\"    \"urls_pos.txt\"    \"urls_unsup.txt\" \n\n\nThe aclImdb/train/pos and aclImdb/train/neg directories contain many text files, each of which is a single movie review. Let’s take a look at one of them.\n\nsample_file <- file.path(train_dir, 'pos/1181_9.txt')\nreadr::read_file(sample_file)\n\n[1] \"Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\"\n\n\n\n\nLoad the dataset\nNext, you will load the data off disk and prepare it into a format suitable for training. To do so, you will use the helpful text_dataset_from_directory utility, which expects a directory structure as follows.\nmain_directory/\n...class_a/\n......a_text_1.txt\n......a_text_2.txt\n...class_b/\n......b_text_1.txt\n......b_text_2.txt\nTo prepare a dataset for binary classification, you will need two folders on disk, corresponding to class_a and class_b. These will be the positive and negative movie reviews, which can be found in aclImdb/train/pos and aclImdb/train/neg. As the IMDB dataset contains additional folders, you will remove them before using this utility.\n\nremove_dir <- file.path(train_dir, 'unsup')\nunlink(remove_dir, recursive = TRUE)\n\nNext, you will use the text_dataset_from_directory utility to create a labeled TensorFlow Dataset. tfdatasets is a powerful collection of tools for working with data.\nWhen running a machine learning experiment, it is a best practice to divide your dataset into three splits: train, validation, and test.\nThe IMDB dataset has already been divided into train and test, but it lacks a validation set. Let’s create a validation set using an 80:20 split of the training data by using the validation_split argument below.\n\nbatch_size <- 32\nseed <- 42\n\nraw_train_ds <- text_dataset_from_directory(\n  'aclImdb/train', \n  batch_size = batch_size, \n  validation_split = 0.2, \n  subset = 'training', \n  seed = seed\n)\n\nAs you can see above, there are 25,000 examples in the training folder, of which you will use 80% (or 20,000) for training. As you will see in a moment, you can train a model by passing a dataset directly to fit(). If you’re new to tfdatasets, you can also iterate over the dataset and print out a few examples as follows.\n\nbatch <- raw_train_ds %>% \n  reticulate::as_iterator() %>% \n  coro::collect(n = 1)\n\nbatch[[1]][[1]][1]\n\ntf.Tensor(b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)', shape=(), dtype=string)\n\nbatch[[1]][[2]][1]\n\ntf.Tensor(0, shape=(), dtype=int32)\n\n\nNotice the reviews contain raw text (with punctuation and occasional HTML tags like <br/>). You will show how to handle these in the following section.\nThe labels are 0 or 1. To see which of these correspond to positive and negative movie reviews, you can check the class_names property on the dataset.\n\ncat(\"Label 0 corresponds to\", raw_train_ds$class_names[1])\n\nLabel 0 corresponds to neg\n\ncat(\"Label 1 corresponds to\", raw_train_ds$class_names[2])\n\nLabel 1 corresponds to pos\n\n\nNext, you will create a validation and test dataset. You will use the remaining 5,000 reviews from the training set for validation.\nNote: When using the validation_split and subset arguments, make sure to either specify a random seed, or to pass shuffle = FALSE, so that the validation and training splits have no overlap.\n\nraw_val_ds <- text_dataset_from_directory(\n  'aclImdb/train', \n  batch_size = batch_size, \n  validation_split = 0.2, \n  subset = 'validation', \n  seed = seed\n)\n\n\nraw_test_ds <- text_dataset_from_directory(\n  'aclImdb/test', \n  batch_size = batch_size\n)\n\n\n\nPrepare the dataset for training\nNext, you will standardize, tokenize, and vectorize the data using the helpful layer_text_vectorization() layer.\nStandardization refers to preprocessing the text, typically to remove punctuation or HTML elements to simplify the dataset. Tokenization refers to splitting strings into tokens (for example, splitting a sentence into individual words, by splitting on whitespace). Vectorization refers to converting tokens into numbers so they can be fed into a neural network. All of these tasks can be accomplished with this layer.\nAs you saw above, the reviews contain various HTML tags like <br />. These tags will not be removed by the default standardizer in the TextVectorization layer (which converts text to lowercase and strips punctuation by default, but doesn’t strip HTML). You will write a custom standardization function to remove the HTML.\nNote: To prevent training-testing skew (also known as training-serving skew), it is important to preprocess the data identically at train and test time. To facilitate this, the text_vectorization layer can be included directly inside your model, as shown later in this tutorial.\n\n# creating a regex with all punctuation characters for replacing.\nre <- reticulate::import(\"re\")\n\npunctuation <- c(\"!\", \"\\\\\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", \"(\", \")\", \"*\", \n\"+\", \",\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \"=\", \">\", \"?\", \"@\", \"[\", \n\"\\\\\", \"\\\\\", \"]\", \"^\", \"_\", \"`\", \"{\", \"|\", \"}\", \"~\")\n\npunctuation_group <- punctuation %>% \n  sapply(re$escape) %>% \n  paste0(collapse = \"\") %>% \n  sprintf(\"[%s]\", .)\n\ncustom_standardization <- function(input_data) {\n  lowercase <- tf$strings$lower(input_data)\n  stripped_html <- tf$strings$regex_replace(lowercase, '<br />', ' ')\n  tf$strings$regex_replace(\n    stripped_html,\n    punctuation_group,\n    \"\"\n  )\n}\n\nNext, you will create a TextVectorization layer. You will use this layer to standardize, tokenize, and vectorize our data. You set the output_mode to int to create unique integer indices for each token.\nNote that you’re using the default split function, and the custom standardization function you defined above. You’ll also define some constants for the model, like an explicit maximum sequence_length, which will cause the layer to pad or truncate sequences to exactly sequence_length values.\n\nmax_features <- 10000\nsequence_length <- 250\n\nvectorize_layer <- layer_text_vectorization(\n  standardize = custom_standardization,\n  max_tokens = max_features,\n  output_mode = \"int\",\n  output_sequence_length = sequence_length\n)\n\nNext, you will call adapt() to fit the state of the preprocessing layer to the dataset. This will cause the model to build an index of strings to integers.\nNote: It’s important to only use your training data when calling adapt (using the test set would leak information).\n\n# Make a text-only dataset (without labels), then call adapt\ntrain_text <- raw_train_ds %>% \n  dataset_map(function(text, label) text)\nvectorize_layer %>% adapt(train_text)\n\nLet’s create a function to see the result of using this layer to preprocess some data.\n\nvectorize_text <- function(text, label) {\n  text <- tf$expand_dims(text, -1L)\n  list(vectorize_layer(text), label)\n}\n\n\n# retrieve a batch (of 32 reviews and labels) from the dataset\nbatch <- reticulate::as_iterator(raw_train_ds) %>% \n  reticulate::iter_next()\nfirst_review <- as.array(batch[[1]][1])\nfirst_label <- as.array(batch[[2]][1])\ncat(\"Review:\\n\", first_review)\n\nReview:\n Great movie - especially the music - Etta James - \"At Last\". This speaks volumes when you have finally found that special someone.\n\ncat(\"Label: \", raw_train_ds$class_names[first_label+1])\n\nLabel:  neg\n\ncat(\"Vectorized review: \\n\")\n\nVectorized review: \n\nprint(vectorize_text(first_review, first_label))\n\n[[1]]\ntf.Tensor(\n[[  86   17  260    2  222    1  571   31  229   11 2418    1   51   22\n    25  404  251   12  306  282    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 250), dtype=int64)\n\n[[2]]\n[1] 0\n\n\nAs you can see above, each token has been replaced by an integer. You can lookup the token (string) that each integer corresponds to by calling .get_vocabulary() on the layer.\n\ncat(\"9257 ---> \",get_vocabulary(vectorize_layer)[9257 + 1]) # because R is onde indexed\n\n9257 --->  recipe\n\ncat(\" 15 ---> \",get_vocabulary(vectorize_layer)[15 + 1])\n\n 15 --->  for\n\ncat(\"Vocabulary size: \" , length(get_vocabulary(vectorize_layer)))\n\nVocabulary size:  10000\n\n\nYou are nearly ready to train your model. As a final preprocessing step, you will apply the text_vectorization layer you created earlier to the train, validation, and test dataset.\n\ntrain_ds <- raw_train_ds %>% dataset_map(vectorize_text)\nval_ds <- raw_val_ds %>% dataset_map(vectorize_text)\ntest_ds <- raw_test_ds %>% dataset_map(vectorize_text)\n\n\n\nConfigure the dataset for performance\nThese are two important methods you should use when loading data to make sure that I/O does not become blocking.\ndataset_cache() keeps data in memory after it’s loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\ndataset_prefetch() overlaps data preprocessing and model execution while training.\nYou can learn more about both methods, as well as how to cache data to disk in the data performance guide.\n\nAUTOTUNE <- tf$data$AUTOTUNE\n\ntrain_ds <- train_ds %>% \n  dataset_cache() %>% \n  dataset_prefetch(buffer_size = AUTOTUNE)\nval_ds <- val_ds %>% \n  dataset_cache() %>% \n  dataset_prefetch(buffer_size = AUTOTUNE)\ntest_ds <- test_ds %>% \n  dataset_cache() %>% \n  dataset_prefetch(buffer_size = AUTOTUNE)\n\n\n\nCreate the model\nIt’s time to create your neural network:\n\nembedding_dim <- 16\n\n\nmodel <- keras_model_sequential() %>% \n  layer_embedding(max_features + 1, embedding_dim) %>% \n  layer_dropout(0.2) %>% \n  layer_global_average_pooling_1d() %>% \n  layer_dropout(0.2) %>% \n  layer_dense(1)\n\nsummary(model)\n\nModel: \"sequential\"\n____________________________________________________________________________\n Layer (type)                     Output Shape                  Param #     \n============================================================================\n embedding (Embedding)            (None, None, 16)              160016      \n dropout_1 (Dropout)              (None, None, 16)              0           \n global_average_pooling1d (Global  (None, 16)                   0           \n AveragePooling1D)                                                          \n dropout (Dropout)                (None, 16)                    0           \n dense (Dense)                    (None, 1)                     17          \n============================================================================\nTotal params: 160,033\nTrainable params: 160,033\nNon-trainable params: 0\n____________________________________________________________________________\n\n\nThe layers are stacked sequentially to build the classifier:\n\nThe first layer is an embedding layer. This layer takes the integer-encoded reviews and looks up an embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding). To learn more about embeddings, check out the Word embeddings tutorial.\nNext, a global_average_pooling_1d layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\nThis fixed-length output vector is piped through a fully-connected (dense) layer with 16 hidden units.\nThe last layer is densely connected with a single output node.\n\n\n\nLoss function and optimizer\nA model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), you’ll use losses$BinaryCrossentropy loss function.\nNow, configure the model to use an optimizer and a loss function:\n\nmodel %>% compile(\n  loss = loss_binary_crossentropy(from_logits = TRUE),\n  optimizer = 'adam',\n  metrics = metric_binary_accuracy(threshold = 0)\n)\n\n\n\nTrain the model\nYou will train the model by passing the dataset object to the fit method.\n\nepochs <- 10\nhistory <- model %>% \n  fit(\n    train_ds,\n    validation_data = val_ds,\n    epochs = epochs\n  )\n\n\n\nEvaluate the model\nLet’s see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy.\n\nmodel %>% evaluate(test_ds)\n\n           loss binary_accuracy \n      0.3103359       0.8733600 \n\n\nThis fairly naive approach achieves an accuracy of about 86%.\n\n\nCreate a plot of accuracy and loss over time\nmodel %>% fit() returns a History object that contains everything that happened during training. You can use as.data.frame(history) to obtain a data.frame with metrics per epoch or plot(history) as below:\n\nplot(history)\n\n\n\n\nNotice the training loss decreases with each epoch and the training accuracy increases with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\nThis isn’t the case for the validation loss and accuracy—they seem to peak before the training accuracy. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations specific to the training data that do not generalize to test data.\nFor this particular case, you could prevent overfitting by simply stopping the training when the validation accuracy is no longer increasing. One way to do so is to use the callback_early_stopping() callback."
  },
  {
    "objectID": "tutorials/keras/text_classification.html#export-the-model",
    "href": "tutorials/keras/text_classification.html#export-the-model",
    "title": "Basic text classification",
    "section": "Export the model",
    "text": "Export the model\nIn the code above, you applied the text_vectorization layer to the dataset before feeding text to the model. If you want to make your model capable of processing raw strings (for example, to simplify deploying it), you can include the text_vectorization layer inside your model. To do so, you can create a new model using the weights you just trained.\n\nexport_model <- keras_model_sequential() %>% \n  vectorize_layer() %>% \n  model() %>% \n  layer_activation(activation = \"sigmoid\")\n  \nexport_model %>% compile(\n  loss = loss_binary_crossentropy(from_logits = FALSE), \n  optimizer = \"adam\", \n  metrics = 'accuracy'\n)\n\n# Test it with `raw_test_ds`, which yields raw strings\nexport_model %>% evaluate(raw_test_ds)\n\n     loss  accuracy \n0.3103358 0.8733600 \n\n\n\nInference on new data\nTo get predictions for new examples, you can simply call predict().\n\nexamples <- c(\n  \"The movie was great!\",\n  \"The movie was okay.\",\n  \"The movie was terrible...\"\n)\n\npredict(export_model, examples)\n\n          [,1]\n[1,] 0.6125446\n[2,] 0.4341286\n[3,] 0.3514057\n\n\nIncluding the text preprocessing logic inside your model enables you to export a model for production that simplifies deployment, and reduces the potential for train/test skew.\nThere is a performance difference to keep in mind when choosing where to apply your TextVectorization layer. Using it outside of your model enables you to do asynchronous CPU processing and buffering of your data when training on GPU. So, if you’re training your model on the GPU, you probably want to go with this option to get the best performance while developing your model, then switch to including the TextVectorization layer inside your model when you’re ready to prepare for deployment.\nVisit this tutorial to learn more about saving models."
  },
  {
    "objectID": "tutorials/keras/text_classification.html#exercise-multi-class-classification-on-stack-overflow-questions",
    "href": "tutorials/keras/text_classification.html#exercise-multi-class-classification-on-stack-overflow-questions",
    "title": "Basic text classification",
    "section": "Exercise: multi-class classification on Stack Overflow questions",
    "text": "Exercise: multi-class classification on Stack Overflow questions\nThis tutorial showed how to train a binary classifier from scratch on the IMDB dataset. As an exercise, you can modify this notebook to train a multi-class classifier to predict the tag of a programming question on Stack Overflow.\nA dataset has been prepared for you to use containing the body of several thousand programming questions (for example, “How can I sort a dictionary by value in Python?”) posted to Stack Overflow. Each of these is labeled with exactly one tag (either Python, CSharp, JavaScript, or Java). Your task is to take a question as input, and predict the appropriate tag, in this case, Python.\nThe dataset you will work with contains several thousand questions extracted from the much larger public Stack Overflow dataset on BigQuery, which contains more than 17 million posts.\nAfter downloading the dataset, you will find it has a similar directory structure to the IMDB dataset you worked with previously.\ntrain/\n...python/\n......0$txt\n......1$txt\n...javascript/\n......0$txt\n......1$txt\n...csharp/\n......0$txt\n......1$txt\n...java/\n......0$txt\n......1$txt\nNote: To increase the difficulty of the classification problem, occurrences of the words Python, CSharp, JavaScript, or Java in the programming questions have been replaced with the word blank (as many questions contain the language they’re about).\nTo complete this exercise, you should modify this notebook to work with(the Stack Overflow dataset by making the following modifications, { })\n\nAt the top of your notebook, update the code that downloads the IMDB dataset with code to download the Stack Overflow dataset that has already been prepared. As the Stack Overflow dataset has a similar directory structure, you will not need to make many modifications.\nModify the last layer of your model to Dense(4), as there are now four output classes.\nWhen compiling the model, change the loss to loss_sparse_categorical_crossentropy(). This is the correct loss function to use for a multi-class classification problem, when the labels for each class are integers (in this case, they can be 0, 1, 2, or 3). In addition, change the metrics to metrics = 'accuracy', since this is a multi-class classification problem (metric_binary_accuracy() is only used for binary classifiers).\nWhen plotting accuracy over time, change binary_accuracy and val_binary_accuracy to accuracy and val_accuracy, respectively.\nOnce these changes are complete, you will be able to train a multi-class classifier."
  },
  {
    "objectID": "tutorials/keras/text_classification.html#learning-more",
    "href": "tutorials/keras/text_classification.html#learning-more",
    "title": "Basic text classification",
    "section": "Learning more",
    "text": "Learning more\nThis tutorial introduced text classification from scratch. To learn more about the text classification workflow in general, check out the Text classification guide from Google Developers."
  },
  {
    "objectID": "tutorials/keras/text_classification_with_hub.html",
    "href": "tutorials/keras/text_classification_with_hub.html",
    "title": "Text Classification with Hub",
    "section": "",
    "text": "This notebook classifies movie reviews as positive or negative using the text of the review. This is an example of binary—or two-class—classification, an important and widely applicable kind of machine learning problem.\nThe tutorial demonstrates the basic application of transfer learning with TensorFlow Hub and Keras.\nIt uses the IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews.\nThis notebook uses keras, a high-level API to build and train models in TensorFlow, and TensorFlow hub, a library for loading trained models from TFHub in a single line of code. For a more advanced text classification tutorial using Keras, see the MLCC Text Classification Guide."
  },
  {
    "objectID": "tutorials/keras/text_classification_with_hub.html#download-the-imdb-dataset",
    "href": "tutorials/keras/text_classification_with_hub.html#download-the-imdb-dataset",
    "title": "Text Classification with Hub",
    "section": "Download the IMDB dataset",
    "text": "Download the IMDB dataset\nThe IMDB dataset is available on imdb reviews or on TensorFlow datasets. The following code downloads the IMDB dataset to your machine:\n\nif (dir.exists(\"aclImdb/\"))\n  unlink(\"aclImdb/\", recursive = TRUE)\nurl <- \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\ndataset <- get_file(\n  \"aclImdb_v1\", \n  url,\n  untar = TRUE, \n  cache_dir = '.',\n  cache_subdir = ''\n)\n\nLoaded Tensorflow version 2.9.1\n\nunlink(\"aclImdb/train/unsup/\", recursive = TRUE)\n\nWe can then create a TensorFlow dataset from the directory structure using the text_dataset_from_directory() function:\n\nbatch_size <- 512\nseed <- 42\n\ntrain_data <- text_dataset_from_directory(\n  'aclImdb/train', \n  batch_size = batch_size, \n  validation_split = 0.2, \n  subset = 'training', \n  seed = seed\n)\nvalidation_data <- text_dataset_from_directory(\n  'aclImdb/train', \n  batch_size = batch_size, \n  validation_split = 0.2, \n  subset = 'validation', \n  seed = seed\n)\ntest_data <- text_dataset_from_directory(\n  'aclImdb/test', \n  batch_size = batch_size\n)"
  },
  {
    "objectID": "tutorials/keras/text_classification_with_hub.html#explore-the-data",
    "href": "tutorials/keras/text_classification_with_hub.html#explore-the-data",
    "title": "Text Classification with Hub",
    "section": "Explore the data",
    "text": "Explore the data\nLet’s take a moment to understand the format of the data. Each example is a sentence representing the movie review and a corresponding label. The sentence is not preprocessed in any way. The label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review.\nLet’s print first 10 examples.\n\nbatch <- train_data %>% \n  reticulate::as_iterator() %>% \n  reticulate::iter_next()\n\nbatch[[1]][1]\n\ntf.Tensor(b'Upon seeing this film once again it appeared infinitely superior to me this time than the previous times I have viewed it. The acting is stunningly wonderful. The characters are very clearly drawn. Brad Pitt is simply superb as the errant son who rebels. The other actors and actresses are equally fine in every respect. Robert Redford creates a wonderful period piece from the days of speakeasies of the 1920s. The scenery is incredibly beautiful of the mountains and streams of western Montana. All in all, this is one of the finest films made in the 1990s.<br /><br />You must see this movie!<br /><br />', shape=(), dtype=string)\n\n\nLet’s also print the first 10 labels.\n\nbatch[[2]][1:10]\n\ntf.Tensor([1 0 1 0 0 0 1 1 0 0], shape=(10), dtype=int32)"
  },
  {
    "objectID": "tutorials/keras/text_classification_with_hub.html#build-the-model",
    "href": "tutorials/keras/text_classification_with_hub.html#build-the-model",
    "title": "Text Classification with Hub",
    "section": "Build the model",
    "text": "Build the model\nThe neural network is created by stacking layers—this requires three main architectural decisions:\n\nHow to represent the text?\nHow many layers to use in the model?\nHow many hidden units to use for each layer?\n\nIn this example, the input data consists of sentences. The labels to predict are either 0 or 1.\nOne way to represent the text is to convert sentences into embeddings vectors. Use a pre-trained text embedding as the first layer, which will have three advantages:\n\nYou don’t have to worry about text preprocessing,\nBenefit from transfer learning,\nthe embedding has a fixed size, so it’s simpler to process.\n\nFor this example you use a pre-trained text embedding model from TensorFlow Hub called google/nnlm-en-dim50/2.\nThere are many other pre-trained text embeddings from TFHub that can be used in this tutorial:\n\ngoogle/nnlm-en-dim128/2 - trained with the same NNLM architecture on the same data as google/nnlm-en-dim50/2, but with a larger embedding dimension. Larger dimensional embeddings can improve on your task but it may take longer to train your model.\ngoogle/nnlm-en-dim128-with-normalization/2 - the same as google/nnlm-en-dim128/2, but with additional text normalization such as removing punctuation. This can help if the text in your task contains additional characters or punctuation.\ngoogle/universal-sentence-encoder/4 - a much larger model yielding 512 dimensional embeddings trained with a deep averaging network (DAN) encoder.\n\nAnd many more! Find more text embedding models on TFHub.\nLet’s first create a Keras layer that uses a TensorFlow Hub model to embed the sentences, and try it out on a couple of input examples. Note that no matter the length of the input text, the output shape of the embeddings is: (num_examples, embedding_dimension).\n\nembedding <- \"https://tfhub.dev/google/nnlm-en-dim50/2\"\nhub_layer <- tfhub::layer_hub(handle = embedding, trainable = TRUE)\nhub_layer(batch[[1]][1:2])\n\ntf.Tensor(\n[[ 0.2563908   0.3877134   0.11458009  0.46377143 -0.27114576 -0.23548658\n  -0.05462555  0.05912564 -0.5467191   0.31118706 -0.16002828 -0.0705342\n  -0.2470538   0.09001822 -0.04209791 -0.33874798 -0.24183154 -0.32309988\n   0.10837323 -0.63822275  0.07474954 -0.47535443  0.40693292  0.31290898\n  -0.15077832  0.16694833 -0.6367394   0.18927394  0.4457423  -0.24568915\n  -0.46415132  0.2513454   0.14228597 -0.44085875 -0.2652811   0.0990484\n   0.18815233 -0.05307329  0.26779363 -0.6057923  -0.27559572  0.05044953\n  -0.48596263  0.21479745 -0.1746156  -0.6422215  -0.3165063  -0.33656728\n  -0.09484117 -0.07192937]\n [ 1.2899797   0.32863247 -0.00310844  0.82322246 -0.4098285  -0.5109544\n   0.08370163 -0.13269287 -1.170054    0.5531664  -0.05031176  0.14853315\n  -0.15995876  0.26997143 -0.34048218 -0.4932976  -0.25939593  0.03390278\n   0.25013083 -1.4177161   0.19143653 -0.23920083  1.2250862   0.41607666\n  -0.6656541   0.4240742  -1.280362    0.4722922   0.5342671  -0.84027433\n  -0.7578844   0.4437543   0.57404625 -0.51910627 -0.673646    0.62554073\n   0.5437521   0.22559977  0.17738008 -1.0557282   0.03807905  0.44274873\n  -0.45797473  0.17220233 -0.20477422 -0.30913746 -0.79076797 -0.72301215\n   0.00783109 -0.0088165 ]], shape=(2, 50), dtype=float32)\n\n\nLet’s now build the full model:\n\nmodel <- keras_model_sequential() %>% \n  hub_layer() %>% \n  layer_dense(16, activation = 'relu') %>% \n  layer_dense(1)\n\nsummary(model)\n\nModel: <no summary available, model was not built>\n\n\nThe layers are stacked sequentially to build the classifier:\n\nThe first layer is a TensorFlow Hub layer. This layer uses a pre-trained Saved Model to map a sentence into its embedding vector. The pre-trained text embedding model that you are using (google/nnlm-en-dim50/2) splits the sentence into tokens, embeds each token and then combines the embedding. The resulting dimensions are: (num_examples, embedding_dimension). For this NNLM model, the embedding_dimension is 50.\nThis fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\nThe last layer is densely connected with a single output node.\n\nLet’s compile the model.\n\nLoss function and optimizer\nA model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs logits (a single-unit layer with a linear activation), you’ll use the binary_crossentropy loss function.\nThis isn’t the only choice for a loss function, you could, for instance, choose mean_squared_error. But, generally, binary_crossentropy is better for dealing with probabilities—it measures the “distance” between probability distributions, or in our case, between the ground-truth distribution and the predictions.\nLater, when you are exploring regression problems (say, to predict the price of a house), you’ll see how to use another loss function called mean squared error.\nNow, configure the model to use an optimizer and a loss function:\n\nmodel %>% compile(\n  optimizer = 'adam',\n  loss = loss_binary_crossentropy(from_logits = TRUE),\n  metrics = 'accuracy'\n)"
  },
  {
    "objectID": "tutorials/keras/text_classification_with_hub.html#train-the-model",
    "href": "tutorials/keras/text_classification_with_hub.html#train-the-model",
    "title": "Text Classification with Hub",
    "section": "Train the model",
    "text": "Train the model\nTrain the model for 10 epochs in mini-batches of 512 samples. This is 10 iterations over all samples in the x_train and y_train tensors. While training, monitor the model’s loss and accuracy on the 10,000 samples from the validation set:\n\nhistory <- model %>% fit(\n  train_data,\n  epochs = 10,\n  validation_data = validation_data,\n  verbose <- 1\n)"
  },
  {
    "objectID": "tutorials/keras/text_classification_with_hub.html#evaluate-the-model",
    "href": "tutorials/keras/text_classification_with_hub.html#evaluate-the-model",
    "title": "Text Classification with Hub",
    "section": "Evaluate the model",
    "text": "Evaluate the model\nAnd let’s see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy.\n\nresults <- model %>% evaluate(test_data, verbose = 2)\nresults\n\n     loss  accuracy \n0.3699927 0.8572000 \n\n\nThis fairly naive approach achieves an accuracy of about 87%. With more advanced approaches, the model should get closer to 95%."
  },
  {
    "objectID": "tutorials/keras/text_classification_with_hub.html#further-reading",
    "href": "tutorials/keras/text_classification_with_hub.html#further-reading",
    "title": "Text Classification with Hub",
    "section": "Further reading",
    "text": "Further reading\n\nFor a more general way to work with string inputs and for a more detailed analysis of the progress of accuracy and loss during training, see the Text classification with preprocessed text tutorial.\nTry out more text-related tutorials using trained models from TFHub."
  },
  {
    "objectID": "tutorials/quickstart/advanced.html",
    "href": "tutorials/quickstart/advanced.html",
    "title": "Advanced",
    "section": "",
    "text": "Import TensorFlow into your program. If you haven’t installed TensorFlow yet, go to the installation guide.\n\nlibrary(tensorflow)\n\nError in reticulate::use_virtualenv(\"r-tensorflow-site\", required = TRUE) : \n  Directory ~/.virtualenvs/r-tensorflow-site is not a Python virtualenv\n\nlibrary(tfdatasets)\nlibrary(keras)\n\nLoad and prepare the MNIST dataset.\n\nc(c(x_train, y_train), c(x_test, y_test)) %<-% keras::dataset_mnist()\n\nLoaded Tensorflow version 2.9.1\n\nx_train[] <- x_train / 255\nx_test[] <-  x_test / 255 \n\nUse TensorFlow datasets to batch and shuffle the dataset:\n\nexpand_and_cast <- function(x, y) {\n  list(\n    tf$cast(tf$expand_dims(x, axis = 2L), tf$float32),\n    y\n  )\n}\n\n\ntrain_ds <- list(x_train, y_train) %>% \n  tensor_slices_dataset() %>% \n  dataset_shuffle(10000) %>% \n  dataset_batch(32)\n\ntest_ds <- tensor_slices_dataset(list(x_test, y_test)) %>% \n  dataset_batch(32)\n\nBuild the a model using the Keras model subclassing API:\n\nmy_model <- new_model_class(\n  \"my_model\",\n  initialize = function() {\n    super()$`__init__`()\n    self$conv1 <- layer_conv_2d(filters = 32, kernel_size = 3, activation = 'relu')\n    self$flatten <- layer_flatten()\n    self$d1 <- layer_dense(units = 128, activation = 'relu')\n    self$d2 <- layer_dense(units = 10)\n  },\n  call = function(inputs) {\n    inputs %>% \n      tf$expand_dims(3L) %>% \n      self$conv1() %>% \n      self$flatten() %>% \n      self$d1() %>% \n      self$d2()\n  }\n)\n\n# Create an instance of the model\nmodel <- my_model()\n\nChoose an optimizer and loss function for training:\n\nloss_object <- loss_sparse_categorical_crossentropy(from_logits = TRUE)\noptimizer <- optimizer_adam()\n\nSelect metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result.\n\ntrain_loss <- metric_mean(name = \"train_loss\")\ntrain_accuracy <- metric_sparse_categorical_accuracy(name = \"train_accuracy\")\n\ntest_loss <- metric_mean(name = \"test_loss\")\ntest_accuracy <- metric_sparse_categorical_accuracy(name = \"test_accuracy\")\n\nUse tf$GradientTape to train the model:\n\ntrain_step <- function(images, labels) {\n  with(tf$GradientTape() %as% tape, {\n    # training = TRUE is only needed if there are layers with different\n    # behavior during training versus inference (e.g. Dropout).\n    predictions <- model(images, training = TRUE)\n    loss <- loss_object(labels, predictions)\n  })\n  gradients <- tape$gradient(loss, model$trainable_variables)\n  optimizer$apply_gradients(zip_lists(gradients, model$trainable_variables))\n  train_loss(loss)\n  train_accuracy(labels, predictions)\n  1\n}\n\ntrain <- tfautograph::autograph(function(train_ds) {\n  for (batch in train_ds) {\n    train_step(batch[[1]], batch[[2]])\n  }\n})\n\nTest the model:\n\ntest_step <- function(images, labels) {\n  # training = FALSE is only needed if there are layers with different\n  # behavior during training versus inference (e.g. Dropout).\n  predictions <- model(images, training = FALSE)\n  t_loss <- loss_object(labels, predictions)\n  test_loss(t_loss)\n  test_accuracy(labels, predictions)\n}\ntest <- tfautograph::autograph(function(test_ds) {\n  for (batch in test_ds) {\n    test_step(batch[[1]], batch[[2]])\n  }\n})\n\n\nEPOCHS <- 1\nfor (epoch in seq_len(EPOCHS)) {\n  # Reset the metrics at the start of the next epoch\n  train_loss$reset_states()\n  train_accuracy$reset_states()\n  test_loss$reset_states()\n  test_accuracy$reset_states()\n  train(train_ds)\n  test(test_ds)\n  cat(sprintf('Epoch %d', epoch), \"\\n\")\n  cat(sprintf('Loss: %f', as.numeric(train_loss$result())), \"\\n\")\n  cat(sprintf('Accuracy: %f', train_accuracy$result() * 100), \"\\n\")\n  cat(sprintf('Test Loss: %f', test_loss$result()), \"\\n\")\n  cat(sprintf('Test Accuracy: %f', test_accuracy$result() * 100), \"\\n\")\n}\n\nEpoch 1 \nLoss: 0.133416 \nAccuracy: 96.003334 \nTest Loss: 0.061812 \nTest Accuracy: 97.879997 \n\n\nThe image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials."
  },
  {
    "objectID": "tutorials/quickstart/beginner.html",
    "href": "tutorials/quickstart/beginner.html",
    "title": "Beginner",
    "section": "",
    "text": "This short introduction uses Keras to:\n\nLoad a prebuilt dataset.\nBuild a neural network machine learning model that classifies images.\nTrain this neural network.\nEvaluate the accuracy of the model.\n\n\n\nImport TensorFlow into your program to get started:\n\nlibrary(tensorflow)\n\nError in reticulate::use_virtualenv(\"r-tensorflow-site\", required = TRUE) : \n  Directory ~/.virtualenvs/r-tensorflow-site is not a Python virtualenv\n\nlibrary(keras)\n\nSee the installation guide to learn how to correctly install TensorFlow for R.\n\n\n\nLoad and prepare the MNIST dataset. Convert the sample data from integers to floating-point numbers:\n\nc(c(x_train, y_train), c(x_test, y_test)) %<-% keras::dataset_mnist()\n\nLoaded Tensorflow version 2.9.1\n\nx_train[] <- x_train / 255\nx_test[] <-  x_test / 255 \n\n\n\n\nBuild a sequential model by stacking layers.\n\nmodel <- keras_model_sequential(input_shape = c(28, 28)) %>% \n  layer_flatten() %>% \n  layer_dense(128, activation = \"relu\") %>% \n  layer_dropout(0.2) %>% \n  layer_dense(10)\n\nFor each example, the model returns a vector of logits or log-odds scores, one for each class.\n\npredictions <- predict(model, x_train[1:2,,])\npredictions\n\n            [,1]      [,2]      [,3]       [,4]      [,5]        [,6]\n[1,] -0.45212924 -1.000679 1.0063702 -0.2813853 0.3640309 -0.03176719\n[2,] -0.03669837 -1.229428 0.5544991 -0.1326344 0.9059005 -0.55074894\n            [,7]        [,8]      [,9]      [,10]\n[1,] -0.01737098 0.002265602 0.4170726 -1.0100819\n[2,]  0.46314085 0.023755193 0.2630941 -0.4941591\n\n\nThe tf$nn$softmax function converts these logits to probabilities for each class:\n\ntf$nn$softmax(predictions)\n\ntf.Tensor(\n[[0.05908425 0.0341381  0.25403292 0.07008497 0.13363666 0.08995652\n  0.09126092 0.09307069 0.14091633 0.03381863]\n [0.08420331 0.02554661 0.15208381 0.07650058 0.21611985 0.05035932\n  0.13880548 0.08945072 0.113639   0.05329132]], shape=(2, 10), dtype=float64)\n\n\nNote: It is possible to bake the tf$nn$softmax function into the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it’s impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output.\nDefine a loss function for training using loss_sparse_categorical_crossentropy(), which takes a vector of logits and a TRUE index and returns a scalar loss for each example.\n\nloss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)\n\nThis loss is equal to the negative log probability of the true class: The loss is zero if the model is sure of the correct class. This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf$math$log(1/10) ~= 2.3.\n\nloss_fn(y_train[1:2], predictions)\n\ntf.Tensor(2.44147489276956, shape=(), dtype=float64)\n\n\nBefore you start training, configure and compile the model using Keras compile(). Set the optimizer class to adam, set the loss to the loss_fn function you defined earlier, and specify a metric to be evaluated for the model by setting the metrics parameter to accuracy.\n\nmodel %>% compile(\n  optimizer = \"adam\",\n  loss = loss_fn,\n  metrics = \"accuracy\"\n)\n\n\n\n\nUse the fit() method to adjust your model parameters and minimize the loss:\n\nmodel %>% fit(x_train, y_train, epochs = 5)\n\nThe evaluate() method checks the models performance, usually on a Validation-set or Test-set.\n\nmodel %>% evaluate(x_test,  y_test, verbose = 2)\n\n      loss   accuracy \n0.07559286 0.97729999 \n\n\nThe image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials.\nIf you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:\n\nprobability_model <- keras_model_sequential() %>% \n  model() %>% \n  layer_activation_softmax()\n\n\nprobability_model(x_test[1:5,,])\n\ntf.Tensor(\n[[5.05482731e-08 8.55492899e-10 7.38288236e-06 1.35267692e-04\n  8.05116390e-12 9.75205694e-09 1.18561099e-13 9.99837637e-01\n  1.85414120e-08 1.96653928e-05]\n [2.48872567e-08 5.27670607e-04 9.99467313e-01 4.85750343e-06\n  2.65540202e-19 1.64506261e-07 3.60757682e-08 1.13698737e-13\n  3.73362452e-09 6.57828216e-14]\n [1.00679961e-06 9.97797489e-01 4.69215098e-04 2.04522312e-05\n  5.64250649e-06 8.54686732e-06 2.22352446e-05 1.26194709e-03\n  4.13237256e-04 1.98122635e-07]\n [9.99778807e-01 8.29056990e-10 6.43533203e-05 8.32866021e-07\n  8.36042034e-07 4.16911098e-06 1.18370135e-05 7.52744018e-05\n  2.53316585e-08 6.39040591e-05]\n [2.04403341e-06 2.65768829e-09 1.00898387e-06 1.76633197e-08\n  9.97162521e-01 5.69798431e-08 3.26826154e-07 1.59583331e-04\n  4.31128592e-06 2.67019332e-03]], shape=(5, 10), dtype=float32)\n\n\n\n\n\nCongratulations! You have trained a machine learning model using a prebuilt dataset using the Keras API.\nFor more examples of using Keras, check out the tutorials. To learn more about building models with Keras, read the guides. If you want learn more about loading and preparing data, see the tutorials on image data loading or CSV data loading."
  },
  {
    "objectID": "tutorials/quickstart/beginner.html#set-up-tensorflow",
    "href": "tutorials/quickstart/beginner.html#set-up-tensorflow",
    "title": "Beginner",
    "section": "Set up TensorFlow",
    "text": "Set up TensorFlow\nImport TensorFlow into your program to get started:\n\nlibrary(tensorflow)\nlibrary(keras)\n\nSee the installation guide to learn how to correctly install TensorFlow for R."
  },
  {
    "objectID": "tutorials/quickstart/beginner.html#load-a-dataset",
    "href": "tutorials/quickstart/beginner.html#load-a-dataset",
    "title": "Beginner",
    "section": "Load a dataset",
    "text": "Load a dataset\nLoad and prepare the MNIST dataset. Convert the sample data from integers to floating-point numbers:\n\nc(c(x_train, y_train), c(x_test, y_test)) %<-% keras::dataset_mnist()\nx_train[] <- x_train / 255\nx_test[] <-  x_test / 255"
  },
  {
    "objectID": "tutorials/quickstart/beginner.html#build-a-machine-learning-model",
    "href": "tutorials/quickstart/beginner.html#build-a-machine-learning-model",
    "title": "Beginner",
    "section": "Build a machine learning model",
    "text": "Build a machine learning model\nBuild a sequential model by stacking layers.\n\nmodel <- keras_model_sequential(input_shape = c(28, 28)) %>% \n  layer_flatten() %>% \n  layer_dense(128, activation = \"relu\") %>% \n  layer_dropout(0.2) %>% \n  layer_dense(10)\n\nFor each example, the model returns a vector of logits or log-odds scores, one for each class.\n\npredictions <- predict(model, x_train[1:2,,])\npredictions\n\nThe tf$nn$softmax function converts these logits to probabilities for each class:\n\ntf$nn$softmax(predictions)\n\nNote: It is possible to bake the tf$nn$softmax function into the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it’s impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output.\nDefine a loss function for training using loss_sparse_categorical_crossentropy(), which takes a vector of logits and a TRUE index and returns a scalar loss for each example.\n\nloss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)\n\nThis loss is equal to the negative log probability of the true class: The loss is zero if the model is sure of the correct class. This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf$math$log(1/10) ~= 2.3.\n\nloss_fn(y_train[1:2], predictions)\n\nBefore you start training, configure and compile the model using Keras compile(). Set the optimizer class to adam, set the loss to the loss_fn function you defined earlier, and specify a metric to be evaluated for the model by setting the metrics parameter to accuracy.\n\nmodel %>% compile(\n  optimizer = \"adam\",\n  loss = loss_fn,\n  metrics = \"accuracy\"\n)"
  },
  {
    "objectID": "tutorials/quickstart/beginner.html#train-and-evaluate-your-model",
    "href": "tutorials/quickstart/beginner.html#train-and-evaluate-your-model",
    "title": "Beginner",
    "section": "Train and evaluate your model",
    "text": "Train and evaluate your model\nUse the fit() method to adjust your model parameters and minimize the loss:\n\nmodel %>% fit(x_train, y_train, epochs = 5)\n\nThe evaluate() method checks the models performance, usually on a Validation-set or Test-set.\n\nmodel %>% evaluate(x_test,  y_test, verbose = 2)\n\nThe image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials.\nIf you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:\n\nprobability_model <- keras_model_sequential() %>% \n  model() %>% \n  layer_activation_softmax()\n\n\nprobability_model(x_test[1:5,,])"
  },
  {
    "objectID": "tutorials/quickstart/beginner.html#conclusion",
    "href": "tutorials/quickstart/beginner.html#conclusion",
    "title": "Beginner",
    "section": "Conclusion",
    "text": "Conclusion\nCongratulations! You have trained a machine learning model using a prebuilt dataset using the Keras API.\nFor more examples of using Keras, check out the tutorials. To learn more about building models with Keras, read the guides. If you want learn more about loading and preparing data, see the tutorials on image data loading or CSV data loading."
  },
  {
    "objectID": "packages/keras/latest/news.html",
    "href": "packages/keras/latest/news.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fixed issue where input_shape supplied to custom layers defined with new_layer_class()\nwould result in an error (#1338)\nNew callback_backup_and_restore(), for resuming an interrupted fit() call.\nThe merging family of layers (layer_add, layer_concatenate, etc.) gain the ability to accept layers in ..., allowing for easier composition of residual blocks with the pipe %>%. e.g. something like this now works:\nblock_1_output <- ...\nblock_2_output <- block_1_output %>% \n  layer_conv_2d(64, 3, activation = \"relu\", padding = \"same\") %>% \n  layer_add(block_1_output)\nmodel$get_config() method now returns an R object that can be safely serialized to rds."
  },
  {
    "objectID": "packages/keras/latest/news.html#keras-2.2.4.1-cran",
    "href": "packages/keras/latest/news.html#keras-2.2.4.1-cran",
    "title": "TensorFlow for R",
    "section": "Keras 2.2.4.1 (CRAN)",
    "text": "Keras 2.2.4.1 (CRAN)\n\nUse tf.keras as default implementation module.\nAdded AppVeyor to test on Windows.\nAdded flow_images_from_dataframe function (#658).\nAllow for unknown input_shape in application_* functions.\nAdded save_model_tf and load_model_tf to save/load models in the TensorFlow’s SavedModel format."
  },
  {
    "objectID": "packages/keras/latest/news.html#keras-2.1.6",
    "href": "packages/keras/latest/news.html#keras-2.1.6",
    "title": "TensorFlow for R",
    "section": "Keras 2.1.6",
    "text": "Keras 2.1.6\n\nFix issue with single-element vectors passed to text preprocessing functions\nCompatibility with TensorFlow v1.7 Keras implementation\nSupport workers parameter for native Keras generators (e.g. flow_images_from_directory())\nAccept tensor as argument to k_pow()\nIn callback_reduce_lr_on_plateau(), rename epsilon argument to min_delta (backwards-compatible).\nAdd axis parameter to k_softmax()\nAdd send_as_json parameter to callback_remote_monitor()\nAdd data_format method to layer_flatten()\nIn multi_gpu_model(), add arguments cpu_merge and cpu_relocation (controlling whether to force the template model’s weights to be on CPU, and whether to operate merge operations on CPU or GPU).\nRecord correct loss name for tfruns when custom functions are provided for loss"
  },
  {
    "objectID": "packages/keras/latest/news.html#keras-2.1.5",
    "href": "packages/keras/latest/news.html#keras-2.1.5",
    "title": "TensorFlow for R",
    "section": "Keras 2.1.5",
    "text": "Keras 2.1.5\n\nSupport for custom constraints from R\nAdded timeseries_generator() utility function\nNew layer layer_depthwise_conv_2d()\nAdded brightness_range and validation_split arguments to [image_data_generator()]."
  },
  {
    "objectID": "packages/keras/latest/news.html#keras-2.1.4",
    "href": "packages/keras/latest/news.html#keras-2.1.4",
    "title": "TensorFlow for R",
    "section": "Keras 2.1.4",
    "text": "Keras 2.1.4\n\nAdded support for remove_learning_phase in export_savedmodel() to avoid removing learning phase.\nNormalize validation data to Keras array in fit() and fit_generator()\nEnsure that custom layers return a tuple from compute_output_shape()\nAdded Nasnet and Densenet pre-trained models\nNew layers layer_activation_softmax() and layer_separable_conv_1d()\nAdded amsgrad parameter to optimizer_adam()\nFix incompatibility with Progbar.update() method in Keras 2.1.4"
  },
  {
    "objectID": "packages/keras/latest/news.html#keras-2.1.3",
    "href": "packages/keras/latest/news.html#keras-2.1.3",
    "title": "TensorFlow for R",
    "section": "Keras 2.1.3",
    "text": "Keras 2.1.3\n\nModels saved via export_savedmodel() that make use of learning phases can now be exported without having to manually reload the original model.\nEnsure that models saved via export_savedmodel() can be served from CloudML\nRun image data generators with R preprocessing functions on the main thread\nReturn R list from texts_to_sequences()\nVarious fixes for use_implementation() function"
  },
  {
    "objectID": "packages/keras/latest/news.html#keras-2.0.6",
    "href": "packages/keras/latest/news.html#keras-2.0.6",
    "title": "TensorFlow for R",
    "section": "keras 2.0.6",
    "text": "keras 2.0.6\n\ninstall_keras() function which installs both TensorFlow and Keras\nUse keras package as default implementation rather than tf.contrib.keras\nTraining metrics plotted in realtime within the RStudio Viewer during fit\nserialize_model() and unserialize_model() functions for saving Keras models as ‘raw’ R objects.\nAutomatically convert 64-bit R floats to backend default float type\nEnsure that arrays passed to generator functions are normalized to C-order\nto_numpy_array() utility function for custom generators (enables custom generators to yield C-ordered arrays of the correct float type)\nAdded batch_size and write_grads arguments to callback_tensorboard()\nAdded return_state argument to recurrent layers.\nDon’t re-export install_tensorflow() and tf_config() from tensorflow package.\nis_keras_available() function to probe whether the Keras Python package is available in the current environment.\nas.data.frame() S3 method for Keras training history\nRemove names from keras_model() inputs\nReturn result of evaluate() as named list\nWrite run metrics and evaluation data to tfruns\nProvide hint to use r-tensorflow environment when importing keras"
  },
  {
    "objectID": "packages/keras/latest/reference/activation_relu.html",
    "href": "packages/keras/latest/reference/activation_relu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Activation functions\n\n\nrelu(...): Applies the rectified linear unit activation function.\nelu(...): Exponential Linear Unit.\nselu(...): Scaled Exponential Linear Unit (SELU).\nhard_sigmoid(...): Hard sigmoid activation function.\nlinear(...): Linear activation function (pass-through).\nsigmoid(...): Sigmoid activation function, sigmoid(x) = 1 / (1 + exp(-x)).\nsoftmax(...): Softmax converts a vector of values to a probability distribution.\nsoftplus(...): Softplus activation function, softplus(x) = log(exp(x) + 1).\nsoftsign(...): Softsign activation function, softsign(x) = x / (abs(x) + 1).\ntanh(...): Hyperbolic tangent activation function.\nexponential(...): Exponential activation function.\ngelu(...): Applies the Gaussian error linear unit (GELU) activation function.\nswish(...): Swish activation function, swish(x) = x * sigmoid(x).\n\n\n\nactivation_relu(x, alpha = 0, max_value = NULL, threshold = 0)\n\nactivation_elu(x, alpha = 1)\n\nactivation_selu(x)\n\nactivation_hard_sigmoid(x)\n\nactivation_linear(x)\n\nactivation_sigmoid(x)\n\nactivation_softmax(x, axis = -1)\n\nactivation_softplus(x)\n\nactivation_softsign(x)\n\nactivation_tanh(x)\n\nactivation_exponential(x)\n\nactivation_gelu(x, approximate = FALSE)\n\nactivation_swish(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor\n\n\nalpha\nAlpha value\n\n\nmax_value\nMax value\n\n\nthreshold\nThreshold value for thresholded activation.\n\n\naxis\nInteger, axis along which the softmax normalization is applied\n\n\napproximate\nA bool, whether to enable approximation.\n\n\n\n\n\n\nActivations functions can either be used through layer_activation(), or through the activation argument supported by all forward layers.\n\nactivation_selu() to be used together with the initialization “lecun_normal”.\nactivation_selu() to be used together with the dropout variant “AlphaDropout”.\n\n\n\n\nTensor with the same shape and dtype as x.\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/activations"
  },
  {
    "objectID": "packages/keras/latest/reference/adapt.html",
    "href": "packages/keras/latest/reference/adapt.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fits the state of the preprocessing layer to the data being passed\n\n\nFits the state of the preprocessing layer to the data being passed\n\n\n\nadapt(object, data, ..., batch_size = NULL, steps = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nPreprocessing layer object\n\n\ndata\nThe data to train on. It can be passed either as a tf.data.Dataset or as an R array.\n\n\n…\nUsed for forwards and backwards compatibility. Passed on to the underlying method.\n\n\nbatch_size\nInteger or NULL. Number of asamples per state update. If unspecified, batch_size will default to 32. Do not specify the batch_size if your data is in the form of datasets, generators, or keras.utils.Sequence instances (since they generate batches).\n\n\nsteps\nInteger or NULL. Total number of steps (batches of samples) When training with input tensors such as TensorFlow data tensors, the default NULL is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. If x is a tf.data.Dataset, and steps is NULL, the epoch will run until the input dataset is exhausted. When passing an infinitely repeating dataset, you must specify the steps argument. This argument is not supported with array inputs.\n\n\n\n\n\n\nAfter calling adapt on a layer, a preprocessing layer’s state will not update during training. In order to make preprocessing layers efficient in any distribution context, they are kept constant with respect to any compiled tf.Graphs that call the layer. This does not affect the layer use when adapting each layer only once, but if you adapt a layer multiple times you will need to take care to re-compile any compiled functions as follows:\n\nIf you are adding a preprocessing layer to a keras.Model, you need to call compile(model) after each subsequent call to adapt().\nIf you are calling a preprocessing layer inside tfdatasets::dataset_map(), you should call dataset_map() again on the input tf.data.Dataset after each adapt().\nIf you are using a tensorflow::tf_function() directly which calls a preprocessing layer, you need to call tf_function again on your callable after each subsequent call to adapt().\n\nkeras_model example with multiple adapts:\nhtml\n\nlayer <- layer_normalization(axis=NULL) adapt(layer, c(0, 2)) model <- keras_model_sequential(layer) predict(model, c(0, 1, 2)) # [1] -1 0 1\nadapt(layer, c(-1, 1)) compile(model) # This is needed to re-compile model.predict! predict(model, c(0, 1, 2)) # [1] 0 1 2 html\n\ntf.data.Dataset example with multiple adapts:\nhtml\n\nlayer <- layer_normalization(axis=NULL) adapt(layer, c(0, 2)) input_ds <- tfdatasets::range_dataset(0, 3) normalized_ds <- input_ds %>% tfdatasets::dataset_map(layer) str(reticulate::iterate(normalized_ds)) # List of 3 # $ :tf.Tensor([-1.], shape=(1,), dtype=float32) # $ :tf.Tensor([0.], shape=(1,), dtype=float32) # $ :tf.Tensor([1.], shape=(1,), dtype=float32) adapt(layer, c(-1, 1)) normalized_ds <- input_ds %>% tfdatasets::dataset_map(layer) # Re-map over the input dataset. str(reticulate::iterate(normalized_ds$as_numpy_iterator())) # List of 3 # $ : num [1(1d)] -1 # $ : num [1(1d)] 0 # $ : num [1(1d)] 1 html\n\n\n\n\n\nhttps://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method\nhttps://keras.io/guides/preprocessing_layers/#the-adapt-method"
  },
  {
    "objectID": "packages/keras/latest/reference/application_densenet.html",
    "href": "packages/keras/latest/reference/application_densenet.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates the DenseNet architecture.\n\n\nInstantiates the DenseNet architecture.\n\n\n\napplication_densenet(\n  blocks,\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000\n)\n\napplication_densenet121(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000\n)\n\napplication_densenet169(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000\n)\n\napplication_densenet201(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000\n)\n\ndensenet_preprocess_input(x, data_format = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nblocks\nnumbers of building blocks for the four dense layers.\n\n\ninclude_top\nwhether to include the fully-connected layer at the top of the network.\n\n\nweights\none of NULL (random initialization), ‘imagenet’ (pre-training on ImageNet), or the path to the weights file to be loaded.\n\n\ninput_tensor\noptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be (224, 224, 3) (with channels_last data format) or (3, 224, 224) (with channels_first data format). It should have exactly 3 inputs channels.\n\n\npooling\noptional pooling mode for feature extraction when include_top is FALSE. - NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. - avg means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. - max means that global max pooling will be applied.\n\n\nclasses\noptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified.\n\n\nx\na 3D or 4D array consists of RGB values within [0, 255].\n\n\ndata_format\ndata format of the image tensor.\n\n\n\n\n\n\nOptionally loads weights pre-trained on ImageNet. Note that when using TensorFlow, for best performance you should set image_data_format='channels_last' in your Keras config at ~/.keras/keras.json.\nThe model and the weights are compatible with TensorFlow, Theano, and CNTK. The data format convention used by the model is the one specified in your Keras config file."
  },
  {
    "objectID": "packages/keras/latest/reference/application_efficientnet.html",
    "href": "packages/keras/latest/reference/application_efficientnet.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates the EfficientNetB0 architecture\n\n\nInstantiates the EfficientNetB0 architecture\n\n\n\napplication_efficientnet_b0(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_efficientnet_b1(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_efficientnet_b2(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_efficientnet_b3(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_efficientnet_b4(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_efficientnet_b5(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_efficientnet_b6(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_efficientnet_b7(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninclude_top\nWhether to include the fully-connected layer at the top of the network. Defaults to TRUE.\n\n\nweights\nOne of NULL (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to 'imagenet'.\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\ninput_shape\nOptional shape list, only to be specified if include_top is FALSE. It should have exactly 3 inputs channels.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. Defaults to NULL. * NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. * 'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. * 'max' means that global max pooling will be applied.\n\n\nclasses\nOptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified. Defaults to 1000 (number of ImageNet classes).\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\n…\nFor backwards and forwards compatibility\n\n\n\n\n\n\nReference:\n\nhttps://arxiv.org/abs/1905.11946EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\n\nThis function returns a Keras image classification model, optionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see https://keras.io/api/applications/#usage-examples-for-image-classification-modelsthis page for detailed examples.\nFor transfer learning use cases, make sure to read the https://keras.io/guides/transfer_learning/guide to transfer learning & fine-tuning.\nEfficientNet models expect their inputs to be float tensors of pixels with values in the [0-255] range.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0\nhttps://keras.io/api/applications/"
  },
  {
    "objectID": "packages/keras/latest/reference/application_inception_resnet_v2.html",
    "href": "packages/keras/latest/reference/application_inception_resnet_v2.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Inception-ResNet v2 model, with weights trained on ImageNet\n\n\nInception-ResNet v2 model, with weights trained on ImageNet\n\n\n\napplication_inception_resnet_v2(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\",\n  ...\n)\n\ninception_resnet_v2_preprocess_input(x)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninclude_top\nWhether to include the fully-connected layer at the top of the network. Defaults to TRUE.\n\n\nweights\nOne of NULL (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to 'imagenet'.\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be (299, 299, 3). It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g. (150, 150, 3) would be one valid value.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. Defaults to NULL. * NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. * 'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. * 'max' means that global max pooling will be applied.\n\n\nclasses\nOptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified. Defaults to 1000 (number of ImageNet classes).\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\n…\nFor backwards and forwards compatibility\n\n\nx\npreprocess_input() takes an array or floating point tensor, 3D or 4D with 3 color channels, with values in the range [0, 255].\n\n\n\n\n\n\nDo note that the input image format for this model is different than for the VGG16 and ResNet models (299x299 instead of 224x224).\nThe inception_resnet_v2_preprocess_input() function should be used for image preprocessing.\n\n\n\nA Keras model instance."
  },
  {
    "objectID": "packages/keras/latest/reference/application_inception_v3.html",
    "href": "packages/keras/latest/reference/application_inception_v3.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Inception V3 model, with weights pre-trained on ImageNet.\n\n\nInception V3 model, with weights pre-trained on ImageNet.\n\n\n\napplication_inception_v3(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\",\n  ...\n)\n\ninception_v3_preprocess_input(x)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninclude_top\nWhether to include the fully-connected layer at the top of the network. Defaults to TRUE.\n\n\nweights\nOne of NULL (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to 'imagenet'.\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be (299, 299, 3). It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g. (150, 150, 3) would be one valid value.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. Defaults to NULL. * NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. * 'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. * 'max' means that global max pooling will be applied.\n\n\nclasses\nOptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified. Defaults to 1000 (number of ImageNet classes).\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\n…\nFor backwards and forwards compatibility\n\n\nx\npreprocess_input() takes an array or floating point tensor, 3D or 4D with 3 color channels, with values in the range [0, 255].\n\n\n\n\n\n\nDo note that the input image format for this model is different than for the VGG16 and ResNet models (299x299 instead of 224x224).\nThe inception_v3_preprocess_input() function should be used for image preprocessing.\n\n\n\nA Keras model instance."
  },
  {
    "objectID": "packages/keras/latest/reference/application_mobilenet.html",
    "href": "packages/keras/latest/reference/application_mobilenet.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "MobileNet model architecture.\n\n\nMobileNet model architecture.\n\n\n\napplication_mobilenet(\n  input_shape = NULL,\n  alpha = 1,\n  depth_multiplier = 1L,\n  dropout = 0.001,\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  pooling = NULL,\n  classes = 1000L,\n  classifier_activation = \"softmax\",\n  ...\n)\n\nmobilenet_preprocess_input(x)\n\nmobilenet_decode_predictions(preds, top = 5)\n\nmobilenet_load_model_hdf5(filepath)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be (224, 224, 3) (with channels_last data format) or (3, 224, 224) (with channels_first data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n\n\nalpha\ncontrols the width of the network. * If alpha < 1.0, proportionally decreases the number of filters in each layer. * If alpha > 1.0, proportionally increases the number of filters in each layer. * If alpha = 1, default number of filters from the paper are used at each layer.\n\n\ndepth_multiplier\ndepth multiplier for depthwise convolution (also called the resolution multiplier)\n\n\ndropout\ndropout rate\n\n\ninclude_top\nwhether to include the fully-connected layer at the top of the network.\n\n\nweights\nNULL (random initialization), imagenet (ImageNet weights), or the path to the weights file to be loaded.\n\n\ninput_tensor\noptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. - NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. - avg means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. - max means that global max pooling will be applied.\n\n\nclasses\noptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified.\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\n…\nFor backwards and forwards compatibility\n\n\nx\ninput tensor, 4D\n\n\npreds\nTensor encoding a batch of predictions.\n\n\ntop\ninteger, how many top-guesses to return.\n\n\nfilepath\nFile path\n\n\n\n\n\n\nThe mobilenet_preprocess_input() function should be used for image preprocessing. To load a saved instance of a MobileNet model use the mobilenet_load_model_hdf5() function. To prepare image input for MobileNet use mobilenet_preprocess_input(). To decode predictions use mobilenet_decode_predictions().\n\n\n\napplication_mobilenet() and mobilenet_load_model_hdf5() return a Keras model instance. mobilenet_preprocess_input() returns image input suitable for feeding into a mobilenet model. mobilenet_decode_predictions() returns a list of data frames with variables class_name, class_description, and score (one data frame per sample in batch input)."
  },
  {
    "objectID": "packages/keras/latest/reference/application_mobilenet_v2.html",
    "href": "packages/keras/latest/reference/application_mobilenet_v2.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "MobileNetV2 model architecture\n\n\nMobileNetV2 model architecture\n\n\n\napplication_mobilenet_v2(\n  input_shape = NULL,\n  alpha = 1,\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\",\n  ...\n)\n\nmobilenet_v2_preprocess_input(x)\n\nmobilenet_v2_decode_predictions(preds, top = 5)\n\nmobilenet_v2_load_model_hdf5(filepath)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be (224, 224, 3) (with channels_last data format) or (3, 224, 224) (with channels_first data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n\n\nalpha\ncontrols the width of the network. * If alpha < 1.0, proportionally decreases the number of filters in each layer. * If alpha > 1.0, proportionally increases the number of filters in each layer. * If alpha = 1, default number of filters from the paper are used at each layer.\n\n\ninclude_top\nwhether to include the fully-connected layer at the top of the network.\n\n\nweights\nNULL (random initialization), imagenet (ImageNet weights), or the path to the weights file to be loaded.\n\n\ninput_tensor\noptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. - NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. - avg means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. - max means that global max pooling will be applied.\n\n\nclasses\noptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified.\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\n…\nFor backwards and forwards compatibility\n\n\nx\ninput tensor, 4D\n\n\npreds\nTensor encoding a batch of predictions.\n\n\ntop\ninteger, how many top-guesses to return.\n\n\nfilepath\nFile path\n\n\n\n\n\n\napplication_mobilenet_v2() and mobilenet_v2_load_model_hdf5() return a Keras model instance. mobilenet_v2_preprocess_input() returns image input suitable for feeding into a mobilenet v2 model. mobilenet_v2_decode_predictions() returns a list of data frames with variables class_name, class_description, and score (one data frame per sample in batch input).\n\n\n\napplication_mobilenet"
  },
  {
    "objectID": "packages/keras/latest/reference/application_mobilenet_v3.html",
    "href": "packages/keras/latest/reference/application_mobilenet_v3.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates the MobileNetV3Large architecture\n\n\nInstantiates the MobileNetV3Large architecture\n\n\n\napplication_mobilenet_v3_large(\n  input_shape = NULL,\n  alpha = 1,\n  minimalistic = FALSE,\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  classes = 1000L,\n  pooling = NULL,\n  dropout_rate = 0.2,\n  classifier_activation = \"softmax\",\n  include_preprocessing = TRUE\n)\n\napplication_mobilenet_v3_small(\n  input_shape = NULL,\n  alpha = 1,\n  minimalistic = FALSE,\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  classes = 1000L,\n  pooling = NULL,\n  dropout_rate = 0.2,\n  classifier_activation = \"softmax\",\n  include_preprocessing = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_shape\nOptional shape vector, to be specified if you would like to use a model with an input image resolution that is not c(224, 224, 3). It should have exactly 3 inputs channels c(224, 224, 3). You can also omit this option if you would like to infer input_shape from an input_tensor. If you choose to include both input_tensor and input_shape then input_shape will be used if they match, if the shapes do not match then we will throw an error. E.g. c(160, 160, 3) would be one valid value.\n\n\nalpha\ncontrols the width of the network. This is known as the depth multiplier in the MobileNetV3 paper, but the name is kept for consistency with MobileNetV1 in Keras. * If alpha < 1.0, proportionally decreases the number of filters in each layer. * If alpha > 1.0, proportionally increases the number of filters in each layer. * If alpha = 1, default number of filters from the paper are used at each layer.\n\n\nminimalistic\nIn addition to large and small models this module also contains so-called minimalistic models, these models have the same per-layer dimensions characteristic as MobilenetV3 however, they don’t utilize any of the advanced blocks (squeeze-and-excite units, hard-swish, and 5x5 convolutions). While these models are less efficient on CPU, they are much more performant on GPU/DSP.\n\n\ninclude_top\nBoolean, whether to include the fully-connected layer at the top of the network. Defaults to TRUE.\n\n\nweights\nString, one of NULL (random initialization), ‘imagenet’ (pre-training on ImageNet), or the path to the weights file to be loaded.\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\nclasses\nInteger, optional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified.\n\n\npooling\nString, optional pooling mode for feature extraction when include_top is FALSE. * NULL means that the output of the model will be the 4D tensor output of the last convolutional block. * avg means that global average pooling will be applied to the output of the last convolutional block, and thus the output of the model will be a 2D tensor. * max means that global max pooling will be applied.\n\n\ndropout_rate\nfraction of the input units to drop on the last layer.\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\ninclude_preprocessing\nBoolean, whether to include the preprocessing layer (Rescaling) at the bottom of the network. Defaults to TRUE.\n\n\n\n\n\n\nReference:\n\nhttps://arxiv.org/pdf/1905.02244.pdfSearching for MobileNetV3 (ICCV 2019)\n\nThe following table describes the performance of MobileNets v3:\nMACs stands for Multiply Addsc(“list(\"lllll\")”, “list(\"\\n\", \" Classification Checkpoint \", list(), \" MACs(M) \", list(), \" Parameters(M) \", list(), \" Top1 Accuracy \", list(), \" Pixel1 CPU(ms) \", list(), \"\\n\", \" mobilenet_v3_large_1.0_224 \", list(), \" 217 \", list(), \" 5.4 \", list(), \" 75.6 \", list(), \" 51.2 \", list(), \"\\n\", \" mobilenet_v3_large_0.75_224 \", list(), \" 155 \", list(), \" 4.0 \", list(), \" 73.3 \", list(), \" 39.8 \", list(), \"\\n\", \" mobilenet_v3_large_minimalistic_1.0_224 \", list(), \" 209 \", list(), \" 3.9 \", list(), \" 72.3 \", list(), \" 44.1 \", list(), \"\\n\", \" mobilenet_v3_small_1.0_224 \", list(), \" 66 \", list(), \" 2.9 \", list(), \" 68.1 \", list(), \" 15.8 \", list(), \"\\n\", \" mobilenet_v3_small_0.75_224 \", list(), \" 44 \", list(), \" 2.4 \", list(), \" 65.4 \", list(), \" 12.8 \", list(), \"\\n\", \" mobilenet_v3_small_minimalistic_1.0_224 \", list(), \" 65 \", list(), \" 2.0 \", list(), \" 61.9 \", list(), \" 12.2 \", list(), \"\\n\")” )\nFor image classification use cases, see c(“list(\"https://keras.io/api/applications/#usage-examples-for-image-classification-models\")”, “list(\"this page for detailed examples\")”).\nFor transfer learning use cases, make sure to read the c(“list(\"https://keras.io/guides/transfer_learning/\")”, “list(\"guide to transfer learning & fine-tuning\")”).\n\n\n\nA keras Model instance\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Large\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small\nhttps://keras.io/api/applications/"
  },
  {
    "objectID": "packages/keras/latest/reference/application_nasnet.html",
    "href": "packages/keras/latest/reference/application_nasnet.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates a NASNet model.\n\n\nNote that only TensorFlow is supported for now, therefore it only works with the data format image_data_format='channels_last' in your Keras config at ~/.keras/keras.json.\n\n\n\napplication_nasnet(\n  input_shape = NULL,\n  penultimate_filters = 4032L,\n  num_blocks = 6L,\n  stem_block_filters = 96L,\n  skip_reduction = TRUE,\n  filter_multiplier = 2L,\n  include_top = TRUE,\n  weights = NULL,\n  input_tensor = NULL,\n  pooling = NULL,\n  classes = 1000,\n  default_size = NULL\n)\n\napplication_nasnetlarge(\n  input_shape = NULL,\n  include_top = TRUE,\n  weights = NULL,\n  input_tensor = NULL,\n  pooling = NULL,\n  classes = 1000\n)\n\napplication_nasnetmobile(\n  input_shape = NULL,\n  include_top = TRUE,\n  weights = NULL,\n  input_tensor = NULL,\n  pooling = NULL,\n  classes = 1000\n)\n\nnasnet_preprocess_input(x)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_shape\nOptional shape list, the input shape is by default (331, 331, 3) for NASNetLarge and (224, 224, 3) for NASNetMobile It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (224, 224, 3) would be one valid value.\n\n\npenultimate_filters\nNumber of filters in the penultimate layer. NASNet models use the notation NASNet (N @ P), where: - N is the number of blocks - P is the number of penultimate filters\n\n\nnum_blocks\nNumber of repeated blocks of the NASNet model. NASNet models use the notation NASNet (N @ P), where: - N is the number of blocks - P is the number of penultimate filters\n\n\nstem_block_filters\nNumber of filters in the initial stem block\n\n\nskip_reduction\nWhether to skip the reduction step at the tail end of the network. Set to FALSE for CIFAR models.\n\n\nfilter_multiplier\nControls the width of the network. * If filter_multiplier < 1.0, proportionally decreases the number of filters in each layer. * If filter_multiplier > 1.0, proportionally increases the number of filters in each layer. - If filter_multiplier = 1, default number of filters from the paper are used at each layer.\n\n\ninclude_top\nWhether to include the fully-connected layer at the top of the network.\n\n\nweights\nNULL (random initialization) or imagenet (ImageNet weights)\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. - NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. - avg means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. - max means that global max pooling will be applied.\n\n\nclasses\nOptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified.\n\n\ndefault_size\nSpecifies the default image size of the model\n\n\nx\na 4D array consists of RGB values within [0, 255]."
  },
  {
    "objectID": "packages/keras/latest/reference/application_resnet.html",
    "href": "packages/keras/latest/reference/application_resnet.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates the ResNet architecture\n\n\nInstantiates the ResNet architecture\n\n\n\napplication_resnet50(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  ...\n)\n\napplication_resnet101(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  ...\n)\n\napplication_resnet152(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  ...\n)\n\napplication_resnet50_v2(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_resnet101_v2(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\",\n  ...\n)\n\napplication_resnet152_v2(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\",\n  ...\n)\n\nresnet_preprocess_input(x)\n\nresnet_v2_preprocess_input(x)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninclude_top\nWhether to include the fully-connected layer at the top of the network. Defaults to TRUE.\n\n\nweights\nOne of NULL (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to 'imagenet'.\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be c(224, 224, 3) (with 'channels_last' data format) or c(3, 224, 224) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. c(200, 200, 3) would be one valid value.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. Defaults to NULL. * NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. * 'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. * 'max' means that global max pooling will be applied.\n\n\nclasses\nOptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified. Defaults to 1000 (number of ImageNet classes).\n\n\n…\nFor backwards and forwards compatibility\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\nx\npreprocess_input() takes an array or floating point tensor, 3D or 4D with 3 color channels, with values in the range [0, 255].\n\n\n\n\n\n\nReference:\n\nhttps://arxiv.org/abs/1512.03385Deep Residual Learning for Image Recognition (CVPR 2015)\n\nFor image classification use cases, see https://keras.io/api/applications/#usage-examples-for-image-classification-modelsthis page for detailed examples.\nFor transfer learning use cases, make sure to read the https://keras.io/guides/transfer_learning/guide to transfer learning & fine-tuning.\nNote: each Keras Application expects a specific kind of input preprocessing. For ResNet, call tf.keras.applications.resnet.preprocess_input on your inputs before passing them to the model. resnet.preprocess_input will convert the input images from RGB to BGR, then will zero-center each color channel with respect to the ImageNet dataset, without scaling.\n\n\n\n\nlibrary(keras)\n\n# instantiate the model\nmodel <- application_resnet50(weights = 'imagenet')\n\n# load the image\nimg_path <- \"elephant.jpg\"\nimg <- image_load(img_path, target_size = c(224,224))\nx <- image_to_array(img)\n\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# make predictions then decode and print them\npreds <- model %>% predict(x)\nimagenet_decode_predictions(preds, top = 3)[[1]]\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet101\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet152\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet101V2\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet152V2\nhttps://keras.io/api/applications/"
  },
  {
    "objectID": "packages/keras/latest/reference/application_vgg.html",
    "href": "packages/keras/latest/reference/application_vgg.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "VGG16 and VGG19 models for Keras.\n\n\nVGG16 and VGG19 models for Keras.\n\n\n\napplication_vgg16(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\"\n)\n\napplication_vgg19(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninclude_top\nwhether to include the 3 fully-connected layers at the top of the network.\n\n\nweights\nOne of NULL (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to 'imagenet'.\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be (224, 224, 3) It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. Defaults to NULL. * NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. * 'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. * 'max' means that global max pooling will be applied.\n\n\nclasses\nOptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified. Defaults to 1000 (number of ImageNet classes).\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\n\n\n\n\nOptionally loads weights pre-trained on ImageNet.\nThe imagenet_preprocess_input() function should be used for image preprocessing.\n\n\n\nKeras model instance.\n\n\n\n\nlibrary(keras)\n\nmodel <- application_vgg16(weights = 'imagenet', include_top = FALSE)\n\nimg_path <- \"elephant.jpg\"\nimg <- image_load(img_path, target_size = c(224,224))\nx <- image_to_array(img)\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\nfeatures <- model %>% predict(x)"
  },
  {
    "objectID": "packages/keras/latest/reference/application_xception.html",
    "href": "packages/keras/latest/reference/application_xception.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates the Xception architecture\n\n\nInstantiates the Xception architecture\n\n\n\napplication_xception(\n  include_top = TRUE,\n  weights = \"imagenet\",\n  input_tensor = NULL,\n  input_shape = NULL,\n  pooling = NULL,\n  classes = 1000,\n  classifier_activation = \"softmax\",\n  ...\n)\n\nxception_preprocess_input(x)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninclude_top\nWhether to include the fully-connected layer at the top of the network. Defaults to TRUE.\n\n\nweights\nOne of NULL (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Defaults to 'imagenet'.\n\n\ninput_tensor\nOptional Keras tensor (i.e. output of layer_input()) to use as image input for the model.\n\n\ninput_shape\noptional shape list, only to be specified if include_top is FALSE (otherwise the input shape has to be (299, 299, 3). It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g. (150, 150, 3) would be one valid value.\n\n\npooling\nOptional pooling mode for feature extraction when include_top is FALSE. Defaults to NULL. * NULL means that the output of the model will be the 4D tensor output of the last convolutional layer. * 'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. * 'max' means that global max pooling will be applied.\n\n\nclasses\nOptional number of classes to classify images into, only to be specified if include_top is TRUE, and if no weights argument is specified. Defaults to 1000 (number of ImageNet classes).\n\n\nclassifier_activation\nA string or callable. The activation function to use on the “top” layer. Ignored unless include_top = TRUE. Set classifier_activation = NULL to return the logits of the “top” layer. Defaults to 'softmax'. When loading pretrained weights, classifier_activation can only be NULL or \"softmax\".\n\n\n…\nFor backwards and forwards compatibility\n\n\nx\npreprocess_input() takes an array or floating point tensor, 3D or 4D with 3 color channels, with values in the range [0, 255].\n\n\n\n\n\n\nFor image classification use cases, see https://keras.io/api/applications/#usage-examples-for-image-classification-modelsthis page for detailed examples.\nFor transfer learning use cases, make sure to read the https://keras.io/guides/transfer_learning/guide to transfer learning & fine-tuning.\nThe default input image size for this model is 299x299.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/Xception\nhttps://keras.io/api/applications/"
  },
  {
    "objectID": "packages/keras/latest/reference/backend.html",
    "href": "packages/keras/latest/reference/backend.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Keras backend tensor engine\n\n\nObtain a reference to the keras.backend Python module used to implement tensor operations.\n\n\n\nbackend(convert = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nconvert\nBoolean; should Python objects be automatically converted to their equivalent? If set to FALSE, you can still manually convert Python objects to via the py_to_r() function.\n\n\n\n\n\n\nReference to Keras backend python module."
  },
  {
    "objectID": "packages/keras/latest/reference/bidirectional.html",
    "href": "packages/keras/latest/reference/bidirectional.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Bidirectional wrapper for RNNs\n\n\nBidirectional wrapper for RNNs\n\n\n\nbidirectional(\n  object,\n  layer,\n  merge_mode = \"concat\",\n  weights = NULL,\n  backward_layer = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nlayer\nA RNN layer instance, such as layer_lstm() or layer_gru(). It could also be a keras$layers$Layer instance that meets the following criteria: * Be a sequence-processing layer (accepts 3D+ inputs). * Have a go_backwards, return_sequences and return_state attribute (with the same semantics as for the RNN class). * Have an input_spec attribute. * Implement serialization via get_config() and from_config(). Note that the recommended way to create new RNN layers is to write a custom RNN cell and use it with layer_rnn(), instead of subclassing keras$layers$Layer directly. * When returns_sequences = TRUE, the output of the masked timestep will be zero regardless of the layer’s original zero_output_for_mask value.\n\n\nmerge_mode\nMode by which outputs of the forward and backward RNNs will be combined. One of 'sum', 'mul', 'concat', 'ave', NULL. If NULL, the outputs will not be combined, they will be returned as a list. Default value is 'concat'.\n\n\nweights\nSplit and propagated to the initial_weights attribute on the forward and backward layer.\n\n\nbackward_layer\nOptional keras.layers.RNN, or keras.layers.Layer instance to be used to handle backwards input processing. If backward_layer is not provided, the layer instance passed as the layer argument will be used to generate the backward layer automatically. Note that the provided backward_layer layer should have properties matching those of the layer argument, in particular it should have the same values for stateful, return_states, return_sequences, etc. In addition, backward_layer and layer should have different go_backwards argument values. A ValueError will be raised if these requirements are not met.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional\nhttps://keras.io/api/layers/recurrent_layers/bidirectional/\n\nOther layer wrappers: time_distributed()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_backup_and_restore.html",
    "href": "packages/keras/latest/reference/callback_backup_and_restore.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Callback to back up and restore the training state\n\n\nCallback to back up and restore the training state\n\n\n\ncallback_backup_and_restore(backup_dir, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nbackup_dir\nString, path to store the checkpoint. e.g. backup_dir = normalizePath('./backup') This is the directory in which the system stores temporary files to recover the model from jobs terminated unexpectedly. The directory cannot be reused elsewhere to store other files, e.g. by BackupAndRestore callback of another training, or by another callback (ModelCheckpoint) of the same training.\n\n\n…\nFor backwards and forwards compatibility\n\n\n\n\n\n\nBackupAndRestore callback is intended to recover training from an interruption that has happened in the middle of a fit(model) execution, by backing up the training states in a temporary checkpoint file (with the help of a tf.train.CheckpointManager), at the end of each epoch. Each backup overwrites the previously written checkpoint file, so at any given time there is at most one such checkpoint file for backup/restoring purpose.\nIf training restarts before completion, the training state (which includes the Model weights and epoch number) is restored to the most recently saved state at the beginning of a new fit() run. At the completion of a fit() run, the temporary checkpoint file is deleted.\nNote that the user is responsible to bring jobs back after the interruption. This callback is important for the backup and restore mechanism for fault tolerance purpose, and the model to be restored from an previous checkpoint is expected to be the same as the one used to back up. If user changes arguments passed to compile or fit, the checkpoint saved for fault tolerance can become invalid.\nNote:\n\nThis callback is not compatible with eager execution disabled.\nA checkpoint is saved at the end of each epoch. After restoring, fit() redoes any partial work during the unfinished epoch in which the training got restarted (so the work done before the interruption doesn’t affect the final model state).\nThis works for both single worker and multi-worker modes. When fit() is used with tf.distribute, it supports tf.distribute.MirroredStrategy, tf.distribute.MultiWorkerMirroredStrategy, tf.distribute.TPUStrategy, and tf.distribute.experimental.ParameterServerStrategy.\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/BackupAndRestore"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_csv_logger.html",
    "href": "packages/keras/latest/reference/callback_csv_logger.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Callback that streams epoch results to a csv file\n\n\nSupports all values that can be represented as a string\n\n\n\ncallback_csv_logger(filename, separator = \",\", append = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfilename\nfilename of the csv file, e.g. ‘run/log.csv’.\n\n\nseparator\nstring used to separate elements in the csv file.\n\n\nappend\nTRUE: append if file exists (useful for continuing training). FALSE: overwrite existing file,\n\n\n\n\n\n\nOther callbacks: callback_early_stopping(), callback_lambda(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_early_stopping.html",
    "href": "packages/keras/latest/reference/callback_early_stopping.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Stop training when a monitored quantity has stopped improving.\n\n\nStop training when a monitored quantity has stopped improving.\n\n\n\ncallback_early_stopping(\n  monitor = \"val_loss\",\n  min_delta = 0,\n  patience = 0,\n  verbose = 0,\n  mode = c(\"auto\", \"min\", \"max\"),\n  baseline = NULL,\n  restore_best_weights = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmonitor\nquantity to be monitored.\n\n\nmin_delta\nminimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\n\n\npatience\nnumber of epochs with no improvement after which training will be stopped.\n\n\nverbose\nverbosity mode, 0 or 1.\n\n\nmode\none of “auto”, “min”, “max”. In min mode, training will stop when the quantity monitored has stopped decreasing; in max mode it will stop when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity.\n\n\nbaseline\nBaseline value for the monitored quantity to reach. Training will stop if the model doesn’t show improvement over the baseline.\n\n\nrestore_best_weights\nWhether to restore model weights from the epoch with the best value of the monitored quantity. If FALSE, the model weights obtained at the last step of training are used.\n\n\n\n\n\n\nOther callbacks: callback_csv_logger(), callback_lambda(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_lambda.html",
    "href": "packages/keras/latest/reference/callback_lambda.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create a custom callback\n\n\nThis callback is constructed with anonymous functions that will be called at the appropriate time. Note that the callbacks expects positional arguments, as:\n\n\n\ncallback_lambda(\n  on_epoch_begin = NULL,\n  on_epoch_end = NULL,\n  on_batch_begin = NULL,\n  on_batch_end = NULL,\n  on_train_batch_begin = NULL,\n  on_train_batch_end = NULL,\n  on_train_begin = NULL,\n  on_train_end = NULL,\n  on_predict_batch_begin = NULL,\n  on_predict_batch_end = NULL,\n  on_predict_begin = NULL,\n  on_predict_end = NULL,\n  on_test_batch_begin = NULL,\n  on_test_batch_end = NULL,\n  on_test_begin = NULL,\n  on_test_end = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\non_epoch_begin\ncalled at the beginning of every epoch.\n\n\non_epoch_end\ncalled at the end of every epoch.\n\n\non_batch_begin\ncalled at the beginning of every training batch.\n\n\non_batch_end\ncalled at the end of every training batch.\n\n\non_train_batch_begin\ncalled at the beginning of every batch.\n\n\non_train_batch_end\ncalled at the end of every batch.\n\n\non_train_begin\ncalled at the beginning of model training.\n\n\non_train_end\ncalled at the end of model training.\n\n\non_predict_batch_begin\ncalled at the beginning of a batch in predict methods.\n\n\non_predict_batch_end\ncalled at the end of a batch in predict methods.\n\n\non_predict_begin\ncalled at the beginning of prediction.\n\n\non_predict_end\ncalled at the end of prediction.\n\n\non_test_batch_begin\ncalled at the beginning of a batch in evaluate methods. Also called at the beginning of a validation batch in the fit methods, if validation data is provided.\n\n\non_test_batch_end\ncalled at the end of a batch in evaluate methods. Also called at the end of a validation batch in the fit methods, if validation data is provided.\n\n\non_test_begin\ncalled at the beginning of evaluation or validation.\n\n\non_test_end\ncalled at the end of evaluation or validation.\n\n\n\n\n\n\n\non_epoch_begin and on_epoch_end expect two positional arguments: epoch, logs\non_batch_, on_train_batch_, on_predict_batch_* and on_test_batch_*, expect two positional arguments: batch, logs\non_train_, on_test_ and on_predict_* expect one positional argument: logs\n\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_learning_rate_scheduler.html",
    "href": "packages/keras/latest/reference/callback_learning_rate_scheduler.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Learning rate scheduler.\n\n\nLearning rate scheduler.\n\n\n\ncallback_learning_rate_scheduler(schedule)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nschedule\na function that takes an epoch index as input (integer, indexed from 0) and current learning rate and returns a new learning rate as output (float).\n\n\n\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_lambda(), callback_model_checkpoint(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_model_checkpoint.html",
    "href": "packages/keras/latest/reference/callback_model_checkpoint.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Save the model after every epoch.\n\n\nfilepath can contain named formatting options, which will be filled the value of epoch and keys in logs (passed in on_epoch_end). For example: if filepath is weights.{epoch:02d}-{val_loss:.2f}.hdf5, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.\n\n\n\ncallback_model_checkpoint(\n  filepath,\n  monitor = \"val_loss\",\n  verbose = 0,\n  save_best_only = FALSE,\n  save_weights_only = FALSE,\n  mode = c(\"auto\", \"min\", \"max\"),\n  period = NULL,\n  save_freq = \"epoch\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfilepath\nstring, path to save the model file.\n\n\nmonitor\nquantity to monitor.\n\n\nverbose\nverbosity mode, 0 or 1.\n\n\nsave_best_only\nif save_best_only=TRUE, the latest best model according to the quantity monitored will not be overwritten.\n\n\nsave_weights_only\nif TRUE, then only the model’s weights will be saved (save_model_weights_hdf5(filepath)), else the full model is saved (save_model_hdf5(filepath)).\n\n\nmode\none of “auto”, “min”, “max”. If save_best_only=TRUE, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically inferred from the name of the monitored quantity.\n\n\nperiod\nInterval (number of epochs) between checkpoints.\n\n\nsave_freq\n'epoch' or integer. When using ‘epoch’, the callback saves the model after each epoch. When using integer, the callback saves the model at end of a batch at which this many samples have been seen since last saving. Note that if the saving isn’t aligned to epochs, the monitored metric may potentially be less reliable (it could reflect as little as 1 batch, since the metrics get reset every epoch). Defaults to 'epoch'\n\n\n\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_lambda(), callback_learning_rate_scheduler(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_progbar_logger.html",
    "href": "packages/keras/latest/reference/callback_progbar_logger.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Callback that prints metrics to stdout.\n\n\nCallback that prints metrics to stdout.\n\n\n\ncallback_progbar_logger(count_mode = \"samples\", stateful_metrics = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncount_mode\nOne of “steps” or “samples”. Whether the progress bar should count samples seens or steps (batches) seen.\n\n\nstateful_metrics\nList of metric names that should not be averaged onver an epoch. Metrics in this list will be logged as-is in on_epoch_end. All others will be averaged in on_epoch_end.\n\n\n\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_lambda(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_reduce_lr_on_plateau.html",
    "href": "packages/keras/latest/reference/callback_reduce_lr_on_plateau.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reduce learning rate when a metric has stopped improving.\n\n\nModels often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced.\n\n\n\ncallback_reduce_lr_on_plateau(\n  monitor = \"val_loss\",\n  factor = 0.1,\n  patience = 10,\n  verbose = 0,\n  mode = c(\"auto\", \"min\", \"max\"),\n  min_delta = 1e-04,\n  cooldown = 0,\n  min_lr = 0\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmonitor\nquantity to be monitored.\n\n\nfactor\nfactor by which the learning rate will be reduced. new_lr = lr * factor\n\n\npatience\nnumber of epochs with no improvement after which learning rate will be reduced.\n\n\nverbose\nint. 0: quiet, 1: update messages.\n\n\nmode\none of “auto”, “min”, “max”. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; in max mode it will be reduced when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity.\n\n\nmin_delta\nthreshold for measuring the new optimum, to only focus on significant changes.\n\n\ncooldown\nnumber of epochs to wait before resuming normal operation after lr has been reduced.\n\n\nmin_lr\nlower bound on the learning rate.\n\n\n\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_lambda(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_progbar_logger(), callback_remote_monitor(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_remote_monitor.html",
    "href": "packages/keras/latest/reference/callback_remote_monitor.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Callback used to stream events to a server.\n\n\nCallback used to stream events to a server.\n\n\n\ncallback_remote_monitor(\n  root = \"https://localhost:9000\",\n  path = \"/publish/epoch/end/\",\n  field = \"data\",\n  headers = NULL,\n  send_as_json = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nroot\nroot url of the target server.\n\n\npath\npath relative to root to which the events will be sent.\n\n\nfield\nJSON field under which the data will be stored.\n\n\nheaders\nOptional named list of custom HTTP headers. Defaults to: list(Accept = “application/json”, Content-Type = “application/json”)\n\n\nsend_as_json\nWhether the request should be sent as application/json.\n\n\n\n\n\n\nEvents are sent to root + '/publish/epoch/end/' by default. Calls are HTTP POST, with a data argument which is a JSON-encoded dictionary of event data. If send_as_json is set to True, the content type of the request will be application/json. Otherwise the serialized JSON will be send within a form\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_lambda(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_tensorboard(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_tensorboard.html",
    "href": "packages/keras/latest/reference/callback_tensorboard.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TensorBoard basic visualizations\n\n\nThis callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, as well as activation histograms for the different layers in your model.\n\n\n\ncallback_tensorboard(\n  log_dir = NULL,\n  histogram_freq = 0,\n  batch_size = NULL,\n  write_graph = TRUE,\n  write_grads = FALSE,\n  write_images = FALSE,\n  embeddings_freq = 0,\n  embeddings_layer_names = NULL,\n  embeddings_metadata = NULL,\n  embeddings_data = NULL,\n  update_freq = \"epoch\",\n  profile_batch = 0\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlog_dir\nThe path of the directory where to save the log files to be parsed by Tensorboard. The default is NULL, which will use the active run directory (if available) and otherwise will use “logs”.\n\n\nhistogram_freq\nfrequency (in epochs) at which to compute activation histograms for the layers of the model. If set to 0, histograms won’t be computed.\n\n\nbatch_size\nsize of batch of inputs to feed to the network for histograms computation. No longer needed, ignored since TF 1.14.\n\n\nwrite_graph\nwhether to visualize the graph in Tensorboard. The log file can become quite large when write_graph is set to TRUE\n\n\nwrite_grads\nwhether to visualize gradient histograms in TensorBoard. histogram_freq must be greater than 0.\n\n\nwrite_images\nwhether to write model weights to visualize as image in Tensorboard.\n\n\nembeddings_freq\nfrequency (in epochs) at which selected embedding layers will be saved.\n\n\nembeddings_layer_names\na list of names of layers to keep eye on. If NULL or empty list all the embedding layers will be watched.\n\n\nembeddings_metadata\na named list which maps layer name to a file name in which metadata for this embedding layer is saved. See the https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin#saving_data_for_tensorboarddetails about the metadata file format. In case if the same metadata file is used for all embedding layers, string can be passed.\n\n\nembeddings_data\nData to be embedded at layers specified in embeddings_layer_names. Array (if the model has a single input) or list of arrays (if the model has multiple inputs). Learn https://www.tensorflow.org/text/guide/word_embeddingsmore about embeddings\n\n\nupdate_freq\n'batch' or 'epoch' or integer. When using 'batch', writes the losses and metrics to TensorBoard after each batch. The same applies for 'epoch'. If using an integer, let’s say 10000, the callback will write the metrics and losses to TensorBoard every 10000 samples. Note that writing too frequently to TensorBoard can slow down your training.\n\n\nprofile_batch\nProfile the batch to sample compute characteristics. By default, it will disbale profiling. Set profile_batch=2 profile the second batch. Must run in TensorFlow eager mode. (TF >= 1.14)\n\n\n\n\n\n\nTensorBoard is a visualization tool provided with TensorFlow.\nYou can find more information about TensorBoard https://www.tensorflow.org/tensorboard/get_startedhere.\nWhen using a backend other than TensorFlow, TensorBoard will still work (if you have TensorFlow installed), but the only feature available will be the display of the losses and metrics plots.\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_lambda(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_terminate_on_naan()"
  },
  {
    "objectID": "packages/keras/latest/reference/callback_terminate_on_naan.html",
    "href": "packages/keras/latest/reference/callback_terminate_on_naan.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Callback that terminates training when a NaN loss is encountered.\n\n\nCallback that terminates training when a NaN loss is encountered.\n\n\n\ncallback_terminate_on_naan()\n\n\n\nOther callbacks: callback_csv_logger(), callback_early_stopping(), callback_lambda(), callback_learning_rate_scheduler(), callback_model_checkpoint(), callback_progbar_logger(), callback_reduce_lr_on_plateau(), callback_remote_monitor(), callback_tensorboard()"
  },
  {
    "objectID": "packages/keras/latest/reference/clone_model.html",
    "href": "packages/keras/latest/reference/clone_model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Clone a model instance.\n\n\nModel cloning is similar to calling a model on new inputs, except that it creates new layers (and thus new weights) instead of sharing the weights of the existing layers.\n\n\n\nclone_model(model, input_tensors = NULL, clone_function = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmodel\nInstance of Keras model (could be a functional model or a Sequential model).\n\n\ninput_tensors\nOptional list of input tensors to build the model upon. If not provided, placeholders will be created.\n\n\nclone_function\nCallable to be used to clone each layer in the target model (except InputLayer instances). It takes as argument the layer instance to be cloned, and returns the corresponding layer instance to be used in the model copy. If unspecified, this callable defaults to the following serialization/deserialization function: function(layer) layer$`__class__`$from_config(layer$get_config()) By passing a custom callable, you can customize your copy of the model, e.g. by wrapping certain layers of interest (you might want to replace all LSTM instances with equivalent Bidirectional(LSTM(...)) instances, for example)."
  },
  {
    "objectID": "packages/keras/latest/reference/compile.keras.engine.training.model.html",
    "href": "packages/keras/latest/reference/compile.keras.engine.training.model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Configure a Keras model for training\n\n\nConfigure a Keras model for training\n\n\n\ncompilekeras.engine.training.Model( object, optimizer = NULL, loss = NULL, metrics = NULL, loss_weights = NULL, weighted_metrics = NULL, run_eagerly = NULL, steps_per_execution = NULL, …, target_tensors = NULL, sample_weight_mode = NULL )\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to compile.\n\n\noptimizer\nString (name of optimizer) or optimizer instance. For most models, this defaults to \"rmsprop\"\n\n\nloss\nString (name of objective function), objective function or a keras$losses$Loss subclass instance. An objective function is any callable with the signature loss = fn(y_true, y_pred), where y_true = ground truth values with shape = [batch_size, d0, .. dN], except sparse loss functions such as sparse categorical crossentropy where shape = [batch_size, d0, .. dN-1]. y_pred = predicted values with shape = [batch_size, d0, .. dN]. It returns a weighted loss float tensor. If a custom Loss instance is used and reduction is set to NULL, return value has the shape [batch_size, d0, .. dN-1] i.e. per-sample or per-timestep loss values; otherwise, it is a scalar. If the model has multiple outputs, you can use a different loss on each output by passing a dictionary or a list of losses. The loss value that will be minimized by the model will then be the sum of all individual losses, unless loss_weights is specified.\n\n\nmetrics\nList of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a keras$metrics$Metric class instance. See ?tf$keras$metrics. Typically you will use metrics=list('accuracy'). A function is any callable with the signature result = fn(y_true, y_pred). To specify different metrics for different outputs of a multi-output model, you could also pass a dictionary, such as metrics=list(output_a = 'accuracy', output_b = c('accuracy', 'mse')). You can also pass a list to specify a metric or a list of metrics for each output, such as metrics=list(list('accuracy'), list('accuracy', 'mse')) or metrics=list('accuracy', c('accuracy', 'mse')). When you pass the strings 'accuracy' or 'acc', this is converted to one of tf.keras.metrics.BinaryAccuracy, tf.keras.metrics.CategoricalAccuracy, tf.keras.metrics.SparseCategoricalAccuracy based on the loss function used and the model output shape. A similar conversion is done for the strings 'crossentropy' and 'ce'.\n\n\nloss_weights\nOptional list, dictionary, or named vector specifying scalar numeric coefficients to weight the loss contributions of different model outputs. The loss value that will be minimized by the model will then be the weighted sum of all individual losses, weighted by the loss_weights coefficients. If a list, it is expected to have a 1:1 mapping to the model’s outputs. If a dict, it is expected to map output names (strings) to scalar coefficients.\n\n\nweighted_metrics\nList of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n\n\nrun_eagerly\nBool. Defaults to FALSE. If TRUE, this Model’s logic will not be wrapped in a tf.function. Recommended to leave this as NULL unless your Model cannot be run inside a tf.function. run_eagerly=True is not supported when using tf.distribute.experimental.ParameterServerStrategy. If the model’s logic uses tensors in R control flow expressions like if and for, the model is still traceable with tf.function, but you will have to enter a tfautograph::autograph({}) directly.\n\n\nsteps_per_execution\nInt. Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python/R overhead. At most, one full epoch will be run each execution. If a number larger than the size of the epoch is passed, the execution will be truncated to the size of the epoch. Note that if steps_per_execution is set to N, Callback.on_batch_begin and Callback.on_batch_end methods will only be called every N batches (i.e. before/after each tf.function execution).\n\n\n…\nArguments supported for backwards compatibility only.\n\n\ntarget_tensors\nBy default, Keras will create a placeholder for the model’s target, which will be fed with the target data during training. If instead you would like to use your own target tensor (in turn, Keras will not expect external data for these targets at training time), you can specify them via the target_tensors argument. It should be a single tensor (for a single-output sequential model).\n\n\nsample_weight_mode\nIf you need to do timestep-wise sample weighting (2D weights), set this to “temporal”. NULL defaults to sample-wise weights (1D). If the model has multiple outputs, you can use a different sample_weight_mode on each output by passing a list of modes.\n\n\n\n\n\n\nOther model functions: evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/constraints.html",
    "href": "packages/keras/latest/reference/constraints.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Weight constraints\n\n\nFunctions that impose constraints on weight values.\n\n\n\nconstraint_maxnorm(max_value = 2, axis = 0)\n\nconstraint_nonneg()\n\nconstraint_unitnorm(axis = 0)\n\nconstraint_minmaxnorm(min_value = 0, max_value = 1, rate = 1, axis = 0)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmax_value\nThe maximum norm for the incoming weights.\n\n\naxis\nThe axis along which to calculate weight norms. For instance, in a dense layer the weight matrix has shape input_dim, output_dim, set axis to 0 to constrain each weight vector of length input_dim,. In a convolution 2D layer with dim_ordering=\"tf\", the weight tensor has shape rows, cols, input_depth, output_depth, set axis to c(0, 1, 2) to constrain the weights of each filter tensor of size rows, cols, input_depth.\n\n\nmin_value\nThe minimum norm for the incoming weights.\n\n\nrate\nThe rate for enforcing the constraint: weights will be rescaled to yield (1 - rate) * norm + rate * norm.clip(low, high). Effectively, this means that rate=1.0 stands for strict enforcement of the constraint, while rate<1.0 means that weights will be rescaled at each step to slowly move towards a value inside the desired interval.\n\n\n\n\n\n\n\nconstraint_maxnorm() constrains the weights incident to each hidden unit to have a norm less than or equal to a desired value.\nconstraint_nonneg() constraints the weights to be non-negative\nconstraint_unitnorm() constrains the weights incident to each hidden unit to have unit norm.\nconstraint_minmaxnorm() constrains the weights incident to each hidden unit to have the norm between a lower bound and an upper bound.\n\n\n\n\nhttps://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdfDropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014\nKerasConstraint"
  },
  {
    "objectID": "packages/keras/latest/reference/count_params.html",
    "href": "packages/keras/latest/reference/count_params.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Count the total number of scalars composing the weights.\n\n\nCount the total number of scalars composing the weights.\n\n\n\ncount_params(object)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nLayer or model object\n\n\n\n\n\n\nAn integer count\n\n\n\nOther layer methods: get_config(), get_input_at(), get_weights(), reset_states()"
  },
  {
    "objectID": "packages/keras/latest/reference/create_layer.html",
    "href": "packages/keras/latest/reference/create_layer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create a Keras Layer\n\n\nCreate a Keras Layer\n\n\n\ncreate_layer(layer_class, object, args = list())\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlayer_class\nPython layer class or R6 class of type KerasLayer\n\n\nobject\nObject to compose layer with. This is either a keras_model_sequential() to add the layer to, or another Layer which this layer will call.\n\n\nargs\nList of arguments to layer constructor function\n\n\n\n\n\n\nA Keras layer"
  },
  {
    "objectID": "packages/keras/latest/reference/create_layer_wrapper.html",
    "href": "packages/keras/latest/reference/create_layer_wrapper.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create a Keras Layer wrapper\n\n\nCreate a Keras Layer wrapper\n\n\n\ncreate_layer_wrapper(Layer, modifiers = NULL, convert = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nLayer\nA R6 or Python class generator that inherits from keras$layers$Layer\n\n\nmodifiers\nA named list of functions to modify to user-supplied arguments before they are passed on to the class constructor. (e.g., list(units = as.integer))\n\n\nconvert\nBoolean, whether the Python class and its methods should by default convert python objects to R objects. See guide ‘making_new_layers_and_models_via_subclassing.Rmd’ for example usage.\n\n\n\n\n\n\nAn R function that behaves similarly to the builtin keras layer_* functions. When called, it will create the class instance, and also optionally call it on a supplied argument object if it is present. This enables keras layers to compose nicely with the pipe (%>%).\nThe R function will arguments taken from the initialize (or init) method of the Layer.\nIf Layer is an R6 object, this will delay initializing the python session, so it is safe to use in an R package."
  },
  {
    "objectID": "packages/keras/latest/reference/create_wrapper.html",
    "href": "packages/keras/latest/reference/create_wrapper.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Create a Keras Wrapper\n\n\nR6 classes that inherit from keras$layers$Wrapper can now be instantiated directly by create_layer\n\n\n\ncreate_wrapper(wrapper_class, object, args = list())\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nwrapper_class\nR6 class of type KerasWrapper\n\n\nobject\nObject to compose layer with. This is either a keras_model_sequential() to add the layer to, or another Layer which this layer will call.\n\n\nargs\nList of arguments to layer constructor function\n\n\n\n\n\n\nA Keras wrapper"
  },
  {
    "objectID": "packages/keras/latest/reference/custom_metric.html",
    "href": "packages/keras/latest/reference/custom_metric.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Custom metric function\n\n\nCustom metric function\n\n\n\ncustom_metric(name, metric_fn)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nname\nname used to show training progress output\n\n\nmetric_fn\nAn R function with signature function(y_true, y_pred){} that accepts tensors.\n\n\n\n\n\n\nYou can provide an arbitrary R function as a custom metric. Note that the y_true and y_pred parameters are tensors, so computations on them should use backend tensor functions.\nUse the custom_metric() function to define a custom metric. Note that a name (‘mean_pred’) is provided for the custom metric function: this name is used within training progress output.\nIf you want to save and load a model with custom metrics, you should also specify the metric in the call the load_model_hdf5(). For example: load_model_hdf5(\"my_model.h5\", c('mean_pred' = metric_mean_pred)).\nAlternatively, you can wrap all of your code in a call to with_custom_object_scope() which will allow you to refer to the metric by name just like you do with built in keras metrics.\nDocumentation on the available backend tensor functions can be found at https://keras.rstudio.com/articles/backend.html#backend-functions.\nAlternative ways of supplying custom metrics:\n\ncustom_metric(): Arbitrary R function.\nmetric_mean_wrapper(): Wrap an arbitrary R function in a Metric instance.\nsubclass keras$metrics$Metric: see ?Metric for example.\n\n\n\n\nOther metrics: metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/dataset_boston_housing.html",
    "href": "packages/keras/latest/reference/dataset_boston_housing.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Boston housing price regression dataset\n\n\nDataset taken from the StatLib library which is maintained at Carnegie Mellon University.\n\n\n\ndataset_boston_housing(\n  path = \"boston_housing.npz\",\n  test_split = 0.2,\n  seed = 113L\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\nPath where to cache the dataset locally (relative to ~/.keras/datasets).\n\n\ntest_split\nfraction of the data to reserve as test set.\n\n\nseed\nRandom seed for shuffling the data before computing the test split.\n\n\n\n\n\n\nLists of training and test data: train\\(x, train\\)y, test\\(x, test\\)y.\nSamples contain 13 attributes of houses at different locations around the Boston suburbs in the late 1970s. Targets are the median values of the houses at a location (in k$).\n\n\n\nOther datasets: dataset_cifar100(), dataset_cifar10(), dataset_fashion_mnist(), dataset_imdb(), dataset_mnist(), dataset_reuters()"
  },
  {
    "objectID": "packages/keras/latest/reference/dataset_cifar10.html",
    "href": "packages/keras/latest/reference/dataset_cifar10.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "CIFAR10 small image classification\n\n\nDataset of 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images.\n\n\n\ndataset_cifar10()\n\n\n\nLists of training and test data: train\\(x, train\\)y, test\\(x, test\\)y.\nThe x data is an array of RGB image data with shape (num_samples, 3, 32, 32).\nThe y data is an array of category labels (integers in range 0-9) with shape (num_samples).\n\n\n\nOther datasets: dataset_boston_housing(), dataset_cifar100(), dataset_fashion_mnist(), dataset_imdb(), dataset_mnist(), dataset_reuters()"
  },
  {
    "objectID": "packages/keras/latest/reference/dataset_cifar100.html",
    "href": "packages/keras/latest/reference/dataset_cifar100.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "CIFAR100 small image classification\n\n\nDataset of 50,000 32x32 color training images, labeled over 100 categories, and 10,000 test images.\n\n\n\ndataset_cifar100(label_mode = c(\"fine\", \"coarse\"))\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlabel_mode\none of “fine”, “coarse”.\n\n\n\n\n\n\nLists of training and test data: train\\(x, train\\)y, test\\(x, test\\)y.\nThe x data is an array of RGB image data with shape (num_samples, 3, 32, 32).\nThe y data is an array of category labels with shape (num_samples).\n\n\n\nOther datasets: dataset_boston_housing(), dataset_cifar10(), dataset_fashion_mnist(), dataset_imdb(), dataset_mnist(), dataset_reuters()"
  },
  {
    "objectID": "packages/keras/latest/reference/dataset_fashion_mnist.html",
    "href": "packages/keras/latest/reference/dataset_fashion_mnist.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fashion-MNIST database of fashion articles\n\n\nDataset of 60,000 28x28 grayscale images of the 10 fashion article classes, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are encoded as integers from 0-9 which correspond to T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt,\n\n\n\ndataset_fashion_mnist()\n\n\n\nDataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:\n\n0 - T-shirt/top\n1 - Trouser\n2 - Pullover\n3 - Dress\n4 - Coat\n5 - Sandal\n6 - Shirt\n7 - Sneaker\n8 - Bag\n9 - Ankle boot\n\n\n\n\nLists of training and test data: train\\(x, train\\)y, test\\(x, test\\)y, where x is an array of grayscale image data with shape (num_samples, 28, 28) and y is an array of article labels (integers in range 0-9) with shape (num_samples).\n\n\n\nOther datasets: dataset_boston_housing(), dataset_cifar100(), dataset_cifar10(), dataset_imdb(), dataset_mnist(), dataset_reuters()"
  },
  {
    "objectID": "packages/keras/latest/reference/dataset_imdb.html",
    "href": "packages/keras/latest/reference/dataset_imdb.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "IMDB Movie reviews sentiment classification\n\n\nDataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer “3” encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: “only consider the top 10,000 most common words, but eliminate the top 20 most common words”.\n\n\n\ndataset_imdb(\n  path = \"imdb.npz\",\n  num_words = NULL,\n  skip_top = 0L,\n  maxlen = NULL,\n  seed = 113L,\n  start_char = 1L,\n  oov_char = 2L,\n  index_from = 3L\n)\n\ndataset_imdb_word_index(path = \"imdb_word_index.json\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\nWhere to cache the data (relative to ~/.keras/dataset).\n\n\nnum_words\nMax number of words to include. Words are ranked by how often they occur (in the training set) and only the most frequent words are kept\n\n\nskip_top\nSkip the top N most frequently occuring words (which may not be informative).\n\n\nmaxlen\nsequences longer than this will be filtered out.\n\n\nseed\nrandom seed for sample shuffling.\n\n\nstart_char\nThe start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.\n\n\noov_char\nWords that were cut out because of the num_words or skip_top limit will be replaced with this character.\n\n\nindex_from\nIndex actual words with this index and higher.\n\n\n\n\n\n\nAs a convention, “0” does not stand for a specific word, but instead is used to encode any unknown word.\n\n\n\nLists of training and test data: train\\(x, train\\)y, test\\(x, test\\)y.\nThe x data includes integer sequences. If the num_words argument was specific, the maximum possible index value is num_words-1. If the maxlen`argument was specified, the largest possible sequence length is maxlen.\nThe y data includes a set of integer labels (0 or 1).\nThe dataset_imdb_word_index() function returns a list where the names are words and the values are integer.\n\n\n\nOther datasets: dataset_boston_housing(), dataset_cifar100(), dataset_cifar10(), dataset_fashion_mnist(), dataset_mnist(), dataset_reuters()"
  },
  {
    "objectID": "packages/keras/latest/reference/dataset_mnist.html",
    "href": "packages/keras/latest/reference/dataset_mnist.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "MNIST database of handwritten digits\n\n\nDataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n\n\n\ndataset_mnist(path = \"mnist.npz\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\nPath where to cache the dataset locally (relative to ~/.keras/datasets).\n\n\n\n\n\n\nLists of training and test data: train\\(x, train\\)y, test\\(x, test\\)y, where x is an array of grayscale image data with shape (num_samples, 28, 28) and y is an array of digit labels (integers in range 0-9) with shape (num_samples).\n\n\n\nOther datasets: dataset_boston_housing(), dataset_cifar100(), dataset_cifar10(), dataset_fashion_mnist(), dataset_imdb(), dataset_reuters()"
  },
  {
    "objectID": "packages/keras/latest/reference/dataset_reuters.html",
    "href": "packages/keras/latest/reference/dataset_reuters.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reuters newswire topics classification\n\n\nDataset of 11,228 newswires from Reuters, labeled over 46 topics. As with dataset_imdb() , each wire is encoded as a sequence of word indexes (same conventions).\n\n\n\ndataset_reuters(\n  path = \"reuters.npz\",\n  num_words = NULL,\n  skip_top = 0L,\n  maxlen = NULL,\n  test_split = 0.2,\n  seed = 113L,\n  start_char = 1L,\n  oov_char = 2L,\n  index_from = 3L\n)\n\ndataset_reuters_word_index(path = \"reuters_word_index.pkl\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\nWhere to cache the data (relative to ~/.keras/dataset).\n\n\nnum_words\nMax number of words to include. Words are ranked by how often they occur (in the training set) and only the most frequent words are kept\n\n\nskip_top\nSkip the top N most frequently occuring words (which may not be informative).\n\n\nmaxlen\nTruncate sequences after this length.\n\n\ntest_split\nFraction of the dataset to be used as test data.\n\n\nseed\nRandom seed for sample shuffling.\n\n\nstart_char\nThe start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.\n\n\noov_char\nwords that were cut out because of the num_words or skip_top limit will be replaced with this character.\n\n\nindex_from\nindex actual words with this index and higher.\n\n\n\n\n\n\nLists of training and test data: train\\(x, train\\)y, test\\(x, test\\)y with same format as dataset_imdb(). The dataset_reuters_word_index() function returns a list where the names are words and the values are integer. e.g. word_index[[\"giraffe\"]] might return 1234.\n\n\n\nOther datasets: dataset_boston_housing(), dataset_cifar100(), dataset_cifar10(), dataset_fashion_mnist(), dataset_imdb(), dataset_mnist()"
  },
  {
    "objectID": "packages/keras/latest/reference/evaluate.keras.engine.training.model.html",
    "href": "packages/keras/latest/reference/evaluate.keras.engine.training.model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Evaluate a Keras model\n\n\nEvaluate a Keras model\n\n\n\nevaluatekeras.engine.training.Model( object, x = NULL, y = NULL, batch_size = NULL, verbose = “auto”, sample_weight = NULL, steps = NULL, callbacks = NULL, … )\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to evaluate\n\n\nx\nVector, matrix, or array of test data (or list if the model has multiple inputs). If all inputs in the model are named, you can also pass a list mapping input names to data. x can be NULL (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors). You can also pass a tfdataset or a generator returning a list with (inputs, targets) or (inputs, targets, sample_weights).\n\n\ny\nVector, matrix, or array of target (label) data (or list if the model has multiple outputs). If all outputs in the model are named, you can also pass a list mapping output names to data. y can be NULL (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors).\n\n\nbatch_size\nInteger or NULL. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n\n\nverbose\nVerbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch).\n\n\nsample_weight\nOptional array of the same length as x, containing weights to apply to the model’s loss for each sample. In the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode=\"temporal\" in compile().\n\n\nsteps\nTotal number of steps (batches of samples) before declaring the evaluation round finished. Ignored with the default value of NULL.\n\n\ncallbacks\nList of callbacks to apply during evaluation.\n\n\n…\nUnused\n\n\n\n\n\n\nNamed list of model test loss (or losses for models with multiple outputs) and model metrics.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/evaluate_generator.html",
    "href": "packages/keras/latest/reference/evaluate_generator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Evaluates the model on a data generator.\n\n\nThe generator should return the same kind of data as accepted by test_on_batch().\n\n\n\nevaluate_generator(\n  object,\n  generator,\n  steps,\n  max_queue_size = 10,\n  workers = 1,\n  callbacks = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to evaluate\n\n\ngenerator\nGenerator yielding lists (inputs, targets) or (inputs, targets, sample_weights)\n\n\nsteps\nTotal number of steps (batches of samples) to yield from generator before stopping.\n\n\nmax_queue_size\nMaximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n\n\nworkers\nMaximum number of threads to use for parallel processing. Note that parallel processing will only be performed for native Keras generators (e.g. flow_images_from_directory()) as R based generators must run on the main thread.\n\n\ncallbacks\nList of callbacks to apply during evaluation.\n\n\n\n\n\n\nNamed list of model test loss (or losses for models with multiple outputs) and model metrics.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/export_savedmodel.keras.engine.training.model.html",
    "href": "packages/keras/latest/reference/export_savedmodel.keras.engine.training.model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Export a Saved Model\n\n\nSerialize a model to disk.\n\n\n\nexport_savedmodelkeras.engine.training.Model( object, export_dir_base, overwrite = TRUE, versioned = !overwrite, remove_learning_phase = TRUE, as_text = FALSE, … )\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nAn object.\n\n\nexport_dir_base\nA string containing a directory in which to export the SavedModel.\n\n\noverwrite\nShould the export_dir_base directory be overwritten?\n\n\nversioned\nShould the model be exported under a versioned subdirectory?\n\n\nremove_learning_phase\nShould the learning phase be removed by saving and reloading the model? Defaults to TRUE.\n\n\nas_text\nWhether to write the SavedModel in text format.\n\n\n…\nOther arguments passed to tf.saved_model.save. (Used only if TensorFlow version >= 2.0)\n\n\n\n\n\n\nThe path to the exported directory, as a string."
  },
  {
    "objectID": "packages/keras/latest/reference/fit.keras.engine.training.model.html",
    "href": "packages/keras/latest/reference/fit.keras.engine.training.model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Train a Keras model\n\n\nTrains the model for a fixed number of epochs (iterations on a dataset).\n\n\n\nfitkeras.engine.training.Model( object, x = NULL, y = NULL, batch_size = NULL, epochs = 10, verbose = getOption(“keras.fit_verbose”, default = “auto”), callbacks = NULL, view_metrics = getOption(“keras.view_metrics”, default = “auto”), validation_split = 0, validation_data = NULL, shuffle = TRUE, class_weight = NULL, sample_weight = NULL, initial_epoch = 0, steps_per_epoch = NULL, validation_steps = NULL, … )\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel to train.\n\n\nx\nVector, matrix, or array of training data (or list if the model has multiple inputs). If all inputs in the model are named, you can also pass a list mapping input names to data. x can be NULL (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors). You can also pass a tfdataset or a generator returning a list with (inputs, targets) or (inputs, targets, sample_weights).\n\n\ny\nVector, matrix, or array of target (label) data (or list if the model has multiple outputs). If all outputs in the model are named, you can also pass a list mapping output names to data. y can be NULL (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors).\n\n\nbatch_size\nInteger or NULL. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n\n\nepochs\nNumber of epochs to train the model. Note that in conjunction with initial_epoch, epochs is to be understood as “final epoch”. The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.\n\n\nverbose\nVerbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch).\n\n\ncallbacks\nList of callbacks to be called during training.\n\n\nview_metrics\nView realtime plot of training metrics (by epoch). The default (\"auto\") will display the plot when running within RStudio, metrics were specified during model compile(), epochs > 1 and verbose > 0. Use the global keras.view_metrics option to establish a different default.\n\n\nvalidation_split\nFloat between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling.\n\n\nvalidation_data\nData on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. This could be a list (x_val, y_val) or a list (x_val, y_val, val_sample_weights). validation_data will override validation_split.\n\n\nshuffle\nshuffle: Logical (whether to shuffle the training data before each epoch) or string (for “batch”). “batch” is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not NULL.\n\n\nclass_weight\nOptional named list mapping indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to “pay more attention” to samples from an under-represented class.\n\n\nsample_weight\nOptional array of the same length as x, containing weights to apply to the model’s loss for each sample. In the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode=\"temporal\" in compile().\n\n\ninitial_epoch\nInteger, Epoch at which to start training (useful for resuming a previous training run).\n\n\nsteps_per_epoch\nTotal number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default NULL is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined.\n\n\nvalidation_steps\nOnly relevant if steps_per_epoch is specified. Total number of steps (batches of samples) to validate before stopping.\n\n\n…\nUnused\n\n\n\n\n\n\nA history object that contains all information collected during training.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/fit_generator.html",
    "href": "packages/keras/latest/reference/fit_generator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Fits the model on data yielded batch-by-batch by a generator.\n\n\nThe generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU.\n\n\n\nfit_generator(\n  object,\n  generator,\n  steps_per_epoch,\n  epochs = 1,\n  verbose = getOption(\"keras.fit_verbose\", default = 1),\n  callbacks = NULL,\n  view_metrics = getOption(\"keras.view_metrics\", default = \"auto\"),\n  validation_data = NULL,\n  validation_steps = NULL,\n  class_weight = NULL,\n  max_queue_size = 10,\n  workers = 1,\n  initial_epoch = 0\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model object\n\n\ngenerator\nA generator (e.g. like the one provided by flow_images_from_directory() or a custom R https://rstudio.github.io/reticulate/articles/calling_python.html#generators-1generator function). The output of the generator must be a list of one of these forms: html\n\n\nsteps_per_epoch\nTotal number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of samples if your dataset divided by the batch size.\n\n\nepochs\nInteger. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. Note that in conjunction with initial_epoch, epochs is to be understood as “final epoch”. The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.\n\n\nverbose\nVerbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch).\n\n\ncallbacks\nList of callbacks to apply during training.\n\n\nview_metrics\nView realtime plot of training metrics (by epoch). The default (\"auto\") will display the plot when running within RStudio, metrics were specified during model compile(), epochs > 1 and verbose > 0. Use the global keras.view_metrics option to establish a different default.\n\n\nvalidation_data\nthis can be either: * a generator for the validation data * a list (inputs, targets) * a list (inputs, targets, sample_weights). on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data.\n\n\nvalidation_steps\nOnly relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from generator before stopping at the end of every epoch. It should typically be equal to the number of samples of your validation dataset divided by the batch size.\n\n\nclass_weight\nOptional named list mapping class indices (integer) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to “pay more attention” to samples from an under-represented class.\n\n\nmax_queue_size\nMaximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n\n\nworkers\nMaximum number of threads to use for parallel processing. Note that parallel processing will only be performed for native Keras generators (e.g. flow_images_from_directory()) as R based generators must run on the main thread.\n\n\ninitial_epoch\nepoch at which to start training (useful for resuming a previous training run)\n\n\n\n\n\n\nTraining history object (invisibly)\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/fit_image_data_generator.html",
    "href": "packages/keras/latest/reference/fit_image_data_generator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fit image data generator internal statistics to some sample data.\n\n\nRequired for featurewise_center, featurewise_std_normalization and zca_whitening.\n\n\n\nfit_image_data_generator(object, x, augment = FALSE, rounds = 1, seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nimage_data_generator()\n\n\nx\narray, the data to fit on (should have rank 4). In case of grayscale data, the channels axis should have value 1, and in case of RGB data, it should have value 3.\n\n\naugment\nWhether to fit on randomly augmented samples\n\n\nrounds\nIf augment, how many augmentation passes to do over the data\n\n\nseed\nrandom seed.\n\n\n\n\n\n\nOther image preprocessing: flow_images_from_dataframe(), flow_images_from_data(), flow_images_from_directory(), image_load(), image_to_array()"
  },
  {
    "objectID": "packages/keras/latest/reference/fit_text_tokenizer.html",
    "href": "packages/keras/latest/reference/fit_text_tokenizer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Update tokenizer internal vocabulary based on a list of texts or list of sequences.\n\n\nUpdate tokenizer internal vocabulary based on a list of texts or list of sequences.\n\n\n\nfit_text_tokenizer(object, x)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nTokenizer returned by text_tokenizer()\n\n\nx\nVector/list of strings, or a generator of strings (for memory-efficiency); Alternatively a list of “sequence” (a sequence is a list of integer word indices).\n\n\n\n\n\n\nOther text tokenization: save_text_tokenizer(), sequences_to_matrix(), text_tokenizer(), texts_to_matrix(), texts_to_sequences_generator(), texts_to_sequences()"
  },
  {
    "objectID": "packages/keras/latest/reference/flow_images_from_data.html",
    "href": "packages/keras/latest/reference/flow_images_from_data.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Generates batches of augmented/normalized data from image data and labels\n\n\nGenerates batches of augmented/normalized data from image data and labels\n\n\n\nflow_images_from_data(\n  x,\n  y = NULL,\n  generator = image_data_generator(),\n  batch_size = 32,\n  shuffle = TRUE,\n  sample_weight = NULL,\n  seed = NULL,\n  save_to_dir = NULL,\n  save_prefix = \"\",\n  save_format = \"png\",\n  subset = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ndata. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, it should have value 3.\n\n\ny\nlabels (can be NULL if no labels are required)\n\n\ngenerator\nImage data generator to use for augmenting/normalizing image data.\n\n\nbatch_size\nint (default: 32).\n\n\nshuffle\nboolean (defaut: TRUE).\n\n\nsample_weight\nSample weights.\n\n\nseed\nint (default: NULL).\n\n\nsave_to_dir\nNULL or str (default: NULL). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).\n\n\nsave_prefix\nstr (default: ’’). Prefix to use for filenames of saved pictures (only relevant if save_to_dir is set).\n\n\nsave_format\none of “png”, “jpeg” (only relevant if save_to_dir is set). Default: “png”.\n\n\nsubset\nSubset of data (\"training\" or \"validation\") if validation_split is set in image_data_generator().\n\n\n\n\n\n\nYields batches indefinitely, in an infinite loop.\n\n\n\nOther image preprocessing: fit_image_data_generator(), flow_images_from_dataframe(), flow_images_from_directory(), image_load(), image_to_array()"
  },
  {
    "objectID": "packages/keras/latest/reference/flow_images_from_dataframe.html",
    "href": "packages/keras/latest/reference/flow_images_from_dataframe.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Takes the dataframe and the path to a directory and generates batches of augmented/normalized data.\n\n\nTakes the dataframe and the path to a directory and generates batches of augmented/normalized data.\n\n\n\nflow_images_from_dataframe(\n  dataframe,\n  directory = NULL,\n  x_col = \"filename\",\n  y_col = \"class\",\n  generator = image_data_generator(),\n  target_size = c(256, 256),\n  color_mode = \"rgb\",\n  classes = NULL,\n  class_mode = \"categorical\",\n  batch_size = 32,\n  shuffle = TRUE,\n  seed = NULL,\n  save_to_dir = NULL,\n  save_prefix = \"\",\n  save_format = \"png\",\n  subset = NULL,\n  interpolation = \"nearest\",\n  drop_duplicates = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataframe\ndata.frame containing the filepaths relative to directory (or absolute paths if directory is NULL) of the images in a character column. It should include other column/s depending on the class_mode: * if class_mode is “categorical” (default value) it must include the y_col column with the class/es of each image. Values in column can be character/list if a single class or list if multiple classes. * if class_mode is “binary” or “sparse” it must include the given y_col column with class values as strings. * if class_mode is “other” it should contain the columns specified in y_col. * if class_mode is “input” or NULL no extra column is needed.\n\n\ndirectory\ncharacter, path to the directory to read images from. If NULL, data in x_col column should be absolute paths.\n\n\nx_col\ncharacter, column in dataframe that contains the filenames (or absolute paths if directory is NULL).\n\n\ny_col\nstring or list, column/s in dataframe that has the target data.\n\n\ngenerator\nImage data generator to use for augmenting/normalizing image data.\n\n\ntarget_size\nEither NULL (default to original size) or integer vector (img_height, img_width).\n\n\ncolor_mode\none of “grayscale”, “rgb”. Default: “rgb”. Whether the images will be converted to have 1 or 3 color channels.\n\n\nclasses\noptional list of classes (e.g. c('dogs', 'cats'). Default: NULL If not provided, the list of classes will be automatically inferred from the y_col, which will map to the label indices, will be alphanumeric). The dictionary containing the mapping from class names to class indices can be obtained via the attribute class_indices.\n\n\nclass_mode\none of “categorical”, “binary”, “sparse”, “input”, “other” or None. Default: “categorical”. Mode for yielding the targets: * “binary”: 1D array of binary labels, * “categorical”: 2D array of one-hot encoded labels. Supports multi-label output. * “sparse”: 1D array of integer labels, * “input”: images identical to input images (mainly used to work with autoencoders), * “other”: array of y_col data, * “multi_output”: allow to train a multi-output model. Y is a list or a vector. NULL, no targets are returned (the generator will only yield batches of image data, which is useful to use in predict_generator()).\n\n\nbatch_size\nint (default: 32).\n\n\nshuffle\nboolean (defaut: TRUE).\n\n\nseed\nint (default: NULL).\n\n\nsave_to_dir\nNULL or str (default: NULL). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).\n\n\nsave_prefix\nstr (default: ’’). Prefix to use for filenames of saved pictures (only relevant if save_to_dir is set).\n\n\nsave_format\none of “png”, “jpeg” (only relevant if save_to_dir is set). Default: “png”.\n\n\nsubset\nSubset of data (\"training\" or \"validation\") if validation_split is set in image_data_generator().\n\n\ninterpolation\nInterpolation method used to resample the image if the target size is different from that of the loaded image. Supported methods are “nearest”, “bilinear”, and “bicubic”. If PIL version 1.1.3 or newer is installed, “lanczos” is also supported. If PIL version 3.4.0 or newer is installed, “box” and “hamming” are also supported. By default, “nearest” is used.\n\n\ndrop_duplicates\n(deprecated in TF >= 2.3) Boolean, whether to drop duplicate rows based on filename. The default value is TRUE.\n\n\n\n\n\n\nYields batches indefinitely, in an infinite loop.\n\n\n\nOther image preprocessing: fit_image_data_generator(), flow_images_from_data(), flow_images_from_directory(), image_load(), image_to_array()"
  },
  {
    "objectID": "packages/keras/latest/reference/flow_images_from_directory.html",
    "href": "packages/keras/latest/reference/flow_images_from_directory.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Generates batches of data from images in a directory (with optional augmented/normalized data)\n\n\nGenerates batches of data from images in a directory (with optional augmented/normalized data)\n\n\n\nflow_images_from_directory(\n  directory,\n  generator = image_data_generator(),\n  target_size = c(256, 256),\n  color_mode = \"rgb\",\n  classes = NULL,\n  class_mode = \"categorical\",\n  batch_size = 32,\n  shuffle = TRUE,\n  seed = NULL,\n  save_to_dir = NULL,\n  save_prefix = \"\",\n  save_format = \"png\",\n  follow_links = FALSE,\n  subset = NULL,\n  interpolation = \"nearest\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndirectory\npath to the target directory. It should contain one subdirectory per class. Any PNG, JPG, BMP, PPM, or TIF images inside each of the subdirectories directory tree will be included in the generator. See https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44dthis script for more details.\n\n\ngenerator\nImage data generator (default generator does no data augmentation/normalization transformations)\n\n\ntarget_size\ninteger vector, default: c(256, 256). The dimensions to which all images found will be resized.\n\n\ncolor_mode\none of “grayscale”, “rbg”. Default: “rgb”. Whether the images will be converted to have 1 or 3 color channels.\n\n\nclasses\noptional list of class subdirectories (e.g. c('dogs', 'cats')). Default: NULL, If not provided, the list of classes will be automatically inferred (and the order of the classes, which will map to the label indices, will be alphanumeric).\n\n\nclass_mode\none of “categorical”, “binary”, “sparse” or NULL. Default: “categorical”. Determines the type of label arrays that are returned: “categorical” will be 2D one-hot encoded labels, “binary” will be 1D binary labels, “sparse” will be 1D integer labels. If NULL, no labels are returned (the generator will only yield batches of image data, which is useful to use predict_generator(), evaluate_generator(), etc.).\n\n\nbatch_size\nint (default: 32).\n\n\nshuffle\nboolean (defaut: TRUE).\n\n\nseed\nint (default: NULL).\n\n\nsave_to_dir\nNULL or str (default: NULL). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).\n\n\nsave_prefix\nstr (default: ’’). Prefix to use for filenames of saved pictures (only relevant if save_to_dir is set).\n\n\nsave_format\none of “png”, “jpeg” (only relevant if save_to_dir is set). Default: “png”.\n\n\nfollow_links\nwhether to follow symlinks inside class subdirectories (default: FALSE)\n\n\nsubset\nSubset of data (\"training\" or \"validation\") if validation_split is set in image_data_generator().\n\n\ninterpolation\nInterpolation method used to resample the image if the target size is different from that of the loaded image. Supported methods are “nearest”, “bilinear”, and “bicubic”. If PIL version 1.1.3 or newer is installed, “lanczos” is also supported. If PIL version 3.4.0 or newer is installed, “box” and “hamming” are also supported. By default, “nearest” is used.\n\n\n\n\n\n\nYields batches indefinitely, in an infinite loop.\n\n\n\nOther image preprocessing: fit_image_data_generator(), flow_images_from_dataframe(), flow_images_from_data(), image_load(), image_to_array()"
  },
  {
    "objectID": "packages/keras/latest/reference/freeze_weights.html",
    "href": "packages/keras/latest/reference/freeze_weights.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Freeze and unfreeze weights\n\n\nFreeze weights in a model or layer so that they are no longer trainable.\n\n\n\nfreeze_weights(object, from = NULL, to = NULL, which = NULL)\n\nunfreeze_weights(object, from = NULL, to = NULL, which = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model or layer object\n\n\nfrom\nLayer instance, layer name, or layer index within model\n\n\nto\nLayer instance, layer name, or layer index within model\n\n\nwhich\nlayer names, integer positions, layers, logical vector (of length(object$layers)), or a function returning a logical vector.\n\n\n\n\n\n\n\nconv_base <- application_vgg16(\n  weights = \"imagenet\",\n  include_top = FALSE,\n  input_shape = c(150, 150, 3)\n)\n\n# freeze it's weights\nfreeze_weights(conv_base)\n\nconv_base\n\n# create a composite model that includes the base + more layers\nmodel <- keras_model_sequential() %>%\n  conv_base() %>%\n  layer_flatten() %>%\n  layer_dense(units = 256, activation = \"relu\") %>%\n  layer_dense(units = 1, activation = \"sigmoid\")\n\n# compile\nmodel %>% compile(\n  loss = \"binary_crossentropy\",\n  optimizer = optimizer_rmsprop(lr = 2e-5),\n  metrics = c(\"accuracy\")\n)\n\nmodel\nprint(model, expand_nested = TRUE)\n\n\n\n# unfreeze weights from \"block5_conv1\" on\nunfreeze_weights(conv_base, from = \"block5_conv1\")\n\n# compile again since we froze or unfroze weights\nmodel %>% compile(\n  loss = \"binary_crossentropy\",\n  optimizer = optimizer_rmsprop(lr = 2e-5),\n  metrics = c(\"accuracy\")\n)\n\nconv_base\nprint(model, expand_nested = TRUE)\n\n# freeze only the last 5 layers\nfreeze_weights(conv_base, from = -5)\nconv_base\n# equivalently, also freeze only the last 5 layers\nunfreeze_weights(conv_base, to = -6)\nconv_base\n\n# Freeze only layers of a certain type, e.g, BatchNorm layers\nbatch_norm_layer_class_name <- class(layer_batch_normalization())[1]\nis_batch_norm_layer <- function(x) inherits(x, batch_norm_layer_class_name)\n\nmodel <- application_efficientnet_b0()\nfreeze_weights(model, which = is_batch_norm_layer)\nmodel\n# equivalent to:\nfor(layer in model$layers) {\n  if(is_batch_norm_layer(layer))\n    layer$trainable <- FALSE\n  else\n    layer$trainable <- TRUE\n}"
  },
  {
    "objectID": "packages/keras/latest/reference/generator_next.html",
    "href": "packages/keras/latest/reference/generator_next.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Retrieve the next item from a generator\n\n\nUse to retrieve items from generators (e.g. image_data_generator()). Will return either the next item or NULL if there are no more items.\n\n\n\ngenerator_next(generator, completed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ngenerator\nGenerator\n\n\ncompleted\nSentinel value to return from generator_next() if the iteration completes (defaults to NULL but can be any R value you specify)."
  },
  {
    "objectID": "packages/keras/latest/reference/get_config.html",
    "href": "packages/keras/latest/reference/get_config.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer/Model configuration\n\n\nA layer config is an object returned from get_config() that contains the configuration of a layer or model. The same layer or model can be reinstantiated later (without its trained weights) from this configuration using from_config(). The config does not include connectivity information, nor the class name (those are handled externally).\n\n\n\nget_config(object)\n\nfrom_config(config, custom_objects = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nLayer or model object\n\n\nconfig\nObject with layer or model configuration\n\n\ncustom_objects\nlist of custom objects needed to instantiate the layer, e.g., custom layers defined by new_layer_class() or similar.\n\n\n\n\n\n\nget_config() returns an object with the configuration, from_config() returns a re-instantiation of the object.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()\nOther layer methods: count_params(), get_input_at(), get_weights(), reset_states()"
  },
  {
    "objectID": "packages/keras/latest/reference/get_file.html",
    "href": "packages/keras/latest/reference/get_file.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Downloads a file from a URL if it not already in the cache.\n\n\nPassing the MD5 hash will verify the file after download as well as if it is already present in the cache.\n\n\n\nget_file(\n  fname,\n  origin,\n  file_hash = NULL,\n  cache_subdir = \"datasets\",\n  hash_algorithm = \"auto\",\n  extract = FALSE,\n  archive_format = \"auto\",\n  cache_dir = NULL,\n  untar = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfname\nName of the file. If an absolute path /path/to/file.txt is specified the file will be saved at that location.\n\n\norigin\nOriginal URL of the file.\n\n\nfile_hash\nThe expected hash string of the file after download. The sha256 and md5 hash algorithms are both supported.\n\n\ncache_subdir\nSubdirectory under the Keras cache dir where the file is saved. If an absolute path /path/to/folder is specified the file will be saved at that location.\n\n\nhash_algorithm\nSelect the hash algorithm to verify the file. options are ‘md5’, ‘sha256’, and ‘auto’. The default ‘auto’ detects the hash algorithm in use.\n\n\nextract\nTrue tries extracting the file as an Archive, like tar or zip.\n\n\narchive_format\nArchive format to try for extracting the file. Options are ‘auto’, ‘tar’, ‘zip’, and None. ‘tar’ includes tar, tar.gz, and tar.bz files. The default ‘auto’ is (‘tar’, ‘zip’). None or an empty list will return no matches found.\n\n\ncache_dir\nLocation to store cached files, when NULL it defaults to the Keras configuration directory.\n\n\nuntar\nDeprecated in favor of ‘extract’. boolean, whether the file should be decompressed\n\n\n\n\n\n\nPath to the downloaded file"
  },
  {
    "objectID": "packages/keras/latest/reference/get_input_at.html",
    "href": "packages/keras/latest/reference/get_input_at.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Retrieve tensors for layers with multiple nodes\n\n\nWhenever you are calling a layer on some input, you are creating a new tensor (the output of the layer), and you are adding a “node” to the layer, linking the input tensor to the output tensor. When you are calling the same layer multiple times, that layer owns multiple nodes indexed as 1, 2, 3. These functions enable you to retrieve various tensor properties of layers with multiple nodes.\n\n\n\nget_input_at(object, node_index)\n\nget_output_at(object, node_index)\n\nget_input_shape_at(object, node_index)\n\nget_output_shape_at(object, node_index)\n\nget_input_mask_at(object, node_index)\n\nget_output_mask_at(object, node_index)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nLayer or model object\n\n\nnode_index\nInteger, index of the node from which to retrieve the attribute. E.g. node_index = 1 will correspond to the first time the layer was called.\n\n\n\n\n\n\nA tensor (or list of tensors if the layer has multiple inputs/outputs).\n\n\n\nOther layer methods: count_params(), get_config(), get_weights(), reset_states()"
  },
  {
    "objectID": "packages/keras/latest/reference/get_layer.html",
    "href": "packages/keras/latest/reference/get_layer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Retrieves a layer based on either its name (unique) or index.\n\n\nIndices are based on order of horizontal graph traversal (bottom-up) and are 1-based. If name and index are both provided, index will take precedence.\n\n\n\nget_layer(object, name = NULL, index = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model object\n\n\nname\nString, name of layer.\n\n\nindex\nInteger, index of layer (1-based). Also valid are negative values, which count from the end of model.\n\n\n\n\n\n\nA layer instance.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/get_weights.html",
    "href": "packages/keras/latest/reference/get_weights.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer/Model weights as R arrays\n\n\nLayer/Model weights as R arrays\n\n\n\nget_weights(object, trainable = NA)\n\nset_weights(object, weights)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nLayer or model object\n\n\ntrainable\nif NA (the default), all weights are returned. If TRUE,\n\n\nweights\nWeights as R array\n\n\n\n\n\n\nOther model persistence: model_to_json(), model_to_yaml(), save_model_hdf5(), save_model_tf(), save_model_weights_hdf5(), serialize_model()\nOther layer methods: count_params(), get_config(), get_input_at(), reset_states()"
  },
  {
    "objectID": "packages/keras/latest/reference/grapes-py_class-grapes.html",
    "href": "packages/keras/latest/reference/grapes-py_class-grapes.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Make a python class constructor\n\n\nMake a python class constructor\n\n\n\nspec %py_class% body\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\na bare symbol MyClassName, or a call MyClassName(SuperClass)\n\n\nbody\nan expression that can be evaluated to construct the class methods.\n\n\n\n\n\n\nThe python class constructor, invisibly. Note, the same constructor is also assigned in the parent frame.\n\n\n\n\nMyClass %py_class% {\n  initialize <- function(x) {\n    print(\"Hi from MyClass$initialize()!\")\n    self$x <- x\n  }\n  my_method <- function() {\n    self$x\n  }\n}\n\nmy_class_instance <- MyClass(42)\nmy_class_instance$my_method()\n\nMyClass2(MyClass) %py_class% {\n  \"This will be a __doc__ string for MyClass2\"\n\n  initialize <- function(...) {\n    \"This will be the __doc__ string for the MyClass2.__init__() method\"\n    print(\"Hi from MyClass2$initialize()!\")\n    super$initialize(...)\n  }\n}\n\nmy_class_instance2 <- MyClass2(42)\nmy_class_instance2$my_method()\n\nreticulate::py_help(MyClass2) # see the __doc__ strings and more!\n\n# In addition to `self`, there is also `private` available.\n# This is an R environment unique to each class instance, where you can\n# store objects that you don't want converted to Python, but still want\n# available from methods. You can also assign methods to private, and\n# `self` and `private` will be available in private methods.\n\nMyClass %py_class% {\n\n  initialize <- function(x) {\n    print(\"Hi from MyClass$initialize()!\")\n    private$y <- paste(\"A Private field:\", x)\n  }\n\n  get_private_field <- function() {\n    private$y\n  }\n\n  private$a_private_method <- function() {\n    cat(\"a_private_method() was called.\\n\")\n    cat(\"private$y is \", sQuote(private$y), \"\\n\")\n  }\n\n  call_private_method <- function()\n    private$a_private_method()\n}\n\ninst1 <- MyClass(1)\ninst2 <- MyClass(2)\ninst1$get_private_field()\ninst2$get_private_field()\ninst1$call_private_method()\ninst2$call_private_method()\n\n\n\nhttps://keras.rstudio.com/articles/new-guides/python_subclasses.html"
  },
  {
    "objectID": "packages/keras/latest/reference/grapes-set-active-grapes.html",
    "href": "packages/keras/latest/reference/grapes-set-active-grapes.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Make an Active Binding\n\n\nMake an Active Binding\n\n\n\nsym %<-active% value\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsym\nsymbol to bind\n\n\nvalue\nA function to call when the value of sym is accessed.\n\n\n\n\n\n\nActive bindings defined in a %py_class% are converted to @property decorated methods.\n\n\n\nvalue, invisibly\n\n\n\nset.seed(1234)\nx %<-active% function(value) {\n  message(\"Evaluating function of active binding\")\n  if(missing(value))\n    runif(1)\n  else\n   message(\"Received: \", value)\n}\nx\nx\nx <- \"foo\"\nx <- \"foo\"\nx\nrm(x) # cleanup\n\n\n\nmakeActiveBinding()"
  },
  {
    "objectID": "packages/keras/latest/reference/hdf5_matrix.html",
    "href": "packages/keras/latest/reference/hdf5_matrix.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Representation of HDF5 dataset to be used instead of an R array\n\n\nRepresentation of HDF5 dataset to be used instead of an R array\n\n\n\nhdf5_matrix(datapath, dataset, start = 0, end = NULL, normalizer = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndatapath\nstring, path to a HDF5 file\n\n\ndataset\nstring, name of the HDF5 dataset in the file specified in datapath\n\n\nstart\nint, start of desired slice of the specified dataset\n\n\nend\nint, end of desired slice of the specified dataset\n\n\nnormalizer\nfunction to be called on data when retrieved\n\n\n\n\n\n\nProviding start and end allows use of a slice of the dataset.\nOptionally, a normalizer function (or lambda) can be given. This will be called on every slice of data retrieved.\n\n\n\nAn array-like HDF5 dataset."
  },
  {
    "objectID": "packages/keras/latest/reference/image_data_generator.html",
    "href": "packages/keras/latest/reference/image_data_generator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Generate batches of image data with real-time data augmentation. The data will be looped over (in batches).\n\n\nGenerate batches of image data with real-time data augmentation. The data will be looped over (in batches).\n\n\n\nimage_data_generator(\n  featurewise_center = FALSE,\n  samplewise_center = FALSE,\n  featurewise_std_normalization = FALSE,\n  samplewise_std_normalization = FALSE,\n  zca_whitening = FALSE,\n  zca_epsilon = 1e-06,\n  rotation_range = 0,\n  width_shift_range = 0,\n  height_shift_range = 0,\n  brightness_range = NULL,\n  shear_range = 0,\n  zoom_range = 0,\n  channel_shift_range = 0,\n  fill_mode = \"nearest\",\n  cval = 0,\n  horizontal_flip = FALSE,\n  vertical_flip = FALSE,\n  rescale = NULL,\n  preprocessing_function = NULL,\n  data_format = NULL,\n  validation_split = 0\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfeaturewise_center\nSet input mean to 0 over the dataset, feature-wise.\n\n\nsamplewise_center\nBoolean. Set each sample mean to 0.\n\n\nfeaturewise_std_normalization\nDivide inputs by std of the dataset, feature-wise.\n\n\nsamplewise_std_normalization\nDivide each input by its std.\n\n\nzca_whitening\napply ZCA whitening.\n\n\nzca_epsilon\nEpsilon for ZCA whitening. Default is 1e-6.\n\n\nrotation_range\ndegrees (0 to 180).\n\n\nwidth_shift_range\nfraction of total width.\n\n\nheight_shift_range\nfraction of total height.\n\n\nbrightness_range\nthe range of brightness to apply\n\n\nshear_range\nshear intensity (shear angle in radians).\n\n\nzoom_range\namount of zoom. if scalar z, zoom will be randomly picked in the range [1-z, 1+z]. A sequence of two can be passed instead to select this range.\n\n\nchannel_shift_range\nshift range for each channels.\n\n\nfill_mode\nOne of “constant”, “nearest”, “reflect” or “wrap”. Points outside the boundaries of the input are filled according to the given mode: * “constant”: kkkkkkkk|abcd|kkkkkkkk (cval=k) * “nearest”: aaaaaaaa|abcd|dddddddd * “reflect”: abcddcba|abcd|dcbaabcd * “wrap”: abcdabcd|abcd|abcdabcd\n\n\ncval\nvalue used for points outside the boundaries when fill_mode is ‘constant’. Default is 0.\n\n\nhorizontal_flip\nwhether to randomly flip images horizontally.\n\n\nvertical_flip\nwhether to randomly flip images vertically.\n\n\nrescale\nrescaling factor. If NULL or 0, no rescaling is applied, otherwise we multiply the data by the value provided (before applying any other transformation).\n\n\npreprocessing_function\nfunction that will be implied on each input. The function will run before any other modification on it. The function should take one argument: one image (tensor with rank 3), and should output a tensor with the same shape.\n\n\ndata_format\n‘channels_first’ or ‘channels_last’. In ‘channels_first’ mode, the channels dimension (the depth) is at index 1, in ‘channels_last’ mode it is at index 3. It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nvalidation_split\nfraction of images reserved for validation (strictly between 0 and 1)."
  },
  {
    "objectID": "packages/keras/latest/reference/image_dataset_from_directory.html",
    "href": "packages/keras/latest/reference/image_dataset_from_directory.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create a dataset from a directory\n\n\nGenerates a tf.data.Dataset from image files in a directory.\n\n\n\nimage_dataset_from_directory(\n  directory,\n  labels = \"inferred\",\n  label_mode = \"int\",\n  class_names = NULL,\n  color_mode = \"rgb\",\n  batch_size = 32,\n  image_size = c(256, 256),\n  shuffle = TRUE,\n  seed = NULL,\n  validation_split = NULL,\n  subset = NULL,\n  interpolation = \"bilinear\",\n  follow_links = FALSE,\n  crop_to_aspect_ratio = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndirectory\nDirectory where the data is located. If labels is “inferred”, it should contain subdirectories, each containing images for a class. Otherwise, the directory structure is ignored.\n\n\nlabels\nEither “inferred” (labels are generated from the directory structure), or a list/tuple of integer labels of the same size as the number of image files found in the directory. Labels should be sorted according to the alphanumeric order of the image file paths (obtained via os.walk(directory) in Python).\n\n\nlabel_mode\nValid values: * ‘int’: labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss). * ‘categorical’: labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss). * ‘binary’: labels (there can be only 2) are encoded as float32 scalars with values 0 or 1 (e.g. for binary_crossentropy). * NULL: (no labels).\n\n\nclass_names\nOnly valid if “labels” is “inferred”. This is the explict list of class names (must match names of subdirectories). Used to control the order of the classes (otherwise alphanumerical order is used).\n\n\ncolor_mode\nOne of “grayscale”, “rgb”, “rgba”. Default: “rgb”. Whether the images will be converted to have 1, 3, or 4 channels.\n\n\nbatch_size\nSize of the batches of data. Default: 32.\n\n\nimage_size\nSize to resize images to after they are read from disk. Defaults to (256, 256). Since the pipeline processes batches of images that must all have the same size, this must be provided.\n\n\nshuffle\nWhether to shuffle the data. Default: TRUE. If set to FALSE, sorts the data in alphanumeric order.\n\n\nseed\nOptional random seed for shuffling and transformations.\n\n\nvalidation_split\nOptional float between 0 and 1, fraction of data to reserve for validation.\n\n\nsubset\nOne of “training” or “validation”. Only used if validation_split is set.\n\n\ninterpolation\nString, the interpolation method used when resizing images. Defaults to bilinear. Supports bilinear, nearest, bicubic, area, lanczos3, lanczos5, gaussian, mitchellcubic.\n\n\nfollow_links\nWhether to visits subdirectories pointed to by symlinks. Defaults to FALSE.\n\n\ncrop_to_aspect_ratio\nIf TRUE, resize the images without aspect ratio distortion. When the original aspect ratio differs from the target aspect ratio, the output image will be cropped so as to return the largest possible window in the image (of size image_size) that matches the target aspect ratio. By default (crop_to_aspect_ratio=False), aspect ratio may not be preserved.\n\n\n…\nLegacy arguments\n\n\n\n\n\n\nIf your directory structure is:\nhtml\n\nmain_directory/ …class_a/ ……a_image_1.jpg ……a_image_2.jpg …class_b/ ……b_image_1.jpg ……b_image_2.jpg html\n\nThen calling image_dataset_from_directory(main_directory, labels='inferred') will return a tf.data.Dataset that yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b).\nSupported image formats: jpeg, png, bmp, gif. Animated gifs are truncated to the first frame.\n\n\n\nA tf.data.Dataset object. If label_mode is NULL, it yields float32 tensors of shape (batch_size, image_size[1], image_size[2], num_channels), encoding images (see below for rules regarding num_channels).\nOtherwise, it yields pairs of (images, labels), where images has shape (batch_size, image_size[1], image_size[2], num_channels), and labels follows the format described below.\nRules regarding labels format:\n\nif label_mode is int, the labels are an int32 tensor of shape (batch_size).\nif label_mode is binary, the labels are a float32 tensor of 1s and 0s of shape (batch_size, 1).\nif label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.\n\nRules regarding number of channels in the yielded images:\n\nif color_mode is grayscale, there’s 1 channel in the image tensors.\nif color_mode is rgb, there are 3 channel in the image tensors.\nif color_mode is rgba, there are 4 channel in the image tensors.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"
  },
  {
    "objectID": "packages/keras/latest/reference/image_load.html",
    "href": "packages/keras/latest/reference/image_load.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Loads an image into PIL format.\n\n\nLoads an image into PIL format.\n\n\n\nimage_load(\n  path,\n  grayscale = FALSE,\n  color_mode = \"rgb\",\n  target_size = NULL,\n  interpolation = \"nearest\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npath\nPath to image file\n\n\ngrayscale\nDEPRECATED use color_mode=\"grayscale\"\n\n\ncolor_mode\nOne of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". The desired image format.\n\n\ntarget_size\nEither NULL (default to original size) or integer vector (img_height, img_width).\n\n\ninterpolation\nInterpolation method used to resample the image if the target size is different from that of the loaded image. Supported methods are “nearest”, “bilinear”, and “bicubic”. If PIL version 1.1.3 or newer is installed, “lanczos” is also supported. If PIL version 3.4.0 or newer is installed, “box” and “hamming” are also supported. By default, “nearest” is used.\n\n\n\n\n\n\nA PIL Image instance.\n\n\n\nOther image preprocessing: fit_image_data_generator(), flow_images_from_dataframe(), flow_images_from_data(), flow_images_from_directory(), image_to_array()"
  },
  {
    "objectID": "packages/keras/latest/reference/image_to_array.html",
    "href": "packages/keras/latest/reference/image_to_array.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "3D array representation of images\n\n\n3D array that represents an image with dimensions (height,width,channels) or (channels,height,width) depending on the data_format.\n\n\n\nimage_to_array(img, data_format = c(\"channels_last\", \"channels_first\"))\n\nimage_array_resize(\n  img,\n  height,\n  width,\n  data_format = c(\"channels_last\", \"channels_first\")\n)\n\nimage_array_save(\n  img,\n  path,\n  data_format = NULL,\n  file_format = NULL,\n  scale = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nimg\nImage\n\n\ndata_format\nImage data format (“channels_last” or “channels_first”)\n\n\nheight\nHeight to resize to\n\n\nwidth\nWidth to resize to\n\n\npath\nPath to save image to\n\n\nfile_format\nOptional file format override. If omitted, the format to use is determined from the filename extension. If a file object was used instead of a filename, this parameter should always be used.\n\n\nscale\nWhether to rescale image values to be within 0,255\n\n\n\n\n\n\nOther image preprocessing: fit_image_data_generator(), flow_images_from_dataframe(), flow_images_from_data(), flow_images_from_directory(), image_load()"
  },
  {
    "objectID": "packages/keras/latest/reference/imagenet_decode_predictions.html",
    "href": "packages/keras/latest/reference/imagenet_decode_predictions.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Decodes the prediction of an ImageNet model.\n\n\nDecodes the prediction of an ImageNet model.\n\n\n\nimagenet_decode_predictions(preds, top = 5)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npreds\nTensor encoding a batch of predictions.\n\n\ntop\ninteger, how many top-guesses to return.\n\n\n\n\n\n\nList of data frames with variables class_name, class_description, and score (one data frame per sample in batch input)."
  },
  {
    "objectID": "packages/keras/latest/reference/imagenet_preprocess_input.html",
    "href": "packages/keras/latest/reference/imagenet_preprocess_input.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Preprocesses a tensor or array encoding a batch of images.\n\n\nPreprocesses a tensor or array encoding a batch of images.\n\n\n\nimagenet_preprocess_input(x, data_format = NULL, mode = \"caffe\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nInput Numpy or symbolic tensor, 3D or 4D.\n\n\ndata_format\nData format of the image tensor/array.\n\n\nmode\nOne of “caffe”, “tf”, or “torch” * caffe: will convert the images from RGB to BGR, then will zero-center each color channel with respect to the ImageNet dataset, without scaling. * tf: will scale pixels between -1 and 1, sample-wise. * torch: will scale pixels between 0 and 1 and then will normalize each channel with respect to the ImageNet dataset.\n\n\n\n\n\n\nPreprocessed tensor or array."
  },
  {
    "objectID": "packages/keras/latest/reference/implementation.html",
    "href": "packages/keras/latest/reference/implementation.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Keras implementation\n\n\nObtain a reference to the Python module used for the implementation of Keras.\n\n\n\nimplementation()\n\n\n\nThere are currently two Python modules which implement Keras:\n\nkeras (“keras”)\ntensorflow.keras (“tensorflow”)\n\nThis function returns a reference to the implementation being currently used by the keras package. The default implementation is “keras”. You can override this by setting the KERAS_IMPLEMENTATION environment variable to “tensorflow”.\n\n\n\nReference to the Python module used for the implementation of Keras."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html",
    "href": "packages/keras/latest/reference/index.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\nkeras_model()\nKeras Model\n\n\nkeras_model_sequential()\nKeras Model composed of a linear stack of layers\n\n\nkeras_model_custom()\n(Deprecated) Create a Keras custom model\n\n\nmulti_gpu_model()\n(Deprecated) Replicates a model on different GPUs.\n\n\nsummary(<keras.engine.training.Model>) format(<keras.engine.training.Model>) print(<keras.engine.training.Model>)\nPrint a summary of a Keras model\n\n\ncompile(<keras.engine.training.Model>)\nConfigure a Keras model for training\n\n\nevaluate(<keras.engine.training.Model>)\nEvaluate a Keras model\n\n\nexport_savedmodel(<keras.engine.training.Model>)\nExport a Saved Model\n\n\nfit(<keras.engine.training.Model>)\nTrain a Keras model\n\n\nfit_generator()\n(Deprecated) Fits the model on data yielded batch-by-batch by a generator.\n\n\nevaluate_generator()\n(Deprecated) Evaluates the model on a data generator.\n\n\npredict(<keras.engine.training.Model>)\nGenerate predictions from a Keras model\n\n\npredict_proba() predict_classes()\n(Deprecated) Generates probability or class probability predictions for the input samples.\n\n\npredict_on_batch()\nReturns predictions for a single batch of samples.\n\n\npredict_generator()\n(Deprecated) Generates predictions for the input samples from a data generator.\n\n\ntrain_on_batch() test_on_batch()\nSingle gradient update or model evaluation over one batch of samples.\n\n\nget_layer()\nRetrieves a layer based on either its name (unique) or index.\n\n\npop_layer()\nRemove the last layer in a model\n\n\nsave_model_hdf5() load_model_hdf5()\nSave/Load models using HDF5 files\n\n\nserialize_model() unserialize_model()\nSerialize a model to an R object\n\n\nclone_model()\nClone a model instance.\n\n\nfreeze_weights() unfreeze_weights()\nFreeze and unfreeze weights"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#core-layers",
    "href": "packages/keras/latest/reference/index.html#core-layers",
    "title": "TensorFlow for R",
    "section": "Core Layers",
    "text": "Core Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_input()\nInput layer\n\n\nlayer_dense()\nAdd a densely-connected NN layer to an output\n\n\nlayer_activation()\nApply an activation function to an output.\n\n\nlayer_dropout()\nApplies Dropout to the input.\n\n\nlayer_reshape()\nReshapes an output to a certain shape.\n\n\nlayer_permute()\nPermute the dimensions of an input according to a given pattern\n\n\nlayer_repeat_vector()\nRepeats the input n times.\n\n\nlayer_lambda()\nWraps arbitrary expression as a layer\n\n\nlayer_activity_regularization()\nLayer that applies an update to the cost function based input activity.\n\n\nlayer_masking()\nMasks a sequence by using a mask value to skip timesteps.\n\n\nlayer_flatten()\nFlattens an input"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#convolutional-layers",
    "href": "packages/keras/latest/reference/index.html#convolutional-layers",
    "title": "TensorFlow for R",
    "section": "Convolutional Layers",
    "text": "Convolutional Layers\n\n\n\nFunction(s)\nDescription"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#pooling-layers",
    "href": "packages/keras/latest/reference/index.html#pooling-layers",
    "title": "TensorFlow for R",
    "section": "Pooling Layers",
    "text": "Pooling Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_global_max_pooling_1d()\nGlobal max pooling operation for temporal data.\n\n\nlayer_global_average_pooling_1d()\nGlobal average pooling operation for temporal data.\n\n\nlayer_global_max_pooling_2d()\nGlobal max pooling operation for spatial data.\n\n\nlayer_global_average_pooling_2d()\nGlobal average pooling operation for spatial data.\n\n\nlayer_global_max_pooling_3d()\nGlobal Max pooling operation for 3D data.\n\n\nlayer_global_average_pooling_3d()\nGlobal Average pooling operation for 3D data."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#activation-layers",
    "href": "packages/keras/latest/reference/index.html#activation-layers",
    "title": "TensorFlow for R",
    "section": "Activation Layers",
    "text": "Activation Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_activation()\nApply an activation function to an output.\n\n\nlayer_activation_relu()\nRectified Linear Unit activation function\n\n\nlayer_activation_leaky_relu()\nLeaky version of a Rectified Linear Unit.\n\n\nlayer_activation_parametric_relu()\nParametric Rectified Linear Unit.\n\n\nlayer_activation_thresholded_relu()\nThresholded Rectified Linear Unit.\n\n\nlayer_activation_elu()\nExponential Linear Unit.\n\n\nlayer_activation_softmax()\nSoftmax activation function.\n\n\nlayer_activation_selu()\nScaled Exponential Linear Unit."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#dropout-layers",
    "href": "packages/keras/latest/reference/index.html#dropout-layers",
    "title": "TensorFlow for R",
    "section": "Dropout Layers",
    "text": "Dropout Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_dropout()\nApplies Dropout to the input."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#locally-connected-layers",
    "href": "packages/keras/latest/reference/index.html#locally-connected-layers",
    "title": "TensorFlow for R",
    "section": "Locally-connected Layers",
    "text": "Locally-connected Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_locally_connected_1d()\nLocally-connected layer for 1D inputs.\n\n\nlayer_locally_connected_2d()\nLocally-connected layer for 2D inputs."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#recurrent-layers",
    "href": "packages/keras/latest/reference/index.html#recurrent-layers",
    "title": "TensorFlow for R",
    "section": "Recurrent Layers",
    "text": "Recurrent Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_simple_rnn()\nFully-connected RNN where the output is to be fed back to input.\n\n\nlayer_gru()\nGated Recurrent Unit - Cho et al.\n\n\nlayer_lstm()\nLong Short-Term Memory unit - Hochreiter 1997."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#customize-recurrent-layers",
    "href": "packages/keras/latest/reference/index.html#customize-recurrent-layers",
    "title": "TensorFlow for R",
    "section": "Customize Recurrent Layers",
    "text": "Customize Recurrent Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_rnn()\nBase class for recurrent layers\n\n\nlayer_simple_rnn_cell()\nCell class for SimpleRNN\n\n\nlayer_gru_cell()\nCell class for the GRU layer\n\n\nlayer_lstm_cell()\nCell class for the LSTM layer\n\n\nlayer_stacked_rnn_cells()\nWrapper allowing a stack of RNN cells to behave as a single cell"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#embedding-layers",
    "href": "packages/keras/latest/reference/index.html#embedding-layers",
    "title": "TensorFlow for R",
    "section": "Embedding Layers",
    "text": "Embedding Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_embedding()\nTurns positive integers (indexes) into dense vectors of fixed size."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#normalization-layers",
    "href": "packages/keras/latest/reference/index.html#normalization-layers",
    "title": "TensorFlow for R",
    "section": "Normalization Layers",
    "text": "Normalization Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_batch_normalization()\nBatch normalization layer (Ioffe and Szegedy, 2014).\n\n\nlayer_layer_normalization()\nLayer normalization layer (Ba et al., 2016)."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#noise-layers",
    "href": "packages/keras/latest/reference/index.html#noise-layers",
    "title": "TensorFlow for R",
    "section": "Noise Layers",
    "text": "Noise Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_gaussian_noise()\nApply additive zero-centered Gaussian noise.\n\n\nlayer_gaussian_dropout()\nApply multiplicative 1-centered Gaussian noise.\n\n\nlayer_alpha_dropout()\nApplies Alpha Dropout to the input."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#merge-layers",
    "href": "packages/keras/latest/reference/index.html#merge-layers",
    "title": "TensorFlow for R",
    "section": "Merge Layers",
    "text": "Merge Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_add()\nLayer that adds a list of inputs.\n\n\nlayer_subtract()\nLayer that subtracts two inputs.\n\n\nlayer_multiply()\nLayer that multiplies (element-wise) a list of inputs.\n\n\nlayer_average()\nLayer that averages a list of inputs.\n\n\nlayer_maximum()\nLayer that computes the maximum (element-wise) a list of inputs.\n\n\nlayer_minimum()\nLayer that computes the minimum (element-wise) a list of inputs.\n\n\nlayer_concatenate()\nLayer that concatenates a list of inputs.\n\n\nlayer_dot()\nLayer that computes a dot product between samples in two tensors."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#image-preprocessing-layers",
    "href": "packages/keras/latest/reference/index.html#image-preprocessing-layers",
    "title": "TensorFlow for R",
    "section": "Image Preprocessing Layers",
    "text": "Image Preprocessing Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_resizing()\nImage resizing layer\n\n\nlayer_rescaling()\nMultiply inputs by scale and adds offset\n\n\nlayer_center_crop()\nCrop the central portion of the images to target height and width"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#image-augmentation-layers",
    "href": "packages/keras/latest/reference/index.html#image-augmentation-layers",
    "title": "TensorFlow for R",
    "section": "Image Augmentation Layers",
    "text": "Image Augmentation Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_random_contrast()\nAdjust the contrast of an image or images by a random factor\n\n\nlayer_random_crop()\nRandomly crop the images to target height and width\n\n\nlayer_random_flip()\nRandomly flip each image horizontally and vertically\n\n\nlayer_random_height()\nRandomly vary the height of a batch of images during training\n\n\nlayer_random_rotation()\nRandomly rotate each image\n\n\nlayer_random_translation()\nRandomly translate each image during training\n\n\nlayer_random_width()\nRandomly vary the width of a batch of images during training\n\n\nlayer_random_zoom()\nA preprocessing layer which randomly zooms images during training."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#categorical-features-preprocessing",
    "href": "packages/keras/latest/reference/index.html#categorical-features-preprocessing",
    "title": "TensorFlow for R",
    "section": "Categorical Features Preprocessing",
    "text": "Categorical Features Preprocessing\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_category_encoding()\nA preprocessing layer which encodes integer features.\n\n\nlayer_hashing()\nA preprocessing layer which hashes and bins categorical features.\n\n\nlayer_integer_lookup()\nA preprocessing layer which maps integer features to contiguous ranges.\n\n\nlayer_string_lookup()\nA preprocessing layer which maps string features to integer indices."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#numerical-features-preprocessing",
    "href": "packages/keras/latest/reference/index.html#numerical-features-preprocessing",
    "title": "TensorFlow for R",
    "section": "Numerical Features Preprocessing",
    "text": "Numerical Features Preprocessing\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_normalization()\nA preprocessing layer which normalizes continuous features.\n\n\nlayer_discretization()\nA preprocessing layer which buckets continuous features by ranges."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#attention-layers",
    "href": "packages/keras/latest/reference/index.html#attention-layers",
    "title": "TensorFlow for R",
    "section": "Attention Layers",
    "text": "Attention Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nlayer_attention()\nCreates attention layer\n\n\nlayer_multi_head_attention()\nMultiHeadAttention layer\n\n\nlayer_additive_attention()\nAdditive attention layer, a.k.a. Bahdanau-style attention"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#layer-wrappers",
    "href": "packages/keras/latest/reference/index.html#layer-wrappers",
    "title": "TensorFlow for R",
    "section": "Layer Wrappers",
    "text": "Layer Wrappers\n\n\n\nFunction(s)\nDescription\n\n\n\n\ntime_distributed()\nThis layer wrapper allows to apply a layer to every temporal slice of an input\n\n\nbidirectional()\nBidirectional wrapper for RNNs"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#layer-methods",
    "href": "packages/keras/latest/reference/index.html#layer-methods",
    "title": "TensorFlow for R",
    "section": "Layer Methods",
    "text": "Layer Methods\n\n\n\nFunction(s)\nDescription\n\n\n\n\nget_config() from_config()\nLayer/Model configuration\n\n\nget_weights() set_weights()\nLayer/Model weights as R arrays\n\n\nget_input_at() get_output_at() get_input_shape_at() get_output_shape_at() get_input_mask_at() get_output_mask_at()\nRetrieve tensors for layers with multiple nodes\n\n\ncount_params()\nCount the total number of scalars composing the weights.\n\n\nreset_states()\nReset the states for a layer"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#custom-layers",
    "href": "packages/keras/latest/reference/index.html#custom-layers",
    "title": "TensorFlow for R",
    "section": "Custom Layers",
    "text": "Custom Layers\n\n\n\nFunction(s)\nDescription\n\n\n\n\n%py_class%\nMake a python class constructor\n\n\nLayer()\n(Deprecated) Create a custom Layer\n\n\ncreate_layer_wrapper()\nCreate a Keras Layer wrapper\n\n\ncreate_layer()\nCreate a Keras Layer"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#model-persistence",
    "href": "packages/keras/latest/reference/index.html#model-persistence",
    "title": "TensorFlow for R",
    "section": "Model Persistence",
    "text": "Model Persistence\n\n\n\nFunction(s)\nDescription\n\n\n\n\nsave_model_hdf5() load_model_hdf5()\nSave/Load models using HDF5 files\n\n\nsave_model_weights_hdf5() load_model_weights_hdf5()\nSave/Load model weights using HDF5 files\n\n\nserialize_model() unserialize_model()\nSerialize a model to an R object\n\n\nget_weights() set_weights()\nLayer/Model weights as R arrays\n\n\nget_config() from_config()\nLayer/Model configuration\n\n\nmodel_to_saved_model()\n(Deprecated) Export to Saved Model format\n\n\nmodel_from_saved_model()\nLoad a Keras model from the Saved Model format\n\n\nsave_model_tf() load_model_tf()\nSave/Load models using SavedModel format\n\n\nsave_model_weights_tf() load_model_weights_tf()\nSave model weights in the SavedModel format\n\n\nmodel_to_json() model_from_json()\nModel configuration as JSON\n\n\nmodel_to_yaml() model_from_yaml()\nModel configuration as YAML"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#datasets",
    "href": "packages/keras/latest/reference/index.html#datasets",
    "title": "TensorFlow for R",
    "section": "Datasets",
    "text": "Datasets\n\n\n\nFunction(s)\nDescription"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#applications",
    "href": "packages/keras/latest/reference/index.html#applications",
    "title": "TensorFlow for R",
    "section": "Applications",
    "text": "Applications\n\n\n\nFunction(s)\nDescription\n\n\n\n\nimagenet_preprocess_input()\nPreprocesses a tensor or array encoding a batch of images.\n\n\nimagenet_decode_predictions()\nDecodes the prediction of an ImageNet model.\n\n\napplication_mobilenet() mobilenet_preprocess_input() mobilenet_decode_predictions() mobilenet_load_model_hdf5()\nMobileNet model architecture."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#sequence-preprocessing",
    "href": "packages/keras/latest/reference/index.html#sequence-preprocessing",
    "title": "TensorFlow for R",
    "section": "Sequence Preprocessing",
    "text": "Sequence Preprocessing\n\n\n\nFunction(s)\nDescription\n\n\n\n\npad_sequences()\nPads sequences to the same length\n\n\nskipgrams()\nGenerates skipgram word pairs.\n\n\nmake_sampling_table()\nGenerates a word rank-based probabilistic sampling table.\n\n\ntimeseries_dataset_from_array()\nCreates a dataset of sliding windows over a timeseries provided as array"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#text-preprocessing",
    "href": "packages/keras/latest/reference/index.html#text-preprocessing",
    "title": "TensorFlow for R",
    "section": "Text Preprocessing",
    "text": "Text Preprocessing\n\n\n\nFunction(s)\nDescription\n\n\n\n\ntext_dataset_from_directory()\nGenerate a tf.data.Dataset from text files in a directory\n\n\ntext_tokenizer()\nText tokenization utility\n\n\nfit_text_tokenizer()\nUpdate tokenizer internal vocabulary based on a list of texts or list of\n\n\n\nsequences. save_text_tokenizer() load_text_tokenizer() | Save a text tokenizer to an external file texts_to_sequences() | Transform each text in texts in a sequence of integers. texts_to_sequences_generator() | Transforms each text in texts in a sequence of integers. texts_to_matrix() | Convert a list of texts to a matrix. sequences_to_matrix() | Convert a list of sequences into a matrix. text_one_hot() | One-hot encode a text into a list of word indexes in a vocabulary of size n. text_hashing_trick() | Converts a text to a sequence of indexes in a fixed-size hashing space. text_to_word_sequence() | Convert text to a sequence of words (or tokens). layer_text_vectorization() get_vocabulary() set_vocabulary() | A preprocessing layer which maps text features to integer sequences. adapt() | Fits the state of the preprocessing layer to the data being passed"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#image-preprocessing",
    "href": "packages/keras/latest/reference/index.html#image-preprocessing",
    "title": "TensorFlow for R",
    "section": "Image Preprocessing",
    "text": "Image Preprocessing\n\n\n\nFunction(s)\nDescription\n\n\n\n\nimage_load()\nLoads an image into PIL format.\n\n\nimage_to_array() image_array_resize() image_array_save()\n3D array representation of images\n\n\nimage_data_generator()\nGenerate batches of image data with real-time data augmentation. The data will be\n\n\n\nlooped over (in batches). fit_image_data_generator() | Fit image data generator internal statistics to some sample data. image_dataset_from_directory() | Create a dataset from a directory flow_images_from_data() | Generates batches of augmented/normalized data from image data and labels flow_images_from_directory() | Generates batches of data from images in a directory (with optional augmented/normalized data) flow_images_from_dataframe() | Takes the dataframe and the path to a directory and generates batches of augmented/normalized data. generator_next() | Retrieve the next item from a generator"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#optimizers",
    "href": "packages/keras/latest/reference/index.html#optimizers",
    "title": "TensorFlow for R",
    "section": "Optimizers",
    "text": "Optimizers\n\n\n\nFunction(s)\nDescription\n\n\n\n\noptimizer_sgd()\nStochastic gradient descent optimizer\n\n\noptimizer_rmsprop()\nRMSProp optimizer\n\n\noptimizer_adagrad()\nAdagrad optimizer.\n\n\noptimizer_adadelta()\nAdadelta optimizer.\n\n\noptimizer_adam()\nAdam optimizer\n\n\noptimizer_adamax()\nAdamax optimizer\n\n\noptimizer_nadam()\nNesterov Adam optimizer"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#learning-rate-schedules",
    "href": "packages/keras/latest/reference/index.html#learning-rate-schedules",
    "title": "TensorFlow for R",
    "section": "Learning Rate Schedules",
    "text": "Learning Rate Schedules\n\n\n\nFunction(s)\nDescription\n\n\n\n\nnew_learning_rate_schedule_class()\nCreate a new learning rate schedule type"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#callbacks",
    "href": "packages/keras/latest/reference/index.html#callbacks",
    "title": "TensorFlow for R",
    "section": "Callbacks",
    "text": "Callbacks\n\n\n\nFunction(s)\nDescription\n\n\n\n\ncallback_progbar_logger()\nCallback that prints metrics to stdout.\n\n\ncallback_model_checkpoint()\nSave the model after every epoch.\n\n\ncallback_early_stopping()\nStop training when a monitored quantity has stopped improving.\n\n\ncallback_remote_monitor()\nCallback used to stream events to a server.\n\n\ncallback_learning_rate_scheduler()\nLearning rate scheduler.\n\n\ncallback_tensorboard()\nTensorBoard basic visualizations\n\n\ncallback_reduce_lr_on_plateau()\nReduce learning rate when a metric has stopped improving.\n\n\ncallback_terminate_on_naan()\nCallback that terminates training when a NaN loss is encountered.\n\n\ncallback_csv_logger()\nCallback that streams epoch results to a csv file\n\n\ncallback_lambda()\nCreate a custom callback"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#initializers",
    "href": "packages/keras/latest/reference/index.html#initializers",
    "title": "TensorFlow for R",
    "section": "Initializers",
    "text": "Initializers\n\n\n\nFunction(s)\nDescription\n\n\n\n\ninitializer_zeros()\nInitializer that generates tensors initialized to 0.\n\n\ninitializer_ones()\nInitializer that generates tensors initialized to 1.\n\n\ninitializer_constant()\nInitializer that generates tensors initialized to a constant value.\n\n\ninitializer_random_normal()\nInitializer that generates tensors with a normal distribution.\n\n\ninitializer_random_uniform()\nInitializer that generates tensors with a uniform distribution.\n\n\ninitializer_truncated_normal()\nInitializer that generates a truncated normal distribution.\n\n\ninitializer_variance_scaling()\nInitializer capable of adapting its scale to the shape of weights.\n\n\ninitializer_orthogonal()\nInitializer that generates a random orthogonal matrix.\n\n\ninitializer_identity()\nInitializer that generates the identity matrix.\n\n\ninitializer_glorot_normal()\nGlorot normal initializer, also called Xavier normal initializer.\n\n\ninitializer_glorot_uniform()\nGlorot uniform initializer, also called Xavier uniform initializer.\n\n\ninitializer_he_normal()\nHe normal initializer.\n\n\ninitializer_he_uniform()\nHe uniform variance scaling initializer.\n\n\ninitializer_lecun_uniform()\nLeCun uniform initializer.\n\n\ninitializer_lecun_normal()\nLeCun normal initializer."
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#constraints",
    "href": "packages/keras/latest/reference/index.html#constraints",
    "title": "TensorFlow for R",
    "section": "Constraints",
    "text": "Constraints\n\n\n\nFunction(s)\nDescription\n\n\n\n\nconstraint_maxnorm() constraint_nonneg() constraint_unitnorm() constraint_minmaxnorm()\nWeight constraints"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#utils",
    "href": "packages/keras/latest/reference/index.html#utils",
    "title": "TensorFlow for R",
    "section": "Utils",
    "text": "Utils\n\n\n\nFunction(s)\nDescription\n\n\n\n\nplot(<keras_training_history>)\nPlot training history\n\n\nplot(<keras.engine.training.Model>)\nPlot a Keras model\n\n\nzip_lists()\nzip lists\n\n\nmark_active() new_metric_class() new_loss_class() new_callback_class() new_model_class() new_layer_class()\nDefine new keras types\n\n\ntimeseries_generator()\nUtility function for generating batches of temporal data.\n\n\nto_categorical()\nConverts a class vector (integers) to binary class matrix.\n\n\nnormalize()\nNormalize a matrix or nd-array\n\n\nwith_custom_object_scope()\nProvide a scope with mappings of names to custom objects\n\n\nkeras_array()\nKeras array object\n\n\nhdf5_matrix()\nRepresentation of HDF5 dataset to be used instead of an R array\n\n\nget_file()\nDownloads a file from a URL if it not already in the cache.\n\n\ninstall_keras()\nInstall TensorFlow and Keras, including all Python dependencies\n\n\nis_keras_available()\nCheck if Keras is Available\n\n\nbackend()\nKeras backend tensor engine\n\n\nimplementation()\nKeras implementation\n\n\nuse_implementation() use_backend()\nSelect a Keras implementation and backend"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#losses",
    "href": "packages/keras/latest/reference/index.html#losses",
    "title": "TensorFlow for R",
    "section": "Losses",
    "text": "Losses\n\n\n\nFunction(s)\nDescription\n\n\n\n\nloss_binary_crossentropy() loss_categorical_crossentropy() loss_categorical_hinge() loss_cosine_similarity() loss_hinge() loss_huber() loss_kullback_leibler_divergence() loss_kl_divergence() loss_logcosh() loss_mean_absolute_error() loss_mean_absolute_percentage_error() loss_mean_squared_error() loss_mean_squared_logarithmic_error() loss_poisson() loss_sparse_categorical_crossentropy() loss_squared_hinge()\nLoss functions"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#metrics",
    "href": "packages/keras/latest/reference/index.html#metrics",
    "title": "TensorFlow for R",
    "section": "Metrics",
    "text": "Metrics\n\n\n\nFunction(s)\nDescription\n\n\n\n\ncustom_metric()\nCustom metric function"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#regularizers",
    "href": "packages/keras/latest/reference/index.html#regularizers",
    "title": "TensorFlow for R",
    "section": "Regularizers",
    "text": "Regularizers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nregularizer_l1() regularizer_l2() regularizer_l1_l2()\nL1 and L2 regularization"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#activations",
    "href": "packages/keras/latest/reference/index.html#activations",
    "title": "TensorFlow for R",
    "section": "Activations",
    "text": "Activations\n\n\n\nFunction(s)\nDescription\n\n\n\n\nactivation_relu() activation_elu() activation_selu() activation_hard_sigmoid() activation_linear() activation_sigmoid() activation_softmax() activation_softplus() activation_softsign() activation_tanh() activation_exponential() activation_gelu() activation_swish()\nActivation functions"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#backend",
    "href": "packages/keras/latest/reference/index.html#backend",
    "title": "TensorFlow for R",
    "section": "Backend",
    "text": "Backend\n\n\n\nFunction(s)\nDescription"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#python",
    "href": "packages/keras/latest/reference/index.html#python",
    "title": "TensorFlow for R",
    "section": "Python",
    "text": "Python\n\n\n\nFunction(s)\nDescription\n\n\n\n\nkeras\nMain Keras module\n\n\n%py_class%\nMake a python class constructor\n\n\n%&lt;-active%\nMake an Active Binding"
  },
  {
    "objectID": "packages/keras/latest/reference/index.html#deprecated",
    "href": "packages/keras/latest/reference/index.html#deprecated",
    "title": "TensorFlow for R",
    "section": "Deprecated",
    "text": "Deprecated\n\n\n\nFunction(s)\nDescription\n\n\n\n\ncreate_wrapper()\n(Deprecated) Create a Keras Wrapper\n\n\nloss_cosine_proximity()\n(Deprecated) loss_cosine_proximity\n\n\nlayer_cudnn_gru()\n(Deprecated) Fast GRU implementation backed by CuDNN.\n\n\nlayer_cudnn_lstm()\n(Deprecated) Fast LSTM implementation backed by CuDNN.\n\n\nlayer_dense_features()\nConstructs a DenseFeatures."
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_constant.html",
    "href": "packages/keras/latest/reference/initializer_constant.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates tensors initialized to a constant value.\n\n\nInitializer that generates tensors initialized to a constant value.\n\n\n\ninitializer_constant(value = 0)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nvalue\nfloat; the value of the generator tensors.\n\n\n\n\n\n\nOther initializers: initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_glorot_normal.html",
    "href": "packages/keras/latest/reference/initializer_glorot_normal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Glorot normal initializer, also called Xavier normal initializer.\n\n\nIt draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n\n\n\ninitializer_glorot_normal(seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_glorot_uniform.html",
    "href": "packages/keras/latest/reference/initializer_glorot_uniform.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Glorot uniform initializer, also called Xavier uniform initializer.\n\n\nIt draws samples from a uniform distribution within -limit, limit where limit is sqrt(6 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n\n\n\ninitializer_glorot_uniform(seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_he_normal.html",
    "href": "packages/keras/latest/reference/initializer_he_normal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "He normal initializer.\n\n\nIt draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in the weight tensor.\n\n\n\ninitializer_he_normal(seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_he_uniform.html",
    "href": "packages/keras/latest/reference/initializer_he_uniform.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "He uniform variance scaling initializer.\n\n\nIt draws samples from a uniform distribution within -limit, limit where limitis sqrt(6 / fan_in)where `fan_in is the number of input units in the weight tensor.\n\n\n\ninitializer_he_uniform(seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_identity.html",
    "href": "packages/keras/latest/reference/initializer_identity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates the identity matrix.\n\n\nOnly use for square 2D matrices.\n\n\n\ninitializer_identity(gain = 1)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ngain\nMultiplicative factor to apply to the identity matrix\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_lecun_normal.html",
    "href": "packages/keras/latest/reference/initializer_lecun_normal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "LeCun normal initializer.\n\n\nIt draws samples from a truncated normal distribution centered on 0 with stddev <- sqrt(1 / fan_in) where fan_in is the number of input units in the weight tensor..\n\n\n\ninitializer_lecun_normal(seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nA Python integer. Used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_lecun_uniform.html",
    "href": "packages/keras/latest/reference/initializer_lecun_uniform.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "LeCun uniform initializer.\n\n\nIt draws samples from a uniform distribution within -limit, limit where limit is sqrt(3 / fan_in) where fan_in is the number of input units in the weight tensor.\n\n\n\ninitializer_lecun_uniform(seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_ones.html",
    "href": "packages/keras/latest/reference/initializer_ones.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates tensors initialized to 1.\n\n\nInitializer that generates tensors initialized to 1.\n\n\n\ninitializer_ones()\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_orthogonal.html",
    "href": "packages/keras/latest/reference/initializer_orthogonal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates a random orthogonal matrix.\n\n\nInitializer that generates a random orthogonal matrix.\n\n\n\ninitializer_orthogonal(gain = 1, seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ngain\nMultiplicative factor to apply to the orthogonal matrix.\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_random_normal.html",
    "href": "packages/keras/latest/reference/initializer_random_normal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates tensors with a normal distribution.\n\n\nInitializer that generates tensors with a normal distribution.\n\n\n\ninitializer_random_normal(mean = 0, stddev = 0.05, seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmean\nMean of the random values to generate.\n\n\nstddev\nStandard deviation of the random values to generate.\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_random_uniform.html",
    "href": "packages/keras/latest/reference/initializer_random_uniform.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates tensors with a uniform distribution.\n\n\nInitializer that generates tensors with a uniform distribution.\n\n\n\ninitializer_random_uniform(minval = -0.05, maxval = 0.05, seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nminval\nLower bound of the range of random values to generate.\n\n\nmaxval\nUpper bound of the range of random values to generate. Defaults to 1 for float types.\n\n\nseed\nseed\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_truncated_normal(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_truncated_normal.html",
    "href": "packages/keras/latest/reference/initializer_truncated_normal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates a truncated normal distribution.\n\n\nThese values are similar to values from an initializer_random_normal() except that values more than two standard deviations from the mean are discarded and re-drawn. This is the recommended initializer for neural network weights and filters.\n\n\n\ninitializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmean\nMean of the random values to generate.\n\n\nstddev\nStandard deviation of the random values to generate.\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_variance_scaling(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_variance_scaling.html",
    "href": "packages/keras/latest/reference/initializer_variance_scaling.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer capable of adapting its scale to the shape of weights.\n\n\nWith distribution=\"normal\", samples are drawn from a truncated normal distribution centered on zero, with stddev = sqrt(scale / n) where n is:\n\nnumber of input units in the weight tensor, if mode = “fan_in”\nnumber of output units, if mode = “fan_out”\naverage of the numbers of input and output units, if mode = “fan_avg”\n\n\n\n\ninitializer_variance_scaling(\n  scale = 1,\n  mode = c(\"fan_in\", \"fan_out\", \"fan_avg\"),\n  distribution = c(\"normal\", \"uniform\", \"truncated_normal\", \"untruncated_normal\"),\n  seed = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nscale\nScaling factor (positive float).\n\n\nmode\nOne of “fan_in”, “fan_out”, “fan_avg”.\n\n\ndistribution\nOne of “truncated_normal”, “untruncated_normal” and “uniform”. For backward compatibility, “normal” will be accepted and converted to “untruncated_normal”.\n\n\nseed\nInteger used to seed the random generator.\n\n\n\n\n\n\nWith distribution=\"uniform\", samples are drawn from a uniform distribution within -limit, limit, with limit = sqrt(3 * scale / n).\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_zeros()"
  },
  {
    "objectID": "packages/keras/latest/reference/initializer_zeros.html",
    "href": "packages/keras/latest/reference/initializer_zeros.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Initializer that generates tensors initialized to 0.\n\n\nInitializer that generates tensors initialized to 0.\n\n\n\ninitializer_zeros()\n\n\n\nOther initializers: initializer_constant(), initializer_glorot_normal(), initializer_glorot_uniform(), initializer_he_normal(), initializer_he_uniform(), initializer_identity(), initializer_lecun_normal(), initializer_lecun_uniform(), initializer_ones(), initializer_orthogonal(), initializer_random_normal(), initializer_random_uniform(), initializer_truncated_normal(), initializer_variance_scaling()"
  },
  {
    "objectID": "packages/keras/latest/reference/install_keras.html",
    "href": "packages/keras/latest/reference/install_keras.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Install TensorFlow and Keras, including all Python dependencies\n\n\nThis function will install Tensorflow and all Keras dependencies. This is a thin wrapper around tensorflow::install_tensorflow(), with the only difference being that this includes by default additional extra packages that keras expects, and the default version of tensorflow installed by install_keras() may at times be different from the default installed install_tensorflow(). The default version of tensorflow installed by install_keras() is “2.9”.\n\n\n\ninstall_keras(\n  method = c(\"auto\", \"virtualenv\", \"conda\"),\n  conda = \"auto\",\n  version = \"default\",\n  tensorflow = version,\n  extra_packages = NULL,\n  ...,\n  pip_ignore_installed = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmethod\nInstallation method. By default, “auto” automatically finds a method that will work in the local environment. Change the default to force a specific installation method. Note that the “virtualenv” method is not available on Windows.\n\n\nconda\nThe path to a conda executable. Use \"auto\" to allow reticulate to automatically find an appropriate conda binary. See Finding Conda and conda_binary() for more details.\n\n\nversion\nTensorFlow version to install. Valid values include: * \"default\" installs 2.9 * \"release\" installs the latest release version of tensorflow (which may be incompatible with the current version of the R package) * A version specification like \"2.4\" or \"2.4.0\". Note that if the patch version is not supplied, the latest patch release is installed (e.g., \"2.4\" today installs version “2.4.2”) * nightly for the latest available nightly build. * To any specification, you can append “-cpu” to install the cpu version only of the package (e.g., \"2.4-cpu\") * The full URL or path to a installer binary or python *.whl file.\n\n\ntensorflow\nSynonym for version. Maintained for backwards.\n\n\nextra_packages\nAdditional Python packages to install along with TensorFlow.\n\n\n…\nother arguments passed to reticulate::conda_install() or reticulate::virtualenv_install(), depending on the method used.\n\n\npip_ignore_installed\nWhether pip should ignore installed python packages and reinstall all already installed python packages. This defaults to TRUE, to ensure that TensorFlow dependencies like NumPy are compatible with the prebuilt TensorFlow binaries.\n\n\n\n\n\n\nThe default additional packages are: tensorflow-hub, tensorflow-datasets, scipy, requests, pyyaml, Pillow, h5py, pandas, pydot, with their versions potentially constrained for compatibility with the requested tensorflow version.\n\n\n\ntensorflow::install_tensorflow()"
  },
  {
    "objectID": "packages/keras/latest/reference/is_keras_available.html",
    "href": "packages/keras/latest/reference/is_keras_available.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Check if Keras is Available\n\n\nProbe to see whether the Keras Python package is available in the current system environment.\n\n\n\nis_keras_available(version = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nversion\nMinimum required version of Keras (defaults to NULL, no required version).\n\n\n\n\n\n\nLogical indicating whether Keras (or the specified minimum version of Keras) is available.\n\n\n\n\n# testthat utilty for skipping tests when Keras isn't available\nskip_if_no_keras <- function(version = NULL) {\n  if (!is_keras_available(version))\n    skip(\"Required keras version not available for testing\")\n}\n\n# use the function within a test\ntest_that(\"keras function works correctly\", {\n  skip_if_no_keras()\n  # test code here\n})"
  },
  {
    "objectID": "packages/keras/latest/reference/k_abs.html",
    "href": "packages/keras/latest/reference/k_abs.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise absolute value.\n\n\nElement-wise absolute value.\n\n\n\nk_abs(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_all.html",
    "href": "packages/keras/latest/reference/k_all.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Bitwise reduction (logical AND).\n\n\nBitwise reduction (logical AND).\n\n\n\nk_all(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\naxis\nAxis along which to perform the reduction (axis indexes are 1-based).\n\n\nkeepdims\nwhether the drop or broadcast the reduction axes.\n\n\n\n\n\n\nA uint8 tensor (0s and 1s)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_any.html",
    "href": "packages/keras/latest/reference/k_any.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Bitwise reduction (logical OR).\n\n\nBitwise reduction (logical OR).\n\n\n\nk_any(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\naxis\nAxis along which to perform the reduction (axis indexes are 1-based).\n\n\nkeepdims\nwhether the drop or broadcast the reduction axes.\n\n\n\n\n\n\nA uint8 tensor (0s and 1s)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_arange.html",
    "href": "packages/keras/latest/reference/k_arange.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a 1D tensor containing a sequence of integers.\n\n\nThe function arguments use the same convention as Theano’s arange: if only one argument is provided, it is in fact the “stop” argument. The default type of the returned tensor is 'int32' to match TensorFlow’s default.\n\n\n\nk_arange(start, stop = NULL, step = 1, dtype = \"int32\")\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nstart\nStart value.\n\n\nstop\nStop value.\n\n\nstep\nDifference between two successive values.\n\n\ndtype\nInteger dtype to use.\n\n\n\n\n\n\nAn integer tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_argmax.html",
    "href": "packages/keras/latest/reference/k_argmax.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the index of the maximum value along an axis.\n\n\nReturns the index of the maximum value along an axis.\n\n\n\nk_argmax(x, axis = -1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\naxis\nAxis along which to perform the reduction (axis indexes are 1-based). Pass -1 (the default) to select the last axis.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_argmin.html",
    "href": "packages/keras/latest/reference/k_argmin.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the index of the minimum value along an axis.\n\n\nReturns the index of the minimum value along an axis.\n\n\n\nk_argmin(x, axis = -1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\naxis\nAxis along which to perform the reduction (axis indexes are 1-based). Pass -1 (the default) to select the last axis.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_backend.html",
    "href": "packages/keras/latest/reference/k_backend.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Active Keras backend\n\n\nActive Keras backend\n\n\n\nk_backend()\n\n\n\nThe name of the backend Keras is currently using."
  },
  {
    "objectID": "packages/keras/latest/reference/k_batch_dot.html",
    "href": "packages/keras/latest/reference/k_batch_dot.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Batchwise dot product.\n\n\nbatch_dot is used to compute dot product of x and y when x and y are data in batch, i.e. in a shape of (batch_size). batch_dot results in a tensor or variable with less dimensions than the input. If the number of dimensions is reduced to 1, we use expand_dims to make sure that ndim is at least 2.\n\n\n\nk_batch_dot(x, y, axes)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nKeras tensor or variable with 2 more more axes.\n\n\ny\nKeras tensor or variable with 2 or more axes\n\n\naxes\nList of (or single) integer with target dimensions (axis indexes are 1-based). The lengths of axes[[1]] and axes[[2]] should be the same.\n\n\n\n\n\n\nA tensor with shape equal to the concatenation of x’s shape (less the dimension that was summed over) and y’s shape (less the batch dimension and the dimension that was summed over). If the final rank is 1, we reshape it to (batch_size, 1)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_batch_flatten.html",
    "href": "packages/keras/latest/reference/k_batch_flatten.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Turn a nD tensor into a 2D tensor with same 1st dimension.\n\n\nIn other words, it flattens each data samples of a batch.\n\n\n\nk_batch_flatten(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_batch_get_value.html",
    "href": "packages/keras/latest/reference/k_batch_get_value.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the value of more than one tensor variable.\n\n\nReturns the value of more than one tensor variable.\n\n\n\nk_batch_get_value(ops)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nops\nList of ops to evaluate.\n\n\n\n\n\n\nA list of arrays.\n\n\n\nk_batch_set_value()"
  },
  {
    "objectID": "packages/keras/latest/reference/k_batch_normalization.html",
    "href": "packages/keras/latest/reference/k_batch_normalization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Applies batch normalization on x given mean, var, beta and gamma.\n\n\ni.e. returns output <- (x - mean) / (sqrt(var) + epsilon) * gamma + beta\n\n\n\nk_batch_normalization(x, mean, var, beta, gamma, axis = -1, epsilon = 0.001)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nInput tensor or variable.\n\n\nmean\nMean of batch.\n\n\nvar\nVariance of batch.\n\n\nbeta\nTensor with which to center the input.\n\n\ngamma\nTensor by which to scale the input.\n\n\naxis\nAxis (axis indexes are 1-based). Pass -1 (the default) to select the last axis.\n\n\nepsilon\nFuzz factor.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_batch_set_value.html",
    "href": "packages/keras/latest/reference/k_batch_set_value.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Sets the values of many tensor variables at once.\n\n\nSets the values of many tensor variables at once.\n\n\n\nk_batch_set_value(lists)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlists\na list of lists (tensor, value). value should be an R array.\n\n\n\n\n\n\nk_batch_get_value()"
  },
  {
    "objectID": "packages/keras/latest/reference/k_bias_add.html",
    "href": "packages/keras/latest/reference/k_bias_add.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Adds a bias vector to a tensor.\n\n\nAdds a bias vector to a tensor.\n\n\n\nk_bias_add(x, bias, data_format = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nbias\nBias tensor to add.\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\n\n\n\n\nOutput tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_binary_crossentropy.html",
    "href": "packages/keras/latest/reference/k_binary_crossentropy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Binary crossentropy between an output tensor and a target tensor.\n\n\nBinary crossentropy between an output tensor and a target tensor.\n\n\n\nk_binary_crossentropy(target, output, from_logits = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntarget\nA tensor with the same shape as output.\n\n\noutput\nA tensor.\n\n\nfrom_logits\nWhether output is expected to be a logits tensor. By default, we consider that output encodes a probability distribution.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_cast.html",
    "href": "packages/keras/latest/reference/k_cast.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Casts a tensor to a different dtype and returns it.\n\n\nYou can cast a Keras variable but it still returns a Keras tensor.\n\n\n\nk_cast(x, dtype)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nKeras tensor (or variable).\n\n\ndtype\nString, either ('float16', 'float32', or 'float64').\n\n\n\n\n\n\nKeras tensor with dtype dtype."
  },
  {
    "objectID": "packages/keras/latest/reference/k_cast_to_floatx.html",
    "href": "packages/keras/latest/reference/k_cast_to_floatx.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cast an array to the default Keras float type.\n\n\nCast an array to the default Keras float type.\n\n\n\nk_cast_to_floatx(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nArray.\n\n\n\n\n\n\nThe same array, cast to its new type."
  },
  {
    "objectID": "packages/keras/latest/reference/k_categorical_crossentropy.html",
    "href": "packages/keras/latest/reference/k_categorical_crossentropy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Categorical crossentropy between an output tensor and a target tensor.\n\n\nCategorical crossentropy between an output tensor and a target tensor.\n\n\n\nk_categorical_crossentropy(target, output, from_logits = FALSE, axis = -1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntarget\nA tensor of the same shape as output.\n\n\noutput\nA tensor resulting from a softmax (unless from_logits is TRUE, in which case output is expected to be the logits).\n\n\nfrom_logits\nLogical, whether output is the result of a softmax, or is a tensor of logits.\n\n\naxis\nAxis (axis indexes are 1-based). Pass -1 (the default) to select the last axis.\n\n\n\n\n\n\nOutput tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_clear_session.html",
    "href": "packages/keras/latest/reference/k_clear_session.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Destroys the current TF graph and creates a new one.\n\n\nUseful to avoid clutter from old models / layers.\n\n\n\nk_clear_session()"
  },
  {
    "objectID": "packages/keras/latest/reference/k_clip.html",
    "href": "packages/keras/latest/reference/k_clip.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise value clipping.\n\n\nElement-wise value clipping.\n\n\n\nk_clip(x, min_value = NULL, max_value = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nmin_value\nFloat or integer.\n\n\nmax_value\nFloat or integer.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_concatenate.html",
    "href": "packages/keras/latest/reference/k_concatenate.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Concatenates a list of tensors alongside the specified axis.\n\n\nConcatenates a list of tensors alongside the specified axis.\n\n\n\nk_concatenate(tensors, axis = -1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntensors\nlist of tensors to concatenate.\n\n\naxis\nconcatenation axis (axis indexes are 1-based). Pass -1 (the default) to select the last axis.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_constant.html",
    "href": "packages/keras/latest/reference/k_constant.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a constant tensor.\n\n\nCreates a constant tensor.\n\n\n\nk_constant(value, dtype = NULL, shape = NULL, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nvalue\nA constant value\n\n\ndtype\nThe type of the elements of the resulting tensor.\n\n\nshape\nOptional dimensions of resulting tensor.\n\n\nname\nOptional name for the tensor.\n\n\n\n\n\n\nA Constant Tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_conv1d.html",
    "href": "packages/keras/latest/reference/k_conv1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "1D convolution.\n\n\n1D convolution.\n\n\n\nk_conv1d(\n  x,\n  kernel,\n  strides = 1,\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = 1\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nkernel\nkernel tensor.\n\n\nstrides\nstride integer.\n\n\npadding\nstring, \"same\", \"causal\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\ndilation_rate\ninteger dilate rate.\n\n\n\n\n\n\nA tensor, result of 1D convolution."
  },
  {
    "objectID": "packages/keras/latest/reference/k_conv2d.html",
    "href": "packages/keras/latest/reference/k_conv2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "2D convolution.\n\n\n2D convolution.\n\n\n\nk_conv2d(\n  x,\n  kernel,\n  strides = c(1, 1),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1, 1)\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nkernel\nkernel tensor.\n\n\nstrides\nstrides\n\n\npadding\nstring, \"same\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\". Whether to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.\n\n\ndilation_rate\nvector of 2 integers.\n\n\n\n\n\n\nA tensor, result of 2D convolution."
  },
  {
    "objectID": "packages/keras/latest/reference/k_conv2d_transpose.html",
    "href": "packages/keras/latest/reference/k_conv2d_transpose.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "2D deconvolution (i.e. transposed convolution).\n\n\n2D deconvolution (i.e. transposed convolution).\n\n\n\nk_conv2d_transpose(\n  x,\n  kernel,\n  output_shape,\n  strides = c(1, 1),\n  padding = \"valid\",\n  data_format = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nkernel\nkernel tensor.\n\n\noutput_shape\n1D int tensor for the output shape.\n\n\nstrides\nstrides list.\n\n\npadding\nstring, \"same\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\". Whether to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.\n\n\n\n\n\n\nA tensor, result of transposed 2D convolution."
  },
  {
    "objectID": "packages/keras/latest/reference/k_conv3d.html",
    "href": "packages/keras/latest/reference/k_conv3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "3D convolution.\n\n\n3D convolution.\n\n\n\nk_conv3d(\n  x,\n  kernel,\n  strides = c(1, 1, 1),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1, 1, 1)\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nkernel\nkernel tensor.\n\n\nstrides\nstrides\n\n\npadding\nstring, \"same\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\". Whether to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.\n\n\ndilation_rate\nlist of 3 integers.\n\n\n\n\n\n\nA tensor, result of 3D convolution."
  },
  {
    "objectID": "packages/keras/latest/reference/k_conv3d_transpose.html",
    "href": "packages/keras/latest/reference/k_conv3d_transpose.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "3D deconvolution (i.e. transposed convolution).\n\n\n3D deconvolution (i.e. transposed convolution).\n\n\n\nk_conv3d_transpose(\n  x,\n  kernel,\n  output_shape,\n  strides = c(1, 1, 1),\n  padding = \"valid\",\n  data_format = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ninput tensor.\n\n\nkernel\nkernel tensor.\n\n\noutput_shape\n1D int tensor for the output shape.\n\n\nstrides\nstrides\n\n\npadding\nstring, “same” or “valid”.\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\". Whether to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.\n\n\n\n\n\n\nA tensor, result of transposed 3D convolution."
  },
  {
    "objectID": "packages/keras/latest/reference/k_cos.html",
    "href": "packages/keras/latest/reference/k_cos.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes cos of x element-wise.\n\n\nComputes cos of x element-wise.\n\n\n\nk_cos(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_count_params.html",
    "href": "packages/keras/latest/reference/k_count_params.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the static number of elements in a Keras variable or tensor.\n\n\nReturns the static number of elements in a Keras variable or tensor.\n\n\n\nk_count_params(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nKeras variable or tensor.\n\n\n\n\n\n\nInteger, the number of elements in x, i.e., the product of the array’s static dimensions."
  },
  {
    "objectID": "packages/keras/latest/reference/k_ctc_batch_cost.html",
    "href": "packages/keras/latest/reference/k_ctc_batch_cost.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Runs CTC loss algorithm on each batch element.\n\n\nRuns CTC loss algorithm on each batch element.\n\n\n\nk_ctc_batch_cost(y_true, y_pred, input_length, label_length)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\ntensor (samples, max_string_length) containing the truth labels.\n\n\ny_pred\ntensor (samples, time_steps, num_categories) containing the prediction, or output of the softmax.\n\n\ninput_length\ntensor (samples, 1) containing the sequence length for each batch item in y_pred.\n\n\nlabel_length\ntensor (samples, 1) containing the sequence length for each batch item in y_true.\n\n\n\n\n\n\nTensor with shape (samples,1) containing the CTC loss of each element."
  },
  {
    "objectID": "packages/keras/latest/reference/k_ctc_decode.html",
    "href": "packages/keras/latest/reference/k_ctc_decode.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Decodes the output of a softmax.\n\n\nCan use either greedy search (also known as best path) or a constrained dictionary search.\n\n\n\nk_ctc_decode(\n  y_pred,\n  input_length,\n  greedy = TRUE,\n  beam_width = 100L,\n  top_paths = 1\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_pred\ntensor (samples, time_steps, num_categories) containing the prediction, or output of the softmax.\n\n\ninput_length\ntensor (samples, ) containing the sequence length for each batch item in y_pred.\n\n\ngreedy\nperform much faster best-path search if TRUE. This does not use a dictionary.\n\n\nbeam_width\nif greedy is FALSE: a beam search decoder will be used with a beam of this width.\n\n\ntop_paths\nif greedy is FALSE, how many of the most probable paths will be returned.\n\n\n\n\n\n\nIf greedy is TRUE, returns a list of one element that contains the decoded sequence. If FALSE, returns the top_paths most probable decoded sequences. Important: blank labels are returned as -1. Tensor (top_paths) that contains the log probability of each decoded sequence."
  },
  {
    "objectID": "packages/keras/latest/reference/k_ctc_label_dense_to_sparse.html",
    "href": "packages/keras/latest/reference/k_ctc_label_dense_to_sparse.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Converts CTC labels from dense to sparse.\n\n\nConverts CTC labels from dense to sparse.\n\n\n\nk_ctc_label_dense_to_sparse(labels, label_lengths)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlabels\ndense CTC labels.\n\n\nlabel_lengths\nlength of the labels.\n\n\n\n\n\n\nA sparse tensor representation of the labels."
  },
  {
    "objectID": "packages/keras/latest/reference/k_cumprod.html",
    "href": "packages/keras/latest/reference/k_cumprod.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cumulative product of the values in a tensor, alongside the specified axis.\n\n\nCumulative product of the values in a tensor, alongside the specified axis.\n\n\n\nk_cumprod(x, axis = 1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, the axis to compute the product (axis indexes are 1-based).\n\n\n\n\n\n\nA tensor of the cumulative product of values of x along axis."
  },
  {
    "objectID": "packages/keras/latest/reference/k_cumsum.html",
    "href": "packages/keras/latest/reference/k_cumsum.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cumulative sum of the values in a tensor, alongside the specified axis.\n\n\nCumulative sum of the values in a tensor, alongside the specified axis.\n\n\n\nk_cumsum(x, axis = 1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, the axis to compute the sum (axis indexes are 1-based).\n\n\n\n\n\n\nA tensor of the cumulative sum of values of x along axis."
  },
  {
    "objectID": "packages/keras/latest/reference/k_depthwise_conv2d.html",
    "href": "packages/keras/latest/reference/k_depthwise_conv2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Depthwise 2D convolution with separable filters.\n\n\nDepthwise 2D convolution with separable filters.\n\n\n\nk_depthwise_conv2d(\n  x,\n  depthwise_kernel,\n  strides = c(1, 1),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1, 1)\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ninput tensor\n\n\ndepthwise_kernel\nconvolution kernel for the depthwise convolution.\n\n\nstrides\nstrides (length 2).\n\n\npadding\nstring, \"same\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\ndilation_rate\nvector of integers, dilation rates for the separable convolution.\n\n\n\n\n\n\nOutput tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_dot.html",
    "href": "packages/keras/latest/reference/k_dot.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Multiplies 2 tensors (and/or variables) and returns a tensor.\n\n\nWhen attempting to multiply a nD tensor with a nD tensor, it reproduces the Theano behavior. (e.g. (2, 3) * (4, 3, 5) -> (2, 4, 5))\n\n\n\nk_dot(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA tensor, dot product of x and y."
  },
  {
    "objectID": "packages/keras/latest/reference/k_dropout.html",
    "href": "packages/keras/latest/reference/k_dropout.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Sets entries in x to zero at random, while scaling the entire tensor.\n\n\nSets entries in x to zero at random, while scaling the entire tensor.\n\n\n\nk_dropout(x, level, noise_shape = NULL, seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ntensor\n\n\nlevel\nfraction of the entries in the tensor that will be set to 0.\n\n\nnoise_shape\nshape for randomly generated keep/drop flags, must be broadcastable to the shape of x\n\n\nseed\nrandom seed to ensure determinism.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_dtype.html",
    "href": "packages/keras/latest/reference/k_dtype.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the dtype of a Keras tensor or variable, as a string.\n\n\nReturns the dtype of a Keras tensor or variable, as a string.\n\n\n\nk_dtype(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nString, dtype of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_elu.html",
    "href": "packages/keras/latest/reference/k_elu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Exponential linear unit.\n\n\nExponential linear unit.\n\n\n\nk_elu(x, alpha = 1)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable to compute the activation function for.\n\n\nalpha\nA scalar, slope of negative section.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_epsilon.html",
    "href": "packages/keras/latest/reference/k_epsilon.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fuzz factor used in numeric expressions.\n\n\nFuzz factor used in numeric expressions.\n\n\n\nk_epsilon()\n\nk_set_epsilon(e)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ne\nfloat. New value of epsilon."
  },
  {
    "objectID": "packages/keras/latest/reference/k_equal.html",
    "href": "packages/keras/latest/reference/k_equal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise equality between two tensors.\n\n\nElement-wise equality between two tensors.\n\n\n\nk_equal(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA bool tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_eval.html",
    "href": "packages/keras/latest/reference/k_eval.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Evaluates the value of a variable.\n\n\nEvaluates the value of a variable.\n\n\n\nk_eval(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA variable.\n\n\n\n\n\n\nAn R array."
  },
  {
    "objectID": "packages/keras/latest/reference/k_exp.html",
    "href": "packages/keras/latest/reference/k_exp.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise exponential.\n\n\nElement-wise exponential.\n\n\n\nk_exp(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_expand_dims.html",
    "href": "packages/keras/latest/reference/k_expand_dims.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Adds a 1-sized dimension at index axis.\n\n\nAdds a 1-sized dimension at index axis.\n\n\n\nk_expand_dims(x, axis = -1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nPosition where to add a new axis (axis indexes are 1-based). Pass -1 (the default) to select the last axis.\n\n\n\n\n\n\nA tensor with expanded dimensions."
  },
  {
    "objectID": "packages/keras/latest/reference/k_eye.html",
    "href": "packages/keras/latest/reference/k_eye.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiate an identity matrix and returns it.\n\n\nInstantiate an identity matrix and returns it.\n\n\n\nk_eye(size, dtype = NULL, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsize\nInteger, number of rows/columns.\n\n\ndtype\nString, data type of returned Keras variable.\n\n\nname\nString, name of returned Keras variable.\n\n\n\n\n\n\nA Keras variable, an identity matrix."
  },
  {
    "objectID": "packages/keras/latest/reference/k_flatten.html",
    "href": "packages/keras/latest/reference/k_flatten.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Flatten a tensor.\n\n\nFlatten a tensor.\n\n\n\nk_flatten(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA tensor, reshaped into 1-D"
  },
  {
    "objectID": "packages/keras/latest/reference/k_floatx.html",
    "href": "packages/keras/latest/reference/k_floatx.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Default float type\n\n\nDefault float type\n\n\n\nk_floatx()\n\nk_set_floatx(floatx)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfloatx\nString, ‘float16’, ‘float32’, or ‘float64’."
  },
  {
    "objectID": "packages/keras/latest/reference/k_foldl.html",
    "href": "packages/keras/latest/reference/k_foldl.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reduce elems using fn to combine them from left to right.\n\n\nReduce elems using fn to combine them from left to right.\n\n\n\nk_foldl(fn, elems, initializer = NULL, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfn\nFunction that will be called upon each element in elems and an accumulator\n\n\nelems\ntensor\n\n\ninitializer\nThe first value used (first element of elems in case of `NULL``)\n\n\nname\nA string name for the foldl node in the graph\n\n\n\n\n\n\nTensor with same type and shape as initializer."
  },
  {
    "objectID": "packages/keras/latest/reference/k_foldr.html",
    "href": "packages/keras/latest/reference/k_foldr.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reduce elems using fn to combine them from right to left.\n\n\nReduce elems using fn to combine them from right to left.\n\n\n\nk_foldr(fn, elems, initializer = NULL, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfn\nFunction that will be called upon each element in elems and an accumulator\n\n\nelems\ntensor\n\n\ninitializer\nThe first value used (last element of elems in case of NULL)\n\n\nname\nA string name for the foldr node in the graph\n\n\n\n\n\n\nTensor with same type and shape as initializer."
  },
  {
    "objectID": "packages/keras/latest/reference/k_function.html",
    "href": "packages/keras/latest/reference/k_function.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates a Keras function\n\n\nInstantiates a Keras function\n\n\n\nk_function(inputs, outputs, updates = NULL, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nList of placeholder tensors.\n\n\noutputs\nList of output tensors.\n\n\nupdates\nList of update ops.\n\n\n…\nNamed arguments passed to tf$Session$run.\n\n\n\n\n\n\nOutput values as R arrays."
  },
  {
    "objectID": "packages/keras/latest/reference/k_gather.html",
    "href": "packages/keras/latest/reference/k_gather.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Retrieves the elements of indices indices in the tensor reference.\n\n\nRetrieves the elements of indices indices in the tensor reference.\n\n\n\nk_gather(reference, indices)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nreference\nA tensor.\n\n\nindices\nIndices. Dimension indices are 1-based. Note however that if you pass a tensor for indices they will be passed as-is, in which case indices will be 0 based because no normalizing of R 1-based axes to Python 0-based axes is performed.\n\n\n\n\n\n\nA tensor of same type as reference."
  },
  {
    "objectID": "packages/keras/latest/reference/k_get_session.html",
    "href": "packages/keras/latest/reference/k_get_session.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TF session to be used by the backend.\n\n\nIf a default TensorFlow session is available, we will return it. Else, we will return the global Keras session. If no global Keras session exists at this point: we will create a new global session. Note that you can manually set the global session via k_set_session().\n\n\n\nk_get_session()\n\nk_set_session(session)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsession\nA TensorFlow Session.\n\n\n\n\n\n\nA TensorFlow session"
  },
  {
    "objectID": "packages/keras/latest/reference/k_get_uid.html",
    "href": "packages/keras/latest/reference/k_get_uid.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Get the uid for the default graph.\n\n\nGet the uid for the default graph.\n\n\n\nk_get_uid(prefix = \"\")\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nprefix\nAn optional prefix of the graph.\n\n\n\n\n\n\nA unique identifier for the graph."
  },
  {
    "objectID": "packages/keras/latest/reference/k_get_value.html",
    "href": "packages/keras/latest/reference/k_get_value.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the value of a variable.\n\n\nReturns the value of a variable.\n\n\n\nk_get_value(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ninput variable.\n\n\n\n\n\n\nAn R array."
  },
  {
    "objectID": "packages/keras/latest/reference/k_get_variable_shape.html",
    "href": "packages/keras/latest/reference/k_get_variable_shape.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the shape of a variable.\n\n\nReturns the shape of a variable.\n\n\n\nk_get_variable_shape(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA variable.\n\n\n\n\n\n\nA vector of integers."
  },
  {
    "objectID": "packages/keras/latest/reference/k_gradients.html",
    "href": "packages/keras/latest/reference/k_gradients.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the gradients of variables w.r.t. loss.\n\n\nReturns the gradients of variables w.r.t. loss.\n\n\n\nk_gradients(loss, variables)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nloss\nScalar tensor to minimize.\n\n\nvariables\nList of variables.\n\n\n\n\n\n\nA gradients tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_greater.html",
    "href": "packages/keras/latest/reference/k_greater.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise truth value of (x > y).\n\n\nElement-wise truth value of (x > y).\n\n\n\nk_greater(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA bool tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_greater_equal.html",
    "href": "packages/keras/latest/reference/k_greater_equal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise truth value of (x >= y).\n\n\nElement-wise truth value of (x >= y).\n\n\n\nk_greater_equal(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA bool tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_hard_sigmoid.html",
    "href": "packages/keras/latest/reference/k_hard_sigmoid.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Segment-wise linear approximation of sigmoid.\n\n\nFaster than sigmoid. Returns 0. if x < -2.5, 1. if x > 2.5. In -2.5 <= x <= 2.5, returns 0.2 * x + 0.5.\n\n\n\nk_hard_sigmoid(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_identity.html",
    "href": "packages/keras/latest/reference/k_identity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns a tensor with the same content as the input tensor.\n\n\nReturns a tensor with the same content as the input tensor.\n\n\n\nk_identity(x, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nThe input tensor.\n\n\nname\nString, name for the variable to create.\n\n\n\n\n\n\nA tensor of the same shape, type and content."
  },
  {
    "objectID": "packages/keras/latest/reference/k_image_data_format.html",
    "href": "packages/keras/latest/reference/k_image_data_format.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Default image data format convention (‘channels_first’ or ‘channels_last’).\n\n\nDefault image data format convention (‘channels_first’ or ‘channels_last’).\n\n\n\nk_image_data_format()\n\nk_set_image_data_format(data_format)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata_format\nstring. 'channels_first' or 'channels_last'."
  },
  {
    "objectID": "packages/keras/latest/reference/k_in_test_phase.html",
    "href": "packages/keras/latest/reference/k_in_test_phase.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Selects x in test phase, and alt otherwise.\n\n\nNote that alt should have the same shape as x.\n\n\n\nk_in_test_phase(x, alt, training = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nWhat to return in test phase (tensor or function that returns a tensor).\n\n\nalt\nWhat to return otherwise (tensor or function that returns a tensor).\n\n\ntraining\nOptional scalar tensor (or R logical or integer) specifying the learning phase.\n\n\n\n\n\n\nEither x or alt based on k_learning_phase()."
  },
  {
    "objectID": "packages/keras/latest/reference/k_in_top_k.html",
    "href": "packages/keras/latest/reference/k_in_top_k.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns whether the targets are in the top k predictions.\n\n\nReturns whether the targets are in the top k predictions.\n\n\n\nk_in_top_k(predictions, targets, k)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npredictions\nA tensor of shape (batch_size, classes) and type float32.\n\n\ntargets\nA 1D tensor of length batch_size and type int32 or int64.\n\n\nk\nAn int, number of top elements to consider.\n\n\n\n\n\n\nA 1D tensor of length batch_size and type bool. output[[i]] is TRUE if predictions[i, targets[[i]] is within top-k values of predictions[[i]]."
  },
  {
    "objectID": "packages/keras/latest/reference/k_in_train_phase.html",
    "href": "packages/keras/latest/reference/k_in_train_phase.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Selects x in train phase, and alt otherwise.\n\n\nNote that alt should have the same shape as x.\n\n\n\nk_in_train_phase(x, alt, training = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nWhat to return in train phase (tensor or function that returns a tensor).\n\n\nalt\nWhat to return otherwise (tensor or function that returns a tensor).\n\n\ntraining\nOptional scalar tensor (or R logical or integer) specifying the learning phase.\n\n\n\n\n\n\nEither x or alt based on the training flag. the training flag defaults to k_learning_phase()."
  },
  {
    "objectID": "packages/keras/latest/reference/k_int_shape.html",
    "href": "packages/keras/latest/reference/k_int_shape.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the shape of tensor or variable as a list of int or NULL entries.\n\n\nReturns the shape of tensor or variable as a list of int or NULL entries.\n\n\n\nk_int_shape(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA list of integers (or NULL entries)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_is_keras_tensor.html",
    "href": "packages/keras/latest/reference/k_is_keras_tensor.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns whether x is a Keras tensor.\n\n\nA “Keras tensor” is a tensor that was returned by a Keras layer\n\n\n\nk_is_keras_tensor(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA candidate tensor.\n\n\n\n\n\n\nA logical: Whether the argument is a Keras tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_is_placeholder.html",
    "href": "packages/keras/latest/reference/k_is_placeholder.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns whether x is a placeholder.\n\n\nReturns whether x is a placeholder.\n\n\n\nk_is_placeholder(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA candidate placeholder.\n\n\n\n\n\n\nA logical"
  },
  {
    "objectID": "packages/keras/latest/reference/k_is_sparse.html",
    "href": "packages/keras/latest/reference/k_is_sparse.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns whether a tensor is a sparse tensor.\n\n\nReturns whether a tensor is a sparse tensor.\n\n\n\nk_is_sparse(tensor)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntensor\nA tensor instance.\n\n\n\n\n\n\nA logical"
  },
  {
    "objectID": "packages/keras/latest/reference/k_is_tensor.html",
    "href": "packages/keras/latest/reference/k_is_tensor.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns whether x is a symbolic tensor.\n\n\nReturns whether x is a symbolic tensor.\n\n\n\nk_is_tensor(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA candidate tensor.\n\n\n\n\n\n\nA logical: Whether the argument is a symbolic tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_l2_normalize.html",
    "href": "packages/keras/latest/reference/k_l2_normalize.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Normalizes a tensor wrt the L2 norm alongside the specified axis.\n\n\nNormalizes a tensor wrt the L2 norm alongside the specified axis.\n\n\n\nk_l2_normalize(x, axis = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\naxis\nAxis along which to perform normalization (axis indexes are 1-based)\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_learning_phase.html",
    "href": "packages/keras/latest/reference/k_learning_phase.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the learning phase flag.\n\n\nThe learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function that uses a different behavior at train time and test time.\n\n\n\nk_learning_phase()\n\n\n\nLearning phase (scalar integer tensor or R integer)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_less.html",
    "href": "packages/keras/latest/reference/k_less.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise truth value of (x < y).\n\n\nElement-wise truth value of (x < y).\n\n\n\nk_less(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA bool tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_less_equal.html",
    "href": "packages/keras/latest/reference/k_less_equal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise truth value of (x <= y).\n\n\nElement-wise truth value of (x <= y).\n\n\n\nk_less_equal(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA bool tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_local_conv1d.html",
    "href": "packages/keras/latest/reference/k_local_conv1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Apply 1D conv with un-shared weights.\n\n\nApply 1D conv with un-shared weights.\n\n\n\nk_local_conv1d(inputs, kernel, kernel_size, strides, data_format = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\n3D tensor with shape: (batch_size, steps, input_dim)\n\n\nkernel\nthe unshared weight for convolution, with shape (output_length, feature_dim, filters)\n\n\nkernel_size\na list of a single integer, specifying the length of the 1D convolution window\n\n\nstrides\na list of a single integer, specifying the stride length of the convolution\n\n\ndata_format\nthe data format, channels_first or channels_last\n\n\n\n\n\n\nthe tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)"
  },
  {
    "objectID": "packages/keras/latest/reference/k_local_conv2d.html",
    "href": "packages/keras/latest/reference/k_local_conv2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Apply 2D conv with un-shared weights.\n\n\nApply 2D conv with un-shared weights.\n\n\n\nk_local_conv2d(\n  inputs,\n  kernel,\n  kernel_size,\n  strides,\n  output_shape,\n  data_format = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\n4D tensor with shape: (batch_size, filters, new_rows, new_cols) if data_format=‘channels_first’ or 4D tensor with shape: (batch_size, new_rows, new_cols, filters) if data_format=‘channels_last’.\n\n\nkernel\nthe unshared weight for convolution, with shape (output_items, feature_dim, filters)\n\n\nkernel_size\na list of 2 integers, specifying the width and height of the 2D convolution window.\n\n\nstrides\na list of 2 integers, specifying the strides of the convolution along the width and height.\n\n\noutput_shape\na list with (output_row, output_col)\n\n\ndata_format\nthe data format, channels_first or channels_last\n\n\n\n\n\n\nA 4d tensor with shape: (batch_size, filters, new_rows, new_cols) if data_format=‘channels_first’ or 4D tensor with shape: (batch_size, new_rows, new_cols, filters) if data_format=‘channels_last’."
  },
  {
    "objectID": "packages/keras/latest/reference/k_log.html",
    "href": "packages/keras/latest/reference/k_log.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise log.\n\n\nElement-wise log.\n\n\n\nk_log(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_logsumexp.html",
    "href": "packages/keras/latest/reference/k_logsumexp.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Computes log(sum(exp(elements across dimensions of a tensor))).\n\n\nThis funciton is deprecated. Please use tensorflow::tf$reduce_logsumexp().\n\n\n\nk_logsumexp(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, the axis to reduce over (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1. If keepdims is TRUE, the reduced dimension is retained with length 1.\n\n\n\n\n\n\nThis function is more numerically stable than log(sum(exp(x))). It avoids overflows caused by taking the exp of large inputs and underflows caused by taking the log of small inputs.\n\n\n\nThe reduced tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_manual_variable_initialization.html",
    "href": "packages/keras/latest/reference/k_manual_variable_initialization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Sets the manual variable initialization flag.\n\n\nThis boolean flag determines whether variables should be initialized as they are instantiated (default), or if the user should handle the initialization (e.g. via tf$initialize_all_variables()).\n\n\n\nk_manual_variable_initialization(value)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nvalue\nLogical"
  },
  {
    "objectID": "packages/keras/latest/reference/k_map_fn.html",
    "href": "packages/keras/latest/reference/k_map_fn.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Map the function fn over the elements elems and return the outputs.\n\n\nMap the function fn over the elements elems and return the outputs.\n\n\n\nk_map_fn(fn, elems, name = NULL, dtype = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfn\nFunction that will be called upon each element in elems\n\n\nelems\ntensor\n\n\nname\nA string name for the map node in the graph\n\n\ndtype\nOutput data type.\n\n\n\n\n\n\nTensor with dtype dtype."
  },
  {
    "objectID": "packages/keras/latest/reference/k_max.html",
    "href": "packages/keras/latest/reference/k_max.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Maximum value in a tensor.\n\n\nMaximum value in a tensor.\n\n\n\nk_max(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, the axis to find maximum values (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1. If keepdims is TRUE, the reduced dimension is retained with length 1.\n\n\n\n\n\n\nA tensor with maximum values of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_maximum.html",
    "href": "packages/keras/latest/reference/k_maximum.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise maximum of two tensors.\n\n\nElement-wise maximum of two tensors.\n\n\n\nk_maximum(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_mean.html",
    "href": "packages/keras/latest/reference/k_mean.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Mean of a tensor, alongside the specified axis.\n\n\nMean of a tensor, alongside the specified axis.\n\n\n\nk_mean(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nA list of axes to compute the mean over (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1 for each entry in axis. If keep_dims is TRUE, the reduced dimensions are retained with length 1.\n\n\n\n\n\n\nA tensor with the mean of elements of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_min.html",
    "href": "packages/keras/latest/reference/k_min.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Minimum value in a tensor.\n\n\nMinimum value in a tensor.\n\n\n\nk_min(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, axis to find minimum values (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1. If keepdims is TRUE, the reduced dimension is retained with length 1.\n\n\n\n\n\n\nA tensor with miminum values of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_minimum.html",
    "href": "packages/keras/latest/reference/k_minimum.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise minimum of two tensors.\n\n\nElement-wise minimum of two tensors.\n\n\n\nk_minimum(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_moving_average_update.html",
    "href": "packages/keras/latest/reference/k_moving_average_update.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Compute the moving average of a variable.\n\n\nCompute the moving average of a variable.\n\n\n\nk_moving_average_update(x, value, momentum)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA Variable.\n\n\nvalue\nA tensor with the same shape as x.\n\n\nmomentum\nThe moving average momentum.\n\n\n\n\n\n\nAn operation to update the variable."
  },
  {
    "objectID": "packages/keras/latest/reference/k_ndim.html",
    "href": "packages/keras/latest/reference/k_ndim.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the number of axes in a tensor, as an integer.\n\n\nReturns the number of axes in a tensor, as an integer.\n\n\n\nk_ndim(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nInteger (scalar), number of axes."
  },
  {
    "objectID": "packages/keras/latest/reference/k_normalize_batch_in_training.html",
    "href": "packages/keras/latest/reference/k_normalize_batch_in_training.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes mean and std for batch then apply batch_normalization on batch.\n\n\nComputes mean and std for batch then apply batch_normalization on batch.\n\n\n\nk_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon = 0.001)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nInput tensor or variable.\n\n\ngamma\nTensor by which to scale the input.\n\n\nbeta\nTensor with which to center the input.\n\n\nreduction_axes\niterable of integers, axes over which to normalize.\n\n\nepsilon\nFuzz factor.\n\n\n\n\n\n\nA list length of 3, (normalized_tensor, mean, variance)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_not_equal.html",
    "href": "packages/keras/latest/reference/k_not_equal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise inequality between two tensors.\n\n\nElement-wise inequality between two tensors.\n\n\n\nk_not_equal(x, y)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\ny\nTensor or variable.\n\n\n\n\n\n\nA bool tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_one_hot.html",
    "href": "packages/keras/latest/reference/k_one_hot.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the one-hot representation of an integer tensor.\n\n\nComputes the one-hot representation of an integer tensor.\n\n\n\nk_one_hot(indices, num_classes)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nindices\nnD integer tensor of shape (batch_size, dim1, dim2, … dim(n-1))\n\n\nnum_classes\nInteger, number of classes to consider.\n\n\n\n\n\n\n(n + 1)D one hot representation of the input with shape (batch_size, dim1, dim2, … dim(n-1), num_classes)"
  },
  {
    "objectID": "packages/keras/latest/reference/k_ones.html",
    "href": "packages/keras/latest/reference/k_ones.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates an all-ones tensor variable and returns it.\n\n\nInstantiates an all-ones tensor variable and returns it.\n\n\n\nk_ones(shape, dtype = NULL, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nTuple of integers, shape of returned Keras variable.\n\n\ndtype\nString, data type of returned Keras variable.\n\n\nname\nString, name of returned Keras variable.\n\n\n\n\n\n\nA Keras variable, filled with 1.0."
  },
  {
    "objectID": "packages/keras/latest/reference/k_ones_like.html",
    "href": "packages/keras/latest/reference/k_ones_like.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates an all-ones variable of the same shape as another tensor.\n\n\nInstantiates an all-ones variable of the same shape as another tensor.\n\n\n\nk_ones_like(x, dtype = NULL, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nKeras variable or tensor.\n\n\ndtype\nString, dtype of returned Keras variable. NULL uses the dtype of x.\n\n\nname\nString, name for the variable to create.\n\n\n\n\n\n\nA Keras variable with the shape of x filled with ones."
  },
  {
    "objectID": "packages/keras/latest/reference/k_permute_dimensions.html",
    "href": "packages/keras/latest/reference/k_permute_dimensions.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Permutes axes in a tensor.\n\n\nPermutes axes in a tensor.\n\n\n\nk_permute_dimensions(x, pattern)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\npattern\nA list of dimension indices, e.g. (1, 3, 2). Dimension indices are 1-based.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_placeholder.html",
    "href": "packages/keras/latest/reference/k_placeholder.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates a placeholder tensor and returns it.\n\n\nInstantiates a placeholder tensor and returns it.\n\n\n\nk_placeholder(\n  shape = NULL,\n  ndim = NULL,\n  dtype = NULL,\n  sparse = FALSE,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nShape of the placeholder (integer list, may include NULL entries).\n\n\nndim\nNumber of axes of the tensor. At least one of shape, ndim must be specified. If both are specified, shape is used.\n\n\ndtype\nPlaceholder type.\n\n\nsparse\nLogical, whether the placeholder should have a sparse type.\n\n\nname\nOptional name string for the placeholder.\n\n\n\n\n\n\nTensor instance (with Keras metadata included)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_pool2d.html",
    "href": "packages/keras/latest/reference/k_pool2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "2D Pooling.\n\n\n2D Pooling.\n\n\n\nk_pool2d(\n  x,\n  pool_size,\n  strides = c(1, 1),\n  padding = \"valid\",\n  data_format = NULL,\n  pool_mode = \"max\"\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\npool_size\nlist of 2 integers.\n\n\nstrides\nlist of 2 integers.\n\n\npadding\nstring, \"same\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\npool_mode\nstring, \"max\" or \"avg\".\n\n\n\n\n\n\nA tensor, result of 2D pooling."
  },
  {
    "objectID": "packages/keras/latest/reference/k_pool3d.html",
    "href": "packages/keras/latest/reference/k_pool3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "3D Pooling.\n\n\n3D Pooling.\n\n\n\nk_pool3d(\n  x,\n  pool_size,\n  strides = c(1, 1, 1),\n  padding = \"valid\",\n  data_format = NULL,\n  pool_mode = \"max\"\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\npool_size\nlist of 3 integers.\n\n\nstrides\nlist of 3 integers.\n\n\npadding\nstring, \"same\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\npool_mode\nstring, \"max\" or \"avg\".\n\n\n\n\n\n\nA tensor, result of 3D pooling."
  },
  {
    "objectID": "packages/keras/latest/reference/k_pow.html",
    "href": "packages/keras/latest/reference/k_pow.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise exponentiation.\n\n\nElement-wise exponentiation.\n\n\n\nk_pow(x, a)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\na\nR integer.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_print_tensor.html",
    "href": "packages/keras/latest/reference/k_print_tensor.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Prints message and the tensor value when evaluated.\n\n\nNote that print_tensor returns a new tensor identical to x which should be used in the following code. Otherwise the print operation is not taken into account during evaluation.\n\n\n\nk_print_tensor(x, message = \"\")\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor to print.\n\n\nmessage\nMessage to print jointly with the tensor.\n\n\n\n\n\n\nThe same tensor x, unchanged."
  },
  {
    "objectID": "packages/keras/latest/reference/k_prod.html",
    "href": "packages/keras/latest/reference/k_prod.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Multiplies the values in a tensor, alongside the specified axis.\n\n\nMultiplies the values in a tensor, alongside the specified axis.\n\n\n\nk_prod(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, axis to compute the product over (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1. If keepdims is TRUE, the reduced dimension is retained with length 1.\n\n\n\n\n\n\nA tensor with the product of elements of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_random_bernoulli.html",
    "href": "packages/keras/latest/reference/k_random_bernoulli.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns a tensor with random binomial distribution of values.\n\n\nk_random_binomial() and k_random_bernoulli() are aliases for the same function. Both are maintained for backwards compatibility. New code should prefer k_random_bernoulli().\n\n\n\nk_random_binomial(shape, p = 0, dtype = NULL, seed = NULL)\n\nk_random_bernoulli(shape, p = 0, dtype = NULL, seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nA list of integers, the shape of tensor to create.\n\n\np\nA float, 0. <= p <= 1, probability of binomial distribution.\n\n\ndtype\nString, dtype of returned tensor.\n\n\nseed\nInteger, random seed.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_random_normal.html",
    "href": "packages/keras/latest/reference/k_random_normal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns a tensor with normal distribution of values.\n\n\nReturns a tensor with normal distribution of values.\n\n\n\nk_random_normal(shape, mean = 0, stddev = 1, dtype = NULL, seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nA list of integers, the shape of tensor to create.\n\n\nmean\nA float, mean of the normal distribution to draw samples.\n\n\nstddev\nA float, standard deviation of the normal distribution to draw samples.\n\n\ndtype\nString, dtype of returned tensor.\n\n\nseed\nInteger, random seed.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_random_normal_variable.html",
    "href": "packages/keras/latest/reference/k_random_normal_variable.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates a variable with values drawn from a normal distribution.\n\n\nInstantiates a variable with values drawn from a normal distribution.\n\n\n\nk_random_normal_variable(\n  shape,\n  mean,\n  scale,\n  dtype = NULL,\n  name = NULL,\n  seed = NULL\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nTuple of integers, shape of returned Keras variable.\n\n\nmean\nFloat, mean of the normal distribution.\n\n\nscale\nFloat, standard deviation of the normal distribution.\n\n\ndtype\nString, dtype of returned Keras variable.\n\n\nname\nString, name of returned Keras variable.\n\n\nseed\nInteger, random seed.\n\n\n\n\n\n\nA Keras variable, filled with drawn samples."
  },
  {
    "objectID": "packages/keras/latest/reference/k_random_uniform.html",
    "href": "packages/keras/latest/reference/k_random_uniform.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns a tensor with uniform distribution of values.\n\n\nReturns a tensor with uniform distribution of values.\n\n\n\nk_random_uniform(shape, minval = 0, maxval = 1, dtype = NULL, seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nA list of integers, the shape of tensor to create.\n\n\nminval\nA float, lower boundary of the uniform distribution to draw samples.\n\n\nmaxval\nA float, upper boundary of the uniform distribution to draw samples.\n\n\ndtype\nString, dtype of returned tensor.\n\n\nseed\nInteger, random seed.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_random_uniform_variable.html",
    "href": "packages/keras/latest/reference/k_random_uniform_variable.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates a variable with values drawn from a uniform distribution.\n\n\nInstantiates a variable with values drawn from a uniform distribution.\n\n\n\nk_random_uniform_variable(\n  shape,\n  low,\n  high,\n  dtype = NULL,\n  name = NULL,\n  seed = NULL\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nTuple of integers, shape of returned Keras variable.\n\n\nlow\nFloat, lower boundary of the output interval.\n\n\nhigh\nFloat, upper boundary of the output interval.\n\n\ndtype\nString, dtype of returned Keras variable.\n\n\nname\nString, name of returned Keras variable.\n\n\nseed\nInteger, random seed.\n\n\n\n\n\n\nA Keras variable, filled with drawn samples."
  },
  {
    "objectID": "packages/keras/latest/reference/k_relu.html",
    "href": "packages/keras/latest/reference/k_relu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Rectified linear unit.\n\n\nWith default values, it returns element-wise max(x, 0).\n\n\n\nk_relu(x, alpha = 0, max_value = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\nalpha\nA scalar, slope of negative section (default=0.).\n\n\nmax_value\nSaturation threshold.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_repeat.html",
    "href": "packages/keras/latest/reference/k_repeat.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Repeats a 2D tensor.\n\n\nIf x has shape (samples, dim) and n is 2, the output will have shape (samples, 2, dim).\n\n\n\nk_repeat(x, n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nn\nInteger, number of times to repeat.\n\n\n\n\n\n\nA tensor"
  },
  {
    "objectID": "packages/keras/latest/reference/k_repeat_elements.html",
    "href": "packages/keras/latest/reference/k_repeat_elements.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Repeats the elements of a tensor along an axis.\n\n\nIf x has shape (s1, s2, s3) and axis is 2, the output will have shape (s1, s2 * rep, s3).\n\n\n\nk_repeat_elements(x, rep, axis)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nrep\nInteger, number of times to repeat.\n\n\naxis\nAxis along which to repeat (axis indexes are 1-based)\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_reset_uids.html",
    "href": "packages/keras/latest/reference/k_reset_uids.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reset graph identifiers.\n\n\nReset graph identifiers.\n\n\n\nk_reset_uids()"
  },
  {
    "objectID": "packages/keras/latest/reference/k_reshape.html",
    "href": "packages/keras/latest/reference/k_reshape.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reshapes a tensor to the specified shape.\n\n\nReshapes a tensor to the specified shape.\n\n\n\nk_reshape(x, shape)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\nshape\nTarget shape list.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_resize_images.html",
    "href": "packages/keras/latest/reference/k_resize_images.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Resizes the images contained in a 4D tensor.\n\n\nResizes the images contained in a 4D tensor.\n\n\n\nk_resize_images(x, height_factor, width_factor, data_format)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable to resize.\n\n\nheight_factor\nPositive integer.\n\n\nwidth_factor\nPositive integer.\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_resize_volumes.html",
    "href": "packages/keras/latest/reference/k_resize_volumes.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Resizes the volume contained in a 5D tensor.\n\n\nResizes the volume contained in a 5D tensor.\n\n\n\nk_resize_volumes(x, depth_factor, height_factor, width_factor, data_format)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable to resize.\n\n\ndepth_factor\nPositive integer.\n\n\nheight_factor\nPositive integer.\n\n\nwidth_factor\nPositive integer.\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_reverse.html",
    "href": "packages/keras/latest/reference/k_reverse.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reverse a tensor along the specified axes.\n\n\nReverse a tensor along the specified axes.\n\n\n\nk_reverse(x, axes)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor to reverse.\n\n\naxes\nInteger or list of integers of axes to reverse (axis indexes are 1-based).\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_rnn.html",
    "href": "packages/keras/latest/reference/k_rnn.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Iterates over the time dimension of a tensor\n\n\nIterates over the time dimension of a tensor\n\n\n\nk_rnn(\n  step_function,\n  inputs,\n  initial_states,\n  go_backwards = FALSE,\n  mask = NULL,\n  constants = NULL,\n  unroll = FALSE,\n  input_length = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nstep_function\nRNN step function.\n\n\ninputs\nTensor with shape (samples, …) (no time dimension), representing input for the batch of samples at a certain time step.\n\n\ninitial_states\nTensor with shape (samples, output_dim) (no time dimension), containing the initial values for the states used in the step function.\n\n\ngo_backwards\nLogical If TRUE, do the iteration over the time dimension in reverse order and return the reversed sequence.\n\n\nmask\nBinary tensor with shape (samples, time, 1), with a zero for every element that is masked.\n\n\nconstants\nA list of constant values passed at each step.\n\n\nunroll\nWhether to unroll the RNN or to use a symbolic loop (while_loop or scan depending on backend).\n\n\ninput_length\nNot relevant in the TensorFlow implementation. Must be specified if using unrolling with Theano.\n\n\n\n\n\n\nA list with:\n\nlast_output: the latest output of the rnn, of shape (samples, …)\noutputs: tensor with shape (samples, time, …) where each entry outputs[s, t] is the output of the step function at time t for sample s.\nnew_states: list of tensors, latest states returned by the step function, of shape (samples, …)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_round.html",
    "href": "packages/keras/latest/reference/k_round.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise rounding to the closest integer.\n\n\nIn case of tie, the rounding mode used is “half to even”.\n\n\n\nk_round(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_separable_conv2d.html",
    "href": "packages/keras/latest/reference/k_separable_conv2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "2D convolution with separable filters.\n\n\n2D convolution with separable filters.\n\n\n\nk_separable_conv2d(\n  x,\n  depthwise_kernel,\n  pointwise_kernel,\n  strides = c(1, 1),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1, 1)\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\ninput tensor\n\n\ndepthwise_kernel\nconvolution kernel for the depthwise convolution.\n\n\npointwise_kernel\nkernel for the 1x1 convolution.\n\n\nstrides\nstrides list (length 2).\n\n\npadding\nstring, \"same\" or \"valid\".\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\ndilation_rate\nlist of integers, dilation rates for the separable convolution.\n\n\n\n\n\n\nOutput tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_set_learning_phase.html",
    "href": "packages/keras/latest/reference/k_set_learning_phase.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Sets the learning phase to a fixed value.\n\n\nSets the learning phase to a fixed value.\n\n\n\nk_set_learning_phase(value)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nvalue\nLearning phase value, either 0 or 1 (integers)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_set_value.html",
    "href": "packages/keras/latest/reference/k_set_value.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Sets the value of a variable, from an R array.\n\n\nSets the value of a variable, from an R array.\n\n\n\nk_set_value(x, value)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor to set to a new value.\n\n\nvalue\nValue to set the tensor to, as an R array (of the same shape)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_shape.html",
    "href": "packages/keras/latest/reference/k_shape.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns the symbolic shape of a tensor or variable.\n\n\nReturns the symbolic shape of a tensor or variable.\n\n\n\nk_shape(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA symbolic shape (which is itself a tensor)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_sigmoid.html",
    "href": "packages/keras/latest/reference/k_sigmoid.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise sigmoid.\n\n\nElement-wise sigmoid.\n\n\n\nk_sigmoid(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_sign.html",
    "href": "packages/keras/latest/reference/k_sign.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise sign.\n\n\nElement-wise sign.\n\n\n\nk_sign(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_sin.html",
    "href": "packages/keras/latest/reference/k_sin.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes sin of x element-wise.\n\n\nComputes sin of x element-wise.\n\n\n\nk_sin(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_softmax.html",
    "href": "packages/keras/latest/reference/k_softmax.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Softmax of a tensor.\n\n\nSoftmax of a tensor.\n\n\n\nk_softmax(x, axis = -1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nThe dimension softmax would be performed on. The default is -1 which indicates the last dimension.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_softplus.html",
    "href": "packages/keras/latest/reference/k_softplus.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Softplus of a tensor.\n\n\nSoftplus of a tensor.\n\n\n\nk_softplus(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_softsign.html",
    "href": "packages/keras/latest/reference/k_softsign.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Softsign of a tensor.\n\n\nSoftsign of a tensor.\n\n\n\nk_softsign(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_sparse_categorical_crossentropy.html",
    "href": "packages/keras/latest/reference/k_sparse_categorical_crossentropy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Categorical crossentropy with integer targets.\n\n\nCategorical crossentropy with integer targets.\n\n\n\nk_sparse_categorical_crossentropy(\n  target,\n  output,\n  from_logits = FALSE,\n  axis = -1\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntarget\nAn integer tensor.\n\n\noutput\nA tensor resulting from a softmax (unless from_logits is TRUE, in which case output is expected to be the logits).\n\n\nfrom_logits\nBoolean, whether output is the result of a softmax, or is a tensor of logits.\n\n\naxis\nAxis (axis indexes are 1-based). Pass -1 (the default) to select the last axis.\n\n\n\n\n\n\nOutput tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_spatial_2d_padding.html",
    "href": "packages/keras/latest/reference/k_spatial_2d_padding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pads the 2nd and 3rd dimensions of a 4D tensor.\n\n\nPads the 2nd and 3rd dimensions of a 4D tensor.\n\n\n\nk_spatial_2d_padding(\n  x,\n  padding = list(list(1, 1), list(1, 1)),\n  data_format = NULL\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\npadding\nTuple of 2 lists, padding pattern.\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\n\n\n\n\nA padded 4D tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_spatial_3d_padding.html",
    "href": "packages/keras/latest/reference/k_spatial_3d_padding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pads 5D tensor with zeros along the depth, height, width dimensions.\n\n\nPads these dimensions with respectively padding[[1]], padding[[2]], and padding[[3]] zeros left and right. For ‘channels_last’ data_format, the 2nd, 3rd and 4th dimension will be padded. For ‘channels_first’ data_format, the 3rd, 4th and 5th dimension will be padded.\n\n\n\nk_spatial_3d_padding(\n  x,\n  padding = list(list(1, 1), list(1, 1), list(1, 1)),\n  data_format = NULL\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\npadding\nList of 3 lists, padding pattern.\n\n\ndata_format\nstring, \"channels_last\" or \"channels_first\".\n\n\n\n\n\n\nA padded 5D tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_sqrt.html",
    "href": "packages/keras/latest/reference/k_sqrt.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise square root.\n\n\nElement-wise square root.\n\n\n\nk_sqrt(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_square.html",
    "href": "packages/keras/latest/reference/k_square.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise square.\n\n\nElement-wise square.\n\n\n\nk_square(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_squeeze.html",
    "href": "packages/keras/latest/reference/k_squeeze.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Removes a 1-dimension from the tensor at index axis.\n\n\nRemoves a 1-dimension from the tensor at index axis.\n\n\n\nk_squeeze(x, axis = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAxis to drop (axis indexes are 1-based).\n\n\n\n\n\n\nA tensor with the same data as x but reduced dimensions."
  },
  {
    "objectID": "packages/keras/latest/reference/k_stack.html",
    "href": "packages/keras/latest/reference/k_stack.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Stacks a list of rank R tensors into a rank R+1 tensor.\n\n\nStacks a list of rank R tensors into a rank R+1 tensor.\n\n\n\nk_stack(x, axis = 1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nList of tensors.\n\n\naxis\nAxis along which to perform stacking (axis indexes are 1-based).\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_std.html",
    "href": "packages/keras/latest/reference/k_std.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Standard deviation of a tensor, alongside the specified axis.\n\n\nStandard deviation of a tensor, alongside the specified axis.\n\n\n\nk_std(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, the axis to compute the standard deviation over (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1. If keepdims is TRUE, the reduced dimension is retained with length 1.\n\n\n\n\n\n\nA tensor with the standard deviation of elements of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_stop_gradient.html",
    "href": "packages/keras/latest/reference/k_stop_gradient.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns variables but with zero gradient w.r.t. every other variable.\n\n\nReturns variables but with zero gradient w.r.t. every other variable.\n\n\n\nk_stop_gradient(variables)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nvariables\ntensor or list of tensors to consider constant with respect to any other variable.\n\n\n\n\n\n\nA single tensor or a list of tensors (depending on the passed argument) that has constant gradient with respect to any other variable."
  },
  {
    "objectID": "packages/keras/latest/reference/k_sum.html",
    "href": "packages/keras/latest/reference/k_sum.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Sum of the values in a tensor, alongside the specified axis.\n\n\nSum of the values in a tensor, alongside the specified axis.\n\n\n\nk_sum(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, the axis to sum over (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1. If keepdims is TRUE, the reduced dimension is retained with length 1.\n\n\n\n\n\n\nA tensor with sum of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_switch.html",
    "href": "packages/keras/latest/reference/k_switch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Switches between two operations depending on a scalar value.\n\n\nNote that both then_expression and else_expression should be symbolic tensors of the same shape.\n\n\n\nk_switch(condition, then_expression, else_expression)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncondition\ntensor (int or bool).\n\n\nthen_expression\neither a tensor, or a function that returns a tensor.\n\n\nelse_expression\neither a tensor, or a function that returns a tensor.\n\n\n\n\n\n\nThe selected tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_tanh.html",
    "href": "packages/keras/latest/reference/k_tanh.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Element-wise tanh.\n\n\nElement-wise tanh.\n\n\n\nk_tanh(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_temporal_padding.html",
    "href": "packages/keras/latest/reference/k_temporal_padding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pads the middle dimension of a 3D tensor.\n\n\nPads the middle dimension of a 3D tensor.\n\n\n\nk_temporal_padding(x, padding = c(1, 1))\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\npadding\nList of 2 integers, how many zeros to add at the start and end of dim 1.\n\n\n\n\n\n\nA padded 3D tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_tile.html",
    "href": "packages/keras/latest/reference/k_tile.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a tensor by tiling x by n.\n\n\nCreates a tensor by tiling x by n.\n\n\n\nk_tile(x, n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable\n\n\nn\nA list of integers. The length must be the same as the number of dimensions in x.\n\n\n\n\n\n\nA tiled tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_to_dense.html",
    "href": "packages/keras/latest/reference/k_to_dense.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Converts a sparse tensor into a dense tensor and returns it.\n\n\nConverts a sparse tensor into a dense tensor and returns it.\n\n\n\nk_to_dense(tensor)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntensor\nA tensor instance (potentially sparse).\n\n\n\n\n\n\nA dense tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_transpose.html",
    "href": "packages/keras/latest/reference/k_transpose.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transposes a tensor and returns it.\n\n\nTransposes a tensor and returns it.\n\n\n\nk_transpose(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTensor or variable.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_truncated_normal.html",
    "href": "packages/keras/latest/reference/k_truncated_normal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns a tensor with truncated random normal distribution of values.\n\n\nThe generated values follow a normal distribution with specified mean and standard deviation, except that values whose magnitude is more than two standard deviations from the mean are dropped and re-picked.\n\n\n\nk_truncated_normal(shape, mean = 0, stddev = 1, dtype = NULL, seed = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nA list of integers, the shape of tensor to create.\n\n\nmean\nMean of the values.\n\n\nstddev\nStandard deviation of the values.\n\n\ndtype\nString, dtype of returned tensor.\n\n\nseed\nInteger, random seed.\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_unstack.html",
    "href": "packages/keras/latest/reference/k_unstack.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Unstack rank R tensor into a list of rank R-1 tensors.\n\n\nUnstack rank R tensor into a list of rank R-1 tensors.\n\n\n\nk_unstack(x, axis = 1L, num = NULL, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na tensor.\n\n\naxis\nAxis along which to perform stacking (axis indexes are 1-based). Negative values wrap around, so the valid range is [R, -R].\n\n\nnum\nAn int. The length of the dimension axis. Automatically inferred if NULL (the default).\n\n\nname\nA name for the operation (optional).\n\n\n\n\n\n\nA tensor."
  },
  {
    "objectID": "packages/keras/latest/reference/k_update.html",
    "href": "packages/keras/latest/reference/k_update.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Update the value of x to new_x.\n\n\nUpdate the value of x to new_x.\n\n\n\nk_update(x, new_x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA Variable.\n\n\nnew_x\nA tensor of same shape as x.\n\n\n\n\n\n\nThe variable x updated."
  },
  {
    "objectID": "packages/keras/latest/reference/k_update_add.html",
    "href": "packages/keras/latest/reference/k_update_add.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Update the value of x by adding increment.\n\n\nUpdate the value of x by adding increment.\n\n\n\nk_update_add(x, increment)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA Variable.\n\n\nincrement\nA tensor of same shape as x.\n\n\n\n\n\n\nThe variable x updated."
  },
  {
    "objectID": "packages/keras/latest/reference/k_update_sub.html",
    "href": "packages/keras/latest/reference/k_update_sub.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Update the value of x by subtracting decrement.\n\n\nUpdate the value of x by subtracting decrement.\n\n\n\nk_update_sub(x, decrement)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA Variable.\n\n\ndecrement\nA tensor of same shape as x.\n\n\n\n\n\n\nThe variable x updated."
  },
  {
    "objectID": "packages/keras/latest/reference/k_var.html",
    "href": "packages/keras/latest/reference/k_var.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Variance of a tensor, alongside the specified axis.\n\n\nVariance of a tensor, alongside the specified axis.\n\n\n\nk_var(x, axis = NULL, keepdims = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA tensor or variable.\n\n\naxis\nAn integer, the axis to compute the variance over (axis indexes are 1-based).\n\n\nkeepdims\nA boolean, whether to keep the dimensions or not. If keepdims is FALSE, the rank of the tensor is reduced by 1. If keepdims is TRUE, the reduced dimension is retained with length 1.\n\n\n\n\n\n\nA tensor with the variance of elements of x."
  },
  {
    "objectID": "packages/keras/latest/reference/k_variable.html",
    "href": "packages/keras/latest/reference/k_variable.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates a variable and returns it.\n\n\nInstantiates a variable and returns it.\n\n\n\nk_variable(value, dtype = NULL, name = NULL, constraint = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nvalue\nNumpy array, initial value of the tensor.\n\n\ndtype\nTensor type.\n\n\nname\nOptional name string for the tensor.\n\n\nconstraint\nOptional projection function to be applied to the variable after an optimizer update.\n\n\n\n\n\n\nA variable instance (with Keras metadata included)."
  },
  {
    "objectID": "packages/keras/latest/reference/k_zeros.html",
    "href": "packages/keras/latest/reference/k_zeros.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates an all-zeros variable and returns it.\n\n\nInstantiates an all-zeros variable and returns it.\n\n\n\nk_zeros(shape, dtype = NULL, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nTuple of integers, shape of returned Keras variable\n\n\ndtype\nString, data type of returned Keras variable\n\n\nname\nString, name of returned Keras variable\n\n\n\n\n\n\nA variable (including Keras metadata), filled with 0.0."
  },
  {
    "objectID": "packages/keras/latest/reference/k_zeros_like.html",
    "href": "packages/keras/latest/reference/k_zeros_like.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Instantiates an all-zeros variable of the same shape as another tensor.\n\n\nInstantiates an all-zeros variable of the same shape as another tensor.\n\n\n\nk_zeros_like(x, dtype = NULL, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nKeras variable or Keras tensor.\n\n\ndtype\nString, dtype of returned Keras variable. NULL uses the dtype of x.\n\n\nname\nString, name for the variable to create.\n\n\n\n\n\n\nA Keras variable with the shape of x filled with zeros."
  },
  {
    "objectID": "packages/keras/latest/reference/keras-package.html",
    "href": "packages/keras/latest/reference/keras-package.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "R interface to Keras\n\n\nKeras is a high-level neural networks API, developed with a focus on enabling fast experimentation. Keras has the following key features:\n\n\n\n\nAllows the same code to run on CPU or on GPU, seamlessly.\nUser-friendly API which makes it easy to quickly prototype deep learning models.\nBuilt-in support for convolutional networks (for computer vision), recurrent networks (for sequence processing), and any combination of both.\nSupports arbitrary network architectures: multi-input or multi-output models, layer sharing, model sharing, etc. This means that Keras is appropriate for building essentially any deep learning model, from a memory network to a neural Turing machine.\nIs capable of running on top of multiple back-ends including https://github.com/tensorflow/tensorflowTensorFlow, https://github.com/Microsoft/cntkCNTK, or https://github.com/Theano/TheanoTheano.\n\nSee the package website at https://keras.rstudio.com for complete documentation.\n\n\n\nUseful links:\n\nhttps://keras.rstudio.com\nReport bugs at https://github.com/rstudio/keras/issues"
  },
  {
    "objectID": "packages/keras/latest/reference/keras.html",
    "href": "packages/keras/latest/reference/keras.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Main Keras module\n\n\nThe keras module object is the equivalent of keras <- tensorflow::tf$keras and provided mainly as a convenience.\n\n\n\nkeras\n\n\n\nthe keras Python module"
  },
  {
    "objectID": "packages/keras/latest/reference/keras_array.html",
    "href": "packages/keras/latest/reference/keras_array.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Keras array object\n\n\nConvert an R vector, matrix, or array object to an array that has the optimal in-memory layout and floating point data type for the current Keras backend.\n\n\n\nkeras_array(x, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nObject or list of objects to convert\n\n\ndtype\nNumPy data type (e.g. float32, float64). If this is unspecified then R doubles will be converted to the default floating point type for the current Keras backend.\n\n\n\n\n\n\nKeras does frequent row-oriented access to arrays (for shuffling and drawing batches) so the order of arrays created by this function is always row-oriented (“C” as opposed to “Fortran” ordering, which is the default for R arrays).\nIf the passed array is already a NumPy array with the desired dtype and “C” order then it is returned unmodified (no additional copies are made).\n\n\n\nNumPy array with the specified dtype (or list of NumPy arrays if a list was passed for x)."
  },
  {
    "objectID": "packages/keras/latest/reference/keras_model.html",
    "href": "packages/keras/latest/reference/keras_model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Keras Model\n\n\nA model is a directed acyclic graph of layers.\n\n\n\nkeras_model(inputs, outputs = NULL, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nInput layer\n\n\noutputs\nOutput layer\n\n\n…\nAny additional arguments\n\n\n\n\n\n\n\nlibrary(keras)\n\n# input layer\ninputs <- layer_input(shape = c(784))\n\n# outputs compose input + dense layers\npredictions <- inputs %>%\n  layer_dense(units = 64, activation = 'relu') %>%\n  layer_dense(units = 64, activation = 'relu') %>%\n  layer_dense(units = 10, activation = 'softmax')\n\n# create and compile model\nmodel <- keras_model(inputs = inputs, outputs = predictions)\nmodel %>% compile(\n  optimizer = 'rmsprop',\n  loss = 'categorical_crossentropy',\n  metrics = c('accuracy')\n)\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/keras_model_custom.html",
    "href": "packages/keras/latest/reference/keras_model_custom.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Create a Keras custom model\n\n\nkeras_model_custom() is soft-deprecated. Please define custom models by subclassing keras$Model directly using %py_class% or R6::R6Class().\n\n\n\nkeras_model_custom(model_fn, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmodel_fn\nFunction that returns an R custom model\n\n\nname\nOptional name for model\n\n\n\n\n\n\nFor documentation on using custom models, see https://keras.rstudio.com/articles/custom_models.html.\n\n\n\nA Keras model"
  },
  {
    "objectID": "packages/keras/latest/reference/keras_model_sequential.html",
    "href": "packages/keras/latest/reference/keras_model_sequential.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Keras Model composed of a linear stack of layers\n\n\nKeras Model composed of a linear stack of layers\n\n\n\nkeras_model_sequential(layers = NULL, name = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlayers\nList of layers to add to the model\n\n\nname\nName of model\n\n\n…\nArguments passed on to sequential_model_input_layer * * * * * * * *\n\n\n\n\n\n\n\n\nlibrary(keras)\n\nmodel <- keras_model_sequential()\nmodel %>%\n  layer_dense(units = 32, input_shape = c(784)) %>%\n  layer_activation('relu') %>%\n  layer_dense(units = 10) %>%\n  layer_activation('softmax')\n\nmodel %>% compile(\n  optimizer = 'rmsprop',\n  loss = 'categorical_crossentropy',\n  metrics = c('accuracy')\n)\n\n# alternative way to provide input shape\nmodel <- keras_model_sequential(input_shape = c(784)) %>%\n  layer_dense(units = 32) %>%\n  layer_activation('relu') %>%\n  layer_dense(units = 10) %>%\n  layer_activation('softmax')\n\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/kerascallback.html",
    "href": "packages/keras/latest/reference/kerascallback.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Base R6 class for Keras callbacks\n\n\nNew custom callbacks implemented as R6 classes are encouraged to inherit from keras$callbacks$Callback directly.\n\n\n\nThe logs named list that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.\nCurrently, the fit.keras.engine.training.Model() method for sequential models will include the following quantities in the logs that it passes to its callbacks:\n\non_epoch_end: logs include acc and loss, and optionally include val_loss (if validation is enabled in fit), and val_acc (if validation and accuracy monitoring are enabled).\non_batch_begin: logs include size, the number of samples in the current batch.\non_batch_end: logs include loss, and optionally acc (if accuracy monitoring is enabled).\n\n\n\n\nKerasCallback.\n\n\n\n\nlibrary(keras)\n\nLossHistory <- R6::R6Class(\"LossHistory\",\n  inherit = KerasCallback,\n\n  public = list(\n\n    losses = NULL,\n\n    on_batch_end = function(batch, logs = list()) {\n      self$losses <- c(self$losses, logs[[\"loss\"]])\n    }\n  )\n)"
  },
  {
    "objectID": "packages/keras/latest/reference/kerasconstraint.html",
    "href": "packages/keras/latest/reference/kerasconstraint.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Base R6 class for Keras constraints\n\n\nNew custom constraints are encouraged to subclass keras$constraints$Constraint directly.\n\n\n\nYou can implement a custom constraint either by creating an R function that accepts a weights (w) parameter, or by creating an R6 class that derives from KerasConstraint and implements a call method.\n\n\n\n\nCustomNonNegConstraint <- R6::R6Class(\n  \"CustomNonNegConstraint\",\n  inherit = KerasConstraint,\n  public = list(\n    call = function(x) {\n       w * k_cast(k_greater_equal(w, 0), k_floatx())\n    }\n  )\n)\n\nlayer_dense(units = 32, input_shape = c(784),\n            kernel_constraint = CustomNonNegConstraint$new())\n\n\n\nconstraints"
  },
  {
    "objectID": "packages/keras/latest/reference/keraslayer.html",
    "href": "packages/keras/latest/reference/keraslayer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Base R6 class for Keras layers\n\n\nCustom R6 layers can now inherit directly from keras$layers$Layer or other layers.\n\n\n\nKerasLayer."
  },
  {
    "objectID": "packages/keras/latest/reference/keraswrapper.html",
    "href": "packages/keras/latest/reference/keraswrapper.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Base R6 class for Keras wrappers\n\n\nInstead of inheriting from the proxy class KerasWrapper and using create_wrapper to create instances, new R6 custom classes are encouraged to inherit directly from keras$layers$Wrapper and use create_layer to create instances.\n\n\n\nKerasWrapper."
  },
  {
    "objectID": "packages/keras/latest/reference/layer.html",
    "href": "packages/keras/latest/reference/layer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Create a custom Layer\n\n\nThis function is maintained but deprecated. Please use new_layer_class() or %py_class% to define custom layers.\n\n\n\nLayer(\n  classname,\n  initialize,\n  build = NULL,\n  call = NULL,\n  compute_output_shape = NULL,\n  ...,\n  inherit = keras::keras$layers$Layer\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nclassname\nthe name of the custom Layer.\n\n\ninitialize\na function. This is where you define the arguments used to further build your layer. For example, a dense layer would take the units argument. You should always call super()$`__init__()``` to initialize the base inherited layer. build | a function that takesinput_shapeas argument. This is where you will define your weights. Note that if your layer doesn't define trainable weights then you need not implement this method. call | This is where the layer's logic lives. Unless you want your layer to support masking, you only have to care about the first argument passed tocall(the input tensor). compute_output_shape | a function that takesinput_shape`` as an argument. In case your layer modifies the shape of its input, you should specify here the shape transformation logic. This allows Keras to do automatic shape inference. If you don’t modify the shape of the input then you need not implement this method.\n\n\n…\nAny other methods and/or attributes can be specified using named arguments. They will be added to the layer class.\n\n\ninherit\nthe Keras layer to inherit from.\n\n\n\n\n\n\nA function that wraps create_layer, similar to keras::layer_dense.\n\n\n\n\n\nlayer_dense2 <- Layer(\n  \"Dense2\",\n\n  initialize = function(units) {\n    super()$`__init__`()\n    self$units <- as.integer(units)\n  },\n\n  build = function(input_shape) {\n    print(class(input_shape))\n    self$kernel <- self$add_weight(\n      name = \"kernel\",\n      shape = list(input_shape[[2]], self$units),\n      initializer = \"uniform\",\n      trainable = TRUE\n    )\n  },\n\n  call = function(x) {\n    tensorflow::tf$matmul(x, self$kernel)\n  },\n\n  compute_output_shape = function(input_shape) {\n    list(input_shape[[1]], self$units)\n  }\n\n)\n\nl <- layer_dense2(units = 10)\nl(matrix(runif(10), ncol = 1))"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation.html",
    "href": "packages/keras/latest/reference/layer_activation.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Apply an activation function to an output.\n\n\nApply an activation function to an output.\n\n\n\nlayer_activation(\n  object,\n  activation,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nactivation\nName of activation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()\nOther activation layers: layer_activation_elu(), layer_activation_leaky_relu(), layer_activation_parametric_relu(), layer_activation_relu(), layer_activation_selu(), layer_activation_softmax(), layer_activation_thresholded_relu()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation_elu.html",
    "href": "packages/keras/latest/reference/layer_activation_elu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Exponential Linear Unit.\n\n\nIt follows: f(x) =  alpha * (exp(x) - 1.0) for x < 0, f(x) = x for x >= 0.\n\n\n\nlayer_activation_elu(\n  object,\n  alpha = 1,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nalpha\nScale for the negative factor.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nhttps://arxiv.org/abs/1511.07289v1Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs).\nOther activation layers: layer_activation_leaky_relu(), layer_activation_parametric_relu(), layer_activation_relu(), layer_activation_selu(), layer_activation_softmax(), layer_activation_thresholded_relu(), layer_activation()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation_leaky_relu.html",
    "href": "packages/keras/latest/reference/layer_activation_leaky_relu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Leaky version of a Rectified Linear Unit.\n\n\nAllows a small gradient when the unit is not active: f(x) = alpha * x for x < 0, f(x) = x for x >= 0.\n\n\n\nlayer_activation_leaky_relu(\n  object,\n  alpha = 0.3,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nalpha\nfloat >= 0. Negative slope coefficient.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nhttps://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdfRectifier Nonlinearities Improve Neural Network Acoustic Models.\nOther activation layers: layer_activation_elu(), layer_activation_parametric_relu(), layer_activation_relu(), layer_activation_selu(), layer_activation_softmax(), layer_activation_thresholded_relu(), layer_activation()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation_parametric_relu.html",
    "href": "packages/keras/latest/reference/layer_activation_parametric_relu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Parametric Rectified Linear Unit.\n\n\nIt follows: f(x) = alpha * xfor x < 0, f(x) = xfor`x >= 0, where alpha is a learned array with the same shape as x.\n\n\n\nlayer_activation_parametric_relu(\n  object,\n  alpha_initializer = \"zeros\",\n  alpha_regularizer = NULL,\n  alpha_constraint = NULL,\n  shared_axes = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nalpha_initializer\nInitializer function for the weights.\n\n\nalpha_regularizer\nRegularizer for the weights.\n\n\nalpha_constraint\nConstraint for the weights.\n\n\nshared_axes\nThe axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set shared_axes=c(1, 2).\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nhttps://arxiv.org/abs/1502.01852Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.\nOther activation layers: layer_activation_elu(), layer_activation_leaky_relu(), layer_activation_relu(), layer_activation_selu(), layer_activation_softmax(), layer_activation_thresholded_relu(), layer_activation()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation_relu.html",
    "href": "packages/keras/latest/reference/layer_activation_relu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Rectified Linear Unit activation function\n\n\nRectified Linear Unit activation function\n\n\n\nlayer_activation_relu(\n  object,\n  max_value = NULL,\n  negative_slope = 0,\n  threshold = 0,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nmax_value\nloat, the maximum output value.\n\n\nnegative_slope\nfloat >= 0 Negative slope coefficient.\n\n\nthreshold\nfloat. Threshold value for thresholded activation.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther activation layers: layer_activation_elu(), layer_activation_leaky_relu(), layer_activation_parametric_relu(), layer_activation_selu(), layer_activation_softmax(), layer_activation_thresholded_relu(), layer_activation()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation_selu.html",
    "href": "packages/keras/latest/reference/layer_activation_selu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Scaled Exponential Linear Unit.\n\n\nSELU is equal to: scale * elu(x, alpha), where alpha and scale are pre-defined constants.\n\n\n\nlayer_activation_selu(\n  object,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nThe values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see initializer_lecun_normal) and the number of inputs is “large enough” (see article for more information).\nNote:\n\nTo be used together with the initialization “lecun_normal”.\nTo be used together with the dropout variant “AlphaDropout”.\n\n\n\n\nhttps://arxiv.org/abs/1706.02515Self-Normalizing Neural Networks, initializer_lecun_normal, layer_alpha_dropout\nOther activation layers: layer_activation_elu(), layer_activation_leaky_relu(), layer_activation_parametric_relu(), layer_activation_relu(), layer_activation_softmax(), layer_activation_thresholded_relu(), layer_activation()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation_softmax.html",
    "href": "packages/keras/latest/reference/layer_activation_softmax.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Softmax activation function.\n\n\nIt follows: f(x) =  alpha * (exp(x) - 1.0) for x < 0, f(x) = x for x >= 0.\n\n\n\nlayer_activation_softmax(\n  object,\n  axis = -1,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\naxis\nInteger, axis along which the softmax normalization is applied.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther activation layers: layer_activation_elu(), layer_activation_leaky_relu(), layer_activation_parametric_relu(), layer_activation_relu(), layer_activation_selu(), layer_activation_thresholded_relu(), layer_activation()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activation_thresholded_relu.html",
    "href": "packages/keras/latest/reference/layer_activation_thresholded_relu.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Thresholded Rectified Linear Unit.\n\n\nIt follows: f(x) = x for x > theta, f(x) = 0 otherwise.\n\n\n\nlayer_activation_thresholded_relu(\n  object,\n  theta = 1,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ntheta\nfloat >= 0. Threshold location of activation.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nhttps://arxiv.org/abs/1402.3337Zero-bias autoencoders and the benefits of co-adapting features.\nOther activation layers: layer_activation_elu(), layer_activation_leaky_relu(), layer_activation_parametric_relu(), layer_activation_relu(), layer_activation_selu(), layer_activation_softmax(), layer_activation()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_activity_regularization.html",
    "href": "packages/keras/latest/reference/layer_activity_regularization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that applies an update to the cost function based input activity.\n\n\nLayer that applies an update to the cost function based input activity.\n\n\n\nlayer_activity_regularization(\n  object,\n  l1 = 0,\n  l2 = 0,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nl1\nL1 regularization factor (positive float).\n\n\nl2\nL2 regularization factor (positive float).\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_add.html",
    "href": "packages/keras/latest/reference/layer_add.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that adds a list of inputs.\n\n\nIt takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).\n\n\n\nlayer_add(inputs, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\n\n\n\n\nA tensor, the sum of the inputs. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/add\nhttps://keras.io/api/layers/merging_layers/add"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_additive_attention.html",
    "href": "packages/keras/latest/reference/layer_additive_attention.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Additive attention layer, a.k.a. Bahdanau-style attention\n\n\nAdditive attention layer, a.k.a. Bahdanau-style attention\n\n\n\nlayer_additive_attention(\n  object,\n  use_scale = TRUE,\n  ...,\n  causal = FALSE,\n  dropout = 0\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nuse_scale\nIf TRUE, will create a variable to scale the attention scores.\n\n\n…\nstandard layer arguments.\n\n\ncausal\nBoolean. Set to TRUE for decoder self-attention. Adds a mask such that position i cannot attend to positions j > i. This prevents the flow of information from the future towards the past.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the attention scores.\n\n\n\n\n\n\nInputs are query tensor of shape [batch_size, Tq, dim], value tensor of shape [batch_size, Tv, dim] and key tensor of shape [batch_size, Tv, dim]. The calculation follows the steps:\n\nReshape query and key into shapes [batch_size, Tq, 1, dim] and [batch_size, 1, Tv, dim] respectively.\nCalculate scores with shape [batch_size, Tq, Tv] as a non-linear sum: scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)\nUse scores to calculate a distribution with shape [batch_size, Tq, Tv]: distribution = tf$nn$softmax(scores).\nUse distribution to create a linear combination of value with shape [batch_size, Tq, dim]: return tf$matmul(distribution, value).\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention\nhttps://keras.io/api/layers/attention_layers/additive_attention/"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_alpha_dropout.html",
    "href": "packages/keras/latest/reference/layer_alpha_dropout.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Applies Alpha Dropout to the input.\n\n\nAlpha Dropout is a dropout that keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout.\n\n\n\nlayer_alpha_dropout(object, rate, noise_shape = NULL, seed = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nrate\nfloat, drop probability (as with layer_dropout()). The multiplicative noise will have standard deviation sqrt(rate / (1 - rate)).\n\n\nnoise_shape\nNoise shape\n\n\nseed\nAn integer to use as random seed.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nAlpha Dropout fits well to Scaled Exponential Linear Units by randomly setting activations to the negative saturation value.\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/AlphaDropout\nOther noise layers: layer_gaussian_dropout(), layer_gaussian_noise()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_attention.html",
    "href": "packages/keras/latest/reference/layer_attention.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates attention layer\n\n\nDot-product attention layer, a.k.a. Luong-style attention.\n\n\n\nlayer_attention(\n  inputs,\n  use_scale = FALSE,\n  causal = FALSE,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\na list of inputs first should be the query tensor, the second the value tensor\n\n\nuse_scale\nIf True, will create a scalar variable to scale the attention scores.\n\n\ncausal\nBoolean. Set to True for decoder self-attention. Adds a mask such that position i cannot attend to positions j > i. This prevents the flow of information from the future towards the past.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_average.html",
    "href": "packages/keras/latest/reference/layer_average.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that averages a list of inputs.\n\n\nIt takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).\n\n\n\nlayer_average(inputs, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\n\n\n\n\nA tensor, the average of the inputs. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/average\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Average\nhttps://keras.io/api/layers/merging_layers/average\n\nOther merge layers: layer_concatenate(), layer_dot(), layer_maximum(), layer_minimum(), layer_multiply(), layer_subtract()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_average_pooling_1d.html",
    "href": "packages/keras/latest/reference/layer_average_pooling_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Average pooling for temporal data.\n\n\nAverage pooling for temporal data.\n\n\n\nlayer_average_pooling_1d(\n  object,\n  pool_size = 2L,\n  strides = NULL,\n  padding = \"valid\",\n  data_format = \"channels_last\",\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npool_size\nInteger, size of the average pooling windows.\n\n\nstrides\nInteger, or NULL. Factor by which to downscale. E.g. 2 will halve the input. If NULL, it will default to pool_size.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nOne of channels_last (default) or channels_first. The ordering of the dimensions in the inputs.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_average_pooling_2d.html",
    "href": "packages/keras/latest/reference/layer_average_pooling_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Average pooling operation for spatial data.\n\n\nAverage pooling operation for spatial data.\n\n\n\nlayer_average_pooling_2d(\n  object,\n  pool_size = c(2L, 2L),\n  strides = NULL,\n  padding = \"valid\",\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npool_size\ninteger or list of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.\n\n\nstrides\nInteger, list of 2 integers, or NULL. Strides values. If NULL, it will default to pool_size.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_average_pooling_3d.html",
    "href": "packages/keras/latest/reference/layer_average_pooling_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Average pooling operation for 3D data (spatial or spatio-temporal).\n\n\nAverage pooling operation for 3D data (spatial or spatio-temporal).\n\n\n\nlayer_average_pooling_3d(\n  object,\n  pool_size = c(2L, 2L, 2L),\n  strides = NULL,\n  padding = \"valid\",\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npool_size\nlist of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.\n\n\nstrides\nlist of 3 integers, or NULL. Strides values.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_batch_normalization.html",
    "href": "packages/keras/latest/reference/layer_batch_normalization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Batch normalization layer (Ioffe and Szegedy, 2014).\n\n\nNormalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n\n\n\nlayer_batch_normalization(\n  object,\n  axis = -1L,\n  momentum = 0.99,\n  epsilon = 0.001,\n  center = TRUE,\n  scale = TRUE,\n  beta_initializer = \"zeros\",\n  gamma_initializer = \"ones\",\n  moving_mean_initializer = \"zeros\",\n  moving_variance_initializer = \"ones\",\n  beta_regularizer = NULL,\n  gamma_regularizer = NULL,\n  beta_constraint = NULL,\n  gamma_constraint = NULL,\n  renorm = FALSE,\n  renorm_clipping = NULL,\n  renorm_momentum = 0.99,\n  fused = NULL,\n  virtual_batch_size = NULL,\n  adjustment = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\naxis\nInteger, the axis that should be normalized (typically the features axis). For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n\n\nmomentum\nMomentum for the moving mean and the moving variance.\n\n\nepsilon\nSmall float added to variance to avoid dividing by zero.\n\n\ncenter\nIf TRUE, add offset of beta to normalized tensor. If FALSE, beta is ignored.\n\n\nscale\nIf TRUE, multiply by gamma. If FALSE, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.\n\n\nbeta_initializer\nInitializer for the beta weight.\n\n\ngamma_initializer\nInitializer for the gamma weight.\n\n\nmoving_mean_initializer\nInitializer for the moving mean.\n\n\nmoving_variance_initializer\nInitializer for the moving variance.\n\n\nbeta_regularizer\nOptional regularizer for the beta weight.\n\n\ngamma_regularizer\nOptional regularizer for the gamma weight.\n\n\nbeta_constraint\nOptional constraint for the beta weight.\n\n\ngamma_constraint\nOptional constraint for the gamma weight.\n\n\nrenorm\nWhether to use Batch Renormalization (https://arxiv.org/abs/1702.03275). This adds extra variables during training. The inference is the same for either value of this parameter.\n\n\nrenorm_clipping\nA named list or dictionary that may map keys rmax, rmin, dmax to scalar Tensors used to clip the renorm correction. The correction (r, d) is used as corrected_value = normalized_value * r + d, with r clipped to [rmin, rmax], and d to [-dmax, dmax]. Missing rmax, rmin, dmax are set to Inf, 0, Inf, respectively.\n\n\nrenorm_momentum\nMomentum used to update the moving means and standard deviations with renorm. Unlike momentum, this affects training and should be neither too small (which would add noise) nor too large (which would give stale estimates). Note that momentum is still applied to get the means and variances for inference.\n\n\nfused\nTRUE, use a faster, fused implementation, or raise a ValueError if the fused implementation cannot be used. If NULL, use the faster implementation if possible. If FALSE, do not use the fused implementation.\n\n\nvirtual_batch_size\nAn integer. By default, virtual_batch_size is NULL, which means batch normalization is performed across the whole batch. When virtual_batch_size is not NULL, instead perform “Ghost Batch Normalization”, which creates virtual sub-batches which are each normalized separately (with shared gamma, beta, and moving statistics). Must divide the actual batch size during execution.\n\n\nadjustment\nA function taking the Tensor containing the (dynamic) shape of the input tensor and returning a pair (scale, bias) to apply to the normalized values (before gamma and beta), only during training. For example, if axis==-1, adjustment <- function(shape) {     tuple(tf$random$uniform(shape[-1:NULL, style = \"python\"], 0.93, 1.07),           tf$random$uniform(shape[-1:NULL, style = \"python\"], -0.1, 0.1))    } will scale the normalized value by up to 7% up or down, then shift the result by up to 0.1 (with independent scaling and bias for each feature but shared across all examples), and finally apply gamma and/or beta. If NULL, no adjustment is applied. Cannot be specified if virtual_batch_size is specified.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer."
  },
  {
    "objectID": "packages/keras/latest/reference/layer_category_encoding.html",
    "href": "packages/keras/latest/reference/layer_category_encoding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which encodes integer features.\n\n\nThis layer provides options for condensing data into a categorical encoding when the total number of tokens are known in advance. It accepts integer values as inputs, and it outputs a dense or sparse representation of those inputs. For integer inputs where the total number of tokens is not known, use layer_integer_lookup() instead.\n\n\n\nlayer_category_encoding(\n  object,\n  num_tokens = NULL,\n  output_mode = \"multi_hot\",\n  sparse = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nnum_tokens\nThe total number of tokens the layer should support. All inputs to the layer must integers in the range 0 <= value < num_tokens, or an error will be thrown.\n\n\noutput_mode\nSpecification for the output of the layer. Defaults to \"multi_hot\". Values can be \"one_hot\", \"multi_hot\" or \"count\", configuring the layer as follows: * \"one_hot\": Encodes each individual element in the input into an array of num_tokens size, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. * \"multi_hot\": Encodes each sample in the input into a single array of num_tokens size, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (…, sample_length), output shape will be (…, num_tokens). * \"count\": Like \"multi_hot\", but the int array contains a count of the number of times the token at that index appeared in the sample. For all output modes, currently only output up to rank 2 is supported.\n\n\nsparse\nBoolean. If TRUE, returns a SparseTensor instead of a dense Tensor. Defaults to FALSE.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding\nhttps://keras.io/api/layers/preprocessing_layers/categorical/category_encoding/\n\nOther categorical features preprocessing layers: layer_hashing(), layer_integer_lookup(), layer_string_lookup()\nOther preprocessing layers: layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_center_crop.html",
    "href": "packages/keras/latest/reference/layer_center_crop.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Crop the central portion of the images to target height and width\n\n\nCrop the central portion of the images to target height and width\n\n\n\nlayer_center_crop(object, height, width, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nheight\nInteger, the height of the output shape.\n\n\nwidth\nInteger, the width of the output shape.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nInput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format.\nOutput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, target_height, target_width, channels).\nIf the input height/width is even and the target height/width is odd (or inversely), the input image is left-padded by 1 pixel.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/CenterCrop\nhttps://keras.io/api/layers/preprocessing_layers/image_preprocessing/center_crop\n\nOther image preprocessing layers: layer_rescaling(), layer_resizing()\nOther preprocessing layers: layer_category_encoding(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_concatenate.html",
    "href": "packages/keras/latest/reference/layer_concatenate.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that concatenates a list of inputs.\n\n\nIt takes as input a list of tensors, all of the same shape expect for the concatenation axis, and returns a single tensor, the concatenation of all inputs.\n\n\n\nlayer_concatenate(inputs, ..., axis = -1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\naxis\nConcatenation axis.\n\n\n\n\n\n\nA tensor, the concatenation of the inputs alongside axis axis. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate\nhttps://keras.io/api/layers/merging_layers/concatenate\n\nOther merge layers: layer_average(), layer_dot(), layer_maximum(), layer_minimum(), layer_multiply(), layer_subtract()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_1d.html",
    "href": "packages/keras/latest/reference/layer_conv_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "1D convolution layer (e.g. temporal convolution).\n\n\nThis layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is TRUE, a bias vector is created and added to the outputs. Finally, if activation is not NULL, it is applied to the outputs as well. When using this layer as the first layer in a model, provide an input_shape argument (list of integers or NULL, e.g. (10, 128) for sequences of 10 vectors of 128-dimensional vectors, or (NULL, 128) for variable-length sequences of 128-dimensional vectors.\n\n\n\nlayer_conv_1d(\n  object,\n  filters,\n  kernel_size,\n  strides = 1L,\n  padding = \"valid\",\n  data_format = \"channels_last\",\n  dilation_rate = 1L,\n  groups = 1L,\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of a single integer, specifying the length of the 1D convolution window.\n\n\nstrides\nAn integer or list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\nOne of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means “no padding”. \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t+1:]. Useful when modeling temporal data where the model should not violate the temporal order. See https://arxiv.org/abs/1609.03499WaveNet: A Generative Model for Raw Audio, section 2.1.\n\n\ndata_format\nA string, one of \"channels_last\" (default) or \"channels_first\". The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, length, channels) (default format for temporal data in Keras) while \"channels_first\" corresponds to inputs with shape (batch, channels, length).\n\n\ndilation_rate\nan integer or list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.\n\n\ngroups\nA positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_1d_transpose.html",
    "href": "packages/keras/latest/reference/layer_conv_1d_transpose.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transposed 1D convolution layer (sometimes called Deconvolution).\n\n\nThe need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 3) for data with 128 time steps and 3 channels.\n\n\n\nlayer_conv_1d_transpose(\n  object,\n  filters,\n  kernel_size,\n  strides = 1,\n  padding = \"valid\",\n  output_padding = NULL,\n  data_format = NULL,\n  dilation_rate = 1,\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of a single integer, specifying the length of the 1D convolution window.\n\n\nstrides\nAn integer or list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive).\n\n\noutput_padding\nAn integer specifying the amount of padding along the time dimension of the output tensor. The amount of output padding must be lower than the stride. If set to NULL (default), the output shape is inferred.\n\n\ndata_format\nA string, one of \"channels_last\" (default) or \"channels_first\". The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, length, channels) (default format for temporal data in Keras) while \"channels_first\" corresponds to inputs with shape (batch, channels, length).\n\n\ndilation_rate\nan integer or list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_2d.html",
    "href": "packages/keras/latest/reference/layer_conv_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "2D convolution layer (e.g. spatial convolution over images).\n\n\nThis layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is TRUE, a bias vector is created and added to the outputs. Finally, if activation is not NULL, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (list of integers, does not include the sample axis), e.g. input_shape=c(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\".\n\n\n\nlayer_conv_2d(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1L, 1L),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1L, 1L),\n  groups = 1L,\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive). Note that \"same\" is slightly inconsistent across backends with strides != 1, as described https://github.com/keras-team/keras/pull/9473#issuecomment-372166860here\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nan integer or list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n\n\ngroups\nA positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_2d_transpose.html",
    "href": "packages/keras/latest/reference/layer_conv_2d_transpose.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transposed 2D convolution layer (sometimes called Deconvolution).\n\n\nThe need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution. When using this layer as the first layer in a model, provide the keyword argument input_shape (list of integers, does not include the sample axis), e.g. input_shape=c(128L, 128L, 3L) for 128x128 RGB pictures in data_format=\"channels_last\".\n\n\n\nlayer_conv_2d_transpose(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1, 1),\n  padding = \"valid\",\n  output_padding = NULL,\n  data_format = NULL,\n  dilation_rate = c(1, 1),\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive).\n\n\noutput_padding\nAn integer or list of 2 integers, specifying the amount of padding along the height and width of the output tensor. Can be a single integer to specify the same value for all spatial dimensions. The amount of output padding along a given dimension must be lower than the stride along that same dimension. If set to NULL (default), the output shape is inferred.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nDialation rate.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_3d.html",
    "href": "packages/keras/latest/reference/layer_conv_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "3D convolution layer (e.g. spatial convolution over volumes).\n\n\nThis layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is TRUE, a bias vector is created and added to the outputs. Finally, if activation is not NULL, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (list of integers, does not include the sample axis), e.g. input_shape=c(128L, 128L, 128L, 3L) for 128x128x128 volumes with a single channel, in data_format=\"channels_last\".\n\n\n\nlayer_conv_3d(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1L, 1L, 1L),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1L, 1L, 1L),\n  groups = 1L,\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of 3 integers, specifying the depth, height, and width of the 3D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 3 integers, specifying the strides of the convolution along each spatial dimension. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nan integer or list of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n\n\ngroups\nA positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_3d_transpose.html",
    "href": "packages/keras/latest/reference/layer_conv_3d_transpose.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transposed 3D convolution layer (sometimes called Deconvolution).\n\n\nThe need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.\n\n\n\nlayer_conv_3d_transpose(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1, 1, 1),\n  padding = \"valid\",\n  output_padding = NULL,\n  data_format = NULL,\n  dilation_rate = c(1L, 1L, 1L),\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of 3 integers, specifying the depth, height, and width of the 3D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 3 integers, specifying the strides of the convolution along the depth, height and width.. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive).\n\n\noutput_padding\nAn integer or list of 3 integers, specifying the amount of padding along the depth, height, and width of the output tensor. Can be a single integer to specify the same value for all spatial dimensions. The amount of output padding along a given dimension must be lower than the stride along that same dimension. If set to NULL (default), the output shape is inferred.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, depth, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, depth, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nAn integer or vector of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix,\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”).\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nWhen using this layer as the first layer in a model, provide the keyword argument input_shape (list of integers, does not include the sample axis), e.g. input_shape = list(128, 128, 128, 3) for a 128x128x128 volume with 3 channels if data_format=\"channels_last\".\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_lstm_1d.html",
    "href": "packages/keras/latest/reference/layer_conv_lstm_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "1D Convolutional LSTM\n\n\n1D Convolutional LSTM\n\n\n\nlayer_conv_lstm_1d(\n  object,\n  filters,\n  kernel_size,\n  strides = 1L,\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = 1L,\n  activation = \"tanh\",\n  recurrent_activation = \"hard_sigmoid\",\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  unit_forget_bias = TRUE,\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  go_backwards = FALSE,\n  stateful = FALSE,\n  dropout = 0,\n  recurrent_dropout = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of n integers, specifying the dimensions of the convolution window.\n\n\nstrides\nAn integer or list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, time, …, channels) while channels_first corresponds to inputs with shape (batch, time, channels, …). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nAn integer or list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.\n\n\nactivation\nActivation function to use. By default hyperbolic tangent activation function is applied (tanh(x)).\n\n\nrecurrent_activation\nActivation function to use for the recurrent step.\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nunit_forget_bias\nBoolean. If TRUE, add 1 to the bias of the forget gate at initialization. Use in combination with bias_initializer=\"zeros\". This is recommended in https://proceedings.mlr.press/v37/jozefowicz15.pdfJozefowicz et al., 2015\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to.\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence. (default FALSE)\n\n\nreturn_state\nBoolean Whether to return the last state in addition to the output. (default FALSE)\n\n\ngo_backwards\nBoolean (default FALSE). If TRUE, process the input sequence backwards.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nSimilar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM1D"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_lstm_2d.html",
    "href": "packages/keras/latest/reference/layer_conv_lstm_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Convolutional LSTM.\n\n\nIt is similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.\n\n\n\nlayer_conv_lstm_2d(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1L, 1L),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1L, 1L),\n  activation = \"tanh\",\n  recurrent_activation = \"hard_sigmoid\",\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  unit_forget_bias = TRUE,\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  go_backwards = FALSE,\n  stateful = FALSE,\n  dropout = 0,\n  recurrent_dropout = 0,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL,\n  input_shape = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of n integers, specifying the dimensions of the convolution window.\n\n\nstrides\nAn integer or list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, time, …, channels) while channels_first corresponds to inputs with shape (batch, time, channels, …). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nAn integer or list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nrecurrent_activation\nActivation function to use for the recurrent step.\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs..\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state..\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nunit_forget_bias\nBoolean. If TRUE, add 1 to the bias of the forget gate at initialization. Use in combination with bias_initializer=\"zeros\". This is recommended in https://proceedings.mlr.press/v37/jozefowicz15.pdfJozefowicz et al.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence.\n\n\nreturn_state\nBoolean. Whether to return the last state in addition to the output.\n\n\ngo_backwards\nBoolean (default FALSE). If TRUE, rocess the input sequence backwards.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_conv_lstm_3d.html",
    "href": "packages/keras/latest/reference/layer_conv_lstm_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "3D Convolutional LSTM\n\n\n3D Convolutional LSTM\n\n\n\nlayer_conv_lstm_3d(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1L, 1L, 1L),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = c(1L, 1L, 1L),\n  activation = \"tanh\",\n  recurrent_activation = \"hard_sigmoid\",\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  unit_forget_bias = TRUE,\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  go_backwards = FALSE,\n  stateful = FALSE,\n  dropout = 0,\n  recurrent_dropout = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of n integers, specifying the dimensions of the convolution window.\n\n\nstrides\nAn integer or list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, time, …, channels) while channels_first corresponds to inputs with shape (batch, time, channels, …). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nAn integer or list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.\n\n\nactivation\nActivation function to use. By default hyperbolic tangent activation function is applied (tanh(x)).\n\n\nrecurrent_activation\nActivation function to use for the recurrent step.\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nunit_forget_bias\nBoolean. If TRUE, add 1 to the bias of the forget gate at initialization. Use in combination with bias_initializer=\"zeros\". This is recommended in https://proceedings.mlr.press/v37/jozefowicz15.pdfJozefowicz et al., 2015\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to.\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence. (default FALSE)\n\n\nreturn_state\nBoolean Whether to return the last state in addition to the output. (default FALSE)\n\n\ngo_backwards\nBoolean (default FALSE). If TRUE, process the input sequence backwards.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nSimilar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM3D"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_cropping_1d.html",
    "href": "packages/keras/latest/reference/layer_cropping_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cropping layer for 1D input (e.g. temporal sequence).\n\n\nIt crops along the time dimension (axis 1).\n\n\n\nlayer_cropping_1d(\n  object,\n  cropping = c(1L, 1L),\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ncropping\nint or list of int (length 2) How many units should be trimmed off at the beginning and end of the cropping dimension (axis 1). If a single int is provided, the same value will be used for both.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_cropping_2d.html",
    "href": "packages/keras/latest/reference/layer_cropping_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cropping layer for 2D input (e.g. picture).\n\n\nIt crops along spatial dimensions, i.e. width and height.\n\n\n\nlayer_cropping_2d(\n  object,\n  cropping = list(c(0L, 0L), c(0L, 0L)),\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ncropping\nint, or list of 2 ints, or list of 2 lists of 2 ints. * If int: the same symmetric cropping is applied to width and height. * If list of 2 ints: interpreted as two different symmetric cropping values for height and width: (symmetric_height_crop, symmetric_width_crop). * If list of 2 lists of 2 ints: interpreted as ((top_crop, bottom_crop), (left_crop, right_crop))\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_cropping_3d.html",
    "href": "packages/keras/latest/reference/layer_cropping_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n\nCropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n\n\nlayer_cropping_3d(\n  object,\n  cropping = list(c(1L, 1L), c(1L, 1L), c(1L, 1L)),\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ncropping\nint, or list of 3 ints, or list of 3 lists of 2 ints. * If int: the same symmetric cropping is applied to depth, height, and width. * If list of 3 ints: interpreted as two different symmetric cropping values for depth, height, and width: (symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop). * If list of 3 list of 2 ints: interpreted as ((left_dim1_crop, right_dim1_crop), (left_dim2_crop, right_dim2_crop), (left_dim3_crop, right_dim3_crop))\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_cudnn_gru.html",
    "href": "packages/keras/latest/reference/layer_cudnn_gru.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Fast GRU implementation backed by https://developer.nvidia.com/cudnnCuDNN.\n\n\nCan only be run on GPU, with the TensorFlow backend.\n\n\n\nlayer_cudnn_gru(\n  object,\n  units,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  stateful = FALSE,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence.\n\n\nreturn_state\nBoolean (default FALSE). Whether to return the last state in addition to the output.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther recurrent layers: layer_cudnn_lstm(), layer_gru(), layer_lstm(), layer_rnn(), layer_simple_rnn()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_cudnn_lstm.html",
    "href": "packages/keras/latest/reference/layer_cudnn_lstm.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Fast LSTM implementation backed by https://developer.nvidia.com/cudnnCuDNN.\n\n\nCan only be run on GPU, with the TensorFlow backend.\n\n\n\nlayer_cudnn_lstm(\n  object,\n  units,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  unit_forget_bias = TRUE,\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  stateful = FALSE,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nunit_forget_bias\nBoolean. If TRUE, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer=\"zeros\". This is recommended in https://proceedings.mlr.press/v37/jozefowicz15.pdfJozefowicz et al.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence.\n\n\nreturn_state\nBoolean (default FALSE). Whether to return the last state in addition to the output.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther recurrent layers: layer_cudnn_gru(), layer_gru(), layer_lstm(), layer_rnn(), layer_simple_rnn()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_dense.html",
    "href": "packages/keras/latest/reference/layer_dense.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Add a densely-connected NN layer to an output\n\n\nImplements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is TRUE). Note: if the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with kernel.\n\n\n\nlayer_dense(\n  object,\n  units,\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nactivation\nName of activation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nWhether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_dense_features.html",
    "href": "packages/keras/latest/reference/layer_dense_features.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Constructs a DenseFeatures.\n\n\nA layer that produces a dense Tensor based on given feature_columns.\n\n\n\nlayer_dense_features(\n  object,\n  feature_columns,\n  name = NULL,\n  trainable = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfeature_columns\nAn iterable containing the FeatureColumns to use as inputs to your model. All items should be instances of classes derived from DenseColumn such as numeric_column, embedding_column, bucketized_column, indicator_column. If you have categorical features, you can wrap them with an embedding_column or indicator_column. See tfestimators::feature_columns().\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_depthwise_conv_1d.html",
    "href": "packages/keras/latest/reference/layer_depthwise_conv_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Depthwise 1D convolution\n\n\nDepthwise 1D convolution\n\n\n\nlayer_depthwise_conv_1d(\n  object,\n  kernel_size,\n  strides = 1L,\n  padding = \"valid\",\n  depth_multiplier = 1L,\n  data_format = NULL,\n  dilation_rate = 1L,\n  activation = NULL,\n  use_bias = TRUE,\n  depthwise_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  depthwise_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  depthwise_constraint = NULL,\n  bias_constraint = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nkernel_size\nAn integer, specifying the height and width of the 1D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of 'valid' or 'same' (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n\n\ndepth_multiplier\nThe number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to filters_in * depth_multiplier.\n\n\ndata_format\nA string, one of \"channels_last\" (default) or \"channels_first\". The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height, width, channels) while channels_first corresponds to inputs with shape (batch_size, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be ‘channels_last’.\n\n\ndilation_rate\nA single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (see ?activation_relu).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\ndepthwise_initializer\nInitializer for the depthwise kernel matrix (see initializer_glorot_uniform). If NULL, the default initializer (\"glorot_uniform\") will be used.\n\n\nbias_initializer\nInitializer for the bias vector (see keras.initializers). If NULL, the default initializer (‘zeros’) will be used.\n\n\ndepthwise_regularizer\nRegularizer function applied to the depthwise kernel matrix (see regularizer_l1()).\n\n\nbias_regularizer\nRegularizer function applied to the bias vector (see regularizer_l1()).\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its ‘activation’) (see regularizer_l1()).\n\n\ndepthwise_constraint\nConstraint function applied to the depthwise kernel matrix (see constraint_maxnorm()).\n\n\nbias_constraint\nConstraint function applied to the bias vector (see constraint_maxnorm()).\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nDepthwise convolution is a type of convolution in which each input channel is convolved with a different kernel (called a depthwise kernel). You can understand depthwise convolution as the first step in a depthwise separable convolution.\nIt is implemented via the following steps:\n\nSplit the input into individual channels.\nConvolve each channel with an individual depthwise kernel with depth_multiplier output channels.\nConcatenate the convolved outputs along the channels axis.\n\nUnlike a regular 1D convolution, depthwise convolution does not mix information across different input channels.\nThe depth_multiplier argument determines how many filter are applied to one input channel. As such, it controls the amount of output channels that are generated per input channel in the depthwise step.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv1D\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_depthwise_conv_2d.html",
    "href": "packages/keras/latest/reference/layer_depthwise_conv_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Depthwise separable 2D convolution.\n\n\nDepthwise Separable convolutions consists in performing just the first step in a depthwise spatial convolution (which acts on each input channel separately). The depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step.\n\n\n\nlayer_depthwise_conv_2d(\n  object,\n  kernel_size,\n  strides = c(1, 1),\n  padding = \"valid\",\n  depth_multiplier = 1,\n  data_format = NULL,\n  dilation_rate = c(1, 1),\n  activation = NULL,\n  use_bias = TRUE,\n  depthwise_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  depthwise_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  depthwise_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nkernel_size\nAn integer or list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive).\n\n\ndepth_multiplier\nThe number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to filters_in * depth_multiplier.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nan integer or list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\ndepthwise_initializer\nInitializer for the depthwise kernel matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\ndepthwise_regularizer\nRegularizer function applied to the depthwise kernel matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\ndepthwise_constraint\nConstraint function applied to the depthwise kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_discretization.html",
    "href": "packages/keras/latest/reference/layer_discretization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which buckets continuous features by ranges.\n\n\nA preprocessing layer which buckets continuous features by ranges.\n\n\n\nlayer_discretization(\n  object,\n  bin_boundaries = NULL,\n  num_bins = NULL,\n  epsilon = 0.01,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nbin_boundaries\nA list of bin boundaries. The leftmost and rightmost bins will always extend to -Inf and Inf, so bin_boundaries = c(0., 1., 2.) generates bins (-Inf, 0.), [0., 1.), [1., 2.), and [2., +Inf). If this option is set, adapt should not be called.\n\n\nnum_bins\nThe integer number of bins to compute. If this option is set, adapt should be called to learn the bin boundaries.\n\n\nepsilon\nError tolerance, typically a small fraction close to zero (e.g. 0.01). Higher values of epsilon increase the quantile approximation, and hence result in more unequal buckets, but could improve performance and resource consumption.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer will place each element of its input data into one of several contiguous ranges and output an integer index indicating which range each element was placed in.\nInput shape: Any tf.Tensor or tf.RaggedTensor of dimension 2 or higher.\nOutput shape: Same as input shape.\n\n\n\n\nadapt()\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Discretization\nhttps://keras.io/api/layers/preprocessing_layers/numerical/discretization\n\nOther numerical features preprocessing layers: layer_normalization()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_dot.html",
    "href": "packages/keras/latest/reference/layer_dot.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that computes a dot product between samples in two tensors.\n\n\nLayer that computes a dot product between samples in two tensors.\n\n\n\nlayer_dot(inputs, ..., axes, normalize = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\naxes\nInteger or list of integers, axis or axes along which to take the dot product.\n\n\nnormalize\nWhether to L2-normalize samples along the dot product axis before taking the dot product. If set to TRUE, then the output of the dot product is the cosine proximity between the two samples.\n\n\n\n\n\n\nIf inputs is supplied: A tensor, the dot product of the samples from the inputs. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/dot\nhttps://keras.io/api/layers/merging_layers/dot/\n\nOther merge layers: layer_average(), layer_concatenate(), layer_maximum(), layer_minimum(), layer_multiply(), layer_subtract()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_dropout.html",
    "href": "packages/keras/latest/reference/layer_dropout.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Applies Dropout to the input.\n\n\nDropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n\n\n\nlayer_dropout(\n  object,\n  rate,\n  noise_shape = NULL,\n  seed = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nrate\nfloat between 0 and 1. Fraction of the input units to drop.\n\n\nnoise_shape\n1D integer tensor representing the shape of the binary dropout mask that will be multiplied with the input. For instance, if your inputs have shape (batch_size, timesteps, features) and you want the dropout mask to be the same for all timesteps, you can use noise_shape=c(batch_size, 1, features).\n\n\nseed\ninteger to use as random seed.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()\nOther dropout layers: layer_spatial_dropout_1d(), layer_spatial_dropout_2d(), layer_spatial_dropout_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_embedding.html",
    "href": "packages/keras/latest/reference/layer_embedding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Turns positive integers (indexes) into dense vectors of fixed size.\n\n\nFor example, list(4L, 20L) -> list(c(0.25, 0.1), c(0.6, -0.2)) This layer can only be used as the first layer in a model.\n\n\n\nlayer_embedding(\n  object,\n  input_dim,\n  output_dim,\n  embeddings_initializer = \"uniform\",\n  embeddings_regularizer = NULL,\n  activity_regularizer = NULL,\n  embeddings_constraint = NULL,\n  mask_zero = FALSE,\n  input_length = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ninput_dim\nint > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n\n\noutput_dim\nint >= 0. Dimension of the dense embedding.\n\n\nembeddings_initializer\nInitializer for the embeddings matrix.\n\n\nembeddings_regularizer\nRegularizer function applied to the embeddings matrix.\n\n\nactivity_regularizer\nactivity_regularizer\n\n\nembeddings_constraint\nConstraint function applied to the embeddings matrix.\n\n\nmask_zero\nWhether or not the input value 0 is a special “padding” value that should be masked out. This is useful when using recurrent layers, which may take variable length inputs. If this is TRUE then all subsequent layers in the model need to support masking or an exception will be raised. If mask_zero is set to TRUE, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).\n\n\ninput_length\nLength of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer."
  },
  {
    "objectID": "packages/keras/latest/reference/layer_flatten.html",
    "href": "packages/keras/latest/reference/layer_flatten.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Flattens an input\n\n\nFlatten a given input, does not affect the batch size.\n\n\n\nlayer_flatten(\n  object,\n  data_format = NULL,\n  input_shape = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndata_format\nA string. one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. The purpose of this argument is to preserve weight ordering when switching a model from one data format to another. channels_last corresponds to inputs with shape (batch, …, channels) while channels_first corresponds to inputs with shape (batch, channels, …). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_gaussian_dropout.html",
    "href": "packages/keras/latest/reference/layer_gaussian_dropout.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Apply multiplicative 1-centered Gaussian noise.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\n\nlayer_gaussian_dropout(\n  object,\n  rate,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nrate\nfloat, drop probability (as with Dropout). The multiplicative noise will have standard deviation sqrt(rate / (1 - rate)).\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther noise layers: layer_alpha_dropout(), layer_gaussian_noise()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_gaussian_noise.html",
    "href": "packages/keras/latest/reference/layer_gaussian_noise.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Apply additive zero-centered Gaussian noise.\n\n\nThis is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs. As it is a regularization layer, it is only active at training time.\n\n\n\nlayer_gaussian_noise(\n  object,\n  stddev,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nstddev\nfloat, standard deviation of the noise distribution.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther noise layers: layer_alpha_dropout(), layer_gaussian_dropout()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_global_average_pooling_1d.html",
    "href": "packages/keras/latest/reference/layer_global_average_pooling_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Global average pooling operation for temporal data.\n\n\nGlobal average pooling operation for temporal data.\n\n\n\nlayer_global_average_pooling_1d(\n  object,\n  data_format = \"channels_last\",\n  keepdims = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndata_format\nOne of channels_last (default) or channels_first. The ordering of the dimensions in the inputs.\n\n\nkeepdims\nA boolean, whether to keep the spatial dimensions or not. If keepdims is FALSE (default), the rank of the tensor is reduced for spatial dimensions. If keepdims is TRUE, the spatial dimensions are retained with length 1. The behavior is the same as for tf.reduce_mean or np.mean.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_global_average_pooling_2d.html",
    "href": "packages/keras/latest/reference/layer_global_average_pooling_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Global average pooling operation for spatial data.\n\n\nGlobal average pooling operation for spatial data.\n\n\n\nlayer_global_average_pooling_2d(\n  object,\n  data_format = NULL,\n  keepdims = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nkeepdims\nA boolean, whether to keep the spatial dimensions or not. If keepdims is FALSE (default), the rank of the tensor is reduced for spatial dimensions. If keepdims is TRUE, the spatial dimensions are retained with length 1. The behavior is the same as for tf.reduce_mean or np.mean.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_global_average_pooling_3d.html",
    "href": "packages/keras/latest/reference/layer_global_average_pooling_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Global Average pooling operation for 3D data.\n\n\nGlobal Average pooling operation for 3D data.\n\n\n\nlayer_global_average_pooling_3d(\n  object,\n  data_format = NULL,\n  keepdims = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nkeepdims\nA boolean, whether to keep the spatial dimensions or not. If keepdims is FALSE (default), the rank of the tensor is reduced for spatial dimensions. If keepdims is TRUE, the spatial dimensions are retained with length 1. The behavior is the same as for tf.reduce_mean or np.mean.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_global_max_pooling_1d.html",
    "href": "packages/keras/latest/reference/layer_global_max_pooling_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Global max pooling operation for temporal data.\n\n\nGlobal max pooling operation for temporal data.\n\n\n\nlayer_global_max_pooling_1d(\n  object,\n  data_format = \"channels_last\",\n  keepdims = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndata_format\nOne of channels_last (default) or channels_first. The ordering of the dimensions in the inputs.\n\n\nkeepdims\nA boolean, whether to keep the spatial dimensions or not. If keepdims is FALSE (default), the rank of the tensor is reduced for spatial dimensions. If keepdims is TRUE, the spatial dimensions are retained with length 1. The behavior is the same as for tf.reduce_mean or np.mean.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_global_max_pooling_2d.html",
    "href": "packages/keras/latest/reference/layer_global_max_pooling_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Global max pooling operation for spatial data.\n\n\nGlobal max pooling operation for spatial data.\n\n\n\nlayer_global_max_pooling_2d(object, data_format = NULL, keepdims = FALSE, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nkeepdims\nA boolean, whether to keep the spatial dimensions or not. If keepdims is FALSE (default), the rank of the tensor is reduced for spatial dimensions. If keepdims is TRUE, the spatial dimensions are retained with length 1. The behavior is the same as for tf.reduce_mean or np.mean.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_global_max_pooling_3d.html",
    "href": "packages/keras/latest/reference/layer_global_max_pooling_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Global Max pooling operation for 3D data.\n\n\nGlobal Max pooling operation for 3D data.\n\n\n\nlayer_global_max_pooling_3d(object, data_format = NULL, keepdims = FALSE, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nkeepdims\nA boolean, whether to keep the spatial dimensions or not. If keepdims is FALSE (default), the rank of the tensor is reduced for spatial dimensions. If keepdims is TRUE, the spatial dimensions are retained with length 1. The behavior is the same as for tf.reduce_mean or np.mean.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_max_pooling_1d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_gru.html",
    "href": "packages/keras/latest/reference/layer_gru.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Gated Recurrent Unit - Cho et al.\n\n\nThere are two variants. The default one is based on 1406.1078v3 and has reset gate applied to hidden state before matrix multiplication. The other one is based on original 1406.1078v1 and has the order reversed.\n\n\n\nlayer_gru(\n  object,\n  units,\n  activation = \"tanh\",\n  recurrent_activation = \"sigmoid\",\n  use_bias = TRUE,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  go_backwards = FALSE,\n  stateful = FALSE,\n  unroll = FALSE,\n  time_major = FALSE,\n  reset_after = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  dropout = 0,\n  recurrent_dropout = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nactivation\nActivation function to use. Default: hyperbolic tangent (tanh). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nrecurrent_activation\nActivation function to use for the recurrent step.\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence.\n\n\nreturn_state\nBoolean (default FALSE). Whether to return the last state in addition to the output.\n\n\ngo_backwards\nBoolean (default FALSE). If TRUE, process the input sequence backwards and return the reversed sequence.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\nunroll\nBoolean (default FALSE). If TRUE, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.\n\n\ntime_major\nIf True, the inputs and outputs will be in shape [timesteps, batch, feature], whereas in the False case, it will be [batch, timesteps, feature]. Using time_major = TRUE is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.\n\n\nreset_after\nGRU convention (whether to apply reset gate after or before matrix multiplication). FALSE = “before” (default), TRUE = “after” (CuDNN compatible).\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n\n\n…\nStandard Layer args.\n\n\n\n\n\n\nThe second variant is compatible with CuDNNGRU (GPU-only) and allows inference on CPU. Thus it has separate biases for kernel and recurrent_kernel. Use reset_after = TRUE and recurrent_activation = \"sigmoid\".\n\n\n\n\nhttps://www.tensorflow.org/guide/keras/rnn\n\nOther recurrent layers: layer_cudnn_gru(), layer_cudnn_lstm(), layer_lstm(), layer_rnn(), layer_simple_rnn()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_gru_cell.html",
    "href": "packages/keras/latest/reference/layer_gru_cell.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cell class for the GRU layer\n\n\nCell class for the GRU layer\n\n\n\nlayer_gru_cell(\n  units,\n  activation = \"tanh\",\n  recurrent_activation = \"sigmoid\",\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  dropout = 0,\n  recurrent_dropout = 0,\n  reset_after = TRUE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nactivation\nActivation function to use. Default: hyperbolic tangent (tanh). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nrecurrent_activation\nActivation function to use for the recurrent step. Default: sigmoid (sigmoid). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, (default TRUE), whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs. Default: glorot_uniform.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state. Default: orthogonal.\n\n\nbias_initializer\nInitializer for the bias vector. Default: zeros.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix. Default: NULL.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix. Default: NULL.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector. Default: NULL.\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix. Default: NULL.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix. Default: NULL.\n\n\nbias_constraint\nConstraint function applied to the bias vector. Default: NULL.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.\n\n\nreset_after\nGRU convention (whether to apply reset gate after or before matrix multiplication). FALSE = “before”, TRUE = “after” (default and CuDNN compatible).\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nSee https://www.tensorflow.org/guide/keras/rnnthe Keras RNN API guide for details about the usage of RNN API.\nThis class processes one step within the whole time sequence input, whereas tf.keras.layer.GRU processes the whole sequence.\nFor example:\nhtml\n\ninputs <- k_random_uniform(c(32, 10, 8)) output <- inputs %>% layer_rnn(layer_gru_cell(4)) output$shape # TensorShape([32, 4])\nrnn <- layer_rnn(cell = layer_gru_cell(4), return_sequence = TRUE, return_state = TRUE) c(whole_sequence_output, final_state) %<-% rnn(inputs) whole_sequence_output\\(shape # TensorShape([32, 10, 4]) final_state\\)shape # TensorShape([32, 4]) html\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell\n\nOther RNN cell layers: layer_lstm_cell(), layer_simple_rnn_cell(), layer_stacked_rnn_cells()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_hashing.html",
    "href": "packages/keras/latest/reference/layer_hashing.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which hashes and bins categorical features.\n\n\nA preprocessing layer which hashes and bins categorical features.\n\n\n\nlayer_hashing(object, num_bins, mask_value = NULL, salt = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nnum_bins\nNumber of hash bins. Note that this includes the mask_value bin, so the effective number of bins is (num_bins - 1) if mask_value is set.\n\n\nmask_value\nA value that represents masked inputs, which are mapped to index 0. Defaults to NULL, meaning no mask term will be added and the hashing will start at index 0.\n\n\nsalt\nA single unsigned integer or NULL. If passed, the hash function used will be SipHash64, with these values used as an additional input (known as a “salt” in cryptography). These should be non-zero. Defaults to NULL (in that case, the FarmHash64 hash function is used). It also supports list of 2 unsigned integer numbers, see reference paper for details.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer transforms single or multiple categorical inputs to hashed output. It converts a sequence of int or string to a sequence of int. The stable hash function uses tensorflow::ops::Fingerprint to produce the same output consistently across all platforms.\nThis layer uses https://github.com/google/farmhashFarmHash64 by default, which provides a consistent hashed output across different platforms and is stable across invocations, regardless of device and context, by mixing the input bits thoroughly.\nIf you want to obfuscate the hashed output, you can also pass a random salt argument in the constructor. In that case, the layer will use the https://github.com/google/highwayhashSipHash64 hash function, with the salt value serving as additional input to the hash function.\nExample (FarmHash64)\nhtml\n\nlayer <- layer_hashing(num_bins=3) inp <- matrix(c(‘A’, ‘B’, ‘C’, ‘D’, ‘E’)) layer(inp) # <tf.Tensor: shape=(5, 1), dtype=int64, numpy= # array([[1], # [0], # [1], # [1], # [2]])> html\n\nExample (FarmHash64) with a mask value\nhtml\n\nlayer <- layer_hashing(num_bins=3, mask_value=’‘) inp <- matrix(c(’A’, ‘B’, ‘C’, ‘D’, ‘E’)) layer(inp) # <tf.Tensor: shape=(5, 1), dtype=int64, numpy= # array([[1], # [1], # [0], # [2], # [2]])> html\n\nExample (SipHash64)\nhtml\n\nlayer <- layer_hashing(num_bins=3, salt=c(133, 137)) inp <- matrix(c(‘A’, ‘B’, ‘C’, ‘D’, ‘E’)) layer(inp) # <tf.Tensor: shape=(5, 1), dtype=int64, numpy= # array([[1], # [2], # [1], # [0], # [2]])> html\n\nExample (Siphash64 with a single integer, same as salt=[133, 133])\nhtml\n\nlayer <- layer_hashing(num_bins=3, salt=133) inp <- matrix(c(‘A’, ‘B’, ‘C’, ‘D’, ‘E’)) layer(inp) # <tf.Tensor: shape=(5, 1), dtype=int64, numpy= # array([[0], # [0], # [2], # [1], # [0]])> html\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing\nhttps://keras.io/api/layers/preprocessing_layers/categorical/hashing/\n\nOther categorical features preprocessing layers: layer_category_encoding(), layer_integer_lookup(), layer_string_lookup()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_input.html",
    "href": "packages/keras/latest/reference/layer_input.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Input layer\n\n\nLayer to be used as an entry point into a graph.\n\n\n\nlayer_input(\n  shape = NULL,\n  batch_shape = NULL,\n  name = NULL,\n  dtype = NULL,\n  sparse = FALSE,\n  tensor = NULL,\n  ragged = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nshape\nShape, not including the batch size. For instance, shape=c(32) indicates that the expected input will be batches of 32-dimensional vectors.\n\n\nbatch_shape\nShape, including the batch size. For instance, shape = c(10,32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_shape = list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nsparse\nBoolean, whether the placeholder created is meant to be sparse.\n\n\ntensor\nExisting tensor to wrap into the Input layer. If set, the layer will not create a placeholder tensor.\n\n\nragged\nA boolean specifying whether the placeholder to be created is ragged. Only one of ‘ragged’ and ‘sparse’ can be TRUE In this case, values of ‘NULL’ in the ‘shape’ argument represent ragged dimensions.\n\n\n\n\n\n\nA tensor\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_integer_lookup.html",
    "href": "packages/keras/latest/reference/layer_integer_lookup.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which maps integer features to contiguous ranges.\n\n\nA preprocessing layer which maps integer features to contiguous ranges.\n\n\n\nlayer_integer_lookup(\n  object,\n  max_tokens = NULL,\n  num_oov_indices = 1L,\n  mask_token = NULL,\n  oov_token = -1L,\n  vocabulary = NULL,\n  invert = FALSE,\n  output_mode = \"int\",\n  sparse = FALSE,\n  pad_to_max_tokens = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nmax_tokens\nThe maximum size of the vocabulary for this layer. If NULL, there is no cap on the size of the vocabulary. Note that this size includes the OOV and mask tokens. Default to NULL.\n\n\nnum_oov_indices\nThe number of out-of-vocabulary tokens to use. If this value is more than 1, OOV inputs are modulated to determine their OOV value. If this value is 0, OOV inputs will cause an error when calling the layer. Defaults to 1.\n\n\nmask_token\nAn integer token that represents masked inputs. When output_mode is \"int\", the token is included in vocabulary and mapped to index 0. In other output modes, the token will not appear in the vocabulary and instances of the mask token in the input will be dropped. If set to NULL, no mask term will be added. Defaults to NULL.\n\n\noov_token\nOnly used when invert is TRUE. The token to return for OOV indices. Defaults to -1.\n\n\nvocabulary\nOptional. Either an array of integers or a string path to a text file. If passing an array, can pass a list, list, 1D numpy array, or 1D tensor containing the integer vocabulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If this argument is set, there is no need to adapt the layer.\n\n\ninvert\nOnly valid when output_mode is \"int\". If TRUE, this layer will map indices to vocabulary items instead of mapping vocabulary items to indices. Default to FALSE.\n\n\noutput_mode\nSpecification for the output of the layer. Defaults to \"int\". Values can be \"int\", \"one_hot\", \"multi_hot\", \"count\", or \"tf_idf\" configuring the layer as follows: * \"int\": Return the vocabulary indices of the input tokens. * \"one_hot\": Encodes each individual element in the input into an array the same size as the vocabulary, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. * \"multi_hot\": Encodes each sample in the input into a single array the same size as the vocabulary, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (…, sample_length), output shape will be (…, num_tokens). * \"count\": As \"multi_hot\", but the int array contains a count of the number of times the token at that index appeared in the sample. * \"tf_idf\": As \"multi_hot\", but the TF-IDF algorithm is applied to find the value in each token slot. For \"int\" output, any shape of input and output is supported. For all other output modes, currently only output up to rank 2 is supported.\n\n\nsparse\nBoolean. Only applicable when output_mode is \"multi_hot\", \"count\", or \"tf_idf\". If TRUE, returns a SparseTensor instead of a dense Tensor. Defaults to FALSE.\n\n\npad_to_max_tokens\nOnly applicable when output_mode is \"multi_hot\", \"count\", or \"tf_idf\". If TRUE, the output will have its feature axis padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to FALSE.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer maps a set of arbitrary integer input tokens into indexed integer output via a table-based vocabulary lookup. The layer’s output indices will be contiguously arranged up to the maximum vocab size, even if the input tokens are non-continguous or unbounded. The layer supports multiple options for encoding the output via output_mode, and has optional support for out-of-vocabulary (OOV) tokens and masking.\nThe vocabulary for the layer can be supplied on construction or learned via adapt(). During adapt(), the layer will analyze a data set, determine the frequency of individual integer tokens, and create a vocabulary from them. If the vocabulary is capped in size, the most frequent tokens will be used to create the vocabulary and all others will be treated as OOV.\nThere are two possible output modes for the layer. When output_mode is \"int\", input integers are converted to their index in the vocabulary (an integer). When output_mode is \"multi_hot\", \"count\", or \"tf_idf\", input integers are encoded into an array where each dimension corresponds to an element in the vocabulary.\nThe vocabulary for the layer must be either supplied on construction or learned via adapt(). During adapt(), the layer will analyze a data set, determine the frequency of individual integer tokens, and create a vocabulary from them. If the vocabulary is capped in size, the most frequent tokens will be used to create the vocabulary and all others will be treated as OOV.\n\n\n\n\nadapt()\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup\nhttps://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup\n\nOther categorical features preprocessing layers: layer_category_encoding(), layer_hashing(), layer_string_lookup()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_lambda.html",
    "href": "packages/keras/latest/reference/layer_lambda.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Wraps arbitrary expression as a layer\n\n\nWraps arbitrary expression as a layer\n\n\n\nlayer_lambda(\n  object,\n  f,\n  output_shape = NULL,\n  mask = NULL,\n  arguments = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nf\nThe function to be evaluated. Takes input tensor as first argument.\n\n\noutput_shape\nExpected output shape from the function (not required when using TensorFlow back-end).\n\n\nmask\nmask\n\n\narguments\noptional named list of keyword arguments to be passed to the function.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_masking(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_layer_normalization.html",
    "href": "packages/keras/latest/reference/layer_layer_normalization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer normalization layer (Ba et al., 2016).\n\n\nNormalize the activations of the previous layer for each given example in a batch independently, rather than across a batch like Batch Normalization. i.e. applies a transformation that maintains the mean activation within each example close to 0 and the activation standard deviation close to 1.\n\n\n\nlayer_layer_normalization(\n  object,\n  axis = -1,\n  epsilon = 0.001,\n  center = TRUE,\n  scale = TRUE,\n  beta_initializer = \"zeros\",\n  gamma_initializer = \"ones\",\n  beta_regularizer = NULL,\n  gamma_regularizer = NULL,\n  beta_constraint = NULL,\n  gamma_constraint = NULL,\n  trainable = TRUE,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\naxis\nInteger or List/Tuple. The axis or axes to normalize across. Typically this is the features axis/axes. The left-out axes are typically the batch axis/axes. This argument defaults to -1, the last dimension in the input.\n\n\nepsilon\nSmall float added to variance to avoid dividing by zero. Defaults to 1e-3\n\n\ncenter\nIf True, add offset of beta to normalized tensor. If False, beta is ignored. Defaults to True.\n\n\nscale\nIf True, multiply by gamma. If False, gamma is not used. Defaults to True. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.\n\n\nbeta_initializer\nInitializer for the beta weight. Defaults to zeros.\n\n\ngamma_initializer\nInitializer for the gamma weight. Defaults to ones.\n\n\nbeta_regularizer\nOptional regularizer for the beta weight. None by default.\n\n\ngamma_regularizer\nOptional regularizer for the gamma weight. None by default.\n\n\nbeta_constraint\nOptional constraint for the beta weight. None by default.\n\n\ngamma_constraint\nOptional constraint for the gamma weight. None by default.\n\n\ntrainable\nBoolean, if True the variables will be marked as trainable. Defaults to True.\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\n\n\n\n\nGiven a tensor inputs, moments are calculated and normalization is performed across the axes specified in axis."
  },
  {
    "objectID": "packages/keras/latest/reference/layer_locally_connected_1d.html",
    "href": "packages/keras/latest/reference/layer_locally_connected_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Locally-connected layer for 1D inputs.\n\n\nlayer_locally_connected_1d() works similarly to layer_conv_1d() , except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n\n\n\nlayer_locally_connected_1d(\n  object,\n  filters,\n  kernel_size,\n  strides = 1L,\n  padding = \"valid\",\n  data_format = NULL,\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  implementation = 1L,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number output of filters in the convolution).\n\n\nkernel_size\nAn integer or list of a single integer, specifying the length of the 1D convolution window.\n\n\nstrides\nAn integer or list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\nCurrently only supports \"valid\" (case-insensitive). \"same\" may be supported in the future.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\nimplementation\neither 1, 2, or 3. 1 loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops. 2 stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops. 3 stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply. How to choose: 1: large, dense models, 2: small models, 3: large, sparse models, where “large” stands for large input/output activations (i.e. many filters, input_filters, large input_size, output_size), and “sparse” stands for few connections between inputs and outputs, i.e. small ratio filters * input_filters * kernel_size / (input_size * strides), where inputs to and outputs of the layer are assumed to have shapes (input_size, input_filters), (output_size, filters) respectively. It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM. Also, only padding=\"valid\" is supported by implementation=1.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther locally connected layers: layer_locally_connected_2d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_locally_connected_2d.html",
    "href": "packages/keras/latest/reference/layer_locally_connected_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Locally-connected layer for 2D inputs.\n\n\nlayer_locally_connected_2d works similarly to layer_conv_2d(), except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n\n\n\nlayer_locally_connected_2d(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1L, 1L),\n  padding = \"valid\",\n  data_format = NULL,\n  activation = NULL,\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  implementation = 1L,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number output of filters in the convolution).\n\n\nkernel_size\nAn integer or list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\nCurrently only supports \"valid\" (case-insensitive). \"same\" may be supported in the future.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, width, height, channels) while channels_first corresponds to inputs with shape (batch, channels, width, height). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\nimplementation\neither 1, 2, or 3. 1 loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops. 2 stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops. 3 stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply. How to choose: 1: large, dense models, 2: small models, 3: large, sparse models, where “large” stands for large input/output activations (i.e. many filters, input_filters, large input_size, output_size), and “sparse” stands for few connections between inputs and outputs, i.e. small ratio filters * input_filters * kernel_size / (input_size * strides), where inputs to and outputs of the layer are assumed to have shapes (input_size, input_filters), (output_size, filters) respectively. It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM. Also, only padding=\"valid\" is supported by implementation=1.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther locally connected layers: layer_locally_connected_1d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_lstm.html",
    "href": "packages/keras/latest/reference/layer_lstm.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Long Short-Term Memory unit - Hochreiter 1997.\n\n\nFor a step-by-step description of the algorithm, see https://colah.github.io/posts/2015-08-Understanding-LSTMs/this tutorial.\n\n\n\nlayer_lstm(\n  object,\n  units,\n  activation = \"tanh\",\n  recurrent_activation = \"sigmoid\",\n  use_bias = TRUE,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  go_backwards = FALSE,\n  stateful = FALSE,\n  time_major = FALSE,\n  unroll = FALSE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  unit_forget_bias = TRUE,\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  dropout = 0,\n  recurrent_dropout = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nactivation\nActivation function to use. Default: hyperbolic tangent (tanh). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nrecurrent_activation\nActivation function to use for the recurrent step.\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence.\n\n\nreturn_state\nBoolean (default FALSE). Whether to return the last state in addition to the output.\n\n\ngo_backwards\nBoolean (default FALSE). If TRUE, process the input sequence backwards and return the reversed sequence.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\ntime_major\nIf True, the inputs and outputs will be in shape [timesteps, batch, feature], whereas in the False case, it will be [batch, timesteps, feature]. Using time_major = TRUE is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.\n\n\nunroll\nBoolean (default FALSE). If TRUE, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nunit_forget_bias\nBoolean. If TRUE, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer=\"zeros\". This is recommended in https://proceedings.mlr.press/v37/jozefowicz15.pdfJozefowicz et al.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n\n\n…\nStandard Layer args.\n\n\n\n\n\n\n\nhttps://www.tensorflow.org/guide/keras/rnn\n\nOther recurrent layers: layer_cudnn_gru(), layer_cudnn_lstm(), layer_gru(), layer_rnn(), layer_simple_rnn()\nOther recurrent layers: layer_cudnn_gru(), layer_cudnn_lstm(), layer_gru(), layer_rnn(), layer_simple_rnn()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_lstm_cell.html",
    "href": "packages/keras/latest/reference/layer_lstm_cell.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cell class for the LSTM layer\n\n\nCell class for the LSTM layer\n\n\n\nlayer_lstm_cell(\n  units,\n  activation = \"tanh\",\n  recurrent_activation = \"sigmoid\",\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  unit_forget_bias = TRUE,\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  dropout = 0,\n  recurrent_dropout = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nactivation\nActivation function to use. Default: hyperbolic tangent (tanh). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nrecurrent_activation\nActivation function to use for the recurrent step. Default: sigmoid (sigmoid). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, (default TRUE), whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs. Default: glorot_uniform.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state. Default: orthogonal.\n\n\nbias_initializer\nInitializer for the bias vector. Default: zeros.\n\n\nunit_forget_bias\nBoolean (default TRUE). If TRUE, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer=\"zeros\". This is recommended in https://proceedings.mlr.press/v37/jozefowicz15.pdfJozefowicz et al.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix. Default: NULL.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix. Default: NULL.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector. Default: NULL.\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix. Default: NULL.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix. Default: NULL.\n\n\nbias_constraint\nConstraint function applied to the bias vector. Default: NULL.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nSee https://www.tensorflow.org/guide/keras/rnnthe Keras RNN API guide for details about the usage of RNN API.\nThis class processes one step within the whole time sequence input, whereas tf$keras$layer$LSTM processes the whole sequence.\nFor example:\nhtml\n\ninputs <- k_random_normal(c(32, 10, 8)) rnn <- layer_rnn(cell = layer_lstm_cell(units = 4)) output <- rnn(inputs) dim(output) # (32, 4)\nrnn <- layer_rnn(cell = layer_lstm_cell(units = 4), return_sequences = TRUE, return_state = TRUE) c(whole_seq_output, final_memory_state, final_carry_state) %<-% rnn(inputs)\ndim(whole_seq_output) # (32, 10, 4) dim(final_memory_state) # (32, 4) dim(final_carry_state) # (32, 4) html\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell\n\nOther RNN cell layers: layer_gru_cell(), layer_simple_rnn_cell(), layer_stacked_rnn_cells()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_masking.html",
    "href": "packages/keras/latest/reference/layer_masking.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Masks a sequence by using a mask value to skip timesteps.\n\n\nFor each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to mask_value, then the timestep will be masked (skipped) in all downstream layers (as long as they support masking). If any downstream layer does not support masking yet receives such an input mask, an exception will be raised.\n\n\n\nlayer_masking(\n  object,\n  mask_value = 0,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nmask_value\nfloat, mask value\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_permute(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_max_pooling_1d.html",
    "href": "packages/keras/latest/reference/layer_max_pooling_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Max pooling operation for temporal data.\n\n\nMax pooling operation for temporal data.\n\n\n\nlayer_max_pooling_1d(\n  object,\n  pool_size = 2L,\n  strides = NULL,\n  padding = \"valid\",\n  data_format = \"channels_last\",\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npool_size\nInteger, size of the max pooling windows.\n\n\nstrides\nInteger, or NULL. Factor by which to downscale. E.g. 2 will halve the input. If NULL, it will default to pool_size.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of “channels_last” (default) or “channels_first”. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, steps, features) while channels_first corresponds to inputs with shape (batch, features, steps).\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_2d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_max_pooling_2d.html",
    "href": "packages/keras/latest/reference/layer_max_pooling_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Max pooling operation for spatial data.\n\n\nMax pooling operation for spatial data.\n\n\n\nlayer_max_pooling_2d(\n  object,\n  pool_size = c(2L, 2L),\n  strides = NULL,\n  padding = \"valid\",\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npool_size\ninteger or list of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.\n\n\nstrides\nInteger, list of 2 integers, or NULL. Strides values. If NULL, it will default to pool_size.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_max_pooling_3d.html",
    "href": "packages/keras/latest/reference/layer_max_pooling_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Max pooling operation for 3D data (spatial or spatio-temporal).\n\n\nMax pooling operation for 3D data (spatial or spatio-temporal).\n\n\n\nlayer_max_pooling_3d(\n  object,\n  pool_size = c(2L, 2L, 2L),\n  strides = NULL,\n  padding = \"valid\",\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npool_size\nlist of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.\n\n\nstrides\nlist of 3 integers, or NULL. Strides values.\n\n\npadding\nOne of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther pooling layers: layer_average_pooling_1d(), layer_average_pooling_2d(), layer_average_pooling_3d(), layer_global_average_pooling_1d(), layer_global_average_pooling_2d(), layer_global_average_pooling_3d(), layer_global_max_pooling_1d(), layer_global_max_pooling_2d(), layer_global_max_pooling_3d(), layer_max_pooling_1d(), layer_max_pooling_2d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_maximum.html",
    "href": "packages/keras/latest/reference/layer_maximum.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that computes the maximum (element-wise) a list of inputs.\n\n\nIt takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).\n\n\n\nlayer_maximum(inputs, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\n\n\n\n\nA tensor, the element-wise maximum of the inputs. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/maximum\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Maximum\nhttps://keras.io/api/layers/merging_layers/maximum\n\nOther merge layers: layer_average(), layer_concatenate(), layer_dot(), layer_minimum(), layer_multiply(), layer_subtract()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_minimum.html",
    "href": "packages/keras/latest/reference/layer_minimum.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that computes the minimum (element-wise) a list of inputs.\n\n\nIt takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).\n\n\n\nlayer_minimum(inputs, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\n\n\n\n\nA tensor, the element-wise maximum of the inputs. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/minimum\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Minimum\nhttps://keras.io/api/layers/merging_layers/minimum\n\nOther merge layers: layer_average(), layer_concatenate(), layer_dot(), layer_maximum(), layer_multiply(), layer_subtract()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_multi_head_attention.html",
    "href": "packages/keras/latest/reference/layer_multi_head_attention.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "MultiHeadAttention layer\n\n\nThis is an implementation of multi-headed attention based on “Attention is all you Need”. If query, key, value are the same, then this is self-attention. Each timestep in query attends to the corresponding sequence in key, and returns a fixed-width vector.\n\n\n\nlayer_multi_head_attention(\n  inputs,\n  num_heads,\n  key_dim,\n  value_dim = NULL,\n  dropout = 0,\n  use_bias = TRUE,\n  output_shape = NULL,\n  attention_axes = NULL,\n  kernel_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  bias_constraint = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\na list of inputs first should be the query tensor, the second the value tensor\n\n\nnum_heads\nNumber of attention heads.\n\n\nkey_dim\nSize of each attention head for query and key.\n\n\nvalue_dim\nSize of each attention head for value.\n\n\ndropout\nDropout probability.\n\n\nuse_bias\nBoolean, whether the dense layers use bias vectors/matrices.\n\n\noutput_shape\nThe expected shape of an output tensor, besides the batch and sequence dims. If not specified, projects back to the key feature dim.\n\n\nattention_axes\naxes over which the attention is applied. None means attention over all axes, but batch, heads, and features.\n\n\nkernel_initializer\nInitializer for dense layer kernels.\n\n\nbias_initializer\nInitializer for dense layer biases.\n\n\nkernel_regularizer\nRegularizer for dense layer kernels.\n\n\nbias_regularizer\nRegularizer for dense layer biases.\n\n\nactivity_regularizer\nRegularizer for dense layer activity.\n\n\nkernel_constraint\nConstraint for dense layer kernels.\n\n\nbias_constraint\nConstraint for dense layer kernels.\n\n\n…\nOther arguments passed to the layer. Eg, name, training.\n\n\n\n\n\n\nThis layer first projects query, key and value. These are (effectively) a list of tensors of length num_attention_heads, where the corresponding shapes are [batch_size, , key_dim], [batch_size, , key_dim], [batch_size, , value_dim].\nThen, the query and key tensors are dot-producted and scaled. These are softmaxed to obtain attention probabilities. The value tensors are then interpolated by these probabilities, then concatenated back to a single tensor.\nFinally, the result tensor with the last dimension as value_dim can take an linear projection and return.\n\n\n\n\nattention_output: The result of the computation, of shape [B, T, E], where T is for target sequence shapes and E is the query input last dimension if output_shape is None. Otherwise, the multi-head outputs are project to the shape specified by output_shape.\nattention_scores: (Optional) multi-head attention coeffients over attention axes."
  },
  {
    "objectID": "packages/keras/latest/reference/layer_multiply.html",
    "href": "packages/keras/latest/reference/layer_multiply.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that multiplies (element-wise) a list of inputs.\n\n\nIt takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).\n\n\n\nlayer_multiply(inputs, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\n\n\n\n\nA tensor, the element-wise product of the inputs. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/multiply\nhttps://keras.io/api/layers/merging_layers/multiply\n\nOther merge layers: layer_average(), layer_concatenate(), layer_dot(), layer_maximum(), layer_minimum(), layer_subtract()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_normalization.html",
    "href": "packages/keras/latest/reference/layer_normalization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which normalizes continuous features.\n\n\nA preprocessing layer which normalizes continuous features.\n\n\n\nlayer_normalization(object, axis = -1L, mean = NULL, variance = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\naxis\nInteger, list of integers, or NULL. The axis or axes that should have a separate mean and variance for each index in the shape. For example, if shape is (NULL, 5) and axis=1, the layer will track 5 separate mean and variance values for the last axis. If axis is set to NULL, the layer will normalize all elements in the input by a scalar mean and variance. Defaults to -1, where the last axis of the input is assumed to be a feature dimension and is normalized per index. Note that in the specific case of batched scalar inputs where the only axis is the batch axis, the default will normalize each index in the batch separately. In this case, consider passing axis = NULL.\n\n\nmean\nThe mean value(s) to use during normalization. The passed value(s) will be broadcast to the shape of the kept axes above; if the value(s) cannot be broadcast, an error will be raised when this layer’s build() method is called.\n\n\nvariance\nThe variance value(s) to use during normalization. The passed value(s) will be broadcast to the shape of the kept axes above; if the value(s) cannot be broadcast, an error will be raised when this layer’s build() method is called.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer will shift and scale inputs into a distribution centered around 0 with standard deviation 1. It accomplishes this by precomputing the mean and variance of the data, and calling (input - mean) / sqrt(var) at runtime.\nThe mean and variance values for the layer must be either supplied on construction or learned via adapt(). adapt() will compute the mean and variance of the data and store them as the layer’s weights. adapt() should be called before fit(), evaluate(), or predict().\n\n\n\n\nadapt()\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization\nhttps://keras.io/api/layers/preprocessing_layers/numerical/normalization\n\nOther numerical features preprocessing layers: layer_discretization()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_permute.html",
    "href": "packages/keras/latest/reference/layer_permute.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Permute the dimensions of an input according to a given pattern\n\n\nPermute the dimensions of an input according to a given pattern\n\n\n\nlayer_permute(\n  object,\n  dims,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ndims\nList of integers. Permutation pattern, does not include the samples dimension. Indexing starts at 1. For instance, (2, 1) permutes the first and second dimension of the input.\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_repeat_vector(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_brightness.html",
    "href": "packages/keras/latest/reference/layer_random_brightness.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which randomly adjusts brightness during training\n\n\nA preprocessing layer which randomly adjusts brightness during training\n\n\n\nlayer_random_brightness(\n  object,\n  factor,\n  value_range = c(0, 255),\n  seed = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfactor\nFloat or a list of 2 floats between -1.0 and 1.0. The factor is used to determine the lower bound and upper bound of the brightness adjustment. A float value will be chosen randomly between the limits. When -1.0 is chosen, the output image will be black, and when 1.0 is chosen, the image will be fully white. When only one float is provided, eg, 0.2, then -0.2 will be used for lower bound and 0.2 will be used for upper bound.\n\n\nvalue_range\nOptional list of 2 floats for the lower and upper limit of the values of the input data. Defaults to [0.0, 255.0]. Can be changed to e.g. [0.0, 1.0] if the image input has been scaled before this layer. The brightness adjustment will be scaled to this range, and the output values will be clipped to this range.\n\n\nseed\noptional integer, for fixed RNG behavior.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer will randomly increase/reduce the brightness for the input RGB images. At inference time, the output will be identical to the input. Call the layer with training=TRUE to adjust the brightness of the input.\nNote that different brightness adjustment factors will be apply to each the images in the batch.\nFor an overview and full list of preprocessing layers, see the preprocessing https://www.tensorflow.org/guide/keras/preprocessing_layersguide.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomBrightness\nhttps://keras.io/api/layers\n\nOther image augmentation layers: layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_contrast.html",
    "href": "packages/keras/latest/reference/layer_random_contrast.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Adjust the contrast of an image or images by a random factor\n\n\nAdjust the contrast of an image or images by a random factor\n\n\n\nlayer_random_contrast(object, factor, seed = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfactor\na positive float represented as fraction of value, or a list of size 2 representing lower and upper bound. When represented as a single float, lower = upper. The contrast factor will be randomly picked between [1.0 - lower, 1.0 + upper].\n\n\nseed\nInteger. Used to create a random seed.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nContrast is adjusted independently for each channel of each image during training.\nFor each channel, this layer computes the mean of the image pixels in the channel and then adjusts each component x of each pixel to (x - mean) * contrast_factor + mean.\nInput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format.\nOutput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomContrast\nhttps://keras.io/api/layers/preprocessing_layers/\n\nOther image augmentation layers: layer_random_brightness(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_crop.html",
    "href": "packages/keras/latest/reference/layer_random_crop.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Randomly crop the images to target height and width\n\n\nRandomly crop the images to target height and width\n\n\n\nlayer_random_crop(object, height, width, seed = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nheight\nInteger, the height of the output shape.\n\n\nwidth\nInteger, the width of the output shape.\n\n\nseed\nInteger. Used to create a random seed.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer will crop all the images in the same batch to the same cropping location. By default, random cropping is only applied during training. At inference time, the images will be first rescaled to preserve the shorter side, and center cropped. If you need to apply random cropping at inference time, set training to TRUE when calling the layer.\nInput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format.\nOutput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, target_height, target_width, channels).\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomCrop\nhttps://keras.io/api/layers/preprocessing_layers/image_augmentation/random_crop\n\nOther image augmentation layers: layer_random_brightness(), layer_random_contrast(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_flip.html",
    "href": "packages/keras/latest/reference/layer_random_flip.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Randomly flip each image horizontally and vertically\n\n\nRandomly flip each image horizontally and vertically\n\n\n\nlayer_random_flip(object, mode = \"horizontal_and_vertical\", seed = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nmode\nString indicating which flip mode to use. Can be \"horizontal\", \"vertical\", or \"horizontal_and_vertical\". Defaults to \"horizontal_and_vertical\". \"horizontal\" is a left-right flip and \"vertical\" is a top-bottom flip.\n\n\nseed\nInteger. Used to create a random seed.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer will flip the images based on the mode attribute. During inference time, the output will be identical to input. Call the layer with training = TRUE to flip the input.\nInput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format.\nOutput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip\nhttps://keras.io/api/layers/preprocessing_layers/image_augmentation/random_flip\n\nOther image augmentation layers: layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_height.html",
    "href": "packages/keras/latest/reference/layer_random_height.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Randomly vary the height of a batch of images during training\n\n\nRandomly vary the height of a batch of images during training\n\n\n\nlayer_random_height(\n  object,\n  factor,\n  interpolation = \"bilinear\",\n  seed = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfactor\nA positive float (fraction of original height), or a list of size 2 representing lower and upper bound for resizing vertically. When represented as a single float, this value is used for both the upper and lower bound. For instance, factor = c(0.2, 0.3) results in an output with height changed by a random amount in the range [20%, 30%]. factor = c(-0.2, 0.3) results in an output with height changed by a random amount in the range [-20%, +30%]. factor=0.2 results in an output with height changed by a random amount in the range [-20%, +20%].\n\n\ninterpolation\nString, the interpolation method. Defaults to \"bilinear\". Supports \"bilinear\", \"nearest\", \"bicubic\", \"area\", \"lanczos3\", \"lanczos5\", \"gaussian\", \"mitchellcubic\".\n\n\nseed\nInteger. Used to create a random seed.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nAdjusts the height of a batch of images by a random factor. The input should be a 3D (unbatched) or 4D (batched) tensor in the \"channels_last\" image data format.\nBy default, this layer is inactive during inference.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomHeight\nhttps://keras.io/api/layers/preprocessing_layers/\n\nOther image augmentation layers: layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_rotation.html",
    "href": "packages/keras/latest/reference/layer_random_rotation.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Randomly rotate each image\n\n\nRandomly rotate each image\n\n\n\nlayer_random_rotation(\n  object,\n  factor,\n  fill_mode = \"reflect\",\n  interpolation = \"bilinear\",\n  seed = NULL,\n  fill_value = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfactor\na float represented as fraction of 2 Pi, or a list of size 2 representing lower and upper bound for rotating clockwise and counter-clockwise. A positive values means rotating counter clock-wise, while a negative value means clock-wise. When represented as a single float, this value is used for both the upper and lower bound. For instance, factor = c(-0.2, 0.3) results in an output rotation by a random amount in the range [-20% * 2pi, 30% * 2pi]. factor = 0.2 results in an output rotating by a random amount in the range [-20% * 2pi, 20% * 2pi].\n\n\nfill_mode\nPoints outside the boundaries of the input are filled according to the given mode (one of {“constant”, “reflect”, “wrap”, “nearest”}). * reflect: (d c b a\n\n\ninterpolation\nInterpolation mode. Supported values: \"nearest\", \"bilinear\".\n\n\nseed\nInteger. Used to create a random seed.\n\n\nfill_value\na float represents the value to be filled outside the boundaries when fill_mode=\"constant\".\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nBy default, random rotations are only applied during training. At inference time, the layer does nothing. If you need to apply random rotations at inference time, set training to TRUE when calling the layer.\nInput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format\nOutput shape: 3D (unbatched) or 4D (batched) tensor with shape: (…, height, width, channels), in \"channels_last\" format\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation\nhttps://keras.io/api/layers/preprocessing_layers/\n\nOther image augmentation layers: layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_translation(), layer_random_width(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_translation.html",
    "href": "packages/keras/latest/reference/layer_random_translation.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Randomly translate each image during training\n\n\nRandomly translate each image during training\n\n\n\nlayer_random_translation(\n  object,\n  height_factor,\n  width_factor,\n  fill_mode = \"reflect\",\n  interpolation = \"bilinear\",\n  seed = NULL,\n  fill_value = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nheight_factor\na float represented as fraction of value, or a list of size 2 representing lower and upper bound for shifting vertically. A negative value means shifting image up, while a positive value means shifting image down. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, height_factor = c(-0.2, 0.3) results in an output shifted by a random amount in the range [-20%, +30%]. height_factor = 0.2 results in an output height shifted by a random amount in the range [-20%, +20%].\n\n\nwidth_factor\na float represented as fraction of value, or a list of size 2 representing lower and upper bound for shifting horizontally. A negative value means shifting image left, while a positive value means shifting image right. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, width_factor = c(-0.2, 0.3) results in an output shifted left by 20%, and shifted right by 30%. width_factor = 0.2 results in an output height shifted left or right by 20%.\n\n\nfill_mode\nPoints outside the boundaries of the input are filled according to the given mode (one of {“constant”, “reflect”, “wrap”, “nearest”}). * reflect: (d c b a\n\n\ninterpolation\nInterpolation mode. Supported values: \"nearest\", \"bilinear\".\n\n\nseed\nInteger. Used to create a random seed.\n\n\nfill_value\na float represents the value to be filled outside the boundaries when fill_mode=\"constant\".\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomTranslation\nhttps://keras.io/api/layers/preprocessing_layers/\n\nOther image augmentation layers: layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_width(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_width.html",
    "href": "packages/keras/latest/reference/layer_random_width.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Randomly vary the width of a batch of images during training\n\n\nRandomly vary the width of a batch of images during training\n\n\n\nlayer_random_width(\n  object,\n  factor,\n  interpolation = \"bilinear\",\n  seed = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfactor\nA positive float (fraction of original height), or a list of size 2 representing lower and upper bound for resizing vertically. When represented as a single float, this value is used for both the upper and lower bound. For instance, factor = c(0.2, 0.3) results in an output with width changed by a random amount in the range [20%, 30%]. factor=(-0.2, 0.3) results in an output with width changed by a random amount in the range [-20%, +30%]. factor = 0.2 results in an output with width changed by a random amount in the range [-20%, +20%].\n\n\ninterpolation\nString, the interpolation method. Defaults to bilinear. Supports \"bilinear\", \"nearest\", \"bicubic\", \"area\", \"lanczos3\", \"lanczos5\", \"gaussian\", \"mitchellcubic\".\n\n\nseed\nInteger. Used to create a random seed.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nAdjusts the width of a batch of images by a random factor. The input should be a 3D (unbatched) or 4D (batched) tensor in the \"channels_last\" image data format.\nBy default, this layer is inactive during inference.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomWidth\nhttps://keras.io/api/layers/preprocessing_layers/\n\nOther image augmentation layers: layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_zoom()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_random_zoom.html",
    "href": "packages/keras/latest/reference/layer_random_zoom.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which randomly zooms images during training.\n\n\nThis layer will randomly zoom in or out on each axis of an image independently, filling empty space according to fill_mode.\n\n\n\nlayer_random_zoom(\n  object,\n  height_factor,\n  width_factor = NULL,\n  fill_mode = \"reflect\",\n  interpolation = \"bilinear\",\n  seed = NULL,\n  fill_value = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nheight_factor\na float represented as fraction of value, or a list of size 2 representing lower and upper bound for zooming vertically. When represented as a single float, this value is used for both the upper and lower bound. A positive value means zooming out, while a negative value means zooming in. For instance, height_factor = c(0.2, 0.3) result in an output zoomed out by a random amount in the range [+20%, +30%]. height_factor = c(-0.3, -0.2) result in an output zoomed in by a random amount in the range [+20%, +30%].\n\n\nwidth_factor\na float represented as fraction of value, or a list of size 2 representing lower and upper bound for zooming horizontally. When represented as a single float, this value is used for both the upper and lower bound. For instance, width_factor = c(0.2, 0.3) result in an output zooming out between 20% to 30%. width_factor = c(-0.3, -0.2) result in an output zooming in between 20% to 30%. Defaults to NULL, i.e., zooming vertical and horizontal directions by preserving the aspect ratio.\n\n\nfill_mode\nPoints outside the boundaries of the input are filled according to the given mode (one of {“constant”, “reflect”, “wrap”, “nearest”}). * reflect: (d c b a\n\n\ninterpolation\nInterpolation mode. Supported values: \"nearest\", \"bilinear\".\n\n\nseed\nInteger. Used to create a random seed.\n\n\nfill_value\na float represents the value to be filled outside the boundaries when fill_mode=\"constant\".\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom\nhttps://keras.io/api/layers/preprocessing_layers/\n\nOther image augmentation layers: layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_rescaling(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_repeat_vector.html",
    "href": "packages/keras/latest/reference/layer_repeat_vector.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Repeats the input n times.\n\n\nRepeats the input n times.\n\n\n\nlayer_repeat_vector(\n  object,\n  n,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nn\ninteger, repetition factor.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_reshape()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_rescaling.html",
    "href": "packages/keras/latest/reference/layer_rescaling.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Multiply inputs by scale and adds offset\n\n\nMultiply inputs by scale and adds offset\n\n\n\nlayer_rescaling(object, scale, offset = 0, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nscale\nFloat, the scale to apply to the inputs.\n\n\noffset\nFloat, the offset to apply to the inputs.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nFor instance:\n\nTo rescale an input in the [0, 255] range to be in the [0, 1] range, you would pass scale=1./255.\nTo rescale an input in the [0, 255] range to be in the [-1, 1] range, you would pass scale = 1/127.5, offset = -1.\n\nThe rescaling is applied both during training and inference.\nInput shape: Arbitrary.\nOutput shape: Same as input.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling\nhttps://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling\n\nOther image preprocessing layers: layer_center_crop(), layer_resizing()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_resizing(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_reshape.html",
    "href": "packages/keras/latest/reference/layer_reshape.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reshapes an output to a certain shape.\n\n\nReshapes an output to a certain shape.\n\n\n\nlayer_reshape(\n  object,\n  target_shape,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ntarget_shape\nList of integers, does not include the samples dimension (batch size).\n\n\ninput_shape\nInput shape (list of integers, does not include the samples axis) which is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther core layers: layer_activation(), layer_activity_regularization(), layer_attention(), layer_dense_features(), layer_dense(), layer_dropout(), layer_flatten(), layer_input(), layer_lambda(), layer_masking(), layer_permute(), layer_repeat_vector()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_resizing.html",
    "href": "packages/keras/latest/reference/layer_resizing.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Image resizing layer\n\n\nImage resizing layer\n\n\n\nlayer_resizing(\n  object,\n  height,\n  width,\n  interpolation = \"bilinear\",\n  crop_to_aspect_ratio = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nheight\nInteger, the height of the output shape.\n\n\nwidth\nInteger, the width of the output shape.\n\n\ninterpolation\nString, the interpolation method. Defaults to \"bilinear\". Supports \"bilinear\", \"nearest\", \"bicubic\", \"area\", \"lanczos3\", \"lanczos5\", \"gaussian\", and \"mitchellcubic\".\n\n\ncrop_to_aspect_ratio\nIf TRUE, resize the images without aspect ratio distortion. When the original aspect ratio differs from the target aspect ratio, the output image will be cropped so as to return the largest possible window in the image (of size (height, width)) that matches the target aspect ratio. By default (crop_to_aspect_ratio = FALSE), aspect ratio may not be preserved.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nResize the batched image input to target height and width. The input should be a 4D (batched) or 3D (unbatched) tensor in \"channels_last\" format.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Resizing\nhttps://keras.io/api/layers/preprocessing_layers/image_preprocessing/resizing\n\nOther image preprocessing layers: layer_center_crop(), layer_rescaling()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_string_lookup(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_rnn.html",
    "href": "packages/keras/latest/reference/layer_rnn.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Base class for recurrent layers\n\n\nBase class for recurrent layers\n\n\n\nlayer_rnn(\n  object,\n  cell,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  go_backwards = FALSE,\n  stateful = FALSE,\n  unroll = FALSE,\n  time_major = FALSE,\n  ...,\n  zero_output_for_mask = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\ncell\nA RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: * A call(input_at_t, states_at_t) method, returning (output_at_t, states_at_t_plus_1). The call method of the cell can also take the optional argument constants, see section “Note on passing external constants” below. * A state_size attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list of integers (one size per state). The state_size can also be TensorShape or list of TensorShape, to represent high dimension state. * A output_size attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the state_size. * A get_initial_state(inputs=NULL, batch_size=NULL, dtype=NULL) method that creates a tensor meant to be fed to call() as the initial state, if the user didn’t specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell\\(state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation. `inputs` is the input tensor to the RNN layer, which should contain the batch size as first dimension (`inputs\\)shape[1]), and also dtype (inputs\\(dtype`). Note that the `shape[1]` might be `NULL` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided. `batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatibility, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell\\)state_size]. In the case that cell is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN.\n\n\nreturn_sequences\nBoolean (default FALSE). Whether to return the last output in the output sequence, or the full sequence.\n\n\nreturn_state\nBoolean (default FALSE). Whether to return the last state in addition to the output.\n\n\ngo_backwards\nBoolean (default FALSE). If TRUE, process the input sequence backwards and return the reversed sequence.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\nunroll\nBoolean (default FALSE). If TRUE, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.\n\n\ntime_major\nThe shape format of the inputs and outputs tensors. If TRUE, the inputs and outputs will be in shape (timesteps, batch, …), whereas in the FALSE case, it will be (batch, timesteps, …). Using time_major = TRUE is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.\n\n\n…\nstandard layer arguments.\n\n\nzero_output_for_mask\nBoolean (default FALSE). Whether the output should use zeros for the masked timesteps. Note that this field is only used when return_sequences is TRUE and mask is provided. It can useful if you want to reuse the raw output sequence of the RNN without interference from the masked timesteps, eg, merging bidirectional RNNs.\n\n\n\n\n\n\nSee https://www.tensorflow.org/guide/keras/rnnthe Keras RNN API guide for details about the usage of RNN API.\n\n\n\n\nhttps://www.tensorflow.org/guide/keras/rnn\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN\nhttps://keras.io/api/layers/recurrent_layers/rnn\nreticulate::py_help(keras$layers$RNN)\n\nOther recurrent layers: layer_cudnn_gru(), layer_cudnn_lstm(), layer_gru(), layer_lstm(), layer_simple_rnn()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_separable_conv_1d.html",
    "href": "packages/keras/latest/reference/layer_separable_conv_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Depthwise separable 1D convolution.\n\n\nSeparable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step. Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block.\n\n\n\nlayer_separable_conv_1d(\n  object,\n  filters,\n  kernel_size,\n  strides = 1,\n  padding = \"valid\",\n  data_format = \"channels_last\",\n  dilation_rate = 1,\n  depth_multiplier = 1,\n  activation = NULL,\n  use_bias = TRUE,\n  depthwise_initializer = \"glorot_uniform\",\n  pointwise_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  depthwise_regularizer = NULL,\n  pointwise_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  depthwise_constraint = NULL,\n  pointwise_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nan integer or list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n\n\ndepth_multiplier\nThe number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to filters_in * depth_multiplier.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\ndepthwise_initializer\nInitializer for the depthwise kernel matrix.\n\n\npointwise_initializer\nInitializer for the pointwise kernel matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\ndepthwise_regularizer\nRegularizer function applied to the depthwise kernel matrix.\n\n\npointwise_regularizer\nRegularizer function applied to the pointwise kernel matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\ndepthwise_constraint\nConstraint function applied to the depthwise kernel matrix.\n\n\npointwise_constraint\nConstraint function applied to the pointwise kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_separable_conv_2d.html",
    "href": "packages/keras/latest/reference/layer_separable_conv_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Separable 2D convolution.\n\n\nSeparable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step. Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block.\n\n\n\nlayer_separable_conv_2d(\n  object,\n  filters,\n  kernel_size,\n  strides = c(1, 1),\n  padding = \"valid\",\n  data_format = NULL,\n  dilation_rate = 1,\n  depth_multiplier = 1,\n  activation = NULL,\n  use_bias = TRUE,\n  depthwise_initializer = \"glorot_uniform\",\n  pointwise_initializer = \"glorot_uniform\",\n  bias_initializer = \"zeros\",\n  depthwise_regularizer = NULL,\n  pointwise_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  depthwise_constraint = NULL,\n  pointwise_constraint = NULL,\n  bias_constraint = NULL,\n  input_shape = NULL,\n  batch_input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nfilters\nInteger, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n\n\nkernel_size\nAn integer or list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n\n\nstrides\nAn integer or list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n\n\npadding\none of \"valid\" or \"same\" (case-insensitive).\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ndilation_rate\nan integer or list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n\n\ndepth_multiplier\nThe number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to filters_in * depth_multiplier.\n\n\nactivation\nActivation function to use. If you don’t specify anything, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\ndepthwise_initializer\nInitializer for the depthwise kernel matrix.\n\n\npointwise_initializer\nInitializer for the pointwise kernel matrix.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\ndepthwise_regularizer\nRegularizer function applied to the depthwise kernel matrix.\n\n\npointwise_regularizer\nRegularizer function applied to the pointwise kernel matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\ndepthwise_constraint\nConstraint function applied to the depthwise kernel matrix.\n\n\npointwise_constraint\nConstraint function applied to the pointwise kernel matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ninput_shape\nDimensionality of the input (integer) not including the samples axis. This argument is required when using this layer as the first layer in a model.\n\n\nbatch_input_shape\nShapes, including the batch size. For instance, batch_input_shape=c(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors. batch_input_shape=list(NULL, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n\n\nbatch_size\nFixed batch size for layer\n\n\ndtype\nThe data type expected by the input, as a string (float32, float64, int32…)\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_simple_rnn.html",
    "href": "packages/keras/latest/reference/layer_simple_rnn.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fully-connected RNN where the output is to be fed back to input.\n\n\nFully-connected RNN where the output is to be fed back to input.\n\n\n\nlayer_simple_rnn(\n  object,\n  units,\n  activation = \"tanh\",\n  use_bias = TRUE,\n  return_sequences = FALSE,\n  return_state = FALSE,\n  go_backwards = FALSE,\n  stateful = FALSE,\n  unroll = FALSE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  activity_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  dropout = 0,\n  recurrent_dropout = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nactivation\nActivation function to use. Default: hyperbolic tangent (tanh). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, whether the layer uses a bias vector.\n\n\nreturn_sequences\nBoolean. Whether to return the last output in the output sequence, or the full sequence.\n\n\nreturn_state\nBoolean (default FALSE). Whether to return the last state in addition to the output.\n\n\ngo_backwards\nBoolean (default FALSE). If TRUE, process the input sequence backwards and return the reversed sequence.\n\n\nstateful\nBoolean (default FALSE). If TRUE, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n\n\nunroll\nBoolean (default FALSE). If TRUE, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state.\n\n\nbias_initializer\nInitializer for the bias vector.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector.\n\n\nactivity_regularizer\nRegularizer function applied to the output of the layer (its “activation”)..\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix.\n\n\nbias_constraint\nConstraint function applied to the bias vector.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n\n\n…\nStandard Layer args.\n\n\n\n\n\n\n\nhttps://www.tensorflow.org/guide/keras/rnn\n\nOther recurrent layers: layer_cudnn_gru(), layer_cudnn_lstm(), layer_gru(), layer_lstm(), layer_rnn()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_simple_rnn_cell.html",
    "href": "packages/keras/latest/reference/layer_simple_rnn_cell.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Cell class for SimpleRNN\n\n\nCell class for SimpleRNN\n\n\n\nlayer_simple_rnn_cell(\n  units,\n  activation = \"tanh\",\n  use_bias = TRUE,\n  kernel_initializer = \"glorot_uniform\",\n  recurrent_initializer = \"orthogonal\",\n  bias_initializer = \"zeros\",\n  kernel_regularizer = NULL,\n  recurrent_regularizer = NULL,\n  bias_regularizer = NULL,\n  kernel_constraint = NULL,\n  recurrent_constraint = NULL,\n  bias_constraint = NULL,\n  dropout = 0,\n  recurrent_dropout = 0,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nunits\nPositive integer, dimensionality of the output space.\n\n\nactivation\nActivation function to use. Default: hyperbolic tangent (tanh). If you pass NULL, no activation is applied (ie. “linear” activation: a(x) = x).\n\n\nuse_bias\nBoolean, (default TRUE), whether the layer uses a bias vector.\n\n\nkernel_initializer\nInitializer for the kernel weights matrix, used for the linear transformation of the inputs. Default: glorot_uniform.\n\n\nrecurrent_initializer\nInitializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state. Default: orthogonal.\n\n\nbias_initializer\nInitializer for the bias vector. Default: zeros.\n\n\nkernel_regularizer\nRegularizer function applied to the kernel weights matrix. Default: NULL.\n\n\nrecurrent_regularizer\nRegularizer function applied to the recurrent_kernel weights matrix. Default: NULL.\n\n\nbias_regularizer\nRegularizer function applied to the bias vector. Default: NULL.\n\n\nkernel_constraint\nConstraint function applied to the kernel weights matrix. Default: NULL.\n\n\nrecurrent_constraint\nConstraint function applied to the recurrent_kernel weights matrix. Default: NULL.\n\n\nbias_constraint\nConstraint function applied to the bias vector. Default: NULL.\n\n\ndropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.\n\n\nrecurrent_dropout\nFloat between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nSee https://www.tensorflow.org/guide/keras/rnnthe Keras RNN API guide for details about the usage of RNN API.\nThis class processes one step within the whole time sequence input, whereas tf.keras.layer.SimpleRNN processes the whole sequence.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNNCell\nhttps://keras.io/api/layers\n\nOther RNN cell layers: layer_gru_cell(), layer_lstm_cell(), layer_stacked_rnn_cells()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_spatial_dropout_1d.html",
    "href": "packages/keras/latest/reference/layer_spatial_dropout_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Spatial 1D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, layer_spatial_dropout_1d will help promote independence between feature maps and should be used instead.\n\n\n\nlayer_spatial_dropout_1d(\n  object,\n  rate,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nrate\nfloat between 0 and 1. Fraction of the input units to drop.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther dropout layers: layer_dropout(), layer_spatial_dropout_2d(), layer_spatial_dropout_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_spatial_dropout_2d.html",
    "href": "packages/keras/latest/reference/layer_spatial_dropout_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Spatial 2D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, layer_spatial_dropout_2d will help promote independence between feature maps and should be used instead.\n\n\n\nlayer_spatial_dropout_2d(\n  object,\n  rate,\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nrate\nfloat between 0 and 1. Fraction of the input units to drop.\n\n\ndata_format\n‘channels_first’ or ‘channels_last’. In ‘channels_first’ mode, the channels dimension (the depth) is at index 1, in ‘channels_last’ mode is it at index 3. It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther dropout layers: layer_dropout(), layer_spatial_dropout_1d(), layer_spatial_dropout_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_spatial_dropout_3d.html",
    "href": "packages/keras/latest/reference/layer_spatial_dropout_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Spatial 3D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, layer_spatial_dropout_3d will help promote independence between feature maps and should be used instead.\n\n\n\nlayer_spatial_dropout_3d(\n  object,\n  rate,\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nrate\nfloat between 0 and 1. Fraction of the input units to drop.\n\n\ndata_format\n‘channels_first’ or ‘channels_last’. In ‘channels_first’ mode, the channels dimension (the depth) is at index 1, in ‘channels_last’ mode is it at index 4. It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther dropout layers: layer_dropout(), layer_spatial_dropout_1d(), layer_spatial_dropout_2d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_stacked_rnn_cells.html",
    "href": "packages/keras/latest/reference/layer_stacked_rnn_cells.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Wrapper allowing a stack of RNN cells to behave as a single cell\n\n\nUsed to implement efficient stacked RNNs.\n\n\n\nlayer_stacked_rnn_cells(cells, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncells\nList of RNN cell instances.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/StackedRNNCells\n\nOther RNN cell layers: layer_gru_cell(), layer_lstm_cell(), layer_simple_rnn_cell()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_string_lookup.html",
    "href": "packages/keras/latest/reference/layer_string_lookup.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which maps string features to integer indices.\n\n\nA preprocessing layer which maps string features to integer indices.\n\n\n\nlayer_string_lookup(\n  object,\n  max_tokens = NULL,\n  num_oov_indices = 1L,\n  mask_token = NULL,\n  oov_token = \"[UNK]\",\n  vocabulary = NULL,\n  encoding = NULL,\n  invert = FALSE,\n  output_mode = \"int\",\n  sparse = FALSE,\n  pad_to_max_tokens = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nmax_tokens\nThe maximum size of the vocabulary for this layer. If NULL, there is no cap on the size of the vocabulary. Note that this size includes the OOV and mask tokens. Default to NULL.\n\n\nnum_oov_indices\nThe number of out-of-vocabulary tokens to use. If this value is more than 1, OOV inputs are hashed to determine their OOV value. If this value is 0, OOV inputs will cause an error when calling the layer. Defaults to 1.\n\n\nmask_token\nA token that represents masked inputs. When output_mode is \"int\", the token is included in vocabulary and mapped to index 0. In other output modes, the token will not appear in the vocabulary and instances of the mask token in the input will be dropped. If set to NULL, no mask term will be added. Defaults to NULL.\n\n\noov_token\nOnly used when invert is TRUE. The token to return for OOV indices. Defaults to \"[UNK]\".\n\n\nvocabulary\nOptional. Either an array of strings or a string path to a text file. If passing an array, can pass a list, list, 1D numpy array, or 1D tensor containing the string vocabulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If this argument is set, there is no need to adapt the layer.\n\n\nencoding\nString encoding. Default of NULL is equivalent to \"utf-8\".\n\n\ninvert\nOnly valid when output_mode is \"int\". If TRUE, this layer will map indices to vocabulary items instead of mapping vocabulary items to indices. Default to FALSE.\n\n\noutput_mode\nSpecification for the output of the layer. Defaults to \"int\". Values can be \"int\", \"one_hot\", \"multi_hot\", \"count\", or \"tf_idf\" configuring the layer as follows: * \"int\": Return the raw integer indices of the input tokens. * \"one_hot\": Encodes each individual element in the input into an array the same size as the vocabulary, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. * \"multi_hot\": Encodes each sample in the input into a single array the same size as the vocabulary, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (…, sample_length), output shape will be (…, num_tokens). * \"count\": As \"multi_hot\", but the int array contains a count of the number of times the token at that index appeared in the sample. * \"tf_idf\": As \"multi_hot\", but the TF-IDF algorithm is applied to find the value in each token slot. For \"int\" output, any shape of input and output is supported. For all other output modes, currently only output up to rank 2 is supported.\n\n\nsparse\nBoolean. Only applicable when output_mode is \"multi_hot\", \"count\", or \"tf_idf\". If TRUE, returns a SparseTensor instead of a dense Tensor. Defaults to FALSE.\n\n\npad_to_max_tokens\nOnly applicable when output_mode is \"multi_hot\", \"count\", or \"tf_idf\". If TRUE, the output will have its feature axis padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to FALSE.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nThis layer translates a set of arbitrary strings into integer output via a table-based vocabulary lookup.\nThe vocabulary for the layer must be either supplied on construction or learned via adapt(). During adapt(), the layer will analyze a data set, determine the frequency of individual strings tokens, and create a vocabulary from them. If the vocabulary is capped in size, the most frequent tokens will be used to create the vocabulary and all others will be treated as out-of-vocabulary (OOV).\nThere are two possible output modes for the layer. When output_mode is \"int\", input strings are converted to their index in the vocabulary (an integer). When output_mode is \"multi_hot\", \"count\", or \"tf_idf\", input strings are encoded into an array where each dimension corresponds to an element in the vocabulary.\nThe vocabulary can optionally contain a mask token as well as an OOV token (which can optionally occupy multiple indices in the vocabulary, as set by num_oov_indices). The position of these tokens in the vocabulary is fixed. When output_mode is \"int\", the vocabulary will begin with the mask token (if set), followed by OOV indices, followed by the rest of the vocabulary. When output_mode is \"multi_hot\", \"count\", or \"tf_idf\" the vocabulary will begin with OOV indices and instances of the mask token will be dropped.\n\n\n\n\nadapt()\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup\nhttps://keras.io/api/layers/preprocessing_layers/categorical/string_lookup\n\nOther categorical features preprocessing layers: layer_category_encoding(), layer_hashing(), layer_integer_lookup()\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_text_vectorization()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_subtract.html",
    "href": "packages/keras/latest/reference/layer_subtract.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Layer that subtracts two inputs.\n\n\nIt takes as input a list of tensors of size 2, both of the same shape, and returns a single tensor, (inputs[[1]] - inputs[[2]]), also of the same shape.\n\n\n\nlayer_subtract(inputs, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninputs\nA input tensor, or list of two input tensors. Can be missing.\n\n\n…\nUnnamed args are treated as additional inputs. Named arguments are passed on as standard layer arguments.\n\n\n\n\n\n\nA tensor, the difference of the inputs. If inputs is missing, a keras layer instance is returned.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/subtract\nhttps://keras.io/api/layers/merging_layers/subtract\n\nOther merge layers: layer_average(), layer_concatenate(), layer_dot(), layer_maximum(), layer_minimum(), layer_multiply()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_text_vectorization.html",
    "href": "packages/keras/latest/reference/layer_text_vectorization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A preprocessing layer which maps text features to integer sequences.\n\n\nA preprocessing layer which maps text features to integer sequences.\n\n\n\nlayer_text_vectorization(\n  object,\n  max_tokens = NULL,\n  standardize = \"lower_and_strip_punctuation\",\n  split = \"whitespace\",\n  ngrams = NULL,\n  output_mode = \"int\",\n  output_sequence_length = NULL,\n  pad_to_max_tokens = FALSE,\n  vocabulary = NULL,\n  ...\n)\n\nget_vocabulary(object, include_special_tokens = TRUE)\n\nset_vocabulary(object, vocabulary, idf_weights = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nmax_tokens\nThe maximum size of the vocabulary for this layer. If NULL, there is no cap on the size of the vocabulary. Note that this vocabulary contains 1 OOV token, so the effective number of tokens is (max_tokens - 1 - (1 if output_mode == “int” else 0)).\n\n\nstandardize\nOptional specification for standardization to apply to the input text. Values can be NULL (no standardization), \"lower_and_strip_punctuation\" (lowercase and remove punctuation) or a Callable. Default is \"lower_and_strip_punctuation\".\n\n\nsplit\nOptional specification for splitting the input text. Values can be NULL (no splitting), \"whitespace\" (split on ASCII whitespace), or a Callable. The default is \"whitespace\".\n\n\nngrams\nOptional specification for ngrams to create from the possibly-split input text. Values can be NULL, an integer or list of integers; passing an integer will create ngrams up to that integer, and passing a list of integers will create ngrams for the specified values in the list. Passing NULL means that no ngrams will be created.\n\n\noutput_mode\nOptional specification for the output of the layer. Values can be \"int\", \"multi_hot\", \"count\" or \"tf_idf\", configuring the layer as follows: * \"int\": Outputs integer indices, one integer index per split string token. When output_mode == \"int\", 0 is reserved for masked locations; this reduces the vocab size to max_tokens - 2 instead of max_tokens - 1. * \"multi_hot\": Outputs a single int array per batch, of either vocab_size or max_tokens size, containing 1s in all elements where the token mapped to that index exists at least once in the batch item. * \"count\": Like \"multi_hot\", but the int array contains a count of the number of times the token at that index appeared in the batch item. * \"tf_idf\": Like \"multi_hot\", but the TF-IDF algorithm is applied to find the value in each token slot. For \"int\" output, any shape of input and output is supported. For all other output modes, currently only rank 1 inputs (and rank 2 outputs after splitting) are supported.\n\n\noutput_sequence_length\nOnly valid in INT mode. If set, the output will have its time dimension padded or truncated to exactly output_sequence_length values, resulting in a tensor of shape (batch_size, output_sequence_length) regardless of how many tokens resulted from the splitting step. Defaults to NULL.\n\n\npad_to_max_tokens\nOnly valid in \"multi_hot\", \"count\", and \"tf_idf\" modes. If TRUE, the output will have its feature axis padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape (batch_size, max_tokens) regardless of vocabulary size. Defaults to FALSE.\n\n\nvocabulary\nOptional for layer_text_vectorization(). Either an array of strings or a string path to a text file. If passing an array, can pass an R list or character vector, 1D numpy array, or 1D tensor containing the string vocabulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If vocabulary is set (either by passing layer_text_vectorization(vocabulary = ...) or by calling set_vocabulary(layer, vocabulary = …), there is no need to adapt() the layer.\n\n\n…\nstandard layer arguments.\n\n\ninclude_special_tokens\nIf True, the returned vocabulary will include the padding and OOV tokens, and a term’s index in the vocabulary will equal the term’s index when calling the layer. If False, the returned vocabulary will not include any padding or OOV tokens.\n\n\nidf_weights\nAn R vector, 1D numpy array, or 1D tensor of inverse document frequency weights with equal length to vocabulary. Must be set if output_mode is “tf_idf”. Should not be set otherwise.\n\n\n\n\n\n\nThis layer has basic options for managing text in a Keras model. It transforms a batch of strings (one example = one string) into either a list of token indices (one example = 1D tensor of integer token indices) or a dense representation (one example = 1D tensor of float values representing data about the example’s tokens).\nThe vocabulary for the layer must be either supplied on construction or learned via adapt(). When this layer is adapted, it will analyze the dataset, determine the frequency of individual string values, and create a vocabulary from them. This vocabulary can have unlimited size or be capped, depending on the configuration options for this layer; if there are more unique values in the input than the maximum vocabulary size, the most frequent terms will be used to create the vocabulary.\nThe processing of each example contains the following steps:\n\nStandardize each example (usually lowercasing + punctuation stripping)\nSplit each example into substrings (usually words)\nRecombine substrings into tokens (usually ngrams)\nIndex tokens (associate a unique int value with each token)\nTransform each example using this index, either into a vector of ints or a dense float vector.\n\nSome notes on passing callables to customize splitting and normalization for this layer:\n\nAny callable can be passed to this Layer, but if you want to serialize this object you should only pass functions that are registered Keras serializables (see https://www.tensorflow.org/api_docs/python/tf/keras/utils/register_keras_serializablelist(“tf\\(keras\\)utils$register_keras_serializable”) for more details).\nWhen using a custom callable for standardize, the data received by the callable will be exactly as passed to this layer. The callable should return a tensor of the same shape as the input.\nWhen using a custom callable for split, the data received by the callable will have the 1st dimension squeezed out - instead of matrix(c(\"string to split\", \"another string to split\")), the Callable will see c(\"string to split\", \"another string to split\"). The callable should return a Tensor with the first dimension containing the split tokens - in this example, we should see something like list(c(\"string\", \"to\", \"split\"), c(\"another\", \"string\", \"to\", \"split\")). This makes the callable site natively compatible with tf$strings$split().\n\n\n\n\n\nadapt()\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\nhttps://keras.io/api/layers/preprocessing_layers/text/text_vectorization\n\nOther preprocessing layers: layer_category_encoding(), layer_center_crop(), layer_discretization(), layer_hashing(), layer_integer_lookup(), layer_normalization(), layer_random_brightness(), layer_random_contrast(), layer_random_crop(), layer_random_flip(), layer_random_height(), layer_random_rotation(), layer_random_translation(), layer_random_width(), layer_random_zoom(), layer_rescaling(), layer_resizing(), layer_string_lookup()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_unit_normalization.html",
    "href": "packages/keras/latest/reference/layer_unit_normalization.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Unit normalization layer\n\n\nUnit normalization layer\n\n\n\nlayer_unit_normalization(object, axis = -1L, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\naxis\nInteger or list. The axis or axes to normalize across. Typically this is the features axis or axes. The left-out axes are typically the batch axis or axes. Defaults to -1, the last dimension in the input.\n\n\n…\nstandard layer arguments. html\n\n\n\n\n\n\nNormalize a batch of inputs so that each input in the batch has a L2 norm equal to 1 (across the axes specified in axis).\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/UnitNormalization"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_upsampling_1d.html",
    "href": "packages/keras/latest/reference/layer_upsampling_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Upsampling layer for 1D inputs.\n\n\nRepeats each temporal step size times along the time axis.\n\n\n\nlayer_upsampling_1d(\n  object,\n  size = 2L,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nsize\ninteger. Upsampling factor.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_upsampling_2d.html",
    "href": "packages/keras/latest/reference/layer_upsampling_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Upsampling layer for 2D inputs.\n\n\nRepeats the rows and columns of the data by size[[0]] and size[[1]] respectively.\n\n\n\nlayer_upsampling_2d(\n  object,\n  size = c(2L, 2L),\n  data_format = NULL,\n  interpolation = \"nearest\",\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nsize\nint, or list of 2 integers. The upsampling factors for rows and columns.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\ninterpolation\nA string, one of nearest or bilinear. Note that CNTK does not support yet the bilinear upscaling and that with Theano, only size=(2, 2) is possible.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_upsampling_3d.html",
    "href": "packages/keras/latest/reference/layer_upsampling_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Upsampling layer for 3D inputs.\n\n\nRepeats the 1st, 2nd and 3rd dimensions of the data by size[[0]], size[[1]] and size[[2]] respectively.\n\n\n\nlayer_upsampling_3d(\n  object,\n  size = c(2L, 2L, 2L),\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nsize\nint, or list of 3 integers. The upsampling factors for dim1, dim2 and dim3.\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_zero_padding_1d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_zero_padding_1d.html",
    "href": "packages/keras/latest/reference/layer_zero_padding_1d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Zero-padding layer for 1D input (e.g. temporal sequence).\n\n\nZero-padding layer for 1D input (e.g. temporal sequence).\n\n\n\nlayer_zero_padding_1d(\n  object,\n  padding = 1L,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npadding\nint, or list of int (length 2) * If int: How many zeros to add at the beginning and end of the padding dimension (axis 1). * If list of int (length 2): How many zeros to add at the beginning and at the end of the padding dimension ((left_pad, right_pad)).\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_2d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_zero_padding_2d.html",
    "href": "packages/keras/latest/reference/layer_zero_padding_2d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Zero-padding layer for 2D input (e.g. picture).\n\n\nThis layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor.\n\n\n\nlayer_zero_padding_2d(\n  object,\n  padding = c(1L, 1L),\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npadding\nint, or list of 2 ints, or list of 2 lists of 2 ints. * If int: the same symmetric padding is applied to width and height. * If list of 2 ints: interpreted as two different symmetric padding values for height and width: (symmetric_height_pad, symmetric_width_pad). * If list of 2 lists of 2 ints: interpreted as ((top_pad, bottom_pad), (left_pad, right_pad))\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_3d()"
  },
  {
    "objectID": "packages/keras/latest/reference/layer_zero_padding_3d.html",
    "href": "packages/keras/latest/reference/layer_zero_padding_3d.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Zero-padding layer for 3D data (spatial or spatio-temporal).\n\n\nZero-padding layer for 3D data (spatial or spatio-temporal).\n\n\n\nlayer_zero_padding_3d(\n  object,\n  padding = c(1L, 1L, 1L),\n  data_format = NULL,\n  batch_size = NULL,\n  name = NULL,\n  trainable = NULL,\n  weights = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\npadding\nint, or list of 3 ints, or list of 3 lists of 2 ints. * If int: the same symmetric padding is applied to width and height. * If list of 3 ints: interpreted as three different symmetric padding values: (symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad). * If list of 3 lists of 2 ints: interpreted as ((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad))\n\n\ndata_format\nA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while channels_first corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be “channels_last”.\n\n\nbatch_size\nFixed batch size for layer\n\n\nname\nAn optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn’t provided.\n\n\ntrainable\nWhether the layer weights will be updated during training.\n\n\nweights\nInitial weights for layer.\n\n\n\n\n\n\nOther convolutional layers: layer_conv_1d_transpose(), layer_conv_1d(), layer_conv_2d_transpose(), layer_conv_2d(), layer_conv_3d_transpose(), layer_conv_3d(), layer_conv_lstm_2d(), layer_cropping_1d(), layer_cropping_2d(), layer_cropping_3d(), layer_depthwise_conv_1d(), layer_depthwise_conv_2d(), layer_separable_conv_1d(), layer_separable_conv_2d(), layer_upsampling_1d(), layer_upsampling_2d(), layer_upsampling_3d(), layer_zero_padding_1d(), layer_zero_padding_2d()"
  },
  {
    "objectID": "packages/keras/latest/reference/learning_rate_schedule_cosine_decay.html",
    "href": "packages/keras/latest/reference/learning_rate_schedule_cosine_decay.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A LearningRateSchedule that uses a cosine decay schedule\n\n\nA LearningRateSchedule that uses a cosine decay schedule\n\n\n\nlearning_rate_schedule_cosine_decay(\n  initial_learning_rate,\n  decay_steps,\n  alpha = 0,\n  ...,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninitial_learning_rate\nA scalar float32 or float64 Tensor or a R number. The initial learning rate.\n\n\ndecay_steps\nA scalar int32 or int64 Tensor or an R number. Number of steps to decay over.\n\n\nalpha\nA scalar float32 or float64 Tensor or an R number. Minimum learning rate value as a fraction of initial_learning_rate.\n\n\n…\nFor backwards and forwards compatibility\n\n\nname\nString. Optional name of the operation. Defaults to ‘CosineDecay’.\n\n\n\n\n\n\nSee https://arxiv.org/abs/1608.03983Loshchilov & Hutter, ICLR2016, SGDR: Stochastic Gradient Descent with Warm Restarts.\nWhen training a model, it is often useful to lower the learning rate as the training progresses. This schedule applies a cosine decay function to an optimizer step, given a provided initial learning rate. It requires a step value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.\nThe schedule is a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:\nhtml\n\ndecayed_learning_rate <- function(step) { step <- min(step, decay_steps) cosine_decay = <- 0.5 * (1 + cos(pi * step / decay_steps)) decayed <- (1 - alpha) * cosine_decay + alpha initial_learning_rate * decayed } html\n\nExample usage:\nhtml\n\ndecay_steps <- 1000 lr_decayed_fn <- learning_rate_schedule_cosine_decay(initial_learning_rate, decay_steps) html\n\nYou can pass this schedule directly into a keras Optimizer as the learning_rate.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay"
  },
  {
    "objectID": "packages/keras/latest/reference/learning_rate_schedule_cosine_decay_restarts.html",
    "href": "packages/keras/latest/reference/learning_rate_schedule_cosine_decay_restarts.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A LearningRateSchedule that uses a cosine decay schedule with restarts\n\n\nA LearningRateSchedule that uses a cosine decay schedule with restarts\n\n\n\nlearning_rate_schedule_cosine_decay_restarts(\n  initial_learning_rate,\n  first_decay_steps,\n  t_mul = 2,\n  m_mul = 1,\n  alpha = 0,\n  ...,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninitial_learning_rate\nA scalar float32 or float64 Tensor or an R number. The initial learning rate.\n\n\nfirst_decay_steps\nA scalar int32 or int64 Tensor or an R number. Number of steps to decay over.\n\n\nt_mul\nA scalar float32 or float64 Tensor or an R number. Used to derive the number of iterations in the i-th period.\n\n\nm_mul\nA scalar float32 or float64 Tensor or an R number. Used to derive the initial learning rate of the i-th period.\n\n\nalpha\nA scalar float32 or float64 Tensor or an R number. Minimum learning rate value as a fraction of the initial_learning_rate.\n\n\n…\nFor backwards and forwards compatibility\n\n\nname\nString. Optional name of the operation. Defaults to ‘SGDRDecay’.\n\n\n\n\n\n\nSee https://arxiv.org/abs/1608.03983Loshchilov & Hutter, ICLR2016, SGDR: Stochastic Gradient Descent with Warm Restarts.\nWhen training a model, it is often useful to lower the learning rate as the training progresses. This schedule applies a cosine decay function with restarts to an optimizer step, given a provided initial learning rate. It requires a step value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.\nThe schedule is a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.\nThe learning rate multiplier first decays from 1 to alpha for first_decay_steps steps. Then, a warm restart is performed. Each new warm restart runs for t_mul times more steps and with m_mul times initial learning rate as the new learning rate.\nYou can pass this schedule directly into a keras Optimizer as the learning_rate.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecayRestarts"
  },
  {
    "objectID": "packages/keras/latest/reference/learning_rate_schedule_exponential_decay.html",
    "href": "packages/keras/latest/reference/learning_rate_schedule_exponential_decay.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A LearningRateSchedule that uses an exponential decay schedule\n\n\nA LearningRateSchedule that uses an exponential decay schedule\n\n\n\nlearning_rate_schedule_exponential_decay(\n  initial_learning_rate,\n  decay_steps,\n  decay_rate,\n  staircase = FALSE,\n  ...,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninitial_learning_rate\nA scalar float32 or float64 Tensor or a R number. The initial learning rate.\n\n\ndecay_steps\nA scalar int32 or int64 Tensor or an R number. Must be positive. See the decay computation above.\n\n\ndecay_rate\nA scalar float32 or float64 Tensor or an R number. The decay rate.\n\n\nstaircase\nBoolean. If TRUE decay the learning rate at discrete intervals.\n\n\n…\nFor backwards and forwards compatibility\n\n\nname\nString. Optional name of the operation. Defaults to ‘ExponentialDecay’.\n\n\n\n\n\n\nWhen training a model, it is often useful to lower the learning rate as the training progresses. This schedule applies an exponential decay function to an optimizer step, given a provided initial learning rate.\nThe schedule is a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:\nhtml\n\ndecayed_learning_rate <- function(step) initial_learning_rate * decay_rate ^ (step / decay_steps) html\n\nIf the argument staircase is TRUE, then step / decay_steps is an integer division (%/%) and the decayed learning rate follows a staircase function.\nYou can pass this schedule directly into a optimizer as the learning rate (see example) Example: When fitting a Keras model, decay every 100000 steps with a base of 0.96:\nhtml\n\ninitial_learning_rate <- 0.1 lr_schedule <- learning_rate_schedule_exponential_decay( initial_learning_rate, decay_steps = 100000, decay_rate = 0.96, staircase = TRUE)\nmodel %>% compile( optimizer= optimizer_sgd(learning_rate = lr_schedule), loss = ‘sparse_categorical_crossentropy’, metrics = ‘accuracy’)\nmodel %>% fit(data, labels, epochs = 5) html\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay"
  },
  {
    "objectID": "packages/keras/latest/reference/learning_rate_schedule_inverse_time_decay.html",
    "href": "packages/keras/latest/reference/learning_rate_schedule_inverse_time_decay.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A LearningRateSchedule that uses an inverse time decay schedule\n\n\nA LearningRateSchedule that uses an inverse time decay schedule\n\n\n\nlearning_rate_schedule_inverse_time_decay(\n  initial_learning_rate,\n  decay_steps,\n  decay_rate,\n  staircase = FALSE,\n  ...,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninitial_learning_rate\nA scalar float32 or float64 Tensor or an R number. The initial learning rate.\n\n\ndecay_steps\nA scalar int32 or int64 Tensor or an R number. How often to apply decay.\n\n\ndecay_rate\nAn R number. The decay rate.\n\n\nstaircase\nBoolean. Whether to apply decay in a discrete staircase, as opposed to continuous, fashion.\n\n\n…\nFor backwards and forwards compatibility\n\n\nname\nString. Optional name of the operation. Defaults to ‘InverseTimeDecay’.\n\n\n\n\n\n\nWhen training a model, it is often useful to lower the learning rate as the training progresses. This schedule applies the inverse decay function to an optimizer step, given a provided initial learning rate. It requires a step value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.\nThe schedule is a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:\nhtml\n\ndecayed_learning_rate <- function(step) { initial_learning_rate / (1 + decay_rate * step / decay_step) } html\n\nor, if staircase is TRUE, as:\nhtml\n\ndecayed_learning_rate function(step) { initial_learning_rate / (1 + decay_rate * floor(step / decay_step)) } html\n\nYou can pass this schedule directly into a keras Optimizer as the learning_rate.\nExample: Fit a Keras model when decaying 1/t with a rate of 0.5:\nhtml\n\n… initial_learning_rate <- 0.1 decay_steps <- 1.0 decay_rate <- 0.5 learning_rate_fn <- learning_rate_schedule_inverse_time_decay( initial_learning_rate, decay_steps, decay_rate)\nmodel %>% compile(optimizer = optimizer_sgd(learning_rate = learning_rate_fn), loss = ‘sparse_categorical_crossentropy’, metrics = ‘accuracy’)\nmodel %>% fit(data, labels, epochs = 5) html\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay"
  },
  {
    "objectID": "packages/keras/latest/reference/learning_rate_schedule_piecewise_constant_decay.html",
    "href": "packages/keras/latest/reference/learning_rate_schedule_piecewise_constant_decay.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A LearningRateSchedule that uses a piecewise constant decay schedule\n\n\nA LearningRateSchedule that uses a piecewise constant decay schedule\n\n\n\nlearning_rate_schedule_piecewise_constant_decay(\n  boundaries,\n  values,\n  ...,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nboundaries\nA list of Tensors or R numerics with strictly increasing entries, and with all elements having the same type as the optimizer step.\n\n\nvalues\nA list of Tensors or R numerics that specifies the values for the intervals defined by boundaries. It should have one more element than boundaries, and all elements should have the same type.\n\n\n…\nFor backwards and forwards compatibility\n\n\nname\nA string. Optional name of the operation. Defaults to ‘PiecewiseConstant’.\n\n\n\n\n\n\nThe function returns a 1-arg callable to compute the piecewise constant when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions.\nExample: use a learning rate that’s 1.0 for the first 100001 steps, 0.5 for the next 10000 steps, and 0.1 for any additional steps.\nhtml\n\nstep <- tf$Variable(0, trainable=FALSE) boundaries <- as.integer(c(100000, 110000)) values <- c(1.0, 0.5, 0.1) learning_rate_fn <- learning_rate_schedule_piecewise_constant_decay( boundaries, values)\n\n\nlearning_rate <- learning_rate_fn(step) html\n\n\nYou can pass this schedule directly into a keras Optimizer as the learning_rate.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay"
  },
  {
    "objectID": "packages/keras/latest/reference/learning_rate_schedule_polynomial_decay.html",
    "href": "packages/keras/latest/reference/learning_rate_schedule_polynomial_decay.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A LearningRateSchedule that uses a polynomial decay schedule\n\n\nA LearningRateSchedule that uses a polynomial decay schedule\n\n\n\nlearning_rate_schedule_polynomial_decay(\n  initial_learning_rate,\n  decay_steps,\n  end_learning_rate = 1e-04,\n  power = 1,\n  cycle = FALSE,\n  ...,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninitial_learning_rate\nA scalar float32 or float64 Tensor or an R number. The initial learning rate.\n\n\ndecay_steps\nA scalar int32 or int64 Tensor or an R number. Must be positive. See the decay computation above.\n\n\nend_learning_rate\nA scalar float32 or float64 Tensor or an R number. The minimal end learning rate.\n\n\npower\nA scalar float32 or float64 Tensor or an R number. The power of the polynomial. Defaults to linear, 1.0.\n\n\ncycle\nA boolean, whether or not it should cycle beyond decay_steps.\n\n\n…\nFor backwards and forwards compatibility\n\n\nname\nString. Optional name of the operation. Defaults to ‘PolynomialDecay’.\n\n\n\n\n\n\nIt is commonly observed that a monotonically decreasing learning rate, whose degree of change is carefully chosen, results in a better performing model. This schedule applies a polynomial decay function to an optimizer step, given a provided initial_learning_rate, to reach an end_learning_rate in the given decay_steps.\nIt requires a step value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.\nThe schedule is a 1-arg callable that produces a decayed learning rate when passed the current optimizer step. This can be useful for changing the learning rate value across different invocations of optimizer functions. It is computed as:\nhtml\n\ndecayed_learning_rate <- function(step) { step <- min(step, decay_steps) ((initial_learning_rate - end_learning_rate) * (1 - step / decay_steps) ^ (power) ) + end_learning_rate } html\n\nIf cycle is TRUE then a multiple of decay_steps is used, the first one that is bigger than step.\nhtml\n\ndecayed_learning_rate <- function(step) { decay_steps <- decay_steps * ceiling(step / decay_steps) ((initial_learning_rate - end_learning_rate) * (1 - step / decay_steps) ^ (power) ) + end_learning_rate } html\n\nYou can pass this schedule directly into a keras Optimizer as the learning_rate.\nExample: Fit a model while decaying from 0.1 to 0.01 in 10000 steps using sqrt (i.e. power=0.5):\nhtml\n\n… starter_learning_rate <- 0.1 end_learning_rate <- 0.01 decay_steps <- 10000 learning_rate_fn <- learning_rate_schedule_polynomial_decay( starter_learning_rate, decay_steps, end_learning_rate, power = 0.5)\nmodel %>% compile(optimizer = optimizer_sgd(learning_rate = learning_rate_fn), loss = ‘sparse_categorical_crossentropy’, metrics = ‘accuracy’)\nmodel %>% fit(data, labels, epochs = 5) html\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay"
  },
  {
    "objectID": "packages/keras/latest/reference/loss-functions.html",
    "href": "packages/keras/latest/reference/loss-functions.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Loss functions\n\n\nLoss functions\n\n\n\nloss_binary_crossentropy(\n  y_true,\n  y_pred,\n  from_logits = FALSE,\n  label_smoothing = 0,\n  axis = -1L,\n  ...,\n  reduction = \"auto\",\n  name = \"binary_crossentropy\"\n)\n\nloss_categorical_crossentropy(\n  y_true,\n  y_pred,\n  from_logits = FALSE,\n  label_smoothing = 0L,\n  axis = -1L,\n  ...,\n  reduction = \"auto\",\n  name = \"categorical_crossentropy\"\n)\n\nloss_categorical_hinge(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"categorical_hinge\"\n)\n\nloss_cosine_similarity(\n  y_true,\n  y_pred,\n  axis = -1L,\n  ...,\n  reduction = \"auto\",\n  name = \"cosine_similarity\"\n)\n\nloss_hinge(y_true, y_pred, ..., reduction = \"auto\", name = \"hinge\")\n\nloss_huber(\n  y_true,\n  y_pred,\n  delta = 1,\n  ...,\n  reduction = \"auto\",\n  name = \"huber_loss\"\n)\n\nloss_kullback_leibler_divergence(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"kl_divergence\"\n)\n\nloss_kl_divergence(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"kl_divergence\"\n)\n\nloss_logcosh(y_true, y_pred, ..., reduction = \"auto\", name = \"log_cosh\")\n\nloss_mean_absolute_error(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"mean_absolute_error\"\n)\n\nloss_mean_absolute_percentage_error(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"mean_absolute_percentage_error\"\n)\n\nloss_mean_squared_error(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"mean_squared_error\"\n)\n\nloss_mean_squared_logarithmic_error(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"mean_squared_logarithmic_error\"\n)\n\nloss_poisson(y_true, y_pred, ..., reduction = \"auto\", name = \"poisson\")\n\nloss_sparse_categorical_crossentropy(\n  y_true,\n  y_pred,\n  from_logits = FALSE,\n  axis = -1L,\n  ...,\n  reduction = \"auto\",\n  name = \"sparse_categorical_crossentropy\"\n)\n\nloss_squared_hinge(\n  y_true,\n  y_pred,\n  ...,\n  reduction = \"auto\",\n  name = \"squared_hinge\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nGround truth values. shape = [batch_size, d1, .. dN].\n\n\ny_pred\nThe predicted values. shape = [batch_size, d1, .. dN]. (Tensor of the same shape as y_true)\n\n\nfrom_logits\nWhether y_pred is expected to be a logits tensor. By default we assume that y_pred encodes a probability distribution.\n\n\nlabel_smoothing\nFloat in [0, 1]. If > 0 then smooth the labels. For example, if 0.1, use 0.1 / num_classes for non-target labels and 0.9 + 0.1 / num_classes for target labels.\n\n\naxis\nThe axis along which to compute crossentropy (the features axis). Axis is 1-based (e.g, first axis is axis=1). Defaults to -1 (the last axis).\n\n\n…\nAdditional arguments passed on to the Python callable (for forward and backwards compatibility).\n\n\nreduction\nOnly applicable if y_true and y_pred are missing. Type of keras$losses$Reduction to apply to loss. Default value is AUTO. AUTO indicates that the reduction option will be determined by the usage context. For almost all cases this defaults to SUM_OVER_BATCH_SIZE. When used with tf$distribute$Strategy, outside of built-in training loops such as compile and fit, using AUTO or SUM_OVER_BATCH_SIZE will raise an error. Please see this custom training https://www.tensorflow.org/tutorials/distribute/custom_trainingtutorial for more details.\n\n\nname\nOnly applicable if y_true and y_pred are missing. Optional name for the Loss instance.\n\n\ndelta\nA float, the point where the Huber loss function changes from a quadratic to linear.\n\n\n\n\n\n\nLoss functions for model training. These are typically supplied in the loss parameter of the compile.keras.engine.training.Model() function.\n\n\n\nIf called with y_true and y_pred, then the corresponding loss is evaluated and the result returned (as a tensor). Alternatively, if y_true and y_pred are missing, then a callable is returned that will compute the loss function and, by default, reduce the loss to a scalar tensor; see the reduction parameter for details. (The callable is a typically a class instance that inherits from keras$losses$Loss).\n\n\n\ncompile.keras.engine.training.Model(), loss_binary_crossentropy()"
  },
  {
    "objectID": "packages/keras/latest/reference/loss_cosine_proximity.html",
    "href": "packages/keras/latest/reference/loss_cosine_proximity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) loss_cosine_proximity\n\n\nloss_cosine_proximity is deprecated and will be removed in a future version. It has been renamed to loss_cosine_similarity().\n\n\n\nloss_cosine_proximity(...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\npassed on to loss_cosine_similarity()"
  },
  {
    "objectID": "packages/keras/latest/reference/make_sampling_table.html",
    "href": "packages/keras/latest/reference/make_sampling_table.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Generates a word rank-based probabilistic sampling table.\n\n\nGenerates a word rank-based probabilistic sampling table.\n\n\n\nmake_sampling_table(size, sampling_factor = 1e-05)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsize\nInt, number of possible words to sample.\n\n\nsampling_factor\nThe sampling factor in the word2vec formula.\n\n\n\n\n\n\nUsed for generating the sampling_table argument for skipgrams(). sampling_table[[i]] is the probability of sampling the word i-th most common word in a dataset (more common words should be sampled less frequently, for balance).\nThe sampling probabilities are generated according to the sampling distribution used in word2vec:\np(word) = min(1, sqrt(word_frequency / sampling_factor) / (word_frequency / sampling_factor))\nWe assume that the word frequencies follow Zipf’s law (s=1) to derive a numerical approximation of frequency(rank):\nfrequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))\nwhere gamma is the Euler-Mascheroni constant.\n\n\n\nAn array of length size where the ith entry is the probability that a word of rank i should be sampled.\n\n\n\nOther text preprocessing: pad_sequences(), skipgrams(), text_hashing_trick(), text_one_hot(), text_to_word_sequence()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric-or-metric.html",
    "href": "packages/keras/latest/reference/metric-or-metric.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "metric-or-Metric\n\n\nmetric-or-Metric\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\naxis\n(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly."
  },
  {
    "objectID": "packages/keras/latest/reference/metric.html",
    "href": "packages/keras/latest/reference/metric.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Metric\n\n\nA Metric object encapsulates metric logic and state that can be used to track model performance during training. It is what is returned by the family of metric functions that start with prefix metric_*.\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage."
  },
  {
    "objectID": "packages/keras/latest/reference/metric_accuracy.html",
    "href": "packages/keras/latest/reference/metric_accuracy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates how often predictions equal labels\n\n\nCalculates how often predictions equal labels\n\n\n\nmetric_accuracy(..., name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThis metric creates two local variables, total and count that are used to compute the frequency with which y_pred matches y_true. This frequency is ultimately returned as binary accuracy: an idempotent operation that simply divides total by count.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_auc.html",
    "href": "packages/keras/latest/reference/metric_auc.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Approximates the AUC (Area under the curve) of the ROC or PR curves\n\n\nApproximates the AUC (Area under the curve) of the ROC or PR curves\n\n\n\nmetric_auc(\n  ...,\n  num_thresholds = 200L,\n  curve = \"ROC\",\n  summation_method = \"interpolation\",\n  thresholds = NULL,\n  multi_label = FALSE,\n  num_labels = NULL,\n  label_weights = NULL,\n  from_logits = FALSE,\n  name = NULL,\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nnum_thresholds\n(Optional) Defaults to 200. The number of thresholds toa use when discretizing the roc curve. Values must be > 1.\n\n\ncurve\n(Optional) Specifies the name of the curve to be computed, ‘ROC’ (default) or ‘PR’ for the Precision-Recall-curve.\n\n\nsummation_method\n(Optional) Specifies the https://en.wikipedia.org/wiki/Riemann_sumRiemann summation method used. ‘interpolation’ (default) applies mid-point summation scheme for ROC. For PR-AUC, interpolates (true/false) positives but not the ratio that is precision (see Davis & Goadrich 2006 for details); ‘minoring’ applies left summation for increasing intervals and right summation for decreasing intervals; ‘majoring’ does the opposite.\n\n\nthresholds\n(Optional) A list of floating point values to use as the thresholds for discretizing the curve. If set, the num_thresholds parameter is ignored. Values should be in [0, 1]. Endpoint thresholds equal to -epsilon, 1+epsilon for a small positive epsilon value will be automatically included with these to correctly handle predictions equal to exactly 0 or 1.\n\n\nmulti_label\nboolean indicating whether multilabel data should be treated as such, wherein AUC is computed separately for each label and then averaged across labels, or (when FALSE) if the data should be flattened into a single label before AUC computation. In the latter case, when multilabel data is passed to AUC, each label-prediction pair is treated as an individual data point. Should be set to FALSE for multi-class data.\n\n\nnum_labels\n(Optional) The number of labels, used when multi_label is TRUE. If num_labels is not specified, then state variables get created on the first call to update_state.\n\n\nlabel_weights\n(Optional) list, array, or tensor of non-negative weights used to compute AUCs for multilabel data. When multi_label is TRUE, the weights are applied to the individual label AUCs when they are averaged to produce the multi-label AUC. When it’s FALSE, they are used to weight the individual label predictions in computing the confusion matrix on the flattened data. Note that this is unlike class_weights in that class_weights weights the example depending on the value of its label, whereas label_weights depends only on the index of that label before flattening; therefore label_weights should not be used for multi-class data.\n\n\nfrom_logits\nboolean indicating whether the predictions (y_pred in update_state) are probabilities or sigmoid logits. As a rule of thumb, when using a keras loss, the from_logits constructor argument of the loss should match the AUC from_logits constructor argument.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThe AUC (Area under the curve) of the ROC (Receiver operating characteristic; default) or PR (Precision Recall) curves are quality measures of binary classifiers. Unlike the accuracy, and like cross-entropy losses, ROC-AUC and PR-AUC evaluate all the operational points of a model.\nThis class approximates AUCs using a Riemann sum. During the metric accumulation phrase, predictions are accumulated within predefined buckets by value. The AUC is then computed by interpolating per-bucket averages. These buckets define the evaluated operational points.\nThis metric creates four local variables, true_positives, true_negatives, false_positives and false_negatives that are used to compute the AUC. To discretize the AUC curve, a linearly spaced set of thresholds is used to compute pairs of recall and precision values. The area under the ROC-curve is therefore computed using the height of the recall values by the false positive rate, while the area under the PR-curve is the computed using the height of the precision values by the recall.\nThis value is ultimately returned as auc, an idempotent operation that computes the area under a discretized curve of precision versus recall values (computed using the aforementioned variables). The num_thresholds variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on num_thresholds. The thresholds parameter can be used to manually specify thresholds which split the predictions more evenly.\nFor a best approximation of the real AUC, predictions should be distributed approximately uniformly in the range [0, 1] (if from_logits=FALSE). The quality of the AUC approximation may be poor if this is not the case. Setting summation_method to ‘minoring’ or ‘majoring’ can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_binary_accuracy.html",
    "href": "packages/keras/latest/reference/metric_binary_accuracy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates how often predictions match binary labels\n\n\nCalculates how often predictions match binary labels\n\n\n\nmetric_binary_accuracy(\n  y_true,\n  y_pred,\n  threshold = 0.5,\n  ...,\n  name = \"binary_accuracy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\nthreshold\n(Optional) Float representing the threshold for deciding whether prediction values are 1 or 0.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThis metric creates two local variables, total and count that are used to compute the frequency with which y_pred matches y_true. This frequency is ultimately returned as binary accuracy: an idempotent operation that simply divides total by count.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_binary_crossentropy.html",
    "href": "packages/keras/latest/reference/metric_binary_crossentropy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the crossentropy metric between the labels and predictions\n\n\nComputes the crossentropy metric between the labels and predictions\n\n\n\nmetric_binary_crossentropy(\n  y_true,\n  y_pred,\n  from_logits = FALSE,\n  label_smoothing = 0,\n  axis = -1L,\n  ...,\n  name = \"binary_crossentropy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\nfrom_logits\n(Optional) Whether output is expected to be a logits tensor. By default, we consider that output encodes a probability distribution.\n\n\nlabel_smoothing\n(Optional) Float in [0, 1]. When > 0, label values are smoothed, meaning the confidence on label values are relaxed. e.g. label_smoothing = 0.2 means that we will use a value of 0.1 for label 0 and 0.9 for label 1“.\n\n\naxis\n(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThis is the crossentropy metric class to be used when there are only two label classes (0 and 1).\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_categorical_accuracy.html",
    "href": "packages/keras/latest/reference/metric_categorical_accuracy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates how often predictions match one-hot labels\n\n\nCalculates how often predictions match one-hot labels\n\n\n\nmetric_categorical_accuracy(\n  y_true,\n  y_pred,\n  ...,\n  name = \"categorical_accuracy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nYou can provide logits of classes as y_pred, since argmax of logits and probabilities are same.\nThis metric creates two local variables, total and count that are used to compute the frequency with which y_pred matches y_true. This frequency is ultimately returned as categorical accuracy: an idempotent operation that simply divides total by count.\ny_pred and y_true should be passed in as vectors of probabilities, rather than as labels. If necessary, use tf.one_hot to expand y_true as a vector.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_categorical_crossentropy.html",
    "href": "packages/keras/latest/reference/metric_categorical_crossentropy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the crossentropy metric between the labels and predictions\n\n\nComputes the crossentropy metric between the labels and predictions\n\n\n\nmetric_categorical_crossentropy(\n  y_true,\n  y_pred,\n  from_logits = FALSE,\n  label_smoothing = 0,\n  axis = -1L,\n  ...,\n  name = \"categorical_crossentropy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\nfrom_logits\n(Optional) Whether output is expected to be a logits tensor. By default, we consider that output encodes a probability distribution.\n\n\nlabel_smoothing\n(Optional) Float in [0, 1]. When > 0, label values are smoothed, meaning the confidence on label values are relaxed. e.g. label_smoothing=0.2 means that we will use a value of 0.1 for label 0 and 0.9 for label 1”\n\n\naxis\n(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThis is the crossentropy metric class to be used when there are multiple label classes (2 or more). Here we assume that labels are given as a one_hot representation. eg., When labels values are c(2, 0, 1):\nhtml\n\ny_true = rbind(c(0, 0, 1), c(1, 0, 0), c(0, 1, 0))` html\n\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_categorical_hinge.html",
    "href": "packages/keras/latest/reference/metric_categorical_hinge.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the categorical hinge metric between y_true and y_pred\n\n\nComputes the categorical hinge metric between y_true and y_pred\n\n\n\nmetric_categorical_hinge(..., name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_cosine_proximity.html",
    "href": "packages/keras/latest/reference/metric_cosine_proximity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) metric_cosine_proximity\n\n\nmetric_cosine_proximity() is deprecated and will be removed in a future version. Please update your code to use metric_cosine_similarity() if possible. If you need the actual function and not a Metric object, (e.g, because you are using the intermediate computed values in a custom training loop before reduction), please use loss_cosine_similarity() or tensorflow::tf$compat$v1$keras$metrics$cosine_proximity()\n\n\n\nmetric_cosine_proximity(y_true, y_pred)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets."
  },
  {
    "objectID": "packages/keras/latest/reference/metric_cosine_similarity.html",
    "href": "packages/keras/latest/reference/metric_cosine_similarity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the cosine similarity between the labels and predictions\n\n\nComputes the cosine similarity between the labels and predictions\n\n\n\nmetric_cosine_similarity(\n  ...,\n  axis = -1L,\n  name = \"cosine_similarity\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\naxis\n(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nhtml\n\ncosine similarity = (a . b) / ||a|| ||b|| html\n\nSee: https://en.wikipedia.org/wiki/Cosine_similarityCosine Similarity.\nThis metric keeps the average cosine similarity between predictions and labels over a stream of data.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_false_negatives.html",
    "href": "packages/keras/latest/reference/metric_false_negatives.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates the number of false negatives\n\n\nCalculates the number of false negatives\n\n\n\nmetric_false_negatives(..., thresholds = NULL, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nthresholds\n(Optional) Defaults to 0.5. A float value or a list of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is TRUE, below is FALSE). One metric value is generated for each threshold value.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf sample_weight is given, calculates the sum of the weights of false negatives. This metric creates one local variable, accumulator that is used to keep track of the number of false negatives.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_false_positives.html",
    "href": "packages/keras/latest/reference/metric_false_positives.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates the number of false positives\n\n\nCalculates the number of false positives\n\n\n\nmetric_false_positives(..., thresholds = NULL, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nthresholds\n(Optional) Defaults to 0.5. A float value or a list of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is true, below is false). One metric value is generated for each threshold value.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf sample_weight is given, calculates the sum of the weights of false positives. This metric creates one local variable, accumulator that is used to keep track of the number of false positives.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_hinge.html",
    "href": "packages/keras/latest/reference/metric_hinge.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the hinge metric between y_true and y_pred\n\n\ny_true values are expected to be -1 or 1. If binary (0 or 1) labels are provided we will convert them to -1 or 1.\n\n\n\nmetric_hinge(y_true, y_pred, ..., name = \"hinge\", dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nhtml\n\nloss = tf\\(reduce_mean(tf\\)maximum(1 - y_true * y_pred, 0L), axis=-1L) html\n\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_kullback_leibler_divergence.html",
    "href": "packages/keras/latest/reference/metric_kullback_leibler_divergence.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes Kullback-Leibler divergence\n\n\nComputes Kullback-Leibler divergence\n\n\n\nmetric_kullback_leibler_divergence(\n  y_true,\n  y_pred,\n  ...,\n  name = \"kullback_leibler_divergence\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nhtml\n\nmetric = y_true * log(y_true / y_pred) html\n\nSee: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_logcosh_error.html",
    "href": "packages/keras/latest/reference/metric_logcosh_error.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the logarithm of the hyperbolic cosine of the prediction error\n\n\nlogcosh = log((exp(x) + exp(-x))/2), where x is the error (y_pred - y_true)\n\n\n\nmetric_logcosh_error(..., name = \"logcosh\", dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean.html",
    "href": "packages/keras/latest/reference/metric_mean.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the (weighted) mean of the given values\n\n\nComputes the (weighted) mean of the given values\n\n\n\nmetric_mean(..., name = \"mean\", dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nFor example, if values is c(1, 3, 5, 7) then the mean is 4. If the weights were specified as c(1, 1, 0, 0) then the mean would be 2.\nThis metric creates two variables, total and count that are used to compute the average of values. This average is ultimately returned as mean which is an idempotent operation that simply divides total by count.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_absolute_error.html",
    "href": "packages/keras/latest/reference/metric_mean_absolute_error.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the mean absolute error between the labels and predictions\n\n\nComputes the mean absolute error between the labels and predictions\n\n\n\nmetric_mean_absolute_error(\n  y_true,\n  y_pred,\n  ...,\n  name = \"mean_absolute_error\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nloss = mean(abs(y_true - y_pred), axis=-1)\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_absolute_percentage_error.html",
    "href": "packages/keras/latest/reference/metric_mean_absolute_percentage_error.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the mean absolute percentage error between y_true and y_pred\n\n\nComputes the mean absolute percentage error between y_true and y_pred\n\n\n\nmetric_mean_absolute_percentage_error(\n  y_true,\n  y_pred,\n  ...,\n  name = \"mean_absolute_percentage_error\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nloss = 100 * mean(abs((y_true - y_pred) / y_true), axis=-1)\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_iou.html",
    "href": "packages/keras/latest/reference/metric_mean_iou.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the mean Intersection-Over-Union metric\n\n\nComputes the mean Intersection-Over-Union metric\n\n\n\nmetric_mean_iou(..., num_classes, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nnum_classes\nThe possible number of labels the prediction task can have. This value must be provided, since a confusion matrix of dim c(num_classes, num_classes) will be allocated.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nMean Intersection-Over-Union is a common evaluation metric for semantic image segmentation, which first computes the IOU for each semantic class and then computes the average over classes. IOU is defined as follows:\nhtml\n\nIOU = true_positive / (true_positive + false_positive + false_negative) html\n\nThe predictions are accumulated in a confusion matrix, weighted by sample_weight and the metric is then calculated from it.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_relative_error.html",
    "href": "packages/keras/latest/reference/metric_mean_relative_error.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the mean relative error by normalizing with the given values\n\n\nComputes the mean relative error by normalizing with the given values\n\n\n\nmetric_mean_relative_error(..., normalizer, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nnormalizer\nThe normalizer values with same shape as predictions.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThis metric creates two local variables, total and count that are used to compute the mean relative error. This is weighted by sample_weight, and it is ultimately returned as mean_relative_error: an idempotent operation that simply divides total by count.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\nhtml\n\nmetric = mean(|y_pred - y_true| / normalizer) html\n\nFor example:\nhtml\n\nm = metric_mean_relative_error(normalizer=c(1, 3, 2, 3)) m\\(update_state(c(1, 3, 2, 3), c(2, 4, 6, 8))  # result = mean(c(1, 1, 4, 5) / c(1, 3, 2, 3)) = mean(c(1, 1/3, 2, 5/3))  # = 5/4 = 1.25 m\\)result() html\n\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_squared_error.html",
    "href": "packages/keras/latest/reference/metric_mean_squared_error.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the mean squared error between labels and predictions\n\n\nComputes the mean squared error between labels and predictions\n\n\n\nmetric_mean_squared_error(\n  y_true,\n  y_pred,\n  ...,\n  name = \"mean_absolute_percentage_error\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nAfter computing the squared distance between the inputs, the mean value over the last dimension is returned.\nloss = mean(square(y_true - y_pred), axis=-1)\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_squared_logarithmic_error.html",
    "href": "packages/keras/latest/reference/metric_mean_squared_logarithmic_error.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the mean squared logarithmic error\n\n\nComputes the mean squared logarithmic error\n\n\n\nmetric_mean_squared_logarithmic_error(\n  y_true,\n  y_pred,\n  ...,\n  name = \"mean_squared_logarithmic_error\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nloss = mean(square(log(y_true + 1) - log(y_pred + 1)), axis=-1)\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_tensor.html",
    "href": "packages/keras/latest/reference/metric_mean_tensor.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the element-wise (weighted) mean of the given tensors\n\n\nComputes the element-wise (weighted) mean of the given tensors\n\n\n\nmetric_mean_tensor(..., shape = NULL, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nshape\n(Optional) A list of integers, a list of integers, or a 1-D Tensor of type int32. If not specified, the shape is inferred from the values at the first call of update_state.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nMeanTensor returns a tensor with the same shape of the input tensors. The mean value is updated by keeping local variables total and count. The total tracks the sum of the weighted values, and count stores the sum of the weighted counts.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_mean_wrapper.html",
    "href": "packages/keras/latest/reference/metric_mean_wrapper.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Wraps a stateless metric function with the Mean metric\n\n\nWraps a stateless metric function with the Mean metric\n\n\n\nmetric_mean_wrapper(..., fn, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nnamed arguments to pass on to fn.\n\n\nfn\nThe metric function to wrap, with signature fn(y_true, y_pred, ...).\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nYou could use this class to quickly build a mean metric from a function. The function needs to have the signature fn(y_true, y_pred) and return a per-sample loss array. MeanMetricWrapper$result() will return the average metric value across all samples seen so far.\nFor example:\nhtml\n\naccuracy <- function(y_true, y_pred) k_cast(y_true == y_pred, ‘float32’)\naccuracy_metric <- metric_mean_wrapper(fn = accuracy)\nmodel %>% compile(…, metrics=accuracy_metric) html\n\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_poisson.html",
    "href": "packages/keras/latest/reference/metric_poisson.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the Poisson metric between y_true and y_pred\n\n\nmetric = y_pred - y_true * log(y_pred)\n\n\n\nmetric_poisson(y_true, y_pred, ..., name = \"poisson\", dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_precision.html",
    "href": "packages/keras/latest/reference/metric_precision.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the precision of the predictions with respect to the labels\n\n\nComputes the precision of the predictions with respect to the labels\n\n\n\nmetric_precision(\n  ...,\n  thresholds = NULL,\n  top_k = NULL,\n  class_id = NULL,\n  name = NULL,\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nthresholds\n(Optional) A float value or a list of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is true, below is false). One metric value is generated for each threshold value. If neither thresholds nor top_k are set, the default is to calculate precision with thresholds=0.5.\n\n\ntop_k\n(Optional) Unset by default. An int value specifying the top-k predictions to consider when calculating precision.\n\n\nclass_id\n(Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval [0, num_classes), where num_classes is the last dimension of predictions.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThe metric creates two local variables, true_positives and false_positives that are used to compute the precision. This value is ultimately returned as precision, an idempotent operation that simply divides true_positives by the sum of true_positives and false_positives.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\nIf top_k is set, we’ll calculate precision as how often on average a class among the top-k classes with the highest predicted values of a batch entry is correct and can be found in the label for that entry.\nIf class_id is specified, we calculate precision by considering only the entries in the batch for which class_id is above the threshold and/or in the top-k highest predictions, and computing the fraction of them for which class_id is indeed a correct label.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_precision_at_recall.html",
    "href": "packages/keras/latest/reference/metric_precision_at_recall.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes best precision where recall is >= specified value\n\n\nComputes best precision where recall is >= specified value\n\n\n\nmetric_precision_at_recall(\n  ...,\n  recall,\n  num_thresholds = 200L,\n  class_id = NULL,\n  name = NULL,\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nrecall\nA scalar value in range [0, 1].\n\n\nnum_thresholds\n(Optional) Defaults to 200. The number of thresholds to use for matching the given recall.\n\n\nclass_id\n(Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval [0, num_classes), where num_classes is the last dimension of predictions.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThis metric creates four local variables, true_positives, true_negatives, false_positives and false_negatives that are used to compute the precision at the given recall. The threshold for the given recall value is computed and used to evaluate the corresponding precision.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\nIf class_id is specified, we calculate precision by considering only the entries in the batch for which class_id is above the threshold predictions, and computing the fraction of them for which class_id is indeed a correct label.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_recall.html",
    "href": "packages/keras/latest/reference/metric_recall.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the recall of the predictions with respect to the labels\n\n\nComputes the recall of the predictions with respect to the labels\n\n\n\nmetric_recall(\n  ...,\n  thresholds = NULL,\n  top_k = NULL,\n  class_id = NULL,\n  name = NULL,\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nthresholds\n(Optional) A float value or a list of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is true, below is false). One metric value is generated for each threshold value. If neither thresholds nor top_k are set, the default is to calculate recall with thresholds=0.5.\n\n\ntop_k\n(Optional) Unset by default. An int value specifying the top-k predictions to consider when calculating recall.\n\n\nclass_id\n(Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval [0, num_classes), where num_classes is the last dimension of predictions.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nThis metric creates two local variables, true_positives and false_negatives, that are used to compute the recall. This value is ultimately returned as recall, an idempotent operation that simply divides true_positives by the sum of true_positives and false_negatives.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\nIf top_k is set, recall will be computed as how often on average a class among the labels of a batch entry is in the top-k predictions.\nIf class_id is specified, we calculate recall by considering only the entries in the batch for which class_id is in the label, and computing the fraction of them for which class_id is above the threshold and/or in the top-k predictions.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_recall_at_precision.html",
    "href": "packages/keras/latest/reference/metric_recall_at_precision.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes best recall where precision is >= specified value\n\n\nComputes best recall where precision is >= specified value\n\n\n\nmetric_recall_at_precision(\n  ...,\n  precision,\n  num_thresholds = 200L,\n  class_id = NULL,\n  name = NULL,\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nprecision\nA scalar value in range [0, 1].\n\n\nnum_thresholds\n(Optional) Defaults to 200. The number of thresholds to use for matching the given precision.\n\n\nclass_id\n(Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval [0, num_classes), where num_classes is the last dimension of predictions.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nFor a given score-label-distribution the required precision might not be achievable, in this case 0.0 is returned as recall.\nThis metric creates four local variables, true_positives, true_negatives, false_positives and false_negatives that are used to compute the recall at the given precision. The threshold for the given precision value is computed and used to evaluate the corresponding recall.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\nIf class_id is specified, we calculate precision by considering only the entries in the batch for which class_id is above the threshold predictions, and computing the fraction of them for which class_id is indeed a correct label.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_root_mean_squared_error.html",
    "href": "packages/keras/latest/reference/metric_root_mean_squared_error.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes root mean squared error metric between y_true and y_pred\n\n\nComputes root mean squared error metric between y_true and y_pred\n\n\n\nmetric_root_mean_squared_error(..., name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_sensitivity_at_specificity.html",
    "href": "packages/keras/latest/reference/metric_sensitivity_at_specificity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes best sensitivity where specificity is >= specified value\n\n\nThe sensitivity at a given specificity.\n\n\n\nmetric_sensitivity_at_specificity(\n  ...,\n  specificity,\n  num_thresholds = 200L,\n  class_id = NULL,\n  name = NULL,\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nspecificity\nA scalar value in range [0, 1].\n\n\nnum_thresholds\n(Optional) Defaults to 200. The number of thresholds to use for matching the given specificity.\n\n\nclass_id\n(Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval [0, num_classes), where num_classes is the last dimension of predictions.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nSensitivity measures the proportion of actual positives that are correctly identified as such (tp / (tp + fn)). Specificity measures the proportion of actual negatives that are correctly identified as such (tn / (tn + fp)).\nThis metric creates four local variables, true_positives, true_negatives, false_positives and false_negatives that are used to compute the sensitivity at the given specificity. The threshold for the given specificity value is computed and used to evaluate the corresponding sensitivity.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\nIf class_id is specified, we calculate precision by considering only the entries in the batch for which class_id is above the threshold predictions, and computing the fraction of them for which class_id is indeed a correct label.\nFor additional information about specificity and sensitivity, see https://en.wikipedia.org/wiki/Sensitivity_and_specificitythe following.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_sparse_categorical_accuracy.html",
    "href": "packages/keras/latest/reference/metric_sparse_categorical_accuracy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates how often predictions match integer labels\n\n\nCalculates how often predictions match integer labels\n\n\n\nmetric_sparse_categorical_accuracy(\n  y_true,\n  y_pred,\n  ...,\n  name = \"sparse_categorical_accuracy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nhtml\n\nacc = k_dot(sample_weight, y_true == k_argmax(y_pred, axis=2)) html\n\nYou can provide logits of classes as y_pred, since argmax of logits and probabilities are same.\nThis metric creates two local variables, total and count that are used to compute the frequency with which y_pred matches y_true. This frequency is ultimately returned as sparse categorical accuracy: an idempotent operation that simply divides total by count.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_sparse_categorical_crossentropy.html",
    "href": "packages/keras/latest/reference/metric_sparse_categorical_crossentropy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the crossentropy metric between the labels and predictions\n\n\nComputes the crossentropy metric between the labels and predictions\n\n\n\nmetric_sparse_categorical_crossentropy(\n  y_true,\n  y_pred,\n  from_logits = FALSE,\n  axis = -1L,\n  ...,\n  name = \"sparse_categorical_crossentropy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\nfrom_logits\n(Optional) Whether output is expected to be a logits tensor. By default, we consider that output encodes a probability distribution.\n\n\naxis\n(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nUse this crossentropy metric when there are two or more label classes. We expect labels to be provided as integers. If you want to provide labels using one-hot representation, please use CategoricalCrossentropy metric. There should be # classes floating point values per feature for y_pred and a single floating point value per feature for y_true.\nIn the snippet below, there is a single floating point value per example for y_true and # classes floating pointing values per example for y_pred. The shape of y_true is [batch_size] and the shape of y_pred is [batch_size, num_classes].\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_sparse_top_k_categorical_accuracy.html",
    "href": "packages/keras/latest/reference/metric_sparse_top_k_categorical_accuracy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes how often integer targets are in the top K predictions\n\n\nComputes how often integer targets are in the top K predictions\n\n\n\nmetric_sparse_top_k_categorical_accuracy(\n  y_true,\n  y_pred,\n  k = 5L,\n  ...,\n  name = \"sparse_top_k_categorical_accuracy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\nk\n(Optional) Number of top elements to look at for computing accuracy. Defaults to 5.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_specificity_at_sensitivity.html",
    "href": "packages/keras/latest/reference/metric_specificity_at_sensitivity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes best specificity where sensitivity is >= specified value\n\n\nComputes best specificity where sensitivity is >= specified value\n\n\n\nmetric_specificity_at_sensitivity(\n  ...,\n  sensitivity,\n  num_thresholds = 200L,\n  class_id = NULL,\n  name = NULL,\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nsensitivity\nA scalar value in range [0, 1].\n\n\nnum_thresholds\n(Optional) Defaults to 200. The number of thresholds to use for matching the given sensitivity.\n\n\nclass_id\n(Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval [0, num_classes), where num_classes is the last dimension of predictions.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nSensitivity measures the proportion of actual positives that are correctly identified as such (tp / (tp + fn)). Specificity measures the proportion of actual negatives that are correctly identified as such (tn / (tn + fp)).\nThis metric creates four local variables, true_positives, true_negatives, false_positives and false_negatives that are used to compute the specificity at the given sensitivity. The threshold for the given sensitivity value is computed and used to evaluate the corresponding specificity.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\nIf class_id is specified, we calculate precision by considering only the entries in the batch for which class_id is above the threshold predictions, and computing the fraction of them for which class_id is indeed a correct label.\nFor additional information about specificity and sensitivity, see https://en.wikipedia.org/wiki/Sensitivity_and_specificitythe following.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_squared_hinge.html",
    "href": "packages/keras/latest/reference/metric_squared_hinge.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the squared hinge metric\n\n\ny_true values are expected to be -1 or 1. If binary (0 or 1) labels are provided we will convert them to -1 or 1.\n\n\n\nmetric_squared_hinge(y_true, y_pred, ..., name = \"squared_hinge\", dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_sum.html",
    "href": "packages/keras/latest/reference/metric_sum.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes the (weighted) sum of the given values\n\n\nComputes the (weighted) sum of the given values\n\n\n\nmetric_sum(..., name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nFor example, if values is c(1, 3, 5, 7) then the sum is 16. If the weights were specified as c(1, 1, 0, 0) then the sum would be 4.\nThis metric creates one variable, total, that is used to compute the sum of values. This is ultimately returned as sum.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_top_k_categorical_accuracy(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_top_k_categorical_accuracy.html",
    "href": "packages/keras/latest/reference/metric_top_k_categorical_accuracy.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Computes how often targets are in the top K predictions\n\n\nComputes how often targets are in the top K predictions\n\n\n\nmetric_top_k_categorical_accuracy(\n  y_true,\n  y_pred,\n  k = 5L,\n  ...,\n  name = \"top_k_categorical_accuracy\",\n  dtype = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny_true\nTensor of true targets.\n\n\ny_pred\nTensor of predicted targets.\n\n\nk\n(Optional) Number of top elements to look at for computing accuracy. Defaults to 5.\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf y_true and y_pred are missing, a (subclassed) Metric instance is returned. The Metric object can be passed directly to compile(metrics = ) or used as a standalone object. See ?Metric for example usage.\nAlternatively, if called with y_true and y_pred arguments, then the computed case-wise values for the mini-batch are returned directly.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_true_negatives(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_true_negatives.html",
    "href": "packages/keras/latest/reference/metric_true_negatives.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates the number of true negatives\n\n\nCalculates the number of true negatives\n\n\n\nmetric_true_negatives(..., thresholds = NULL, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nthresholds\n(Optional) Defaults to 0.5. A float value or a list of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is true, below is false). One metric value is generated for each threshold value.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf sample_weight is given, calculates the sum of the weights of true negatives. This metric creates one local variable, accumulator that is used to keep track of the number of true negatives.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_positives()"
  },
  {
    "objectID": "packages/keras/latest/reference/metric_true_positives.html",
    "href": "packages/keras/latest/reference/metric_true_positives.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Calculates the number of true positives\n\n\nCalculates the number of true positives\n\n\n\nmetric_true_positives(..., thresholds = NULL, name = NULL, dtype = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nPassed on to the underlying metric. Used for forwards and backwards compatibility.\n\n\nthresholds\n(Optional) Defaults to 0.5. A float value or a list of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is true, below is false). One metric value is generated for each threshold value.\n\n\nname\n(Optional) string name of the metric instance.\n\n\ndtype\n(Optional) data type of the metric result.\n\n\n\n\n\n\nIf sample_weight is given, calculates the sum of the weights of true positives. This metric creates one local variable, true_positives that is used to keep track of the number of true positives.\nIf sample_weight is NULL, weights default to 1. Use sample_weight of 0 to mask values.\n\n\n\nA (subclassed) Metric instance that can be passed directly to compile(metrics = ), or used as a standalone object. See ?Metric for example usage.\n\n\n\nOther metrics: custom_metric(), metric_accuracy(), metric_auc(), metric_binary_accuracy(), metric_binary_crossentropy(), metric_categorical_accuracy(), metric_categorical_crossentropy(), metric_categorical_hinge(), metric_cosine_similarity(), metric_false_negatives(), metric_false_positives(), metric_hinge(), metric_kullback_leibler_divergence(), metric_logcosh_error(), metric_mean_absolute_error(), metric_mean_absolute_percentage_error(), metric_mean_iou(), metric_mean_relative_error(), metric_mean_squared_error(), metric_mean_squared_logarithmic_error(), metric_mean_tensor(), metric_mean_wrapper(), metric_mean(), metric_poisson(), metric_precision_at_recall(), metric_precision(), metric_recall_at_precision(), metric_recall(), metric_root_mean_squared_error(), metric_sensitivity_at_specificity(), metric_sparse_categorical_accuracy(), metric_sparse_categorical_crossentropy(), metric_sparse_top_k_categorical_accuracy(), metric_specificity_at_sensitivity(), metric_squared_hinge(), metric_sum(), metric_top_k_categorical_accuracy(), metric_true_negatives()"
  },
  {
    "objectID": "packages/keras/latest/reference/model_from_saved_model.html",
    "href": "packages/keras/latest/reference/model_from_saved_model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Load a Keras model from the Saved Model format\n\n\nLoad a Keras model from the Saved Model format\n\n\n\nmodel_from_saved_model(saved_model_path, custom_objects = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsaved_model_path\na string specifying the path to the SavedModel directory.\n\n\ncustom_objects\nOptional dictionary mapping string names to custom classes or functions (e.g. custom loss functions).\n\n\n\n\n\n\na Keras model.\n\n\n\nOther saved_model: model_to_saved_model()"
  },
  {
    "objectID": "packages/keras/latest/reference/model_to_json.html",
    "href": "packages/keras/latest/reference/model_to_json.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Model configuration as JSON\n\n\nSave and re-load models configurations as JSON. Note that the representation does not include the weights, only the architecture.\n\n\n\nmodel_to_json(object)\n\nmodel_from_json(json, custom_objects = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to save\n\n\njson\nJSON with model configuration\n\n\ncustom_objects\nOptional named list mapping names to custom classes or functions to be considered during deserialization.\n\n\n\n\n\n\nOther model persistence: get_weights(), model_to_yaml(), save_model_hdf5(), save_model_tf(), save_model_weights_hdf5(), serialize_model()"
  },
  {
    "objectID": "packages/keras/latest/reference/model_to_saved_model.html",
    "href": "packages/keras/latest/reference/model_to_saved_model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Export to Saved Model format\n\n\n(Deprecated) Export to Saved Model format\n\n\n\nmodel_to_saved_model(\n  model,\n  saved_model_path,\n  custom_objects = NULL,\n  as_text = FALSE,\n  input_signature = NULL,\n  serving_only = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmodel\nA Keras model to be saved. If the model is subclassed, the flag serving_only must be set to TRUE.\n\n\nsaved_model_path\na string specifying the path to the SavedModel directory.\n\n\ncustom_objects\nOptional dictionary mapping string names to custom classes or functions (e.g. custom loss functions).\n\n\nas_text\nbool, FALSE by default. Whether to write the SavedModel proto in text format. Currently unavailable in serving-only mode.\n\n\ninput_signature\nA possibly nested sequence of tf.TensorSpec objects, used to specify the expected model inputs. See tf.function for more details.\n\n\nserving_only\nbool, FALSE by default. When this is true, only the prediction graph is saved.\n\n\n\n\n\n\nInvisibly returns the saved_model_path.\n\n\n\nOther saved_model: model_from_saved_model()"
  },
  {
    "objectID": "packages/keras/latest/reference/model_to_yaml.html",
    "href": "packages/keras/latest/reference/model_to_yaml.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Model configuration as YAML\n\n\nSave and re-load models configurations as YAML Note that the representation does not include the weights, only the architecture.\n\n\n\nmodel_to_yaml(object)\n\nmodel_from_yaml(yaml, custom_objects = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to save\n\n\nyaml\nYAML with model configuration\n\n\ncustom_objects\nOptional named list mapping names to custom classes or functions to be considered during deserialization.\n\n\n\n\n\n\nOther model persistence: get_weights(), model_to_json(), save_model_hdf5(), save_model_tf(), save_model_weights_hdf5(), serialize_model()"
  },
  {
    "objectID": "packages/keras/latest/reference/multi-assign.html",
    "href": "packages/keras/latest/reference/multi-assign.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Assign values to names\n\n\nSee %<-% for more details.\n\n\n\nx %<-% value"
  },
  {
    "objectID": "packages/keras/latest/reference/multi_gpu_model.html",
    "href": "packages/keras/latest/reference/multi_gpu_model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Replicates a model on different GPUs.\n\n\n(Deprecated) Replicates a model on different GPUs.\n\n\n\nmulti_gpu_model(model, gpus = NULL, cpu_merge = TRUE, cpu_relocation = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmodel\nA Keras model instance. To avoid OOM errors, this model could have been built on CPU, for instance (see usage example below).\n\n\ngpus\nNULL to use all available GPUs (default). Integer >= 2 or list of integers, number of GPUs or list of GPU IDs on which to create model replicas.\n\n\ncpu_merge\nA boolean value to identify whether to force merging model weights under the scope of the CPU or not.\n\n\ncpu_relocation\nA boolean value to identify whether to create the model’s weights under the scope of the CPU. If the model is not defined under any preceding device scope, you can still rescue it by activating this option.\n\n\n\n\n\n\nSpecifically, this function implements single-machine multi-GPU data parallelism. It works in the following way:\n\nDivide the model’s input(s) into multiple sub-batches.\nApply a model copy on each sub-batch. Every model copy is executed on a dedicated GPU.\nConcatenate the results (on CPU) into one big batch.\n\nE.g. if your batch_size is 64 and you use gpus=2, then we will divide the input into 2 sub-batches of 32 samples, process each sub-batch on one GPU, then return the full batch of 64 processed samples.\nThis induces quasi-linear speedup on up to 8 GPUs.\nThis function is only available with the TensorFlow backend for the time being.\n\n\n\nA Keras model object which can be used just like the initial model argument, but which distributes its workload on multiple GPUs.\n\n\n\n\n\nlibrary(keras)\nlibrary(tensorflow)\n\nnum_samples <- 1000\nheight <- 224\nwidth <- 224\nnum_classes <- 1000\n\n# Instantiate the base model (or \"template\" model).\n# We recommend doing this with under a CPU device scope,\n# so that the model's weights are hosted on CPU memory.\n# Otherwise they may end up hosted on a GPU, which would\n# complicate weight sharing.\nwith(tf$device(\"/cpu:0\"), {\n  model <- application_xception(\n    weights = NULL,\n    input_shape = c(height, width, 3),\n    classes = num_classes\n  )\n})\n\n# Replicates the model on 8 GPUs.\n# This assumes that your machine has 8 available GPUs.\nparallel_model <- multi_gpu_model(model, gpus = 8)\nparallel_model %>% compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = \"rmsprop\"\n)\n\n# Generate dummy data.\nx <- array(runif(num_samples * height * width*3),\n           dim = c(num_samples, height, width, 3))\ny <- array(runif(num_samples * num_classes),\n           dim = c(num_samples, num_classes))\n\n# This `fit` call will be distributed on 8 GPUs.\n# Since the batch size is 256, each GPU will process 32 samples.\nparallel_model %>% fit(x, y, epochs = 20, batch_size = 256)\n\n# Save model via the template model (which shares the same weights):\nmodel %>% save_model_hdf5(\"my_model.h5\")\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/new-classes.html",
    "href": "packages/keras/latest/reference/new-classes.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Define new keras types\n\n\nThese functions can be used to make custom objects that fit in the family of existing keras types. For example, new_layer_class() will return a class constructor, an object that behaves like other layer functions such as layer_dense(). new_callback_class() will return an object that behaves similarly to other callback functions, like callback_reduce_lr_on_plateau(), and so on. All arguments with a default NULL value are optional methods that can be provided.\n\n\n\nmark_active(x)\n\nnew_metric_class(classname, ..., initialize, update_state, result)\n\nnew_loss_class(classname, ..., call = NULL)\n\nnew_callback_class(\n  classname,\n  ...,\n  on_epoch_begin = NULL,\n  on_epoch_end = NULL,\n  on_train_begin = NULL,\n  on_train_end = NULL,\n  on_batch_begin = NULL,\n  on_batch_end = NULL,\n  on_predict_batch_begin = NULL,\n  on_predict_batch_end = NULL,\n  on_predict_begin = NULL,\n  on_predict_end = NULL,\n  on_test_batch_begin = NULL,\n  on_test_batch_end = NULL,\n  on_test_begin = NULL,\n  on_test_end = NULL,\n  on_train_batch_begin = NULL,\n  on_train_batch_end = NULL\n)\n\nnew_model_class(\n  classname,\n  ...,\n  initialize = NULL,\n  call = NULL,\n  train_step = NULL,\n  predict_step = NULL,\n  test_step = NULL,\n  compute_loss = NULL,\n  compute_metrics = NULL\n)\n\nnew_layer_class(\n  classname,\n  ...,\n  initialize = NULL,\n  build = NULL,\n  call = NULL,\n  get_config = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA function that should be converted to an active property of the class type.\n\n\nclassname\nThe classname as a string. Convention is for the classname to be a CamelCase version of the constructor.\n\n\n…\nAdditional fields and methods for the new type.\n\n\ninitialize, build, call, get_config, on_epoch_begin, on_epoch_end, on_train_begin, on_train_end, on_batch_begin, on_batch_end, on_predict_batch_begin, on_predict_batch_end, on_predict_begin, on_predict_end, on_test_batch_begin, on_test_batch_end, on_test_begin, on_test_end, on_train_batch_begin, on_train_batch_end, update_state, result, train_step, predict_step, test_step, compute_loss, compute_metrics\nOptional methods that can be overridden.\n\n\n\n\n\n\nmark_active() is a decorator that can be used to indicate functions that should become active properties of the class instances.\n\n\n\nA new class generator object that inherits from the appropriate Keras base class."
  },
  {
    "objectID": "packages/keras/latest/reference/new_learning_rate_schedule_class.html",
    "href": "packages/keras/latest/reference/new_learning_rate_schedule_class.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create a new learning rate schedule type\n\n\nCreate a new learning rate schedule type\n\n\n\nnew_learning_rate_schedule_class(\n  classname,\n  ...,\n  initialize = NULL,\n  call,\n  get_config = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nclassname\nstring\n\n\n…\nmethods and properties of the schedule class\n\n\ninitialize, get_config\nAdditional recommended methods to implement. * https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule\n\n\ncall\nfunction which takes a step argument (scalar integer tensor, the current training step count, and returns the new learning rate). For tracking additional state, objects self and private are automatically injected into the scope of the function.\n\n\n\n\n\n\nA LearningRateSchedule class generator."
  },
  {
    "objectID": "packages/keras/latest/reference/normalize.html",
    "href": "packages/keras/latest/reference/normalize.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Normalize a matrix or nd-array\n\n\nNormalize a matrix or nd-array\n\n\n\nnormalize(x, axis = -1, order = 2)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nMatrix or array to normalize\n\n\naxis\nAxis along which to normalize. Axis indexes are 1-based (pass -1 to select the last axis).\n\n\norder\nNormalization order (e.g. 2 for L2 norm)\n\n\n\n\n\n\nA normalized copy of the array."
  },
  {
    "objectID": "packages/keras/latest/reference/optimizer_adadelta.html",
    "href": "packages/keras/latest/reference/optimizer_adadelta.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Adadelta optimizer.\n\n\nAdadelta optimizer as described in https://arxiv.org/abs/1212.5701ADADELTA: An Adaptive Learning Rate Method.\n\n\n\noptimizer_adadelta(\n  learning_rate = 1,\n  rho = 0.95,\n  epsilon = NULL,\n  decay = 0,\n  clipnorm = NULL,\n  clipvalue = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlearning_rate\nfloat >= 0. Learning rate.\n\n\nrho\nfloat >= 0. Decay factor.\n\n\nepsilon\nfloat >= 0. Fuzz factor. If NULL, defaults to k_epsilon().\n\n\ndecay\nfloat >= 0. Learning rate decay over each update.\n\n\nclipnorm\nGradients will be clipped when their L2 norm exceeds this value.\n\n\nclipvalue\nGradients will be clipped when their absolute value exceeds this value.\n\n\n…\nUnused, present only for backwards compatability\n\n\n\n\n\n\nOther optimizers: optimizer_adagrad(), optimizer_adamax(), optimizer_adam(), optimizer_nadam(), optimizer_rmsprop(), optimizer_sgd()"
  },
  {
    "objectID": "packages/keras/latest/reference/optimizer_adagrad.html",
    "href": "packages/keras/latest/reference/optimizer_adagrad.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Adagrad optimizer.\n\n\nAdagrad optimizer as described in https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdfAdaptive Subgradient Methods for Online Learning and Stochastic Optimization.\n\n\n\noptimizer_adagrad(\n  learning_rate = 0.01,\n  epsilon = NULL,\n  decay = 0,\n  clipnorm = NULL,\n  clipvalue = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlearning_rate\nfloat >= 0. Learning rate.\n\n\nepsilon\nfloat >= 0. Fuzz factor. If NULL, defaults to k_epsilon().\n\n\ndecay\nfloat >= 0. Learning rate decay over each update.\n\n\nclipnorm\nGradients will be clipped when their L2 norm exceeds this value.\n\n\nclipvalue\nGradients will be clipped when their absolute value exceeds this value.\n\n\n…\nUnused, present only for backwards compatability\n\n\n\n\n\n\nOther optimizers: optimizer_adadelta(), optimizer_adamax(), optimizer_adam(), optimizer_nadam(), optimizer_rmsprop(), optimizer_sgd()"
  },
  {
    "objectID": "packages/keras/latest/reference/optimizer_adam.html",
    "href": "packages/keras/latest/reference/optimizer_adam.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Adam optimizer\n\n\nAdam optimizer as described in https://arxiv.org/abs/1412.6980v8Adam - A Method for Stochastic Optimization.\n\n\n\noptimizer_adam(\n  learning_rate = 0.001,\n  beta_1 = 0.9,\n  beta_2 = 0.999,\n  epsilon = NULL,\n  decay = 0,\n  amsgrad = FALSE,\n  clipnorm = NULL,\n  clipvalue = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlearning_rate\nfloat >= 0. Learning rate.\n\n\nbeta_1\nThe exponential decay rate for the 1st moment estimates. float, 0 < beta < 1. Generally close to 1.\n\n\nbeta_2\nThe exponential decay rate for the 2nd moment estimates. float, 0 < beta < 1. Generally close to 1.\n\n\nepsilon\nfloat >= 0. Fuzz factor. If NULL, defaults to k_epsilon().\n\n\ndecay\nfloat >= 0. Learning rate decay over each update.\n\n\namsgrad\nWhether to apply the AMSGrad variant of this algorithm from the paper “On the Convergence of Adam and Beyond”.\n\n\nclipnorm\nGradients will be clipped when their L2 norm exceeds this value.\n\n\nclipvalue\nGradients will be clipped when their absolute value exceeds this value.\n\n\n…\nUnused, present only for backwards compatability\n\n\n\n\n\n\nOther optimizers: optimizer_adadelta(), optimizer_adagrad(), optimizer_adamax(), optimizer_nadam(), optimizer_rmsprop(), optimizer_sgd()"
  },
  {
    "objectID": "packages/keras/latest/reference/optimizer_adamax.html",
    "href": "packages/keras/latest/reference/optimizer_adamax.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Adamax optimizer\n\n\nAdamax optimizer from Section 7 of the https://arxiv.org/abs/1412.6980v8Adam paper. It is a variant of Adam based on the infinity norm.\n\n\n\noptimizer_adamax(\n  learning_rate = 0.002,\n  beta_1 = 0.9,\n  beta_2 = 0.999,\n  epsilon = NULL,\n  decay = 0,\n  clipnorm = NULL,\n  clipvalue = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlearning_rate\nfloat >= 0. Learning rate.\n\n\nbeta_1\nThe exponential decay rate for the 1st moment estimates. float, 0 < beta < 1. Generally close to 1.\n\n\nbeta_2\nThe exponential decay rate for the 2nd moment estimates. float, 0 < beta < 1. Generally close to 1.\n\n\nepsilon\nfloat >= 0. Fuzz factor. If NULL, defaults to k_epsilon().\n\n\ndecay\nfloat >= 0. Learning rate decay over each update.\n\n\nclipnorm\nGradients will be clipped when their L2 norm exceeds this value.\n\n\nclipvalue\nGradients will be clipped when their absolute value exceeds this value.\n\n\n…\nUnused, present only for backwards compatability\n\n\n\n\n\n\nOther optimizers: optimizer_adadelta(), optimizer_adagrad(), optimizer_adam(), optimizer_nadam(), optimizer_rmsprop(), optimizer_sgd()"
  },
  {
    "objectID": "packages/keras/latest/reference/optimizer_nadam.html",
    "href": "packages/keras/latest/reference/optimizer_nadam.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Nesterov Adam optimizer\n\n\nMuch like Adam is essentially RMSprop with momentum, Nadam is Adam RMSprop with Nesterov momentum.\n\n\n\noptimizer_nadam(\n  learning_rate = 0.002,\n  beta_1 = 0.9,\n  beta_2 = 0.999,\n  epsilon = NULL,\n  schedule_decay = 0.004,\n  clipnorm = NULL,\n  clipvalue = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlearning_rate\nfloat >= 0. Learning rate.\n\n\nbeta_1\nThe exponential decay rate for the 1st moment estimates. float, 0 < beta < 1. Generally close to 1.\n\n\nbeta_2\nThe exponential decay rate for the 2nd moment estimates. float, 0 < beta < 1. Generally close to 1.\n\n\nepsilon\nfloat >= 0. Fuzz factor. If NULL, defaults to k_epsilon().\n\n\nschedule_decay\nSchedule deacy.\n\n\nclipnorm\nGradients will be clipped when their L2 norm exceeds this value.\n\n\nclipvalue\nGradients will be clipped when their absolute value exceeds this value.\n\n\n…\nUnused, present only for backwards compatability\n\n\n\n\n\n\nDefault parameters follow those provided in the paper. It is recommended to leave the parameters of this optimizer at their default values.\n\n\n\nhttps://www.cs.toronto.edu/~fritz/absps/momentum.pdfOn the importance of initialization and momentum in deep learning.\nOther optimizers: optimizer_adadelta(), optimizer_adagrad(), optimizer_adamax(), optimizer_adam(), optimizer_rmsprop(), optimizer_sgd()"
  },
  {
    "objectID": "packages/keras/latest/reference/optimizer_rmsprop.html",
    "href": "packages/keras/latest/reference/optimizer_rmsprop.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "RMSProp optimizer\n\n\nRMSProp optimizer\n\n\n\noptimizer_rmsprop(\n  learning_rate = 0.001,\n  rho = 0.9,\n  epsilon = NULL,\n  decay = 0,\n  clipnorm = NULL,\n  clipvalue = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlearning_rate\nfloat >= 0. Learning rate.\n\n\nrho\nfloat >= 0. Decay factor.\n\n\nepsilon\nfloat >= 0. Fuzz factor. If NULL, defaults to k_epsilon().\n\n\ndecay\nfloat >= 0. Learning rate decay over each update.\n\n\nclipnorm\nGradients will be clipped when their L2 norm exceeds this value.\n\n\nclipvalue\nGradients will be clipped when their absolute value exceeds this value.\n\n\n…\nUnused, present only for backwards compatability\n\n\n\n\n\n\nOther optimizers: optimizer_adadelta(), optimizer_adagrad(), optimizer_adamax(), optimizer_adam(), optimizer_nadam(), optimizer_sgd()"
  },
  {
    "objectID": "packages/keras/latest/reference/optimizer_sgd.html",
    "href": "packages/keras/latest/reference/optimizer_sgd.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Stochastic gradient descent optimizer\n\n\nStochastic gradient descent optimizer with support for momentum, learning rate decay, and Nesterov momentum.\n\n\n\noptimizer_sgd(\n  learning_rate = 0.01,\n  momentum = 0,\n  decay = 0,\n  nesterov = FALSE,\n  clipnorm = NULL,\n  clipvalue = NULL,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlearning_rate\nfloat >= 0. Learning rate.\n\n\nmomentum\nfloat >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n\n\ndecay\nfloat >= 0. Learning rate decay over each update.\n\n\nnesterov\nboolean. Whether to apply Nesterov momentum.\n\n\nclipnorm\nGradients will be clipped when their L2 norm exceeds this value.\n\n\nclipvalue\nGradients will be clipped when their absolute value exceeds this value.\n\n\n…\nUnused, present only for backwards compatability\n\n\n\n\n\n\nOptimizer for use with compile.keras.engine.training.Model.\n\n\n\nOther optimizers: optimizer_adadelta(), optimizer_adagrad(), optimizer_adamax(), optimizer_adam(), optimizer_nadam(), optimizer_rmsprop()"
  },
  {
    "objectID": "packages/keras/latest/reference/pad_sequences.html",
    "href": "packages/keras/latest/reference/pad_sequences.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pads sequences to the same length\n\n\nPads sequences to the same length\n\n\n\npad_sequences(\n  sequences,\n  maxlen = NULL,\n  dtype = \"int32\",\n  padding = \"pre\",\n  truncating = \"pre\",\n  value = 0\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsequences\nList of lists where each element is a sequence\n\n\nmaxlen\nint, maximum length of all sequences\n\n\ndtype\ntype of the output sequences\n\n\npadding\n‘pre’ or ‘post’, pad either before or after each sequence.\n\n\ntruncating\n‘pre’ or ‘post’, remove values from sequences larger than maxlen either in the beginning or in the end of the sequence\n\n\nvalue\nfloat, padding value\n\n\n\n\n\n\nThis function transforms a list of num_samples sequences (lists of integers) into a matrix of shape (num_samples, num_timesteps). num_timesteps is either the maxlen argument if provided, or the length of the longest sequence otherwise.\nSequences that are shorter than num_timesteps are padded with value at the end.\nSequences longer than num_timesteps are truncated so that they fit the desired length. The position where padding or truncation happens is determined by the arguments padding and truncating, respectively.\nPre-padding is the default.\n\n\n\nMatrix with dimensions (number_of_sequences, maxlen)\n\n\n\nOther text preprocessing: make_sampling_table(), skipgrams(), text_hashing_trick(), text_one_hot(), text_to_word_sequence()"
  },
  {
    "objectID": "packages/keras/latest/reference/pipe.html",
    "href": "packages/keras/latest/reference/pipe.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pipe operator\n\n\nSee %>% for more details.\n\n\n\nlhs %>% rhs"
  },
  {
    "objectID": "packages/keras/latest/reference/plot.keras.engine.training.model.html",
    "href": "packages/keras/latest/reference/plot.keras.engine.training.model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Plot a Keras model\n\n\nPlot a Keras model\n\n\n\nplotkeras.engine.training.Model( x, show_shapes = FALSE, show_dtype = FALSE, show_layer_names = TRUE, …, rankdir = “TB”, expand_nested = FALSE, dpi = 96, layer_range = NULL, show_layer_activations = FALSE, to_file = NULL )\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA Keras model instance\n\n\nshow_shapes\nwhether to display shape information.\n\n\nshow_dtype\nwhether to display layer dtypes.\n\n\nshow_layer_names\nwhether to display layer names.\n\n\n…\npassed on to keras$utils$plot_model(). Used for forward and backward compatibility.\n\n\nrankdir\na string specifying the format of the plot: 'TB' creates a vertical plot; 'LR' creates a horizontal plot. (argument passed to PyDot)\n\n\nexpand_nested\nWhether to expand nested models into clusters.\n\n\ndpi\nDots per inch. Increase this value if the image text appears excessively pixelated.\n\n\nlayer_range\nlist containing two character strings, which is the starting layer name and ending layer name (both inclusive) indicating the range of layers for which the plot will be generated. It also accepts regex patterns instead of exact name. In such case, start predicate will be the first element it matches to layer_range[1] and the end predicate will be the last element it matches to layer_range[2]. By default NULL which considers all layers of model. Note that you must pass range such that the resultant subgraph must be complete.\n\n\nshow_layer_activations\nDisplay layer activations (only for layers that have an activation property).\n\n\nto_file\nFile name of the plot image. If NULL (the default), the model is drawn on the default graphics device. Otherwise, a file is saved.\n\n\n\n\n\n\nNothing, called for it’s side effects."
  },
  {
    "objectID": "packages/keras/latest/reference/plot.keras_training_history.html",
    "href": "packages/keras/latest/reference/plot.keras_training_history.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Plot training history\n\n\nPlots metrics recorded during training.\n\n\n\nplotkeras_training_history( x, y, metrics = NULL, method = c(“auto”, “ggplot2”, “base”), smooth = getOption(“keras.plot.history.smooth”, TRUE), theme_bw = getOption(“keras.plot.history.theme_bw”, FALSE), … )\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nTraining history object returned from fit.keras.engine.training.Model().\n\n\ny\nUnused.\n\n\nmetrics\nOne or more metrics to plot (e.g. c('loss', 'accuracy')). Defaults to plotting all captured metrics.\n\n\nmethod\nMethod to use for plotting. The default “auto” will use ggplot2 if available, and otherwise will use base graphics.\n\n\nsmooth\nWhether a loess smooth should be added to the plot, only available for the ggplot2 method. If the number of epochs is smaller than ten, it is forced to false.\n\n\ntheme_bw\nUse ggplot2::theme_bw() to plot the history in black and white.\n\n\n…\nAdditional parameters to pass to the plot() method."
  },
  {
    "objectID": "packages/keras/latest/reference/pop_layer.html",
    "href": "packages/keras/latest/reference/pop_layer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Remove the last layer in a model\n\n\nRemove the last layer in a model\n\n\n\npop_layer(object)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model object\n\n\n\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/predict.keras.engine.training.model.html",
    "href": "packages/keras/latest/reference/predict.keras.engine.training.model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Generate predictions from a Keras model\n\n\nGenerates output predictions for the input samples, processing the samples in a batched way.\n\n\n\npredictkeras.engine.training.Model( object, x, batch_size = NULL, verbose = “auto”, steps = NULL, callbacks = NULL, … )\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model\n\n\nx\nInput data (vector, matrix, or array). You can also pass a tfdataset or a generator returning a list with (inputs, targets) or (inputs, targets, sample_weights).\n\n\nbatch_size\nInteger. If unspecified, it will default to 32.\n\n\nverbose\nVerbosity mode, 0, 1, 2, or “auto”. “auto” defaults to 1 for for most cases and defaults to verbose=2 when used with ParameterServerStrategy or with interactive logging disabled.\n\n\nsteps\nTotal number of steps (batches of samples) before declaring the evaluation round finished. Ignored with the default value of NULL.\n\n\ncallbacks\nList of callbacks to apply during prediction.\n\n\n…\nUnused\n\n\n\n\n\n\nvector, matrix, or array of predictions\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/predict_generator.html",
    "href": "packages/keras/latest/reference/predict_generator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Generates predictions for the input samples from a data generator.\n\n\nThe generator should return the same kind of data as accepted by predict_on_batch().\n\n\n\npredict_generator(\n  object,\n  generator,\n  steps,\n  max_queue_size = 10,\n  workers = 1,\n  verbose = 0,\n  callbacks = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model object\n\n\ngenerator\nGenerator yielding batches of input samples.\n\n\nsteps\nTotal number of steps (batches of samples) to yield from generator before stopping.\n\n\nmax_queue_size\nMaximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n\n\nworkers\nMaximum number of threads to use for parallel processing. Note that parallel processing will only be performed for native Keras generators (e.g. flow_images_from_directory()) as R based generators must run on the main thread.\n\n\nverbose\nverbosity mode, 0 or 1.\n\n\ncallbacks\nList of callbacks to apply during prediction.\n\n\n\n\n\n\nNumpy array(s) of predictions.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/predict_on_batch.html",
    "href": "packages/keras/latest/reference/predict_on_batch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Returns predictions for a single batch of samples.\n\n\nReturns predictions for a single batch of samples.\n\n\n\npredict_on_batch(object, x)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model object\n\n\nx\nInput data (vector, matrix, or array). You can also pass a tfdataset or a generator returning a list with (inputs, targets) or (inputs, targets, sample_weights).\n\n\n\n\n\n\narray of predictions.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_proba(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/predict_proba.html",
    "href": "packages/keras/latest/reference/predict_proba.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Generates probability or class probability predictions for the input samples.\n\n\nThese functions were removed in Tensorflow version 2.6. See details for how to update your code:\n\n\n\npredict_proba(object, x, batch_size = NULL, verbose = 0, steps = NULL)\n\npredict_classes(object, x, batch_size = NULL, verbose = 0, steps = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model object\n\n\nx\nInput data (vector, matrix, or array). You can also pass a tfdataset or a generator returning a list with (inputs, targets) or (inputs, targets, sample_weights).\n\n\nbatch_size\nInteger. If unspecified, it will default to 32.\n\n\nverbose\nVerbosity mode, 0, 1, 2, or “auto”. “auto” defaults to 1 for for most cases and defaults to verbose=2 when used with ParameterServerStrategy or with interactive logging disabled.\n\n\nsteps\nTotal number of steps (batches of samples) before declaring the evaluation round finished. The default NULL is equal to the number of samples in your dataset divided by the batch size.\n\n\n\n\n\n\nHow to update your code:\npredict_proba(): use predict() directly.\npredict_classes():\n\nIf your model does multi-class classification: (e.g. if it uses a softmax last-layer activation).\n\nhtml\n\n model %>% predict(x) %>% k_argmax()\nhtml\n\n\nif your model does binary classification (e.g. if it uses a sigmoid last-layer activation).\n\nhtml\n\n model %>% predict(x) %>% `>`(0.5) %>% k_cast(\"int32\")\nhtml\n\nThe input samples are processed batch by batch.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), summary.keras.engine.training.Model(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/reexports.html",
    "href": "packages/keras/latest/reference/reexports.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Objects exported from other packages\n\n\nThese objects are imported from other packages. Follow the links below to see their documentation."
  },
  {
    "objectID": "packages/keras/latest/reference/regularizer_l1.html",
    "href": "packages/keras/latest/reference/regularizer_l1.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "L1 and L2 regularization\n\n\nL1 and L2 regularization\n\n\n\nregularizer_l1(l = 0.01)\n\nregularizer_l2(l = 0.01)\n\nregularizer_l1_l2(l1 = 0.01, l2 = 0.01)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nl\nRegularization factor.\n\n\nl1\nL1 regularization factor.\n\n\nl2\nL2 regularization factor."
  },
  {
    "objectID": "packages/keras/latest/reference/regularizer_orthogonal.html",
    "href": "packages/keras/latest/reference/regularizer_orthogonal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A regularizer that encourages input vectors to be orthogonal to each other\n\n\nA regularizer that encourages input vectors to be orthogonal to each other\n\n\n\nregularizer_orthogonal(factor = 0.01, mode = \"rows\", ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfactor\nFloat. The regularization factor. The regularization penalty will be proportional to factor times the mean of the dot products between the L2-normalized rows (if mode=\"rows\", or columns if mode=\"columns\") of the inputs, excluding the product of each row/column with itself. Defaults to 0.01.\n\n\nmode\nString, one of {“rows”, “columns”}. Defaults to \"rows\". In rows mode, the regularization effect seeks to make the rows of the input orthogonal to each other. In columns mode, it seeks to make the columns of the input orthogonal to each other.\n\n\n…\nFor backwards and forwards compatibility html\n\n\n\n\n\n\nIt can be applied to either the rows of a matrix (mode=\"rows\") or its columns (mode=\"columns\"). When applied to a Dense kernel of shape (input_dim, units), rows mode will seek to make the feature vectors (i.e. the basis of the output space) orthogonal to each other.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/regularizers/OrthogonalRegularizer"
  },
  {
    "objectID": "packages/keras/latest/reference/reset_states.html",
    "href": "packages/keras/latest/reference/reset_states.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reset the states for a layer\n\n\nReset the states for a layer\n\n\n\nreset_states(object)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel or layer object\n\n\n\n\n\n\nOther layer methods: count_params(), get_config(), get_input_at(), get_weights()"
  },
  {
    "objectID": "packages/keras/latest/reference/save_model_hdf5.html",
    "href": "packages/keras/latest/reference/save_model_hdf5.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Save/Load models using HDF5 files\n\n\nSave/Load models using HDF5 files\n\n\n\nsave_model_hdf5(object, filepath, overwrite = TRUE, include_optimizer = TRUE)\n\nload_model_hdf5(filepath, custom_objects = NULL, compile = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to save\n\n\nfilepath\nFile path\n\n\noverwrite\nOverwrite existing file if necessary\n\n\ninclude_optimizer\nIf TRUE, save optimizer’s state.\n\n\ncustom_objects\nMapping class names (or function names) of custom (non-Keras) objects to class/functions (for example, custom metrics or custom loss functions). This mapping can be done with the dict() function of reticulate.\n\n\ncompile\nWhether to compile the model after loading.\n\n\n\n\n\n\nThe following components of the model are saved:\n\nThe model architecture, allowing to re-instantiate the model.\nThe model weights.\nThe state of the optimizer, allowing to resume training exactly where you left off. This allows you to save the entirety of the state of a model in a single file.\n\nSaved models can be reinstantiated via load_model_hdf5(). The model returned by load_model_hdf5() is a compiled model ready to be used (unless the saved model was never compiled in the first place or compile = FALSE is specified).\nAs an alternative to providing the custom_objects argument, you can execute the definition and persistence of your model using the with_custom_object_scope() function.\n\n\n\nOther model persistence: get_weights(), model_to_json(), model_to_yaml(), save_model_tf(), save_model_weights_hdf5(), serialize_model()"
  },
  {
    "objectID": "packages/keras/latest/reference/save_model_tf.html",
    "href": "packages/keras/latest/reference/save_model_tf.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Save/Load models using SavedModel format\n\n\nSave/Load models using SavedModel format\n\n\n\nsave_model_tf(\n  object,\n  filepath,\n  overwrite = TRUE,\n  include_optimizer = TRUE,\n  signatures = NULL,\n  options = NULL\n)\n\nload_model_tf(filepath, custom_objects = NULL, compile = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to save\n\n\nfilepath\nFile path\n\n\noverwrite\nOverwrite existing file if necessary\n\n\ninclude_optimizer\nIf TRUE, save optimizer’s state.\n\n\nsignatures\nSignatures to save with the SavedModel. Please see the signatures argument in tf$saved_model$save for details.\n\n\noptions\nOptional tf$saved_model$SaveOptions object that specifies options for saving to SavedModel\n\n\ncustom_objects\nMapping class names (or function names) of custom (non-Keras) objects to class/functions (for example, custom metrics or custom loss functions). This mapping can be done with the dict() function of reticulate.\n\n\ncompile\nWhether to compile the model after loading.\n\n\n\n\n\n\nOther model persistence: get_weights(), model_to_json(), model_to_yaml(), save_model_hdf5(), save_model_weights_hdf5(), serialize_model()"
  },
  {
    "objectID": "packages/keras/latest/reference/save_model_weights_hdf5.html",
    "href": "packages/keras/latest/reference/save_model_weights_hdf5.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Save/Load model weights using HDF5 files\n\n\nSave/Load model weights using HDF5 files\n\n\n\nsave_model_weights_hdf5(object, filepath, overwrite = TRUE)\n\nload_model_weights_hdf5(\n  object,\n  filepath,\n  by_name = FALSE,\n  skip_mismatch = FALSE,\n  reshape = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to save/load\n\n\nfilepath\nPath to the file\n\n\noverwrite\nWhether to silently overwrite any existing file at the target location\n\n\nby_name\nWhether to load weights by name or by topological order.\n\n\nskip_mismatch\nLogical, whether to skip loading of layers where there is a mismatch in the number of weights, or a mismatch in the shape of the weight (only valid when by_name = FALSE).\n\n\nreshape\nReshape weights to fit the layer when the correct number of values are present but the shape does not match.\n\n\n\n\n\n\nThe weight file has:\n\nlayer_names (attribute), a list of strings (ordered names of model layers).\nFor every layer, a group named layer.name\nFor every such layer group, a group attribute weight_names, a list of strings (ordered names of weights tensor of the layer).\nFor every weight in the layer, a dataset storing the weight value, named after the weight tensor.\n\nFor load_model_weights(), if by_name is FALSE (default) weights are loaded based on the network’s topology, meaning the architecture should be the same as when the weights were saved. Note that layers that don’t have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don’t have weights.\nIf by_name is TRUE, weights are loaded into layers only if they share the same name. This is useful for fine-tuning or transfer-learning models where some of the layers have changed.\n\n\n\nOther model persistence: get_weights(), model_to_json(), model_to_yaml(), save_model_hdf5(), save_model_tf(), serialize_model()"
  },
  {
    "objectID": "packages/keras/latest/reference/save_model_weights_tf.html",
    "href": "packages/keras/latest/reference/save_model_weights_tf.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Save model weights in the SavedModel format\n\n\nSave model weights in the SavedModel format\n\n\n\nsave_model_weights_tf(object, filepath, overwrite = TRUE)\n\nload_model_weights_tf(\n  object,\n  filepath,\n  by_name = FALSE,\n  skip_mismatch = FALSE,\n  reshape = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel object to save/load\n\n\nfilepath\nPath to the file\n\n\noverwrite\nWhether to silently overwrite any existing file at the target location\n\n\nby_name\nWhether to load weights by name or by topological order.\n\n\nskip_mismatch\nLogical, whether to skip loading of layers where there is a mismatch in the number of weights, or a mismatch in the shape of the weight (only valid when by_name = FALSE).\n\n\nreshape\nReshape weights to fit the layer when the correct number of values are present but the shape does not match.\n\n\n\n\n\n\nWhen saving in TensorFlow format, all objects referenced by the network are saved in the same format as tf.train.Checkpoint, including any Layer instances or Optimizer instances assigned to object attributes. For networks constructed from inputs and outputs using tf.keras.Model(inputs, outputs), Layer instances used by the network are tracked/saved automatically. For user-defined classes which inherit from tf.keras.Model, Layer instances must be assigned to object attributes, typically in the constructor.\nSee the documentation of tf.train.Checkpoint and tf.keras.Model for details."
  },
  {
    "objectID": "packages/keras/latest/reference/save_text_tokenizer.html",
    "href": "packages/keras/latest/reference/save_text_tokenizer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Save a text tokenizer to an external file\n\n\nEnables persistence of text tokenizers alongside saved models.\n\n\n\nsave_text_tokenizer(object, filename)\n\nload_text_tokenizer(filename)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nText tokenizer fit with fit_text_tokenizer()\n\n\nfilename\nFile to save/load\n\n\n\n\n\n\nYou should always use the same text tokenizer for training and prediction. In many cases however prediction will occur in another session with a version of the model loaded via load_model_hdf5().\nIn this case you need to save the text tokenizer object after training and then reload it prior to prediction.\n\n\n\n\n\n# vectorize texts then save for use in prediction\ntokenizer <- text_tokenizer(num_words = 10000) %>%\nfit_text_tokenizer(tokenizer, texts)\nsave_text_tokenizer(tokenizer, \"tokenizer\")\n\n# (train model, etc.)\n\n# ...later in another session\ntokenizer <- load_text_tokenizer(\"tokenizer\")\n\n# (use tokenizer to preprocess data for prediction)\n\n\n\n\nOther text tokenization: fit_text_tokenizer(), sequences_to_matrix(), text_tokenizer(), texts_to_matrix(), texts_to_sequences_generator(), texts_to_sequences()"
  },
  {
    "objectID": "packages/keras/latest/reference/sequences_to_matrix.html",
    "href": "packages/keras/latest/reference/sequences_to_matrix.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Convert a list of sequences into a matrix.\n\n\nConvert a list of sequences into a matrix.\n\n\n\nsequences_to_matrix(\n  tokenizer,\n  sequences,\n  mode = c(\"binary\", \"count\", \"tfidf\", \"freq\")\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntokenizer\nTokenizer\n\n\nsequences\nList of sequences (a sequence is a list of integer word indices).\n\n\nmode\none of “binary”, “count”, “tfidf”, “freq”.\n\n\n\n\n\n\nA matrix\n\n\n\nOther text tokenization: fit_text_tokenizer(), save_text_tokenizer(), text_tokenizer(), texts_to_matrix(), texts_to_sequences_generator(), texts_to_sequences()"
  },
  {
    "objectID": "packages/keras/latest/reference/sequential_model_input_layer.html",
    "href": "packages/keras/latest/reference/sequential_model_input_layer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "sequential_model_input_layer\n\n\nsequential_model_input_layer\n\n\n\nsequential_model_input_layer(\n  input_shape = NULL,\n  batch_size = NULL,\n  dtype = NULL,\n  input_tensor = NULL,\n  sparse = NULL,\n  name = NULL,\n  ragged = NULL,\n  type_spec = NULL,\n  ...,\n  input_layer_name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_shape\nan integer vector of dimensions (not including the batch axis), or a tf$TensorShape instance (also not including the batch axis).\n\n\nbatch_size\nOptional input batch size (integer or NULL).\n\n\ndtype\nOptional datatype of the input. When not provided, the Keras default float type will be used.\n\n\ninput_tensor\nOptional tensor to use as layer input. If set, the layer will use the tf$TypeSpec of this tensor rather than creating a new placeholder tensor.\n\n\nsparse\nBoolean, whether the placeholder created is meant to be sparse. Default to FALSE.\n\n\nragged\nBoolean, whether the placeholder created is meant to be ragged. In this case, values of ‘NULL’ in the ‘shape’ argument represent ragged dimensions. For more information about RaggedTensors, see this https://www.tensorflow.org/guide/ragged_tensorguide. Default to FALSE.\n\n\ntype_spec\nA tf$TypeSpec object to create Input from. This tf$TypeSpec represents the entire batch. When provided, all other args except name must be NULL.\n\n\n…\nadditional arguments passed on to keras$layers$InputLayer.\n\n\ninput_layer_name, name\nOptional name of the input layer (string)."
  },
  {
    "objectID": "packages/keras/latest/reference/serialize_model.html",
    "href": "packages/keras/latest/reference/serialize_model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Serialize a model to an R object\n\n\nModel objects are external references to Keras objects which cannot be saved and restored across R sessions. The serialize_model() and unserialize_model() functions provide facilities to convert Keras models to R objects for persistence within R data files.\n\n\n\nserialize_model(model, include_optimizer = TRUE)\n\nunserialize_model(model, custom_objects = NULL, compile = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmodel\nKeras model or R “raw” object containing serialized Keras model.\n\n\ninclude_optimizer\nIf TRUE, save optimizer’s state.\n\n\ncustom_objects\nMapping class names (or function names) of custom (non-Keras) objects to class/functions (for example, custom metrics or custom loss functions). This mapping can be done with the dict() function of reticulate.\n\n\ncompile\nWhether to compile the model after loading.\n\n\n\n\n\n\nserialize_model() returns an R “raw” object containing an hdf5 version of the Keras model. unserialize_model() returns a Keras model.\n\n\n\nOther model persistence: get_weights(), model_to_json(), model_to_yaml(), save_model_hdf5(), save_model_tf(), save_model_weights_hdf5()"
  },
  {
    "objectID": "packages/keras/latest/reference/skipgrams.html",
    "href": "packages/keras/latest/reference/skipgrams.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Generates skipgram word pairs.\n\n\nGenerates skipgram word pairs.\n\n\n\nskipgrams(\n  sequence,\n  vocabulary_size,\n  window_size = 4,\n  negative_samples = 1,\n  shuffle = TRUE,\n  categorical = FALSE,\n  sampling_table = NULL,\n  seed = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsequence\nA word sequence (sentence), encoded as a list of word indices (integers). If using a sampling_table, word indices are expected to match the rank of the words in a reference dataset (e.g. 10 would encode the 10-th most frequently occuring token). Note that index 0 is expected to be a non-word and will be skipped.\n\n\nvocabulary_size\nInt, maximum possible word index + 1\n\n\nwindow_size\nInt, size of sampling windows (technically half-window). The window of a word w_i will be [i-window_size, i+window_size+1]\n\n\nnegative_samples\nfloat >= 0. 0 for no negative (i.e. random) samples. 1 for same number as positive samples.\n\n\nshuffle\nwhether to shuffle the word couples before returning them.\n\n\ncategorical\nbool. if FALSE, labels will be integers (eg. [0, 1, 1 .. ]), if TRUE labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n\n\nsampling_table\n1D array of size vocabulary_size where the entry i encodes the probabibily to sample a word of rank i.\n\n\nseed\nRandom seed\n\n\n\n\n\n\nThis function transforms a list of word indexes (lists of integers) into lists of words of the form:\n\n(word, word in the same window), with label 1 (positive samples).\n(word, random word from the vocabulary), with label 0 (negative samples).\n\nRead more about Skipgram in this gnomic paper by Mikolov et al.: https://arxiv.org/pdf/1301.3781v3.pdfEfficient Estimation of Word Representations in Vector Space\n\n\n\nList of couples, labels where:\n\ncouples is a list of 2-element integer vectors: [word_index, other_word_index].\nlabels is an integer vector of 0 and 1, where 1 indicates that other_word_index was found in the same window as word_index, and 0 indicates that other_word_index was random.\nif categorical is set to TRUE, the labels are categorical, ie. 1 becomes [0,1], and 0 becomes [1, 0].\n\n\n\n\nOther text preprocessing: make_sampling_table(), pad_sequences(), text_hashing_trick(), text_one_hot(), text_to_word_sequence()"
  },
  {
    "objectID": "packages/keras/latest/reference/summary.keras.engine.training.model.html",
    "href": "packages/keras/latest/reference/summary.keras.engine.training.model.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Print a summary of a Keras model\n\n\nPrint a summary of a Keras model\n\n\n\nsummarykeras.engine.training.Model(object, …)\nformatkeras.engine.training.Model( x, line_length = width - (11L * show_trainable), positions = NULL, expand_nested = FALSE, show_trainable = x\\(built && as.logical(length(x\\)non_trainable_weights)), …, compact = TRUE, width = getOption(“width”) )\nprintkeras.engine.training.Model(x, …)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject, x\nKeras model instance\n\n\n…\nfor summary() and print(), passed on to format(). For format(), passed on to model$summary().\n\n\nline_length\nTotal length of printed lines\n\n\npositions\nRelative or absolute positions of log elements in each line. If not provided, defaults to c(0.33, 0.55, 0.67, 1.0).\n\n\nexpand_nested\nWhether to expand the nested models. If not provided, defaults to FALSE.\n\n\nshow_trainable\nWhether to show if a layer is trainable. If not provided, defaults to FALSE.\n\n\ncompact\nWhether to remove white-space only lines from the model summary. (Default TRUE)\n\n\nwidth\nthe column width to use for printing.\n\n\n\n\n\n\nformat() returns a length 1 character vector. print() returns the model object invisibly. summary() returns the output of format() invisibly after printing it.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), train_on_batch()"
  },
  {
    "objectID": "packages/keras/latest/reference/text_dataset_from_directory.html",
    "href": "packages/keras/latest/reference/text_dataset_from_directory.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Generate a tf.data.Dataset from text files in a directory\n\n\nGenerate a tf.data.Dataset from text files in a directory\n\n\n\ntext_dataset_from_directory(\n  directory,\n  labels = \"inferred\",\n  label_mode = \"int\",\n  class_names = NULL,\n  batch_size = 32L,\n  max_length = NULL,\n  shuffle = TRUE,\n  seed = NULL,\n  validation_split = NULL,\n  subset = NULL,\n  follow_links = FALSE,\n  ...\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndirectory\nDirectory where the data is located. If labels is “inferred”, it should contain subdirectories, each containing text files for a class. Otherwise, the directory structure is ignored.\n\n\nlabels\nEither “inferred” (labels are generated from the directory structure), NULL (no labels), or a list of integer labels of the same size as the number of text files found in the directory. Labels should be sorted according to the alphanumeric order of the text file paths (obtained via os.walk(directory) in Python).\n\n\nlabel_mode\n* 'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss). * 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss). * 'binary' means that the labels (there can be only 2) are encoded as float32 scalars with values 0 or 1 (e.g. for binary_crossentropy). * NULL (no labels).\n\n\nclass_names\nOnly valid if labels is \"inferred\". This is the explicit list of class names (must match names of subdirectories). Used to control the order of the classes (otherwise alphanumerical order is used).\n\n\nbatch_size\nSize of the batches of data. Default: 32.\n\n\nmax_length\nMaximum size of a text string. Texts longer than this will be truncated to max_length.\n\n\nshuffle\nWhether to shuffle the data. Default: TRUE. If set to FALSE, sorts the data in alphanumeric order.\n\n\nseed\nOptional random seed for shuffling and transformations.\n\n\nvalidation_split\nOptional float between 0 and 1, fraction of data to reserve for validation.\n\n\nsubset\nOne of “training” or “validation”. Only used if validation_split is set.\n\n\nfollow_links\nWhether to visits subdirectories pointed to by symlinks. Defaults to FALSE.\n\n\n…\nFor future compatibility (unused presently).\n\n\n\n\n\n\nIf your directory structure is:\nhtml\n\nmain_directory/ …class_a/ ……a_text_1.txt ……a_text_2.txt …class_b/ ……b_text_1.txt ……b_text_2.txt html\n\nThen calling text_dataset_from_directory(main_directory, labels = 'inferred') will return a tf.data.Dataset that yields batches of texts from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b).\nOnly .txt files are supported at this time.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory"
  },
  {
    "objectID": "packages/keras/latest/reference/text_hashing_trick.html",
    "href": "packages/keras/latest/reference/text_hashing_trick.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Converts a text to a sequence of indexes in a fixed-size hashing space.\n\n\nConverts a text to a sequence of indexes in a fixed-size hashing space.\n\n\n\ntext_hashing_trick(\n  text,\n  n,\n  hash_function = NULL,\n  filters = \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\",\n  lower = TRUE,\n  split = \" \"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntext\nInput text (string).\n\n\nn\nDimension of the hashing space.\n\n\nhash_function\nif NULL uses the Python hash() function. Otherwise can be 'md5' or any function that takes in input a string and returns an int. Note that hash is not a stable hashing function, so it is not consistent across different runs, while 'md5' is a stable hashing function.\n\n\nfilters\nSequence of characters to filter out such as punctuation. Default includes basic punctuation, tabs, and newlines.\n\n\nlower\nWhether to convert the input to lowercase.\n\n\nsplit\nSentence split marker (string).\n\n\n\n\n\n\nTwo or more words may be assigned to the same index, due to possible collisions by the hashing function.\n\n\n\nA list of integer word indices (unicity non-guaranteed).\n\n\n\nOther text preprocessing: make_sampling_table(), pad_sequences(), skipgrams(), text_one_hot(), text_to_word_sequence()"
  },
  {
    "objectID": "packages/keras/latest/reference/text_one_hot.html",
    "href": "packages/keras/latest/reference/text_one_hot.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "One-hot encode a text into a list of word indexes in a vocabulary of size n.\n\n\nOne-hot encode a text into a list of word indexes in a vocabulary of size n.\n\n\n\ntext_one_hot(\n  input_text,\n  n,\n  filters = \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\",\n  lower = TRUE,\n  split = \" \",\n  text = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_text\nInput text (string).\n\n\nn\nSize of vocabulary (integer)\n\n\nfilters\nSequence of characters to filter out such as punctuation. Default includes basic punctuation, tabs, and newlines.\n\n\nlower\nWhether to convert the input to lowercase.\n\n\nsplit\nSentence split marker (string).\n\n\ntext\nfor compatibility purpose. use input_text instead.\n\n\n\n\n\n\nList of integers in [1, n]. Each integer encodes a word (unicity non-guaranteed).\n\n\n\nOther text preprocessing: make_sampling_table(), pad_sequences(), skipgrams(), text_hashing_trick(), text_to_word_sequence()"
  },
  {
    "objectID": "packages/keras/latest/reference/text_to_word_sequence.html",
    "href": "packages/keras/latest/reference/text_to_word_sequence.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Convert text to a sequence of words (or tokens).\n\n\nConvert text to a sequence of words (or tokens).\n\n\n\ntext_to_word_sequence(\n  text,\n  filters = \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\",\n  lower = TRUE,\n  split = \" \"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntext\nInput text (string).\n\n\nfilters\nSequence of characters to filter out such as punctuation. Default includes basic punctuation, tabs, and newlines.\n\n\nlower\nWhether to convert the input to lowercase.\n\n\nsplit\nSentence split marker (string).\n\n\n\n\n\n\nWords (or tokens)\n\n\n\nOther text preprocessing: make_sampling_table(), pad_sequences(), skipgrams(), text_hashing_trick(), text_one_hot()"
  },
  {
    "objectID": "packages/keras/latest/reference/text_tokenizer.html",
    "href": "packages/keras/latest/reference/text_tokenizer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Text tokenization utility\n\n\nVectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf…\n\n\n\ntext_tokenizer(\n  num_words = NULL,\n  filters = \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\",\n  lower = TRUE,\n  split = \" \",\n  char_level = FALSE,\n  oov_token = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nnum_words\nthe maximum number of words to keep, based on word frequency. Only the most common num_words words will be kept.\n\n\nfilters\na string where each element is a character that will be filtered from the texts. The default is all punctuation, plus tabs and line breaks, minus the ’ character.\n\n\nlower\nboolean. Whether to convert the texts to lowercase.\n\n\nsplit\ncharacter or string to use for token splitting.\n\n\nchar_level\nif TRUE, every character will be treated as a token\n\n\noov_token\nNULL or string If given, it will be added to `word_index`` and used to replace out-of-vocabulary words during text_to_sequence calls.\n\n\n\n\n\n\nBy default, all punctuation is removed, turning the texts into space-separated sequences of words (words maybe include the ’ character). These sequences are then split into lists of tokens. They will then be indexed or vectorized. 0 is a reserved index that won’t be assigned to any word.\n\n\n\nOther text tokenization: fit_text_tokenizer(), save_text_tokenizer(), sequences_to_matrix(), texts_to_matrix(), texts_to_sequences_generator(), texts_to_sequences()"
  },
  {
    "objectID": "packages/keras/latest/reference/texts_to_matrix.html",
    "href": "packages/keras/latest/reference/texts_to_matrix.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Convert a list of texts to a matrix.\n\n\nConvert a list of texts to a matrix.\n\n\n\ntexts_to_matrix(tokenizer, texts, mode = c(\"binary\", \"count\", \"tfidf\", \"freq\"))\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntokenizer\nTokenizer\n\n\ntexts\nVector/list of texts (strings).\n\n\nmode\none of “binary”, “count”, “tfidf”, “freq”.\n\n\n\n\n\n\nA matrix\n\n\n\nOther text tokenization: fit_text_tokenizer(), save_text_tokenizer(), sequences_to_matrix(), text_tokenizer(), texts_to_sequences_generator(), texts_to_sequences()"
  },
  {
    "objectID": "packages/keras/latest/reference/texts_to_sequences.html",
    "href": "packages/keras/latest/reference/texts_to_sequences.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transform each text in texts in a sequence of integers.\n\n\nOnly top “num_words” most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.\n\n\n\ntexts_to_sequences(tokenizer, texts)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntokenizer\nTokenizer\n\n\ntexts\nVector/list of texts (strings).\n\n\n\n\n\n\nOther text tokenization: fit_text_tokenizer(), save_text_tokenizer(), sequences_to_matrix(), text_tokenizer(), texts_to_matrix(), texts_to_sequences_generator()"
  },
  {
    "objectID": "packages/keras/latest/reference/texts_to_sequences_generator.html",
    "href": "packages/keras/latest/reference/texts_to_sequences_generator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transforms each text in texts in a sequence of integers.\n\n\nOnly top “num_words” most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.\n\n\n\ntexts_to_sequences_generator(tokenizer, texts)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntokenizer\nTokenizer\n\n\ntexts\nVector/list of texts (strings).\n\n\n\n\n\n\nGenerator which yields individual sequences\n\n\n\nOther text tokenization: fit_text_tokenizer(), save_text_tokenizer(), sequences_to_matrix(), text_tokenizer(), texts_to_matrix(), texts_to_sequences()"
  },
  {
    "objectID": "packages/keras/latest/reference/time_distributed.html",
    "href": "packages/keras/latest/reference/time_distributed.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "This layer wrapper allows to apply a layer to every temporal slice of an input\n\n\nThis layer wrapper allows to apply a layer to every temporal slice of an input\n\n\n\ntime_distributed(object, layer, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nWhat to compose the new Layer instance with. Typically a Sequential model or a Tensor (e.g., as returned by layer_input()). The return value depends on object. If object is: * missing or NULL, the Layer instance is returned. * a Sequential model, the model with an additional layer is returned. * a Tensor, the output tensor from layer_instance(object) is returned.\n\n\nlayer\na tf.keras.layers.Layer instance.\n\n\n…\nstandard layer arguments.\n\n\n\n\n\n\nEvery input should be at least 3D, and the dimension of index one of the first input will be considered to be the temporal dimension.\nConsider a batch of 32 video samples, where each sample is a 128x128 RGB image with channels_last data format, across 10 timesteps. The batch input shape is (32, 10, 128, 128, 3).\nYou can then use TimeDistributed to apply the same Conv2D layer to each of the 10 timesteps, independently:\nhtml\n\ninput <- layer_input(c(10, 128, 128, 3)) conv_layer <- layer_conv_2d(filters = 64, kernel_size = c(3, 3)) output <- input %>% time_distributed(conv_layer) output$shape # TensorShape([None, 10, 126, 126, 64]) html\n\nBecause TimeDistributed applies the same instance of Conv2D to each of the timestamps, the same set of weights are used at each timestamp.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed\n\nOther layer wrappers: bidirectional()"
  },
  {
    "objectID": "packages/keras/latest/reference/timeseries_dataset_from_array.html",
    "href": "packages/keras/latest/reference/timeseries_dataset_from_array.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset of sliding windows over a timeseries provided as array\n\n\nCreates a dataset of sliding windows over a timeseries provided as array\n\n\n\ntimeseries_dataset_from_array(\n  data,\n  targets,\n  sequence_length,\n  sequence_stride = 1L,\n  sampling_rate = 1L,\n  batch_size = 128L,\n  shuffle = FALSE,\n  ...,\n  seed = NULL,\n  start_index = NULL,\n  end_index = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata\narray or eager tensor containing consecutive data points (timesteps). The first axis is expected to be the time dimension.\n\n\ntargets\nTargets corresponding to timesteps in data. targets[i] should be the target corresponding to the window that starts at index i (see example 2 below). Pass NULL if you don’t have target data (in this case the dataset will only yield the input data).\n\n\nsequence_length\nLength of the output sequences (in number of timesteps).\n\n\nsequence_stride\nPeriod between successive output sequences. For stride s, output samples would start at index data[i], data[i + s], data[i + (2 * s)], etc.\n\n\nsampling_rate\nPeriod between successive individual timesteps within sequences. For rate r, timesteps data[i], data[i + r], … data[i + sequence_length] are used for create a sample sequence.\n\n\nbatch_size\nNumber of timeseries samples in each batch (except maybe the last one).\n\n\nshuffle\nWhether to shuffle output samples, or instead draw them in chronological order.\n\n\n…\nFor backwards and forwards compatibility, ignored presently.\n\n\nseed\nOptional int; random seed for shuffling.\n\n\nstart_index, end_index\nOptional int (1 based); data points earlier than start_index or later then end_index will not be used in the output sequences. This is useful to reserve part of the data for test or validation.\n\n\n\n\n\n\nThis function takes in a sequence of data-points gathered at equal intervals, along with time series parameters such as length of the sequences/windows, spacing between two sequence/windows, etc., to produce batches of timeseries inputs and targets.\n\n\n\nA tf.data.Dataset instance. If targets was passed, the dataset yields batches of two items: (batch_of_sequences, batch_of_targets). If not, the dataset yields only batch_of_sequences.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array"
  },
  {
    "objectID": "packages/keras/latest/reference/timeseries_generator.html",
    "href": "packages/keras/latest/reference/timeseries_generator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Utility function for generating batches of temporal data.\n\n\nUtility function for generating batches of temporal data.\n\n\n\ntimeseries_generator(\n  data,\n  targets,\n  length,\n  sampling_rate = 1,\n  stride = 1,\n  start_index = 0,\n  end_index = NULL,\n  shuffle = FALSE,\n  reverse = FALSE,\n  batch_size = 128\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata\nObject containing consecutive data points (timesteps). The data should be 2D, and axis 1 is expected to be the time dimension.\n\n\ntargets\nTargets corresponding to timesteps in data. It should have same length as data.\n\n\nlength\nLength of the output sequences (in number of timesteps).\n\n\nsampling_rate\nPeriod between successive individual timesteps within sequences. For rate r, timesteps data[i], data[i-r], … data[i - length] are used for create a sample sequence.\n\n\nstride\nPeriod between successive output sequences. For stride s, consecutive output samples would be centered around data[i], data[i+s], data[i+2*s], etc.\n\n\nstart_index, end_index\nData points earlier than start_index or later than end_index will not be used in the output sequences. This is useful to reserve part of the data for test or validation.\n\n\nshuffle\nWhether to shuffle output samples, or instead draw them in chronological order.\n\n\nreverse\nBoolean: if true, timesteps in each output sample will be in reverse chronological order.\n\n\nbatch_size\nNumber of timeseries samples in each batch (except maybe the last one).\n\n\n\n\n\n\nAn object that can be passed to generator based training functions (e.g. fit_generator()).ma"
  },
  {
    "objectID": "packages/keras/latest/reference/to_categorical.html",
    "href": "packages/keras/latest/reference/to_categorical.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Converts a class vector (integers) to binary class matrix.\n\n\nConverts a class vector (integers) to binary class matrix.\n\n\n\nto_categorical(y, num_classes = NULL, dtype = \"float32\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ny\nClass vector to be converted into a matrix (integers from 0 to num_classes).\n\n\nnum_classes\nTotal number of classes.\n\n\ndtype\nThe data type expected by the input, as a string\n\n\n\n\n\n\nE.g. for use with loss_categorical_crossentropy().\n\n\n\nA binary matrix representation of the input."
  },
  {
    "objectID": "packages/keras/latest/reference/train_on_batch.html",
    "href": "packages/keras/latest/reference/train_on_batch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Single gradient update or model evaluation over one batch of samples.\n\n\nSingle gradient update or model evaluation over one batch of samples.\n\n\n\ntrain_on_batch(object, x, y, class_weight = NULL, sample_weight = NULL)\n\ntest_on_batch(object, x, y, sample_weight = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nKeras model object\n\n\nx\ninput data, as an array or list of arrays (if the model has multiple inputs).\n\n\ny\nlabels, as an array.\n\n\nclass_weight\nnamed list mapping classes to a weight value, used for scaling the loss function (during training only).\n\n\nsample_weight\nsample weights, as an array.\n\n\n\n\n\n\nScalar training or test loss (if the model has no metrics) or list of scalars (if the model computes other metrics). The property model$metrics_names will give you the display labels for the scalar outputs.\n\n\n\nOther model functions: compile.keras.engine.training.Model(), evaluate.keras.engine.training.Model(), evaluate_generator(), fit.keras.engine.training.Model(), fit_generator(), get_config(), get_layer(), keras_model_sequential(), keras_model(), multi_gpu_model(), pop_layer(), predict.keras.engine.training.Model(), predict_generator(), predict_on_batch(), predict_proba(), summary.keras.engine.training.Model()"
  },
  {
    "objectID": "packages/keras/latest/reference/use_implementation.html",
    "href": "packages/keras/latest/reference/use_implementation.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Select a Keras implementation and backend\n\n\nSelect a Keras implementation and backend\n\n\n\nuse_implementation(implementation = c(\"keras\", \"tensorflow\"))\n\nuse_backend(backend = c(\"tensorflow\", \"cntk\", \"theano\", \"plaidml\"))\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nimplementation\nOne of “keras” or “tensorflow” (defaults to “keras”).\n\n\nbackend\nOne of “tensorflow”, “cntk”, or “theano” (defaults to “tensorflow”)\n\n\n\n\n\n\nKeras has multiple implementations (the original keras implementation and the implementation native to TensorFlow) and supports multiple backends (“tensorflow”, “cntk”, “theano”, and “plaidml”). These functions allow switching between the various implementations and backends.\nThe functions should be called after library(keras) and before calling other functions within the package (see below for an example).\nThe default implementation and backend should be suitable for most use cases. The “tensorflow” implementation is useful when using Keras in conjunction with TensorFlow Estimators (the tfestimators R package).\n\n\n\n\n# use the tensorflow implementation\nlibrary(keras)\nuse_implementation(\"tensorflow\")\n\n# use the cntk backend\nlibrary(keras)\nuse_backend(\"theano\")"
  },
  {
    "objectID": "packages/keras/latest/reference/with_custom_object_scope.html",
    "href": "packages/keras/latest/reference/with_custom_object_scope.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Provide a scope with mappings of names to custom objects\n\n\nProvide a scope with mappings of names to custom objects\n\n\n\nwith_custom_object_scope(objects, expr)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobjects\nNamed list of objects\n\n\nexpr\nExpression to evaluate\n\n\n\n\n\n\nThere are many elements of Keras models that can be customized with user objects (e.g. losses, metrics, regularizers, etc.). When loading saved models that use these functions you typically need to explicitily map names to user objects via the custom_objects parmaeter.\nThe with_custom_object_scope() function provides an alternative that lets you create a named alias for a user object that applies to an entire block of code, and is automatically recognized when loading saved models.\n\n\n\n\n# define custom metric\nmetric_top_3_categorical_accuracy <-\n  custom_metric(\"top_3_categorical_accuracy\", function(y_true, y_pred) {\n    metric_top_k_categorical_accuracy(y_true, y_pred, k = 3)\n  })\n\nwith_custom_object_scope(c(top_k_acc = sparse_top_k_cat_acc), {\n\n  # ...define model...\n\n  # compile model (refer to \"top_k_acc\" by name)\n  model %>% compile(\n    loss = \"binary_crossentropy\",\n    optimizer = optimizer_nadam(),\n    metrics = c(\"top_k_acc\")\n  )\n\n  # save the model\n  save_model_hdf5(\"my_model.h5\")\n\n  # loading the model within the custom object scope doesn't\n  # require explicitly providing the custom_object\n  load_model_hdf5(\"my_model.h5\")\n})"
  },
  {
    "objectID": "packages/keras/latest/reference/zip_lists.html",
    "href": "packages/keras/latest/reference/zip_lists.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "zip lists\n\n\nThis is conceptually similar to zip() in Python, or R functions purrr::transpose() and data.table::transpose() (albeit, accepting elements in ... instead of a single list), with one crucial difference: if the provided objects are named, then matching is done by names, not positions.\n\n\n\nzip_lists(...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nR lists or atomic vectors, optionally named.\n\n\n\n\n\n\nAll arguments supplied must be of the same length. If positional matching is required, then all arguments provided must be unnamed. If matching by names, then all arguments must have the same set of names, but they can be in different orders.\n\n\n\nA inverted list\n\n\n\ngradients <- list(\"grad_for_wt_1\", \"grad_for_wt_2\", \"grad_for_wt_3\")\nweights <- list(\"weight_1\", \"weight_2\", \"weight_3\")\nstr(zip_lists(gradients, weights))\nstr(zip_lists(gradient = gradients, weight = weights))\n\nnames(gradients) <- names(weights) <- paste0(\"layer_\", 1:3)\nstr(zip_lists(gradients, weights[c(3, 1, 2)]))\n\nnames(gradients) <- paste0(\"gradient_\", 1:3)\ntry(zip_lists(gradients, weights)) # error, names don't match\n# call unname directly for positional matching\nzip_lists(unname(gradients), unname(weights))"
  },
  {
    "objectID": "packages/tensorflow/latest/news.html",
    "href": "packages/tensorflow/latest/news.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tensorflow 2.9.0\n\nGeneric method updates:\n\nNew methods: all(), any(), sum(), prod(), min(), max(), mean(), range(), cbind(), rbind(), t(), aperm(), sort(), as.vector(), as.character(), as.raster(), is.infinite(), is.finite(), is.nan()\n^ will now invoke tf.square() or tf.sqrt() directly when appropriate\n|, &, and ! now cast arguments to ‘bool’ dtype.\nprint() now shows 1d shapes without a trailing commas.\nstr() method for tensors now returns only a single compact line; str() on a list of tensors now does something sensible.\n\ninstall_tensorflow() now install TensorFlow 2.9 by default.\ninstall_tensorflow() no longer requires conda on Windows, now works in a regular venv.\nComparing two partially-defined TensorShape now returns TRUE if each dimension matches. e.g.: shape(NA, 4) == shape(NA, 4) now returns TRUE, previously FALSE.\nTensors with dtype ‘string’ now convert to R character vectors by methods as.array() and as.matrix(). (previously they converted to python.builtin.bytes, or an R list of python.builtin.bytes objects)\nas_tensor():\n\natomic R integer vectors now convert to ‘int32’, not ‘int64’\ncasting between integer and floating dtypes is now done via tf$dtypes$saturate_cast() instead of tf$cast().\nshape argument now accepts a tensor.\nfixed issue where expanding a scalar tensor to an nd-array with shape provided as a tensor would raise an error.\n\ntf.SparseTensor objects now inherit from \"tensorflow.tensor\".\n\n\n\ntensorflow 2.8.0\n\nUpdated default Tensorflow version installed by install_tensorflow() to 2.8.\nas_tensor() gains a shape argument, can be used to fill or reshape tensors. Scalars can be recycled to a tensor of arbitrary shape, otherwise supplied objects are reshaped using row-major (C-style) semantics.\ninstall_tensorflow() now provides experimental support for Arm Macs, with the following restrictions:\n\n“conda” is the only supported installation method.\nrequests for non-default or older tensorflow versions are not supported.\n\ninstall_tensorflow() default conda_python_version changes from 3.7 to NULL.\ntf.TensorShape()’s gain format() and print() S3 methods.\n[ method for slicing tensors now accepts NA as a synonym for a missing or NULL spec. For example x[NA:3] is now valid, equivalent to x[:3] in Python.\n\n\n\ntensorflow 2.7.0\n\nDefault Tensorflow version installed by install_tensorflow() updated to 2.7\nBreaking changes:\n\nshape() now returns a tf.TensorShape() object (Previously an R-list of NULLs or integers).\n[ method for tf.TensorShape() objects also now returns a tf.TensorShape(). Use [[, as.numeric, as.integer, and/or as.list to convert to R objects.\nlength() method for tensorflow.tensor now returns NA_integer_ for tensors with not fully defined shapes. (previously a zero length integer vector).\ndim() method for tensorflow.tensor now returns an R integer vector with NA for dimensions that are undefined. (previously an R list with NULL for undefined dimension)\n\nNew S3 generics for tf.TensorShape()’s: c, length, [<-, [[<-, merge, ==, !=, as_tensor(), as.list, as.integer, as.numeric, as.double, py_str (joining previous generics [ and [[). See ?shape for extended examples.\nOps S3 generics for tensorflow.tensors that take two arguments now automatically cast a supplied non-tensor to the dtype of the supplied tensor that triggered the S3 dispatch. Casting is done via as_tensor(). e.g., this now works: as_tensor(5L) - 2     # now returns tf.Tensor(3, shape=(), dtype=int32) previously it would raise an error: TypeError: `x` and `y` must have the same dtype, got tf.int32 != tf.float32 Generics that now do autocasting: +, -, *, /, %/%, %%, ^, &, |, ==, !=, <, <=, >, >=\ninstall_tensorflow(): new argument with default pip_ignore_installed = TRUE. This ensures that all Tensorflow dependencies like Numpy are installed by pip rather than conda.\nA message with the Tensorflow version is now shown when the python module is loaded, e.g: “Loaded Tensorflow version 2.6.0”\n\n\n\ntensorflow 2.6.0\n\nUpdated default Tensorflow version to 2.6.\nChanged default in tf_function() to autograph=TRUE.\nAdded S3 generic as_tensor().\ntfautograph added to Imports\njsonlite removed from Imports, tfestimators removed from Suggests\nRefactored install_tensorflow().\n\nPotentially breaking change: numeric versions supplied without a patchlevel now automatically pull the latest patch release. (e.g. install_tensorflow(version=\"2.4\") will install \"2.4.2\". Previously it would install “2.4.0”)\n\nRemoved “Config/reticulate” declaration from DESCRIPTION.\n\nSetting RETICULATE_AUTOCONFIGURE=FALSE environment variable when using non-default tensorflow installations (e.g., ‘tensorflow-cpu’) no longer required.\nUsers will have to call install_tensorflow() for automatic installation.\n\nRefactored automated tests to closer match the default installation procedure and compute environment of most user.\nExpanded CI test coverage to include R devel, oldrel and 3.6.\nFixed an issue where extra packages with version constraints like install_tensorflow(extra_packages = \"Pillow<8.3\") were not quoted properly.\nFixed an issue where valid tensor-like objects supplied to log(x, base), cospi(), tanpi(), and sinpi() would raise an error.\n\n\n\ntensorflow 2.5.0\n\nUpdated default Tensorflow version to 2.5.\nAdded support for additional arguments in tf_function() (e.g., jit_compile)\nAdded support for expm1 S3 generic.\ntfe_enable_eager_execution is deprecated. Eager mode has been the default since TF version 2.0.\nImproved error message in tf_config() on unsuccessful installation.\n\n\n\ntensorflow 2.4.0\n\nFixed error with use_session_with_seed (#428)\nAdded a new set_random_seed function that makes more sense for TensorFlow >= 2.0 (#442)\nUpdated the default version of TensorFlow to 2.4 as well as the default Python to 3.7 (#454)\n\n\n\nTensorFlow 2.2.0 (CRAN)\n\nBugfix with all_dims (#398)\nIndexing for TensorShape & py_to_r conversion (#379, #388)\n\n\n\nTensorFlow 2.0.0 (CRAN)\n\nUpgraded default installed version to 2.0.0.\nTensorboard log directory path fixes (#360).\nAllow for v1 and v2 compat (#358).\ninstall_tensorflow now does not installs tfprobability, tfhub and other related packages.\n\n\n\nTensorFlow 1.14.1 (CRAN)\n\nUpgraded default installed version to 1.14.0\nRefactored the install_tensorflow code delegating to reticulate (#333, #341): We completely delegate to installation to reticulate::py_install, the main difference is that now the default environment name to install is r-reticulate and not r-tensorflow.\n\n\n\nTensorFlow 1.13.1 (CRAN)\n\nadded option to silence TF CPP info output\ntf_gpu_configured function to check if GPU was correctly"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/all_dims.html",
    "href": "packages/tensorflow/latest/reference/all_dims.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "All dims\n\n\nThis function returns an object that can be used when subsetting tensors with [. If you are familiar with python,, this is equivalent to the python Ellipsis ..., (not to be confused with ... in R).\n\n\n\nall_dims()\n\n\n\n\n# in python, if x is a numpy array or tensorflow tensor\nx[..., i]\n# the ellipsis means \"expand to match number of dimension of x\".\n# to translate the above python expression to R, write:\nx[all_dims(), i]"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/as_tensor.html",
    "href": "packages/tensorflow/latest/reference/as_tensor.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "as_tensor\n\n\nCoerce objects to tensorflow tensors (potentially of a specific dtype or shape). The provided default methods will call https://www.tensorflow.org/api_docs/python/tf/convert_to_tensortf$convert_to_tensor. Depending on arguments supplied it may also call some combination of\n\nhttps://www.tensorflow.org/api_docs/python/tf/dtypes/saturate_castlist(“tf\\(saturate_cast\") or https://www.tensorflow.org/api_docs/python/tf/castlist(\"tf\\)cast”)\nhttps://www.tensorflow.org/api_docs/python/tf/filllist(“tf\\(fill\") or https://www.tensorflow.org/api_docs/python/tf/reshapelist(\"tf\\)reshape”)\n\n\n\n\nas_tensor(x, dtype = NULL, …, name = NULL)\nas_tensordefault(x, dtype = NULL, …, shape = NULL, name = NULL)\nas_tensordouble(x, dtype = NULL, …, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nobject to convert\n\n\ndtype\nNULL, a tensorflow dtype (tf$int32), or something coercible to one (e.g. a string \"int32\")\n\n\n…,\nignored\n\n\nname\nNULL or a string. Useful for debugging in graph mode, ignored while in eager mode.\n\n\nshape\nan integer vector, tensor, or tf.TensorShape. Can contain up to 1 unspecified dimension, encoded as a -1 or NA. This will reshape x using row-major (C-style) semantics. It will prefer reshaping using non-graph operations if possible, but will otherwise invoke tf$reshape(). If x is a scalar and the requested shape is fully defined or a tensor, the value of x will be recycled to fill a tensor of the requested shape (it will dispatch to tf$fill()).\n\n\n\n\n\n\na tensorflow tensor\n\n\n\n\nas_tensor(42, \"int32\")\nas_tensor(as_tensor(42))"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/evaluate.html",
    "href": "packages/tensorflow/latest/reference/evaluate.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Evaluate a Model\n\n\nEvaluate a model object. See implementations in the keras and tfestimators packages.\n\n\n\nevaluate(object, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nAn evaluatable object.\n\n\n…\nOptional arguments passed on to implementing methods."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/export_savedmodel.html",
    "href": "packages/tensorflow/latest/reference/export_savedmodel.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Export a Saved Model\n\n\nSerialize a model to disk. See implementations in the keras and tfestimators packages.\n\n\n\nexport_savedmodel(object, export_dir_base, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nAn object.\n\n\nexport_dir_base\nA string containing a directory in which to export the SavedModel.\n\n\n…\nOptional arguments passed on to implementing methods.\n\n\n\n\n\n\nThe path to the exported directory, as a string."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/index.html",
    "href": "packages/tensorflow/latest/reference/index.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\ninstall_tensorflow()\nInstall TensorFlow and its dependencies\n\n\ntf_config() tf_version()\nTensorFlow configuration information"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/index.html#configuration",
    "href": "packages/tensorflow/latest/reference/index.html#configuration",
    "title": "TensorFlow for R",
    "section": "Configuration",
    "text": "Configuration\n\n\n\nFunction(s)\nDescription\n\n\n\n\nparse_flags()\nParse Configuration Flags for a TensorFlow Application\n\n\nparse_arguments()\nParse Command Line Arguments"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/index.html#tensorflow-api",
    "href": "packages/tensorflow/latest/reference/index.html#tensorflow-api",
    "title": "TensorFlow for R",
    "section": "TensorFlow API",
    "text": "TensorFlow API\n\n\n\nFunction(s)\nDescription\n\n\n\n\ntf\nMain TensorFlow module\n\n\nshape()\nCreate a tf.TensorShape object"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/index.html#utilities",
    "href": "packages/tensorflow/latest/reference/index.html#utilities",
    "title": "TensorFlow for R",
    "section": "Utilities",
    "text": "Utilities\n\n\n\nFunction(s)\nDescription\n\n\n\n\ntensorboard()\nTensorBoard Visualization Tool\n\n\nuse_session_with_seed()\nUse a session with a random seed"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/install_tensorflow.html",
    "href": "packages/tensorflow/latest/reference/install_tensorflow.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Install TensorFlow and its dependencies\n\n\ninstall_tensorflow() installs just the tensorflow python package and it’s direct dependencies. For a more complete installation that includes additional optional dependencies, use keras::install_keras().\n\n\n\ninstall_tensorflow(\n  method = c(\"auto\", \"virtualenv\", \"conda\"),\n  conda = \"auto\",\n  version = \"default\",\n  envname = NULL,\n  extra_packages = NULL,\n  restart_session = TRUE,\n  conda_python_version = NULL,\n  ...,\n  pip_ignore_installed = TRUE,\n  python_version = conda_python_version\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmethod\nInstallation method. By default, “auto” automatically finds a method that will work in the local environment. Change the default to force a specific installation method. Note that the “virtualenv” method is not available on Windows.\n\n\nconda\nThe path to a conda executable. Use \"auto\" to allow reticulate to automatically find an appropriate conda binary. See Finding Conda and conda_binary() for more details.\n\n\nversion\nTensorFlow version to install. Valid values include: * \"default\" installs 2.9 * \"release\" installs the latest release version of tensorflow (which may be incompatible with the current version of the R package) * A version specification like \"2.4\" or \"2.4.0\". Note that if the patch version is not supplied, the latest patch release is installed (e.g., \"2.4\" today installs version “2.4.2”) * nightly for the latest available nightly build. * To any specification, you can append “-cpu” to install the cpu version only of the package (e.g., \"2.4-cpu\") * The full URL or path to a installer binary or python *.whl file.\n\n\nenvname\nThe name, or full path, of the environment in which Python packages are to be installed. When NULL (the default), the active environment as set by the RETICULATE_PYTHON_ENV variable will be used; if that is unset, then the r-reticulate environment will be used.\n\n\nextra_packages\nAdditional Python packages to install along with TensorFlow.\n\n\nrestart_session\nRestart R session after installing (note this will only occur within RStudio).\n\n\n…\nother arguments passed to reticulate::conda_install() or reticulate::virtualenv_install(), depending on the method used.\n\n\npip_ignore_installed\nWhether pip should ignore installed python packages and reinstall all already installed python packages. This defaults to TRUE, to ensure that TensorFlow dependencies like NumPy are compatible with the prebuilt TensorFlow binaries.\n\n\npython_version, conda_python_version\nPass a string like “3.8” to request that conda install a specific Python version. This is ignored when attempting to install in a Python virtual environment. Note that the Python version must be compatible with the requested Tensorflow version, documented here: https://www.tensorflow.org/install/pip#system-requirements\n\n\n\n\n\n\nYou may be prompted to download and install miniconda if reticulate did not find a non-system installation of python. Miniconda is the recommended installation method for most users, as it ensures that the R python installation is isolated from other python installations. All python packages will by default be installed into a self-contained conda or venv environment named “r-reticulate”. Note that “conda” is the only supported method on M1 Mac.\nIf you initially declined the miniconda installation prompt, you can later manually install miniconda by running reticulate::install_miniconda().\n\n\n\nkeras::install_keras()"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/install_tensorflow_extras.html",
    "href": "packages/tensorflow/latest/reference/install_tensorflow_extras.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Defunct) Install additional Python packages alongside TensorFlow\n\n\nThis function is deprecated. Use the extra_packages argument to install_tensorflow() or reticulate::py_install() to install additional packages.\n\n\n\ninstall_tensorflow_extras(packages, conda = \"auto\")\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npackages\nPython packages to install\n\n\nconda\nPath to conda executable (or “auto” to find conda using the PATH and other conventional install locations). Only used when TensorFlow is installed within a conda environment."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/parse_arguments.html",
    "href": "packages/tensorflow/latest/reference/parse_arguments.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Parse Command Line Arguments\n\n\nParse command line arguments of the form --key=value and –key value. The values are assumed to be valid yaml and will be converted using yaml.load().\n\n\n\nparse_arguments(arguments = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\narguments\nA vector of command line arguments. When NULL (the default), the command line arguments received by the current process are used."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/parse_flags.html",
    "href": "packages/tensorflow/latest/reference/parse_flags.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Parse Configuration Flags for a TensorFlow Application\n\n\nParse configuration flags for a TensorFlow application. Use this to parse and unify the configuration(s) specified through a flags.yml configuration file, alongside other arguments set through the command line.\n\n\n\nparse_flags(\n  config = Sys.getenv(\"R_CONFIG_ACTIVE\", unset = \"default\"),\n  file = \"flags.yml\",\n  arguments = commandArgs(TRUE)\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nconfig\nThe configuration to use. Defaults to the active configuration for the current environment (as specified by the R_CONFIG_ACTIVE environment variable), or default when unset.\n\n\nfile\nThe configuration file to read.\n\n\narguments\nThe command line arguments (as a character vector) to be parsed.\n\n\n\n\n\n\nA named list, mapping configuration keys to values.\n\n\n\n\n# examine an example configuration file provided by tensorflow\nfile <- system.file(\"examples/config/flags.yml\", package = \"tensorflow\")\ncat(readLines(file), sep = \"\\n\")\n\n# read the default configuration\nFLAGS <- tensorflow::parse_flags(\"default\", file = file)\nstr(FLAGS)\n\n# read the alternate configuration: note that\n# the default configuration is inherited, but\n# we override the 'string' configuration here\nFLAGS <- tensorflow::parse_flags(\"alternate\", file = file)\nstr(FLAGS)\n\n# override configuration values using command\n# line arguments (normally, these would be\n# passed in through the command line invocation\n# used to start the process)\nFLAGS <- tensorflow::parse_flags(\n  \"alternate\",\n  file = file,\n  arguments = c(\"--foo=1\")\n)\nstr(FLAGS)"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/reexports.html",
    "href": "packages/tensorflow/latest/reference/reexports.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Objects exported from other packages\n\n\nThese objects are imported from other packages. Follow the links below to see their documentation."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/set_random_seed.html",
    "href": "packages/tensorflow/latest/reference/set_random_seed.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Set random seed for TensorFlow\n\n\nSets all random seeds needed to make TensorFlow code reproducible.\n\n\n\nset_random_seed(seed, disable_gpu = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nA single value, interpreted as an integer\n\n\ndisable_gpu\nTRUE to disable GPU execution (see Parallelism below).\n\n\n\n\n\n\nThis function should be used instead of use_session_with_seed() if you are using TensorFlow >= 2.0, as the concept of session doesn’t really make sense anymore.\nThis functions sets:\n\nThe R random seed with set.seed().\nThe python and Numpy seeds via (reticulate::py_set_seed()).\nThe TensorFlow seed with (tf$random$set_seed())\n\nIt also optionally disables the GPU execution as this is a potential source of non-reproducibility."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/shape.html",
    "href": "packages/tensorflow/latest/reference/shape.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create a tf.TensorShape object\n\n\nCreate a tf.TensorShape object\n\n\n\nshape(..., dims = list(...))\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nTensor dimensions as integers or NULL for an unknown dimensions. NA and -1 are synonyms for NULL.\n\n\ndims\nTensor dimensions as a vector.\n\n\n\n\n\n\n\n\n# --- construct ---\nshape()       # tf.TensorShape()       # scalar\nshape(NULL)   # tf.TensorShape([None]) # 1-D array of unknown length\nshape(NA)     # tf.TensorShape([None]) # 1-D array of unknown length, NA is a synonym for NULL\n\nshape(dims = NULL) # TensorShape(None)    # Unknown rank, unknown size\nshape(3, 4)        # TensorShape([3, 4])  # 2-D array (matrix) with 3 rows, 4 columns\nshape(NA, 4)           # TensorShape([None, 4])  # 2-D array (matrix) with unknown rows, 4 columns\nshape(dims = c(NA, 4)) # TensorShape([None, 4]) # same as above; bypass ... and pass dims directly\n\n# --- inspect ---\nlength(shape(dims = NULL)) # NA_integer_\nlength(shape(1,2,3,NA))    # 4L\n\n# ---convert ---\nx <- shape(dims = list(3L, 5L))\nas.list(x)     # list(3L, 5L)\nas.integer(x)  # c(3L, 5L)\nas.numeric(x)  # c(3, 5)\nas.double(x)   # c(3, 5) # alias for as.numeric\nas_tensor(x)   # tf.Tensor([3 5], shape=(2,), dtype=int32)\n\n# convert partially undefined shapes\nx <- shape(NA, 3)\nas.list(x)     # list(NULL, 3L)\nas.integer(x)  # c(NA, 3L)\nas_tensor(x)   # tf.Tensor([-1  3], shape=(2,), dtype=int32) # unspecified dims default is -1\n\n# as_tensor() converts undefined dimensions to -1, which is useful for\n# tf functions that only accept tensors for shapes, e.g,\ntf$reshape(tf$zeros(shape(8)),\n           as_tensor(shape(NA, 4)))\n# tf.Tensor([[0. 0. 0. 0.]\n#            [0. 0. 0. 0.]], shape=(2, 4), dtype=float32)\n\n# converting fully unknown shapes raises an error\ntry(as.list(shape(dims = NULL))) # ValueError: as_list() is not defined on an unknown TensorShape.\n# test for rank first if this a concern:\nas.list_or_null <- function(x) if(is.na(length(x))) NULL else as.list(x)\nas.list_or_null(shape(dims = NULL))\n\n\n# --- compare ---\n# Fully known shapes return TRUE if and only if each element is equal\nshape(3, 4) == shape(3, 4) # TRUE\nshape(3, 4) == shape(4, 4) # FALSE\n\n# two unknown dimensions are treated as equal\nshape(NA, 4) == shape(NA, 4) # TRUE\nshape(NA, 4) == shape(3, 4)  # FALSE\n\n# Two unknown shapes, return TRUE\nshape(dims = NULL) == shape(dims = NULL) # TRUE\n\n# Comparing an unknown shape to a partially or fully defined shape returns FALSE\nshape(dims = NULL) == shape(NULL) # FALSE\nshape(dims = NULL) == shape(4)    # FALSE\n\n\nvalues of length greater than one supplied to `...`  are automatically flattened\nshape(1, c(2, 3), 4) # shape(1, 2, 3, 4)\nshape(1, shape(2, 3), 4) # shape(1, 2, 3, 4)\nshape(1, as_tensor(2, 3), 4) # shape(1, 2, 3, 4)\n\n# --- extract or replace ---\n# regular R-list semantics for `[`, `[[`, `[<-`, `[[<-`\nx <- shape(1, 2, 3)\nx[1]       # TensorShape([1])\nx[[1]]     # 1L\nx[2:3]     # TensorShape([2, 3])\nx[-1]      # TensorShape([2, 3])\n\nx[1] <- 11        ; x # TensorShape([11, 2, 3])\nx[1] <- shape(11) ; x # TensorShape([11, 2, 3])\nx[1] <- list(11)  ; x # TensorShape([11, 2, 3])\n\nx[[1]] <- 22            ; x # TensorShape([22, 2, 3])\nx[1:2] <- c(NA, 99)     ; x # TensorShape([None, 99, 3])\nx[1:2] <- shape(33, 44) ; x # TensorShape([33, 44, 3])\n\n# --- concatenate ---\nc(shape(1), shape(2, 3), shape(4, NA)) # TensorShape([1, 2, 3, 4, None])\n\n# --- merge ---\nmerge(shape(NA, 2),\n      shape(1 , 2)) # TensorShape([1, 2])\n\ntry(merge(shape(2, 2),\n          shape(1, 2))) # ValueError: Shapes (2, 2) and (1, 2) are not compatible\n\nrm(x) # cleanup\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/TensorShape"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/sub-.tensorflow.tensor.html",
    "href": "packages/tensorflow/latest/reference/sub-.tensorflow.tensor.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "negative numbers are always interpreted python style\n\n\nThe first time a negative number is supplied to [, a warning is issued\n\n\nabout the non-standard behavior.\nx[-1,] # last row, with a warning x[-1,] # the warning is only issued once\n\n\nspecifying style = 'python' changes the following:\n\n\n+ zero-based indexing is used\n\n\n+ slice sequences in the form of start:stop do not include stop\n\n\nin the returned value\n\n\n+ out-of-bounds indices in a slice are valid\n\n\nThe style argument can be supplied to individual calls of [ or set\n\n\nas a global option\n\n\nexample of zero based indexing\nx[0, , style = ‘python’] # first row x[1, , style = ‘python’] # second row\n\n\nexample of slices with exclusive stop\noptions(tensorflow.extract.style = ‘python’) x[, 0:1] # just the first column x[, 0:2] # first and second column\n\n\nexample of out-of-bounds index\nx[, 0:10] options(tensorflow.extract.style = NULL)\n\n\nslicing with tensors is valid too, but note, tensors are never\n\n\ntranslated and are always interpreted python-style.\n\n\nA warning is issued the first time a tensor is passed to [\nx[, tf\\(constant(0L):tf\\)constant(2L)] # just as in python, only scalar tensors are valid # https://www.tensorflow.org/api_docs/python/tf/Tensor#getitem\n\n\nTo silence the warnings about tensors being passed as-is and negative numbers\n\n\nbeing interpreted python-style, set\noptions(tensorflow.extract.style = ‘R’)\n\n\nclean up from examples\noptions(tensorflow.extract.style = NULL)\n```"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tensorboard.html",
    "href": "packages/tensorflow/latest/reference/tensorboard.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TensorBoard Visualization Tool\n\n\nTensorBoard is a tool inspecting and understanding your TensorFlow runs and graphs.\n\n\n\ntensorboard(\n  log_dir,\n  action = c(\"start\", \"stop\"),\n  host = \"127.0.0.1\",\n  port = \"auto\",\n  launch_browser = getOption(\"tensorflow.tensorboard.browser\", interactive()),\n  reload_interval = 5,\n  purge_orphaned_data = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlog_dir\nDirectories to scan for training logs. If this is a named character vector then the specified names will be used as aliases within TensorBoard.\n\n\naction\nSpecify whether to start or stop TensorBoard (TensorBoard will be stopped automatically when the R session from which it is launched is terminated).\n\n\nhost\nHost for serving TensorBoard\n\n\nport\nPort for serving TensorBoard. If “auto” is specified (the default) then an unused port will be chosen automatically.\n\n\nlaunch_browser\nOpen a web browser for TensorBoard after launching. Defaults to TRUE in interactive sessions. When running under RStudio uses an RStudio window by default (pass a function e.g. utils::browseURL() to open in an external browser). Use the tensorflow.tensorboard.browser option to establish a global default behavior.\n\n\nreload_interval\nHow often the backend should load more data.\n\n\npurge_orphaned_data\nWhether to purge data that may have been orphaned due to TensorBoard restarts. Disabling purge_orphaned_data can be used to debug data disappearance.\n\n\n\n\n\n\nWhen TensorBoard is passed a logdir at startup, it recursively walks the directory tree rooted at logdir looking for subdirectories that contain tfevents data. Every time it encounters such a subdirectory, it loads it as a new run, and the frontend will organize the data accordingly.\nThe TensorBoard process will be automatically destroyed when the R session in which it is launched exits. You can pass action = \"stop\" to manually terminate TensorBoard.\n\n\n\nURL for browsing TensorBoard (invisibly)."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tensorflow.html",
    "href": "packages/tensorflow/latest/reference/tensorflow.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TensorFlow for R\n\n\nhttps://www.tensorflow.orgTensorFlow is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API.\n\n\n\nThe https://www.tensorflow.org/api_docs/python/tf/all_symbolsTensorFlow API is composed of a set of Python modules that enable constructing and executing TensorFlow graphs. The tensorflow package provides access to the complete TensorFlow API from within R.\nFor additional documentation on the tensorflow package see https://tensorflow.rstudio.comhttps://tensorflow.rstudio.com"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tf.html",
    "href": "packages/tensorflow/latest/reference/tf.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Main TensorFlow module\n\n\nInterface to main TensorFlow module. Provides access to top level classes and functions as well as sub-modules (e.g. tf$nn, tf$contrib$learn, etc.).\n\n\n\ntf\n\n\n\n\nlibrary(tensorflow)\n\nhello <- tf$constant('Hello, TensorFlow!')\nzeros <- tf$Variable(tf$zeros(shape(1L)))\n\ntf$print(hello)\ntf$print(zeros)"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tf_config.html",
    "href": "packages/tensorflow/latest/reference/tf_config.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TensorFlow configuration information\n\n\nTensorFlow configuration information\n\n\n\ntf_config()\n\ntf_version()\n\n\n\nList with information on the current configuration of TensorFlow. You can determine whether TensorFlow was found using the available member (other members vary depending on whether available is TRUE or FALSE)"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tf_extract_opts.html",
    "href": "packages/tensorflow/latest/reference/tf_extract_opts.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Tensor extract options\n\n\nTensor extract options\n\n\n\ntf_extract_opts(\n  style = getOption(\"tensorflow.extract.style\"),\n  ...,\n  one_based = getOption(\"tensorflow.extract.one_based\", TRUE),\n  inclusive_stop = getOption(\"tensorflow.extract.inclusive_stop\", TRUE),\n  disallow_out_of_bounds = getOption(\"tensorflow.extract.dissallow_out_of_bounds\",\n    TRUE),\n  warn_tensors_passed_asis = getOption(\"tensorflow.extract.warn_tensors_passed_asis\",\n    TRUE),\n  warn_negatives_pythonic = getOption(\"tensorflow.extract.warn_negatives_pythonic\",\n    TRUE)\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nstyle\none of NULL (the default) \"R\" or \"python\". If supplied, this overrides all other options. \"python\" is equivalent to all the other arguments being FALSE. \"R\" is equivalent to warn_tensors_passed_asis and warn_negatives_pythonic set to FALSE\n\n\n…\nignored\n\n\none_based\nTRUE or FALSE, if one-based indexing should be used\n\n\ninclusive_stop\nTRUE or FALSE, if slices like start:stop should be inclusive of stop\n\n\ndisallow_out_of_bounds\nTRUE or FALSE, whether checks are performed on the slicing index to ensure it is within bounds.\n\n\nwarn_tensors_passed_asis\nTRUE or FALSE, whether to emit a warning the first time a tensor is supplied to [ that tensors are passed as-is, with no R to python translation\n\n\nwarn_negatives_pythonic\nTRUE or FALSE, whether to emit a warning the first time a negative number is supplied to [ about the non-standard (python-style) interpretation\n\n\n\n\n\n\nan object with class “tf_extract_opts”, suitable for passing to [.tensorflow.tensor()\n\n\n\n\nx <- tf$constant(1:10)\n\nopts <-  tf_extract_opts(\"R\")\nx[1, options = opts]\n\n# or for more fine-grained control\nopts <- tf_extract_opts(\n    one_based = FALSE,\n    warn_tensors_passed_asis = FALSE,\n    warn_negatives_pythonic = FALSE\n)\nx[0:2, options = opts]"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tf_function.html",
    "href": "packages/tensorflow/latest/reference/tf_function.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a callable TensorFlow graph from an R function.\n\n\ntf_function constructs a callable that executes a TensorFlow graph created by tracing the TensorFlow operations in f. This allows the TensorFlow runtime to apply optimizations and exploit parallelism in the computation defined by f.\n\n\n\ntf_function(f, input_signature = NULL, autograph = TRUE, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nf\nthe function to be compiled\n\n\ninput_signature\nA possibly nested sequence of tf$TensorSpec objects specifying the shapes and dtypes of the tensors that will be supplied to this function. If NULL, a separate function is instantiated for each inferred input signature. If input_signature is specified, every input to f must be a tensor.\n\n\nautograph\nTRUE or FALSE. If TRUE (the default), you can use tensors in R control flow expressions if, while, for and break and they will be traced into the tensorflow graph. A guide to getting started and additional details can be found: https://t-kalinowski.github.io/tfautograph/here\n\n\n…\nadditional arguments passed on to tf.function (vary based on Tensorflow version). See https://www.tensorflow.org/api_docs/python/tf/function#args_1here for details.\n\n\n\n\n\n\nA guide to getting started with https://www.tensorflow.org/api_docs/python/tf/functiontf.function can be found https://www.tensorflow.org/guide/functionhere."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tf_gpu_configured.html",
    "href": "packages/tensorflow/latest/reference/tf_gpu_configured.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TensorFlow GPU configuration information\n\n\nTensorFlow GPU configuration information\n\n\n\ntf_gpu_configured(verbose = TRUE)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nverbose\nboolean. Wether to show extra GPU info.\n\n\n\n\n\n\nA bool, wether GPU is configured or not, or NA if could not be determined."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tf_probability.html",
    "href": "packages/tensorflow/latest/reference/tf_probability.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TensorFlow Probability Module\n\n\nTensorFlow Probability Module\n\n\n\ntf_probability()\n\n\n\nReference to https://www.tensorflow.org/probabilityTensorFlow Probability functions and classes\n\n\n\n\nlibrary(tensorflow)\ntfp <- tf_probability()\ntfp$distributions$Normal(loc=0, scale=1)"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/tfe_enable_eager_execution.html",
    "href": "packages/tensorflow/latest/reference/tfe_enable_eager_execution.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Enables, for the rest of the lifetime of this program, eager execution.\n\n\nThis function is no longer needed since Tensorflow 2.0, when eager execution became the default.\n\n\n\ntfe_enable_eager_execution(\n  config = NULL,\n  device_policy = c(\"explicit\", \"warn\", \"silent\")\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nconfig\n(Optional) A tf$ConfigProto() protocol buffer with configuration options for the Context. Note that a lot of these options may be currently unimplemented or irrelevant when eager execution is enabled.\n\n\ndevice_policy\n(Optional) What policy to use when trying to run an operation on a device with inputs which are not on that device. Valid values: “explicit”: raises an error if the placement is not correct. “warn”: copies the tensors which are not on the right device but raises a warning. “silent”: silently copies the tensors. This might hide performance problems.\n\n\n\n\n\n\nIf not called immediately on startup risks creating breakage and bugs.\nAfter eager execution is enabled, operations are executed as they are defined and tensors hold concrete values, and can be accessed as R matrices or arrays with as.matrix(), as.array(), as.double(), etc.\n\n\n\n\n\n# load tensorflow and enable eager execution\nlibrary(tensorflow)\ntfe_enable_eager_execution()\n\n# create a random 10x10 matrix\nx <- tf$random$normal(shape(10, 10))\n\n# use it in R via as.matrix()\nheatmap(as.matrix(x))"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/train.html",
    "href": "packages/tensorflow/latest/reference/train.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Train a Model\n\n\nTrain a model object. See implementation in the tfestimators package.\n\n\n\ntrain(object, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nA trainable object.\n\n\n…\nOptional arguments passed on to implementing methods."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/train_and_evaluate.html",
    "href": "packages/tensorflow/latest/reference/train_and_evaluate.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "(Deprecated) Simultaneously Train and Evaluate a Model\n\n\nTrain and evaluate a model object. See implementation in the tfestimators package.\n\n\n\ntrain_and_evaluate(object, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nAn object.\n\n\n…\nOptional arguments passed on to implementing methods."
  },
  {
    "objectID": "packages/tensorflow/latest/reference/use_compat.html",
    "href": "packages/tensorflow/latest/reference/use_compat.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Use Compatibility\n\n\nEnables TensorFlow to run under a different API version for compatibility with previous versions. For instance, this is useful to run TensorFlow 1.x code when using TensorFlow 2.x.\n\n\n\nuse_compat(version = c(\"v1\", \"v2\"))\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nversion\nThe version to activate. Must be \"v1\" or \"v2\"\n\n\n\n\n\n\n\nlibrary(tensorflow)\nuse_compat(\"v1\")"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/use_session_with_seed.html",
    "href": "packages/tensorflow/latest/reference/use_session_with_seed.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Use a session with a random seed\n\n\nSet various random seeds required to ensure reproducible results. The provided seed value will establish a new random seed for R, Python, NumPy, and TensorFlow. GPU computations and CPU parallelism will also be disabled by default.\n\n\n\nuse_session_with_seed(\n  seed,\n  disable_gpu = TRUE,\n  disable_parallel_cpu = TRUE,\n  quiet = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\nA single value, interpreted as an integer\n\n\ndisable_gpu\nTRUE to disable GPU execution (see Parallelism below).\n\n\ndisable_parallel_cpu\nTRUE to disable CPU parallelism (see Parallelism below).\n\n\nquiet\nTRUE to suppress printing of messages.\n\n\n\n\n\n\nThis function must be called at the very top of your script (i.e. immediately after library(tensorflow), library(keras), etc.). Any existing TensorFlow session is torn down via tf$reset_default_graph().\nThis function takes all measures known to promote reproducible results from TensorFlow sessions, however it’s possible that various individual TensorFlow features or dependent libraries escape its effects. If you encounter non-reproducible results please investigate the possible sources of the problem, contributions via pull request are very welcome!\nPackages which need to be notified before and after the seed is set can register for the “tensorflow.on_before_use_session” and “tensorflow.on_use_session” hooks (see setHook()) for additional details on hooks).\n\n\n\nTensorFlow session object, invisibly\n\n\n\n\nlibrary(tensorflow)\nuse_session_with_seed(42)"
  },
  {
    "objectID": "packages/tensorflow/latest/reference/view_savedmodel.html",
    "href": "packages/tensorflow/latest/reference/view_savedmodel.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "View a Saved Model\n\n\nView a serialized model from disk.\n\n\n\nview_savedmodel(model_dir)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmodel_dir\nThe path to the exported model, as a string.\n\n\n\n\n\n\nURL for browsing TensorBoard (invisibly)."
  },
  {
    "objectID": "packages/tfautograph/latest/news.html",
    "href": "packages/tfautograph/latest/news.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tfautograph 0.3.2\n\nAdded back compatibility with R-3.3 and R-3.4\n\n\n\ntfautograph 0.3.1\n\nFixed issue that prevented the package from being loaded by devtools::load_all()\n\n\n\ntfautograph 0.3.0\n\nImproved handling of shape_invariants supplied to ag_while_opts. A named list of user variable shapes can be passed directly now, without requiring users to manually specify shapes of internal loop tracking tensors.\nDeprecated back_prop arg in ag_while_opts()\nMove ‘tensorflow’ package from ‘Imports’ to ‘Suggests’ to avoid circular dependency.\nAdded a NEWS.md file to track changes to the package."
  },
  {
    "objectID": "packages/tfautograph/latest/reference/ag_if_vars.html",
    "href": "packages/tfautograph/latest/reference/ag_if_vars.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Specify tf.cond() output structure when autographing if\n\n\nThis function can be used to specify the output structure from tf.cond() when autographing an if statement. In most use cases, use of this function is purely optional. If not supplied, the if output structure is automatically built.\n\n\n\nag_if_vars(\n  ...,\n  modified = list(),\n  return = FALSE,\n  undefs = NULL,\n  control_flow = 0\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nVariables modified by the tf.cond() node supplied as bare symbols like foo or expressions using $ e.g, foo$bar. Symbols do not have to exist before the autographed if so long as they are created in both branches.\n\n\nmodified\nVariables names supplied as a character vector, or a list of character vectors if specifying nested complex structures. This is an escape hatch for the lazy evaluation semantics of ...\n\n\nreturn\nlogical, whether to include the return value the evaluated R expression in the tf.cond(). if FALSE (the default), only the objects assigned in scope are captured.\n\n\nundefs\nA bare character vector or a list of character vectors. Supplied names are exported as undefs in the parent frame. This is used to give a more informative error message when attempting to access a variable that can’t be balanced between branches.\n\n\ncontrol_flow\nAn integer, the maximum number of control-flow statements (break and/or next) that will be captured in a single branch as part of the tf.cond(). Do not count statements in loops that are dispatching to standard R control flow (e.g., don’t count break statements in a for loop that is iterating over an R vector)\n\n\n\n\n\n\nIf the output structure is not explicitly supplied via ag_if_vars(), then the output structure is automatically composed: The true and false branches of the expression are traced into concrete functions, then the output signature from the two branch functions are balanced. Balancing is performed by either fetching a variable from an outer scope or by reclassifying a symbol as an undef.\nWhen dealing with complex composites (that is, nested structures where a modified tensor is part of a named list or dictionary), care is taken to prevent unnecessarily capturing other unmodified tensors in the structure. This is done by pruning unmodified tensors from the returned output structure, and then merging them back with the original object recursively. One limitation of the implementation is that lists must either be fully named with unique names, or not named at all, partially named lists or duplicated names in a list throw an error. This is due to the conversion that happens when going between python and R: named lists get converted to python dictionaries, which require that all keys are unique. Additionally, pruning of unmodified objects from an autographed if is currently only supported for named lists (python dictionaries). Unnamed lists or tuples are passed as is (e.g, no pruning and merging done), which may lead to unnecessarily bloat in the constructed graphs.\n\n\n\nNULL, invisibly\n\n\n\n\n# these examples only have an effect in graph mode\n# to enter graph mode easily we'll create a few helpers\nag <- autograph\n\n# pass which symbols you expect to be modifed or created liks this:\nag_if_vars(x)\nag(if (y > 0) {\n  x <- y * y\n} else {\n  x <- y\n})\n\n# if the return value from the if expression is important, pass `return = TRUE`\nag_if_vars(return = TRUE)\nx <- ag(if(y > 0) y * y else y)\n\n# pass complex nested structures like this\nx <- list(a = 1, b = 2)\n\nag_if_vars(x$a)\nag(if(y > 0) {\n  x$a <- y\n})\n\n# undefs are for mark branch-local variables\nag_if_vars(y, x$a, undef = \"tmp_local_var\")\nag(if(y > 0) {\n  y <- y * 100\n  tmp_local_var <- y + 1\n  x$a <- tmp_local_var\n})\n\n# supplying `undef` is not necessary, it exists purely as a way to supply a\n# guardrail for defensive programming and/or to improve code readability\n\n## modified vars can be supplied in `...` or as a named arg.\n## these paires of ag_if_vars() calls are equivalent\nag_if_vars(y, x$a)\nag_if_vars(modified = list(\"y\", c(\"x\", \"a\")))\n\nag_if_vars(x, y, z)\nag_if_vars(modified = c(\"x\", \"y\", \"z\"))\n\n\n## control flow\n# count number of odds between 0:10\nag({\n  x <- 10\n  count <- 0\n  while(x > 0) {\n    ag_if_vars(control_flow = 1)\n    if(x %% 2 == 0)\n      next\n    count <- count + 1\n  }\n})"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/ag_loop_vars.html",
    "href": "packages/tfautograph/latest/reference/ag_loop_vars.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Specify loop variables\n\n\nThis can be used to manually specify which variables are to be included explicitly as loop_vars when autographing an expression into a tf.while_loop() call, or the loop_vars equivalent when building a dataset.reduce().\n\n\n\nag_loop_vars(\n  ...,\n  list = character(),\n  include = character(),\n  exclude = character(),\n  undef = character()\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nVariables as bare symbol names\n\n\nlist, include, exclude\noptionally, the variable names as a character vector (use this as an escape hatch from the ... lazy evaluation semantics).\n\n\nundef\ncharacter vector of symbols\n\n\n\n\n\n\nUse of this is usually not required as the loop variables are automatically inferred. Inference is done by statically looking through the loop body and finding the symbols that are the targets of the common assignment operators from base R (<-, ->, =), from package:zeallot (%<-% and %->%) and package:magrittr (%<>%).\nIn certain circumstances, this approach may capture variables that are intended to be local variables only. In those circumstances it is also possible to specify them preceded with a -.\nNote, the specified loop vars are expected to exist before the autographed expression, and a warning is issued otherwise (usually immediately preceding an error thrown when attempting to actually autograph the expression)\nOnly bare symbol names can be supplied as loop vars. In the future, support may be expanded to allow for nested complex composites (e.g., specifying variables that are nested within a more complex structure–passing ag_loop_vars(foo$bar$baz) is currently not supported.)\n\n\n\nthe specified hint invisibly.\n\n\n\n\ni <- tf$constant(0L)\n\nautograph({\n  ag_loop_vars(x, i)\n  while(x > 0) {\n    if(x %%2 == 0)\n      i <- i + 1L\n    x <- x - 1\n  }\n})\n\n## sometimes, a variable is infered to be a loop_var unnecessarily. For example\nx <- tf$constant(1:10)\n\n# imagine x is left over in the current scope from some previous calculations\n# It's value is not important, but it exists\nautograph({\n  for(i in tf$constant(1:6)) {\n    x <- i * i\n    tf$print(x)\n  }\n})\n\n# this will throw an error because `x` was infered to be a `loop_var`,\n# but it's shape witin the loop body is different from what it was before.\n# there are two solutions to prevent `x` from being captured as a loop_var\n## 1) remove `x` from the current scope like so:\nrm(x)\n\n## 2) provide a hint like so:\nag_loop_vars(-x)\n\n## if your variable names are being dynamically generated, there is an\n## escape hatch for the lazy evaluation semantics of ...\nag_loop_vars(exclude = \"x\")"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/ag_name.html",
    "href": "packages/tfautograph/latest/reference/ag_name.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Specify a tensor name\n\n\nThis can be used before any autographed expression that results in the creation of a tensor or op graph node. This can be used before for (both with tensors and datasets), while, and if statements.\n\n\n\nag_name(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA string\n\n\n\n\n\n\nx, invisibly\n\n\n\n\n## when you're in graph mode. (e.g, tf$executing_eagerly == FALSE)\n\nag_name(\"main-training-loop\")\nfor(elem in dataset) ..."
  },
  {
    "objectID": "packages/tfautograph/latest/reference/ag_while_opts.html",
    "href": "packages/tfautograph/latest/reference/ag_while_opts.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "specify tf.while_loop options\n\n\nSee https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/while_loop for additional details.\n\n\n\nag_while_opts(\n  ...,\n  shape_invariants = NULL,\n  parallel_iterations = 10L,\n  back_prop = TRUE,\n  swap_memory = FALSE,\n  maximum_iterations = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nIgnored, used to ensure all arguments supplied are named.\n\n\nshape_invariants\nThe shape invariants for the loop variables.\n\n\nparallel_iterations\nThe number of iterations allowed to run in parallel. It must be a positive integer.\n\n\nback_prop\nDeprecated (optional). FALSE disables support for back propagation. Prefer using tf$stop_gradient instead.\n\n\nswap_memory\nWhether GPU-CPU memory swap is enabled for this loop.\n\n\nmaximum_iterations\nOptional maximum number of iterations of the while loop to run. If provided, the cond output is AND-ed with an additional condition ensuring the number of iterations executed is no greater than maximum_iterations.\n\n\n\n\n\n\n`NULL`` invisibly, called for it’s side effect.\n\n\n\n\n## use tf_function() to enter graph mode:\ntf_function(autograph(function(n) {\n  ag_name(\"silly-example\")\n  ag_while_opts(back_prop = FALSE)\n  while(n > 0)\n    n <- n - 1\n}))"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/autograph.html",
    "href": "packages/tfautograph/latest/reference/autograph.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Autograph R code\n\n\nNote, this documentation page is meant to serve as a technical reference, not an introduction to autograph. For the latter, please visit the documentation website: (https://t-kalinowski.github.io/tfautograph/) or see the package vignettes.\n\n\n\nautograph(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na function supplied as a bare symbol, or an expression\n\n\n\n\n\n\nif x is a function, then the the same function with a new parent environment, package:tfautograph:ag_mask, which is the autograph mask that contains implementations of R control flow primitives that are capable of handling tensorflow tensors. The parent of the package:tfautograph:ag_mask in turn is the original environment of x.\nif x is an expression, then that expression is evaluated in a special environment with the autograph mask ag_mask active. If the result of that expression included local assignment or modifications of variables, (for example, via <-), those modified variables are then exported into the current frame. The return value of the expression is then returned."
  },
  {
    "objectID": "packages/tfautograph/latest/reference/index.html",
    "href": "packages/tfautograph/latest/reference/index.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\nautograph()\nAutograph R code"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/index.html#options",
    "href": "packages/tfautograph/latest/reference/index.html#options",
    "title": "TensorFlow for R",
    "section": "Options",
    "text": "Options\n\n\n\nFunction(s)\nDescription\n\n\n\n\nag_name()\nSpecify a tensor name\n\n\nag_while_opts()\nspecify tf.while_loop options"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/index.html#hints",
    "href": "packages/tfautograph/latest/reference/index.html#hints",
    "title": "TensorFlow for R",
    "section": "Hints",
    "text": "Hints\n\n\n\nFunction(s)\nDescription\n\n\n\n\nag_if_vars()\nSpecify tf.cond() output structure when autographing if\n\n\nag_loop_vars()\nSpecify loop variables"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/index.html#thin-convenience-wrappers",
    "href": "packages/tfautograph/latest/reference/index.html#thin-convenience-wrappers",
    "title": "TensorFlow for R",
    "section": "Thin Convenience Wrappers",
    "text": "Thin Convenience Wrappers\n\n\n\nFunction(s)\nDescription"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/index.html#interactive-helpers",
    "href": "packages/tfautograph/latest/reference/index.html#interactive-helpers",
    "title": "TensorFlow for R",
    "section": "Interactive helpers",
    "text": "Interactive helpers\n\n\n\nFunction(s)\nDescription\n\n\n\n\nview_function_graph()\nVisualizes the generated graph"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/sub-subset-.tensorflow.python.ops.tensor_array_ops.tensorarray.html",
    "href": "packages/tfautograph/latest/reference/sub-subset-.tensorflow.python.ops.tensor_array_ops.tensorarray.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "TensorArray.write()\n\n\nTensorArray.write()\n\n\n\n[[tensorflow.python.ops.tensor_array_ops.TensorArray(ta, i, …, name = NULL) <- value\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nta\na tensorflow TensorArray\n\n\ni\nsomething castable to an int32 scalar tensor. 0-based.\n\n\n…\nError if anything is passed to ...\n\n\nname\nA scalar string, name of the op\n\n\nvalue\nThe value to write.\n\n\n\n\n\n\n\nta <- tf$TensorArray(tf$float32, size = 5L)\nfor(i in 0:4)\n  ta[[i]] <- i\nta$stack()\n\n# You can use this to grow objects in graph mode\naccuracies_log <- tf$TensorArray(tf$float32, size = 0L, dynamic_size=TRUE)\nfor(epoch in 0:4)\n  accuracies_log[[epoch]] <- runif(1)\nacc <- accuracies_log$stack()\nacc"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/tf_assert.html",
    "href": "packages/tfautograph/latest/reference/tf_assert.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tf_assert\n\n\nA thin wrapper around tf$Assert() that automatically constructs an informative error message (passed on to data argument), which includes the expression passed to condition, the values of the symbols found in the expression, as well as the full R call stack at the time the tf$Assert() node is created.\n\n\n\ntf_assert(\n  condition,\n  ...,\n  expr = substitute(condition),\n  summarize = NULL,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncondition\nA boolean tensor\n\n\n…\nAdditional elements passed on to data. (e.g, an informative error message as a string, additional tensor values that might be useful to have in the error message, etc.)\n\n\nexpr\nA language object, provided in case condition is already computed prior to the call\n\n\nsummarize\nPrint this many entries of each tensor.\n\n\nname\nA name for this operation (optional).\n\n\n\n\n\n\n\nx <- tf$constant(-1)\ntry(tf_assert(x > 0, \"oopsies! x must be greater than 0\"))"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/tf_case.html",
    "href": "packages/tfautograph/latest/reference/tf_case.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tf.case\n\n\nThis is a minimal wrapper around tf.case() that allows you to supply the pred_fn_pairs using the ~.\n\n\n\ntf_case(\n  ...,\n  pred_fn_pairs = list(...),\n  default = NULL,\n  exclusive = FALSE,\n  name = \"case\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…, pred_fn_pairs\na list pred_fn_pairs supplied with the ~ like so: pred ~ fn_body\n\n\ndefault\na function, optionally specified with the ~, (or something coercible to a function via as.function())\n\n\nexclusive\nbool, whether to evaluate all preds and ensure only one is true. If FALSE (the default), then the preds are evaluated in the order supplied until the first TRUE value is encountered (effectively, acting as an if()… else if() … else if() … chain)\n\n\nname\na string, passed on to tf.case()\n\n\n\n\n\n\nThe result from tf$case()\n\n\n\n\nfizz_buzz_one <- function(x) {\n  tf_case(\n    x %% 15 == 0 ~ \"FizzBuzz\",\n    x %%  5 == 0 ~ \"Buzz\",\n    x %%  3 == 0 ~ \"Fizz\",\n    default = ~ tf$as_string(x, precision = 0L)\n  )\n}\n\nfn <- tf_function(autograph(function(n) {\n  for(e in tf$range(n))\n    tf$print(fizz_buzz_one(e))\n}))\n\nx <- tf$constant(16)\nfn(x)"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/tf_cond.html",
    "href": "packages/tfautograph/latest/reference/tf_cond.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tf.cond\n\n\nThis is a minimal wrapper around tf$cond() that allows you to supply true_fn and false_fn as lambda functions defined using the tilde ~.\n\n\n\ntf_cond(pred, true_fn, false_fn, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\npred\nR logical or a tensor.\n\n\ntrue_fn, false_fn\na ~ function, a function, or something coercible to a function via as.function\n\n\nname\na string, passed on to tf.cond()\n\n\n\n\n\n\nif cond is a tensor, then the result of tf.cond(). Otherwise, if pred is an EagerTensor or an R logical, then the result of either true_fn() or false_fn()\n\n\n\n\n## square if positive\n# using tf$cond directly:\nraw <- function(x) tf$cond(x > 0, function() x * x, function() x)\n\n# using tf_cond() wrapper\ntilde <- function(x) tf_cond(x > 0, ~ x * x, ~ x)"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/tf_map.html",
    "href": "packages/tfautograph/latest/reference/tf_map.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tf.map_fn()\n\n\nThin wrapper around tf.map_fn() with the following differences:\n\naccepts purrr style ~ lambda syntax to define function fn.\nThe order of elems and fn is switched to make it more pipe %>% friendly and consistent with R mappers lapply() and purrr::map().\n\n\n\n\ntf_map(\n  elems,\n  fn,\n  dtype = NULL,\n  parallel_iterations = NULL,\n  back_prop = TRUE,\n  swap_memory = FALSE,\n  infer_shape = TRUE,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nelems\nA tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be applied to fn.\n\n\nfn\nAn R function, specified using purrr style ~ syntax, a character string, a python function (or more generally, any python object with a call method) or anything coercible via as.function(). The function will be be called with one argument, which will have the same (possibly nested) structure as elems. Its output must return the same structure as dtype if one is provided, otherwise it must return the same structure as elems.\n\n\ndtype\n(optional) The output type(s) of fn. If fn returns a structure of Tensors differing from the structure of elems, then dtype is not optional and must have the same structure as the output of fn.\n\n\nparallel_iterations\n(optional) The number of iterations allowed to run in parallel. When graph building, the default value is 10. While executing eagerly, the default value is set to 1.\n\n\nback_prop\n(optional) True enables support for back propagation.\n\n\nswap_memory\n(optional) True enables GPU-CPU memory swapping.\n\n\ninfer_shape\n(optional) False disables tests for consistent output shapes.\n\n\nname\n(optional) Name prefix for the returned tensors.\n\n\n\n\n\n\nA tensor or (possibly nested) sequence of tensors. Each tensor packs the results of applying fn to tensors unpacked from elems along the first dimension, from first to last."
  },
  {
    "objectID": "packages/tfautograph/latest/reference/tf_switch.html",
    "href": "packages/tfautograph/latest/reference/tf_switch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tf.switch_case\n\n\ntf.switch_case\n\n\n\ntf_switch(\n  branch_index,\n  ...,\n  branch_fns = list(...),\n  default = NULL,\n  name = \"switch_case\"\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nbranch_index\nan integer tensor\n\n\n…, branch_fns\na list of function bodies specified with a ~, optionally supplied with a branch index on the left hand side. See examples\n\n\ndefault\nA function defined with a ~, or something coercible via `as.function()name | a string, passed on totf.switch_case()``\n\n\n\n\n\n\nThe result from tf.switch_case()\n\n\n\n\ntf_pow <- tf_function(function(x, pow) {\n   tf_switch(pow,\n   0 ~ 1,\n   1 ~ x,\n   2 ~ x * x,\n   3 ~ x * x * x,\n   default = ~ -1)\n})\n\n# can optionally also omit the left hand side int, in which case the order of\n# the functions is used.\ntf_pow <- function(x, pow) {\n  tf_switch(pow,\n            ~ 1,\n            ~ x,\n            ~ x * x,\n            ~ x * x * x,\n            default = ~ -1)\n}\n\n# supply just some of the ints to override the default order\ntf_pow <- function(x, pow) {\n  tf_switch(pow,\n            3 ~ x * x * x,\n            2 ~ x * x,\n            ~ 1,\n            ~ x,\n            default = ~ -1)\n}\n\n# A slightly less contrived example:\ntf_norm <- tf_function(function(x, l) {\n  tf_switch(l,\n            0 ~ tf$reduce_sum(tf$cast(x != 0, tf$float32)), # L0 norm\n            1 ~ tf$reduce_sum(tf$abs(x)),                   # L1 norm\n            2 ~ tf$sqrt(tf$reduce_sum(tf$square(x))),       # L2 norm\n            default = ~ tf$reduce_max(tf$abs(x)))         # L-infinity norm\n})"
  },
  {
    "objectID": "packages/tfautograph/latest/reference/view_function_graph.html",
    "href": "packages/tfautograph/latest/reference/view_function_graph.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Visualizes the generated graph\n\n\nVisualizes the generated graph\n\n\n\nview_function_graph(\n  fn,\n  args,\n  ...,\n  name = deparse(substitute(fn)),\n  profiler = FALSE,\n  concrete_fn = do.call(fn$get_concrete_fn, args),\n  graph = concrete_fn$graph\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfn\nTensorFlow function (returned from tf.function())\n\n\nargs\narguments passed to fun\n\n\n…\nother arguments passed to tensorflow::tensorboard()\n\n\nname\nstring, provided to tensorboard\n\n\nprofiler\nlogical, passed on to tf.compat.v2.summary.trace_on() (only used in eager mode)\n\n\nconcrete_fn\na ConcreteFunction (only used in graph mode, ignored with a warning if executing eagerly)\n\n\ngraph\na tensorflow graph (only used in graph mode, ignored with a warning if executing eagerly)\n\n\n\n\n\n\n\nfn <- tf_function(function(x) autograph(if(x > 0) x * x else x))\nview_function_graph(fn, list(tf$constant(5)))"
  },
  {
    "objectID": "packages/tfdatasets/latest/news.html",
    "href": "packages/tfdatasets/latest/news.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tfdatasets 2.9.0\n\nNew dataset_unbatch()\nNew dataset_group_by_window()\nNew dataset_take_while()\nNew as_tensor() and as.array() methods which can be used on TF Datasets with a single element.\n\n\n\ntfdatasets 2.7.0\n\nAdded compatability with Tensorflow version 2.7\nas_iterator(), iter_next() and iterate() are is now reexported from {reticualte}.\nNew as_array_iterator(), for converting a dataset into an iterable that yields R arrays. (as_iterator() yields tensorflow tensors)\nNew dataset_bucket_by_sequence_length()\nNew dataset_rejection_resample()\nNew dataset_unique()\nNew choose_from_datasets()\nsample_from_datasets() gains argument stop_on_empty_dataset.\ndataset_batch() gains arguments num_parallel_calls and deterministic.\ndataset_padded_batch(): Fixed error raised when drop_remainder=TRUE with recent TF versions. Added examples, docs, and tests.\ndataset_concatenate() gains ... and the ability to combine multiple datasets in one call.\n\n\n\ntfdatasets 2.6.0\n\nNew dataset_options() for setting and getting dataset options.\nNew length() method for tensorflow datasets.\nNew dataset_enumerate().\nNew random_integer_dataset().\nNew dataset_scan(), a stateful variant of dataset_map().\nNew dataset_snapshot() for persisting the output of a dataset to disk.\nrange_dataset() gains a dtype argument.\ndataset_prefetch() argument buffer_size is now optional, defaults to tf$data$AUTOTUNE\n\n\n\ntfdatasets 2.4.0\n\nFixed problem when saving models with feature specs (#82).\n\n\n\ntfdatasets 1.13.1\n\nAdd datatset_window method.\nAllow purrr style lambda functions in dataset_map.\nAdded a NEWS.md file to track changes to the package.\nAdded a new feature spec interface that can be used to easily create feature_columns. (#42)"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/all_nominal.html",
    "href": "packages/tfdatasets/latest/reference/all_nominal.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Find all nominal variables.\n\n\nCurrently we only consider “string” type as nominal.\n\n\n\nall_nominal()\n\n\n\nOther Selectors: all_numeric(), has_type()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/all_numeric.html",
    "href": "packages/tfdatasets/latest/reference/all_numeric.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Speciy all numeric variables.\n\n\nFind all the variables with the following types: “float16”, “float32”, “float64”, “int16”, “int32”, “int64”, “half”, “double”.\n\n\n\nall_numeric()\n\n\n\nOther Selectors: all_nominal(), has_type()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/as_array_iterator.html",
    "href": "packages/tfdatasets/latest/reference/as_array_iterator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Convert tf_dataset to an iterator that yields R arrays.\n\n\nConvert tf_dataset to an iterator that yields R arrays.\n\n\n\nas_array_iterator(dataset)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA tensorflow dataset\n\n\n\n\n\n\nAn iterable. Use iterate() or iter_next() to access values from the iterator."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/as_tensor.tf_dataset.html",
    "href": "packages/tfdatasets/latest/reference/as_tensor.tf_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Get the single element of the dataset.\n\n\nThe function enables you to use a TF Dataset in a stateless “tensor-in tensor-out” expression, without creating an iterator. This facilitates the ease of data transformation on tensors using the optimized TF Dataset abstraction on top of them.\n\n\n\nas_tensortensorflow.python.data.ops.dataset_ops.DatasetV2(x, …, name = NULL)\nas.arraytensorflow.python.data.ops.dataset_ops.DatasetV2(x, …)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA TF Dataset\n\n\n…\npassed on to tensorflow::as_tensor()\n\n\nname\n(Optional.) A name for the TensorFlow operation.\n\n\n\n\n\n\nFor example, consider a preprocess_batch() which would take as an input a batch of raw features and returns the processed feature.\nhtml\n\npreprocess_one_case <- function(x) x + 100\npreprocess_batch <- function(raw_features) { batch_size <- dim(raw_features)[1] ds <- raw_features %>% tensor_slices_dataset() %>% dataset_map(preprocess_one_case, num_parallel_calls = batch_size) %>% dataset_batch(batch_size) as_tensor(ds) }\nraw_features <- array(seq(prod(4, 5)), c(4, 5)) preprocess_batch(raw_features) html\n\nIn the above example, the batch of raw_features was converted to a TF Dataset. Next, each of the raw_feature cases in the batch was mapped using the preprocess_one_case and the processed features were grouped into a single batch. The final dataset contains only one element which is a batch of all the processed features.\nNote: The dataset should contain only one element. Now, instead of creating an iterator for the dataset and retrieving the batch of features, the as_tensor() function is used to skip the iterator creation process and directly output the batch of features.\nThis can be particularly useful when your tensor transformations are expressed as TF Dataset operations, and you want to use those transformations while serving your model.\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#get_single_element"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/as_tf_dataset.html",
    "href": "packages/tfdatasets/latest/reference/as_tf_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Add the tf_dataset class to a dataset\n\n\nCalling this function on a dataset adds the “tf_dataset” class to the dataset object. All datasets returned by functions in the tfdatasets package call this function on the dataset before returning it.\n\n\n\nas_tf_dataset(dataset)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\n\n\n\n\nA dataset with class “tf_dataset”"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/choose_from_datasets.html",
    "href": "packages/tfdatasets/latest/reference/choose_from_datasets.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset that deterministically chooses elements from datasets.\n\n\nCreates a dataset that deterministically chooses elements from datasets.\n\n\n\nchoose_from_datasets(datasets, choice_dataset, stop_on_empty_dataset = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndatasets\nA non-empty list of tf.data.Dataset objects with compatible structure.\n\n\nchoice_dataset\nA tf.data.Dataset of scalar tf.int64 tensors between 0 and length(datasets) - 1.\n\n\nstop_on_empty_dataset\nIf TRUE, selection stops if it encounters an empty dataset. If FALSE, it skips empty datasets. It is recommended to set it to TRUE. Otherwise, the selected elements start off as the user intends, but may change as input datasets become empty. This can be difficult to detect since the dataset starts off looking correct. Defaults to TRUE.\n\n\n\n\n\n\nReturns a dataset that interleaves elements from datasets according to the values of choice_dataset.\n\n\n\n\ndatasets <- list(tensors_dataset(\"foo\") %>% dataset_repeat(),\n                 tensors_dataset(\"bar\") %>% dataset_repeat(),\n                 tensors_dataset(\"baz\") %>% dataset_repeat())\n\n# Define a dataset containing `[0, 1, 2, 0, 1, 2, 0, 1, 2]`.\nchoice_dataset <- range_dataset(0, 3) %>% dataset_repeat(3)\nresult <- choose_from_datasets(datasets, choice_dataset)\nresult %>% as_array_iterator() %>% iterate(function(s) s$decode()) %>% print()\n# [1] \"foo\" \"bar\" \"baz\" \"foo\" \"bar\" \"baz\" \"foo\" \"bar\" \"baz\""
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_batch.html",
    "href": "packages/tfdatasets/latest/reference/dataset_batch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Combines consecutive elements of this dataset into batches.\n\n\nThe components of the resulting element will have an additional outer dimension, which will be batch_size (or N %% batch_size for the last element if batch_size does not divide the number of input elements N evenly and drop_remainder is FALSE). If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to TRUE to prevent the smaller batch from being produced.\n\n\n\ndataset_batch(\n  dataset,\n  batch_size,\n  drop_remainder = FALSE,\n  num_parallel_calls = NULL,\n  deterministic = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nbatch_size\nAn integer, representing the number of consecutive elements of this dataset to combine in a single batch.\n\n\ndrop_remainder\n(Optional.) A boolean, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n\n\nnum_parallel_calls\n(Optional.) A scalar integer, representing the number of batches to compute asynchronously in parallel. If not specified, batches will be computed sequentially. If the value tf$data$AUTOTUNE is used, then the number of parallel calls is set dynamically based on available resources.\n\n\ndeterministic\n(Optional.) When num_parallel_calls is specified, if this boolean is specified (TRUE or FALSE), it controls the order in which the transformation produces elements. If set to FALSE, the transformation is allowed to yield elements out of order to trade determinism for performance. If not specified, the tf.data.Options.experimental_deterministic option (TRUE by default) controls the behavior. See dataset_options() for how to set dataset options.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_bucket_by_sequence_length.html",
    "href": "packages/tfdatasets/latest/reference/dataset_bucket_by_sequence_length.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A transformation that buckets elements in a Dataset by length\n\n\nA transformation that buckets elements in a Dataset by length\n\n\n\ndataset_bucket_by_sequence_length(\n  dataset,\n  element_length_func,\n  bucket_boundaries,\n  bucket_batch_sizes,\n  padded_shapes = NULL,\n  padding_values = NULL,\n  pad_to_bucket_boundary = FALSE,\n  no_padding = FALSE,\n  drop_remainder = FALSE,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA tf_dataset\n\n\nelement_length_func\nfunction from element in Dataset to tf$int32, determines the length of the element, which will determine the bucket it goes into.\n\n\nbucket_boundaries\nintegers, upper length boundaries of the buckets.\n\n\nbucket_batch_sizes\nintegers, batch size per bucket. Length should be length(bucket_boundaries) + 1.\n\n\npadded_shapes\nNested structure of tf.TensorShape (returned by tensorflow::shape()) to pass to tf.data.Dataset.padded_batch. If not provided, will use dataset.output_shapes, which will result in variable length dimensions being padded out to the maximum length in each batch.\n\n\npadding_values\nValues to pad with, passed to tf.data.Dataset.padded_batch. Defaults to padding with 0.\n\n\npad_to_bucket_boundary\nbool, if FALSE, will pad dimensions with unknown size to maximum length in batch. If TRUE, will pad dimensions with unknown size to bucket boundary minus 1 (i.e., the maximum length in each bucket), and caller must ensure that the source Dataset does not contain any elements with length longer than max(bucket_boundaries).\n\n\nno_padding\nboolean, indicates whether to pad the batch features (features need to be either of type tf.sparse.SparseTensor or of same shape).\n\n\ndrop_remainder\n(Optional.) A logical scalar, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n\n\nname\n(Optional.) A name for the tf.data operation.\n\n\n\n\n\n\nElements of the Dataset are grouped together by length and then are padded and batched.\nThis is useful for sequence tasks in which the elements have variable length. Grouping together elements that have similar lengths reduces the total fraction of padding in a batch which increases training step efficiency.\nBelow is an example to bucketize the input data to the 3 buckets “[0, 3), [3, 5), [5, Inf)” based on sequence length, with batch size 2.\n\n\n\n\ndataset <- list(c(0),\n                c(1, 2, 3, 4),\n                c(5, 6, 7),\n                c(7, 8, 9, 10, 11),\n                c(13, 14, 15, 16, 17, 18, 19, 20),\n                c(21, 22)) %>%\n  lapply(as.array) %>% lapply(as_tensor, \"int32\") %>%\n  lapply(tensors_dataset) %>%\n  Reduce(dataset_concatenate, .)\n\ndataset %>%\n  dataset_bucket_by_sequence_length(\n    element_length_func = function(elem) tf$shape(elem)[1],\n    bucket_boundaries = c(3, 5),\n    bucket_batch_sizes = c(2, 2, 2)\n  ) %>%\n  as_array_iterator() %>%\n  iterate(print)\n#      [,1] [,2] [,3] [,4]\n# [1,]    1    2    3    4\n# [2,]    5    6    7    0\n#      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n# [1,]    7    8    9   10   11    0    0    0\n# [2,]   13   14   15   16   17   18   19   20\n#      [,1] [,2]\n# [1,]    0    0\n# [2,]   21   22\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#bucket_by_sequence_length"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_cache.html",
    "href": "packages/tfdatasets/latest/reference/dataset_cache.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Caches the elements in this dataset.\n\n\nCaches the elements in this dataset.\n\n\n\ndataset_cache(dataset, filename = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nfilename\nString with the name of a directory on the filesystem to use for caching tensors in this Dataset. If a filename is not provided, the dataset will be cached in memory.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_collect.html",
    "href": "packages/tfdatasets/latest/reference/dataset_collect.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Collects a dataset\n\n\nIterates throught the dataset collecting every element into a list. It’s useful for looking at the full result of the dataset. Note: You may run out of memory if your dataset is too big.\n\n\n\ndataset_collect(dataset, iter_max = Inf)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\niter_max\nMaximum number of iterations. Inf until the end of the dataset\n\n\n\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_concatenate.html",
    "href": "packages/tfdatasets/latest/reference/dataset_concatenate.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset by concatenating given dataset with this dataset.\n\n\nCreates a dataset by concatenating given dataset with this dataset.\n\n\n\ndataset_concatenate(dataset, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset, …\ntf_datasets to be concatenated\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_decode_delim.html",
    "href": "packages/tfdatasets/latest/reference/dataset_decode_delim.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transform a dataset with delimted text lines into a dataset with named columns\n\n\nTransform a dataset with delimted text lines into a dataset with named columns\n\n\n\ndataset_decode_delim(dataset, record_spec, parallel_records = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nDataset containing delimited text lines (e.g. a CSV)\n\n\nrecord_spec\nSpecification of column names and types (see delim_record_spec()).\n\n\nparallel_records\n(Optional) An integer, representing the number of records to decode in parallel. If not specified, records will be processed sequentially.\n\n\n\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_enumerate.html",
    "href": "packages/tfdatasets/latest/reference/dataset_enumerate.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Enumerates the elements of this dataset\n\n\nEnumerates the elements of this dataset\n\n\n\ndataset_enumerate(dataset, start = 0L)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA tensorflow dataset\n\n\nstart\nAn integer (coerced to a tf$int64 scalar tf.Tensor), representing the start value for enumeration.\n\n\n\n\n\n\nIt is similar to python’s enumerate, this transforms a sequence of elements into a sequence of list(index, element), where index is an integer that indicates the position of the element in the sequence.\n\n\n\n\ndataset <- tensor_slices_dataset(100:103) %>%\n  dataset_enumerate()\n\niterator <- reticulate::as_iterator(dataset)\nreticulate::iter_next(iterator) # list(0, 100)\nreticulate::iter_next(iterator) # list(1, 101)\nreticulate::iter_next(iterator) # list(2, 102)\nreticulate::iter_next(iterator) # list(3, 103)\nreticulate::iter_next(iterator) # NULL (iterator exhausted)\nreticulate::iter_next(iterator) # NULL (iterator exhausted)"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_filter.html",
    "href": "packages/tfdatasets/latest/reference/dataset_filter.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Filter a dataset by a predicate\n\n\nFilter a dataset by a predicate\n\n\n\ndataset_filter(dataset, predicate)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\npredicate\nA function mapping a nested structure of tensors (having shapes and types defined by output_shapes() and output_types() to a scalar tf$bool tensor.\n\n\n\n\n\n\nNote that the functions used inside the predicate must be tensor operations (e.g. tf$not_equal, tf$less, etc.). R generic methods for relational operators (e.g. <, >, <=, etc.) and logical operators (e.g. !, &, |, etc.) are provided so you can use shorthand syntax for most common comparisions (this is illustrated by the example below).\n\n\n\nA dataset composed of records that matched the predicate.\n\n\n\n\n\ndataset <- text_line_dataset(\"mtcars.csv\", record_spec = mtcars_spec) %>%\n  dataset_filter(function(record) {\n    record$mpg >= 20\n})\n\ndataset <- text_line_dataset(\"mtcars.csv\", record_spec = mtcars_spec) %>%\n  dataset_filter(function(record) {\n    record$mpg >= 20 & record$cyl >= 6L\n  })\n\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_flat_map.html",
    "href": "packages/tfdatasets/latest/reference/dataset_flat_map.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Maps map_func across this dataset and flattens the result.\n\n\nMaps map_func across this dataset and flattens the result.\n\n\n\ndataset_flat_map(dataset, map_func)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nmap_func\nA function mapping a nested structure of tensors (having shapes and types defined by output_shapes() and output_types() to a dataset.\n\n\n\n\n\n\nA dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_group_by_window.html",
    "href": "packages/tfdatasets/latest/reference/dataset_group_by_window.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Group windows of elements by key and reduce them\n\n\nGroup windows of elements by key and reduce them\n\n\n\ndataset_group_by_window(\n  dataset,\n  key_func,\n  reduce_func,\n  window_size = NULL,\n  window_size_func = NULL,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\na TF Dataset\n\n\nkey_func\nA function mapping a nested structure of tensors (having shapes and types defined by self$output_shapes and self$output_types) to a scalar tf.int64 tensor.\n\n\nreduce_func\nA function mapping a key and a dataset of up to window_size consecutive elements matching that key to another dataset.\n\n\nwindow_size\nA tf.int64 scalar tf.Tensor, representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to reduce_func. Mutually exclusive with window_size_func.\n\n\nwindow_size_func\nA function mapping a key to a tf.int64 scalar tf.Tensor, representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to reduce_func. Mutually exclusive with window_size.\n\n\nname\n(Optional.) A name for the Tensorflow operation.\n\n\n\n\n\n\nThis transformation maps each consecutive element in a dataset to a key using key_func() and groups the elements by key. It then applies reduce_func() to at most window_size_func(key) elements matching the same key. All except the final window for each key will contain window_size_func(key) elements; the final window may be smaller.\nYou may provide either a constant window_size or a window size determined by the key through window_size_func.\nhtml\n\nwindow_size <- 5 dataset <- range_dataset(to = 10) %>% dataset_group_by_window( key_func = function(x) x %% 2, reduce_func = function(key, ds) dataset_batch(ds, window_size), window_size = window_size )\nit <- as_array_iterator(dataset) while (!is.null(elem <- iter_next(it))) print(elem) #> tf.Tensor([0 2 4 6 8], shape=(5), dtype=int64) #> tf.Tensor([1 3 5 7 9], shape=(5), dtype=int64) html\n\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#group_by_window"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_interleave.html",
    "href": "packages/tfdatasets/latest/reference/dataset_interleave.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Maps map_func across this dataset, and interleaves the results\n\n\nMaps map_func across this dataset, and interleaves the results\n\n\n\ndataset_interleave(dataset, map_func, cycle_length, block_length = 1)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nmap_func\nA function mapping a nested structure of tensors (having shapes and types defined by output_shapes() and output_types() to a dataset.\n\n\ncycle_length\nThe number of elements from this dataset that will be processed concurrently.\n\n\nblock_length\nThe number of consecutive elements to produce from each input element before cycling to another input element.\n\n\n\n\n\n\nThe cycle_length and block_length arguments control the order in which elements are produced. cycle_length controls the number of input elements that are processed concurrently. In general, this transformation will apply map_func to cycle_length input elements, open iterators on the returned dataset objects, and cycle through them producing block_length consecutive elements from each iterator, and consuming the next input element each time it reaches the end of an iterator.\n\n\n\n\n\ndataset <- tensor_slices_dataset(c(1,2,3,4,5)) %>%\n dataset_interleave(cycle_length = 2, block_length = 4, function(x) {\n   tensors_dataset(x) %>%\n     dataset_repeat(6)\n })\n\n# resulting dataset (newlines indicate \"block\" boundaries):\nc(1, 1, 1, 1,\n  2, 2, 2, 2,\n  1, 1,\n  2, 2,\n  3, 3, 3, 3,\n  4, 4, 4, 4,\n  3, 3,\n  4, 4,\n  5, 5, 5, 5,\n  5, 5,\n)\n\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_map.html",
    "href": "packages/tfdatasets/latest/reference/dataset_map.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Map a function across a dataset.\n\n\nMap a function across a dataset.\n\n\n\ndataset_map(dataset, map_func, num_parallel_calls = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nmap_func\nA function mapping a nested structure of tensors (having shapes and types defined by output_shapes() and output_types() to another nested structure of tensors. It also supports purrr style lambda functions powered by rlang::as_function().\n\n\nnum_parallel_calls\n(Optional) An integer, representing the number of elements to process in parallel If not specified, elements will be processed sequentially.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_map_and_batch.html",
    "href": "packages/tfdatasets/latest/reference/dataset_map_and_batch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fused implementation of dataset_map() and dataset_batch()\n\n\nMaps `map_func`` across batch_size consecutive elements of this dataset and then combines them into a batch. Functionally, it is equivalent to map followed by batch. However, by fusing the two transformations together, the implementation can be more efficient.\n\n\n\ndataset_map_and_batch(\n  dataset,\n  map_func,\n  batch_size,\n  num_parallel_batches = NULL,\n  drop_remainder = FALSE,\n  num_parallel_calls = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nmap_func\nA function mapping a nested structure of tensors (having shapes and types defined by output_shapes() and output_types() to another nested structure of tensors. It also supports purrr style lambda functions powered by rlang::as_function().\n\n\nbatch_size\nAn integer, representing the number of consecutive elements of this dataset to combine in a single batch.\n\n\nnum_parallel_batches\n(Optional) An integer, representing the number of batches to create in parallel. On one hand, higher values can help mitigate the effect of stragglers. On the other hand, higher values can increase contention if CPU is scarce.\n\n\ndrop_remainder\n(Optional.) A boolean, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n\n\nnum_parallel_calls\n(Optional) An integer, representing the number of elements to process in parallel If not specified, elements will be processed sequentially.\n\n\n\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_options.html",
    "href": "packages/tfdatasets/latest/reference/dataset_options.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Get or Set Dataset Options\n\n\nGet or Set Dataset Options\n\n\n\ndataset_options(dataset, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\na tensorflow dataset\n\n\n…\nValid values include: * A set of named arguments setting options. Names of nested attributes can be separated with a \".\" (see examples). The set of named arguments can be supplied individually to ..., or as a single named list. * a tf$data$Options() instance.\n\n\n\n\n\n\nThe options are “global” in the sense they apply to the entire dataset. If options are set multiple times, they are merged as long as different options do not use different non-default values.\n\n\n\nIf values are supplied to ..., returns a tf.data.Dataset with the given options set/updated. Otherwise, returns the currently set options for the dataset.\n\n\n\n\n# pass options directly:\nrange_dataset(0, 10) %>%\n  dataset_options(\n    experimental_deterministic = FALSE,\n    threading.private_threadpool_size = 10\n  )\n\n# pass options as a named list:\nopts <- list(\n  experimental_deterministic = FALSE,\n  threading.private_threadpool_size = 10\n)\nrange_dataset(0, 10) %>%\n  dataset_options(opts)\n\n# pass a tf.data.Options() instance\nopts <- tf$data$Options()\nopts$experimental_deterministic <- FALSE\nopts$threading$private_threadpool_size <- 10L\nrange_dataset(0, 10) %>%\n  dataset_options(opts)\n\n# get currently set options\nrange_dataset(0, 10) %>% dataset_options()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_padded_batch.html",
    "href": "packages/tfdatasets/latest/reference/dataset_padded_batch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Combines consecutive elements of this dataset into padded batches.\n\n\nCombines consecutive elements of this dataset into padded batches.\n\n\n\ndataset_padded_batch(\n  dataset,\n  batch_size,\n  padded_shapes = NULL,\n  padding_values = NULL,\n  drop_remainder = FALSE,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nbatch_size\nAn integer, representing the number of consecutive elements of this dataset to combine in a single batch.\n\n\npadded_shapes\n(Optional.) A (nested) structure of tf.TensorShape (returned by tensorflow::shape()) or tf$int64 vector tensor-like objects representing the shape to which the respective component of each input element should be padded prior to batching. Any unknown dimensions will be padded to the maximum size of that dimension in each batch. If unset, all dimensions of all components are padded to the maximum size in the batch. padded_shapes must be set if any component has an unknown rank.\n\n\npadding_values\n(Optional.) A (nested) structure of scalar-shaped tf.Tensor, representing the padding values to use for the respective components. NULL represents that the (nested) structure should be padded with default values. Defaults are 0 for numeric types and the empty string \"\" for string types. The padding_values should have the same (nested) structure as the input dataset. If padding_values is a single element and the input dataset has multiple components, then the same padding_values will be used to pad every component of the dataset. If padding_values is a scalar, then its value will be broadcasted to match the shape of each component.\n\n\ndrop_remainder\n(Optional.) A boolean scalar, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n\n\nname\n(Optional.) A name for the tf.data operation. Requires tensorflow version >= 2.7.\n\n\n\n\n\n\nThis transformation combines multiple consecutive elements of the input dataset into a single element.\nLike dataset_batch(), the components of the resulting element will have an additional outer dimension, which will be batch_size (or N %% batch_size for the last element if batch_size does not divide the number of input elements N evenly and drop_remainder is FALSE). If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to TRUE to prevent the smaller batch from being produced.\nUnlike dataset_batch(), the input elements to be batched may have different shapes, and this transformation will pad each component to the respective shape in padded_shapes. The padded_shapes argument determines the resulting shape for each dimension of each component in an output element:\n\nIf the dimension is a constant, the component will be padded out to that length in that dimension.\nIf the dimension is unknown, the component will be padded out to the maximum length of all elements in that dimension.\n\nSee also tf$data$experimental$dense_to_sparse_batch, which combines elements that may have different shapes into a tf$sparse$SparseTensor.\n\n\n\nA tf_dataset\n\n\n\n\nA <- range_dataset(1, 5, dtype = tf$int32) %>%\n  dataset_map(function(x) tf$fill(list(x), x))\n\n# Pad to the smallest per-batch size that fits all elements.\nB <- A %>% dataset_padded_batch(2)\nB %>% as_array_iterator() %>% iterate(print)\n\n# Pad to a fixed size.\nC <- A %>% dataset_padded_batch(2, padded_shapes=5)\nC %>% as_array_iterator() %>% iterate(print)\n\n# Pad with a custom value.\nD <- A %>% dataset_padded_batch(2, padded_shapes=5, padding_values = -1L)\nD %>% as_array_iterator() %>% iterate(print)\n\n# Pad with a single value and multiple components.\nE <- zip_datasets(A, A) %>%  dataset_padded_batch(2, padding_values = -1L)\nE %>% as_array_iterator() %>% iterate(print)\n\n\n\n\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_prefetch.html",
    "href": "packages/tfdatasets/latest/reference/dataset_prefetch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a Dataset that prefetches elements from this dataset.\n\n\nCreates a Dataset that prefetches elements from this dataset.\n\n\n\ndataset_prefetch(dataset, buffer_size = tf$data$AUTOTUNE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nbuffer_size\nAn integer, representing the maximum number elements that will be buffered when prefetching.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_prefetch_to_device.html",
    "href": "packages/tfdatasets/latest/reference/dataset_prefetch_to_device.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A transformation that prefetches dataset values to the given device\n\n\nA transformation that prefetches dataset values to the given device\n\n\n\ndataset_prefetch_to_device(dataset, device, buffer_size = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\ndevice\nA string. The name of a device to which elements will be prefetched (e.g. “/gpu:0”).\n\n\nbuffer_size\n(Optional.) The number of elements to buffer on device. Defaults to an automatically chosen value.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_prepare.html",
    "href": "packages/tfdatasets/latest/reference/dataset_prepare.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Prepare a dataset for analysis\n\n\nTransform a dataset with named columns into a list with features (x) and response (y) elements.\n\n\n\ndataset_prepare(\n  dataset,\n  x,\n  y = NULL,\n  named = TRUE,\n  named_features = FALSE,\n  parallel_records = NULL,\n  batch_size = NULL,\n  num_parallel_batches = NULL,\n  drop_remainder = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nx\nFeatures to include. When named_features is FALSE all features will be stacked into a single tensor so must have an identical data type.\n\n\ny\n(Optional). Response variable.\n\n\nnamed\nTRUE to name the dataset elements “x” and “y”, FALSE to not name the dataset elements.\n\n\nnamed_features\nTRUE to yield features as a named list; FALSE to stack features into a single array. Note that in the case of FALSE (the default) all features will be stacked into a single 2D tensor so need to have the same underlying data type.\n\n\nparallel_records\n(Optional) An integer, representing the number of records to decode in parallel. If not specified, records will be processed sequentially.\n\n\nbatch_size\n(Optional). Batch size if you would like to fuse the dataset_prepare() operation together with a dataset_batch() (fusing generally improves overall training performance).\n\n\nnum_parallel_batches\n(Optional) An integer, representing the number of batches to create in parallel. On one hand, higher values can help mitigate the effect of stragglers. On the other hand, higher values can increase contention if CPU is scarce.\n\n\ndrop_remainder\n(Optional.) A boolean, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n\n\n\n\n\n\nA dataset. The dataset will have a structure of either:\n\nWhen named_features is TRUE: list(x = list(feature_name = feature_values, ...), y = response_values)\nWhen named_features is FALSE: list(x = features_array, y = response_values), where features_array is a Rank 2 array of (batch_size, num_features).\n\nNote that the y element will be omitted when y is NULL.\n\n\n\ninput_fn() for use with tfestimators."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_reduce.html",
    "href": "packages/tfdatasets/latest/reference/dataset_reduce.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reduces the input dataset to a single element.\n\n\nThe transformation calls reduce_func successively on every element of the input dataset until the dataset is exhausted, aggregating information in its internal state. The initial_state argument is used for the initial state and the final state is returned as the result.\n\n\n\ndataset_reduce(dataset, initial_state, reduce_func)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\ninitial_state\nAn element representing the initial state of the transformation.\n\n\nreduce_func\nA function that maps (old_state, input_element) to new_state. It must take two arguments and return a new element. The structure of new_state must match the structure of initial_state.\n\n\n\n\n\n\nA dataset element.\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_rejection_resample.html",
    "href": "packages/tfdatasets/latest/reference/dataset_rejection_resample.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A transformation that resamples a dataset to a target distribution.\n\n\nA transformation that resamples a dataset to a target distribution.\n\n\n\ndataset_rejection_resample(\n  dataset,\n  class_func,\n  target_dist,\n  initial_dist = NULL,\n  seed = NULL,\n  name = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA tf.Dataset\n\n\nclass_func\nA function mapping an element of the input dataset to a scalar tf.int32 tensor. Values should be in [0, num_classes).\n\n\ntarget_dist\nA floating point type tensor, shaped [num_classes].\n\n\ninitial_dist\n(Optional.) A floating point type tensor, shaped [num_classes]. If not provided, the true class distribution is estimated live in a streaming fashion.\n\n\nseed\n(Optional.) Integer seed for the resampler.\n\n\nname\n(Optional.) A name for the tf.data operation.\n\n\n\n\n\n\nA tf.Dataset\n\n\n\n\ninitial_dist <- c(.5, .5)\ntarget_dist <- c(.6, .4)\nnum_classes <- length(initial_dist)\nnum_samples <- 100000\ndata <- sample.int(num_classes, num_samples, prob = initial_dist, replace = TRUE)\ndataset <- tensor_slices_dataset(data)\ntally <- c(0, 0)\n`add<-` <- function (x, value) x + value\n# tfautograph::autograph({\n#   for(i in dataset)\n#     add(tally[as.numeric(i)]) <- 1\n# })\ndataset %>%\n  as_array_iterator() %>%\n  iterate(function(i) {\n    add(tally[i]) <<- 1\n  }, simplify = FALSE)\n# The value of `tally` will be close to c(50000, 50000) as\n# per the `initial_dist` distribution.\ntally # c(50287, 49713)\n\ntally <- c(0, 0)\ndataset %>%\n  dataset_rejection_resample(\n    class_func = function(x) (x-1) %% 2,\n    target_dist = target_dist,\n    initial_dist = initial_dist\n  ) %>%\n  as_array_iterator() %>%\n  iterate(function(element) {\n    names(element) <- c(\"class_id\", \"i\")\n    add(tally[element$i]) <<- 1\n  }, simplify = FALSE)\n# The value of tally will be now be close to c(75000, 50000)\n# thus satisfying the target_dist distribution.\ntally # c(74822, 49921)"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_repeat.html",
    "href": "packages/tfdatasets/latest/reference/dataset_repeat.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Repeats a dataset count times.\n\n\nRepeats a dataset count times.\n\n\n\ndataset_repeat(dataset, count = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\ncount\n(Optional.) An integer value representing the number of times the elements of this dataset should be repeated. The default behavior (if count is NULL or -1) is for the elements to be repeated indefinitely.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_scan.html",
    "href": "packages/tfdatasets/latest/reference/dataset_scan.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A transformation that scans a function across an input dataset\n\n\nA transformation that scans a function across an input dataset\n\n\n\ndataset_scan(dataset, initial_state, scan_func)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA tensorflow dataset\n\n\ninitial_state\nA nested structure of tensors, representing the initial state of the accumulator.\n\n\nscan_func\nA function that maps (old_state, input_element) to (new_state, output_element). It must take two arguments and return a pair of nested structures of tensors. The new_state must match the structure of initial_state.\n\n\n\n\n\n\nThis transformation is a stateful relative of dataset_map(). In addition to mapping scan_func across the elements of the input dataset, scan() accumulates one or more state tensors, whose initial values are initial_state.\n\n\n\n\ninitial_state <- as_tensor(0, dtype=\"int64\")\nscan_func <- function(state, i) list(state + i, state + i)\ndataset <- range_dataset(0, 10) %>%\n  dataset_scan(initial_state, scan_func)\n\nreticulate::iterate(dataset, as.array) %>%\n  unlist()\n# 0  1  3  6 10 15 21 28 36 45"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_shard.html",
    "href": "packages/tfdatasets/latest/reference/dataset_shard.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset that includes only 1 / num_shards of this dataset.\n\n\nThis dataset operator is very useful when running distributed training, as it allows each worker to read a unique subset.\n\n\n\ndataset_shard(dataset, num_shards, index)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nnum_shards\nA integer representing the number of shards operating in parallel.\n\n\nindex\nA integer, representing the worker index.\n\n\n\n\n\n\nA dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_shuffle.html",
    "href": "packages/tfdatasets/latest/reference/dataset_shuffle.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Randomly shuffles the elements of this dataset.\n\n\nRandomly shuffles the elements of this dataset.\n\n\n\ndataset_shuffle(\n  dataset,\n  buffer_size,\n  seed = NULL,\n  reshuffle_each_iteration = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nbuffer_size\nAn integer, representing the number of elements from this dataset from which the new dataset will sample.\n\n\nseed\n(Optional) An integer, representing the random seed that will be used to create the distribution.\n\n\nreshuffle_each_iteration\n(Optional) A boolean, which if true indicates that the dataset should be pseudorandomly reshuffled each time it is iterated over. (Defaults to TRUE). Not used if TF version < 1.15\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_shuffle_and_repeat.html",
    "href": "packages/tfdatasets/latest/reference/dataset_shuffle_and_repeat.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Shuffles and repeats a dataset returning a new permutation for each epoch.\n\n\nShuffles and repeats a dataset returning a new permutation for each epoch.\n\n\n\ndataset_shuffle_and_repeat(dataset, buffer_size, count = NULL, seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nbuffer_size\nAn integer, representing the number of elements from this dataset from which the new dataset will sample.\n\n\ncount\n(Optional.) An integer value representing the number of times the elements of this dataset should be repeated. The default behavior (if count is NULL or -1) is for the elements to be repeated indefinitely.\n\n\nseed\n(Optional) An integer, representing the random seed that will be used to create the distribution.\n\n\n\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_skip.html",
    "href": "packages/tfdatasets/latest/reference/dataset_skip.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset that skips count elements from this dataset\n\n\nCreates a dataset that skips count elements from this dataset\n\n\n\ndataset_skip(dataset, count)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\ncount\nAn integer, representing the number of elements of this dataset that should be skipped to form the new dataset. If count is greater than the size of this dataset, the new dataset will contain no elements. If count is -1, skips the entire dataset.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_take_while(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_snapshot.html",
    "href": "packages/tfdatasets/latest/reference/dataset_snapshot.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Persist the output of a dataset\n\n\nPersist the output of a dataset\n\n\n\ndataset_snapshot(\n  dataset,\n  path,\n  compression = c(\"AUTO\", \"GZIP\", \"SNAPPY\", \"None\"),\n  reader_func = NULL,\n  shard_func = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA tensorflow dataset\n\n\npath\nRequired. A directory to use for storing/loading the snapshot to/from.\n\n\ncompression\nOptional. The type of compression to apply to the snapshot written to disk. Supported options are \"GZIP\", \"SNAPPY\", \"AUTO\" or NULL (values of \"\", NA, and \"None\" are synonymous with NULL) Defaults to AUTO, which attempts to pick an appropriate compression algorithm for the dataset.\n\n\nreader_func\nOptional. A function to control how to read data from snapshot shards.\n\n\nshard_func\nOptional. A function to control how to shard data when writing a snapshot.\n\n\n\n\n\n\nThe snapshot API allows users to transparently persist the output of their preprocessing pipeline to disk, and materialize the pre-processed data on a different training run.\nThis API enables repeated preprocessing steps to be consolidated, and allows re-use of already processed data, trading off disk storage and network bandwidth for freeing up more valuable CPU resources and accelerator compute time.\nhttps://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md has detailed design documentation of this feature.\nUsers can specify various options to control the behavior of snapshot, including how snapshots are read from and written to by passing in user-defined functions to the reader_func and shard_func parameters.\nshard_func is a user specified function that maps input elements to snapshot shards.\nhtml\n\nNUM_SHARDS <- parallel::detectCores() dataset %>% dataset_enumerate() %>% dataset_snapshot( “/path/to/snapshot/dir”, shard_func = function(index, ds_elem) x %% NUM_SHARDS) %>% dataset_map(function(index, ds_elem) ds_elem) html\n\nreader_func is a user specified function that accepts a single argument: a Dataset of Datasets, each representing a “split” of elements of the original dataset. The cardinality of the input dataset matches the number of the shards specified in the shard_func. The function should return a Dataset of elements of the original dataset.\nUsers may want specify this function to control how snapshot files should be read from disk, including the amount of shuffling and parallelism.\nHere is an example of a standard reader function a user can define. This function enables both dataset shuffling and parallel reading of datasets:\nhtml\n\nuser_reader_func <- function(datasets) { num_cores <- parallel::detectCores() datasets %>% dataset_shuffle(num_cores) %>% dataset_interleave(function(x) x, num_parallel_calls=AUTOTUNE) }\ndataset <- dataset %>% dataset_snapshot(“/path/to/snapshot/dir”, reader_func = user_reader_func) html\n\nBy default, snapshot parallelizes reads by the number of cores available on the system, but will not attempt to shuffle the data."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_take.html",
    "href": "packages/tfdatasets/latest/reference/dataset_take.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset with at most count elements from this dataset\n\n\nCreates a dataset with at most count elements from this dataset\n\n\n\ndataset_take(dataset, count)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\ncount\nInteger representing the number of elements of this dataset that should be taken to form the new dataset. If count is -1, or if count is greater than the size of this dataset, the new dataset will contain all elements of this dataset.\n\n\n\n\n\n\nA dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_take_while.html",
    "href": "packages/tfdatasets/latest/reference/dataset_take_while.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A transformation that stops dataset iteration based on a predicate.\n\n\nA transformation that stops dataset iteration based on a predicate.\n\n\n\ndataset_take_while(dataset, predicate, name = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA TF dataset\n\n\npredicate\nA function that maps a nested structure of tensors (having shapes and types defined by self$output_shapes and self$output_types) to a scalar tf.bool tensor.\n\n\nname\n(Optional.) A name for the tf.data operation.\n\n\n\n\n\n\nExample usage:\nhtml\n\nrange_dataset(from = 0, to = 10) %>% dataset_take_while( ~ .x < 5) %>% as_array_iterator() %>% iterate(simplify = FALSE) %>% str() #> List of 5 #> $ : num 0 #> $ : num 1 #> $ : num 2 #> $ : num 3 #> $ : num 4 html\n\n\n\n\nA TF Dataset\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take(), dataset_window()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_unbatch.html",
    "href": "packages/tfdatasets/latest/reference/dataset_unbatch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Unbatch a dataset\n\n\nSplits elements of a dataset into multiple elements.\n\n\n\ndataset_unbatch(dataset, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nname\n(Optional.) A name for the tf.data operation."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_unique.html",
    "href": "packages/tfdatasets/latest/reference/dataset_unique.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A transformation that discards duplicate elements of a Dataset.\n\n\nUse this transformation to produce a dataset that contains one instance of each unique element in the input (See example).\n\n\n\ndataset_unique(dataset, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA tf.Dataset.\n\n\nname\n(Optional.) A name for the tf.data operation.\n\n\n\n\n\n\nA tf.Dataset\n\n\n\n\nc(0, 37, 2, 37, 2, 1) %>% as_tensor(\"int32\") %>%\n  tensor_slices_dataset() %>%\n  dataset_unique() %>%\n  as_array_iterator() %>% iterate() %>% sort()\n# [1]  0  1  2 37"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_use_spec.html",
    "href": "packages/tfdatasets/latest/reference/dataset_use_spec.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Transform the dataset using the provided spec.\n\n\nPrepares the dataset to be used directly in a model.The transformed dataset is prepared to return tuples (x,y) that can be used directly in Keras.\n\n\n\ndataset_use_spec(dataset, spec)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA TensorFlow dataset.\n\n\nspec\nA feature specification created with feature_spec().\n\n\n\n\n\n\nA TensorFlow dataset.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ age) %>%\n  step_numeric_column(age)\n\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\n\nfeature_spec() to initialize the feature specification.\nfit.FeatureSpec() to create a tensorflow dataset prepared to modeling.\nsteps to a list of all implemented steps.\n\nOther Feature Spec Functions: feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dataset_window.html",
    "href": "packages/tfdatasets/latest/reference/dataset_window.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Combines input elements into a dataset of windows.\n\n\nCombines input elements into a dataset of windows.\n\n\n\ndataset_window(dataset, size, shift = NULL, stride = 1, drop_remainder = FALSE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nsize\nrepresenting the number of elements of the input dataset to combine into a window.\n\n\nshift\nepresenting the forward shift of the sliding window in each iteration. Defaults to size.\n\n\nstride\nrepresenting the stride of the input elements in the sliding window.\n\n\ndrop_remainder\nrepresenting whether a window should be dropped in case its size is smaller than window_size.\n\n\n\n\n\n\nOther dataset methods: dataset_batch(), dataset_cache(), dataset_collect(), dataset_concatenate(), dataset_decode_delim(), dataset_filter(), dataset_interleave(), dataset_map_and_batch(), dataset_map(), dataset_padded_batch(), dataset_prefetch_to_device(), dataset_prefetch(), dataset_reduce(), dataset_repeat(), dataset_shuffle_and_repeat(), dataset_shuffle(), dataset_skip(), dataset_take_while(), dataset_take()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/delim_record_spec.html",
    "href": "packages/tfdatasets/latest/reference/delim_record_spec.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Specification for reading a record from a text file with delimited values\n\n\nSpecification for reading a record from a text file with delimited values\n\n\n\ndelim_record_spec(\n  example_file,\n  delim = \",\",\n  skip = 0,\n  names = NULL,\n  types = NULL,\n  defaults = NULL\n)\n\ncsv_record_spec(\n  example_file,\n  skip = 0,\n  names = NULL,\n  types = NULL,\n  defaults = NULL\n)\n\ntsv_record_spec(\n  example_file,\n  skip = 0,\n  names = NULL,\n  types = NULL,\n  defaults = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nexample_file\nFile that provides an example of the records to be read. If you don’t explicitly specify names and types (or defaults) then this file will be read to generate default values.\n\n\ndelim\nCharacter delimiter to separate fields in a record (defaults to “,”)\n\n\nskip\nNumber of lines to skip before reading data. Note that if names is explicitly provided and there are column names witin the file then skip should be set to 1 to ensure that the column names are bypassed.\n\n\nnames\nCharacter vector with column names (or NULL to automatically detect the column names from the first row of example_file). If names is a character vector, the values will be used as the names of the columns, and the first row of the input will be read into the first row of the datset. Note that if the underlying text file also includes column names in it’s first row, this row should be skipped explicitly with skip = 1. If NULL, the first row of the example_file will be used as the column names, and will be skipped when reading the dataset.\n\n\ntypes\nColumn types. If NULL and defaults is specified then types will be imputed from the defaults. Otherwise, all column types will be imputed from the first 1000 rows of the example_file. This is convenient (and fast), but not robust. If the imputation fails, you’ll need to supply the correct types yourself. Types can be explicitliy specified in a character vector as “integer”, “double”, and “character” (e.g. col_types = c(“double”, “double”, “integer”). Alternatively, you can use a compact string representation where each character represents one column: c = character, i = integer, d = double (e.g. types = ddi`).\n\n\ndefaults\nList of default values which are used when data is missing from a record (e.g. list(0, 0, 0L). If NULL then defaults will be automatically provided based on types (0 for numeric columns and \"\" for character columns)."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/dense_features.html",
    "href": "packages/tfdatasets/latest/reference/dense_features.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Dense Features\n\n\nRetrives the Dense Features from a spec.\n\n\n\ndense_features(spec)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n\n\n\n\nA list of feature columns."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/feature_spec.html",
    "href": "packages/tfdatasets/latest/reference/feature_spec.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a feature specification.\n\n\nUsed to create initialize a feature columns specification.\n\n\n\nfeature_spec(dataset, x, y = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA TensorFlow dataset.\n\n\nx\nFeatures to include can use tidyselect::select_helpers() or a formula.\n\n\ny\n(Optional) The response variable. Can also be specified using a formula in the x argument.\n\n\n\n\n\n\nAfter creating the feature_spec object you can add steps using the step functions.\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ .)\n\n# select using `tidyselect` helpers\nspec <- feature_spec(hearts, x = c(thal, age), y = target)\n\n\n\n\nfit.FeatureSpec() to fit the FeatureSpec\ndataset_use_spec() to create a tensorflow dataset prepared to modeling.\nsteps to a list of all implemented steps.\n\nOther Feature Spec Functions: dataset_use_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/file_list_dataset.html",
    "href": "packages/tfdatasets/latest/reference/file_list_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A dataset of all files matching a pattern\n\n\nA dataset of all files matching a pattern\n\n\n\nfile_list_dataset(file_pattern, shuffle = NULL, seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfile_pattern\nA string, representing the filename pattern that will be matched.\n\n\nshuffle\n(Optional) If TRUE`, the file names will be shuffled randomly. Defaults to TRUE\n\n\nseed\n(Optional) An integer, representing the random seed that will be used to create the distribution.\n\n\n\n\n\n\nFor example, if we had the following files on our filesystem: - /path/to/dir/a.txt - /path/to/dir/b.csv - /path/to/dir/c.csv\nIf we pass “/path/to/dir/*.csv” as the file_pattern, the dataset would produce: - /path/to/dir/b.csv - /path/to/dir/c.csv\n\n\n\nA dataset of string correponding to file names"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/fit.featurespec.html",
    "href": "packages/tfdatasets/latest/reference/fit.featurespec.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Fits a feature specification.\n\n\nThis function will fit the specification. Depending on the steps added to the specification it will compute for example, the levels of categorical features, normalization constants, etc.\n\n\n\nfitFeatureSpec(object, dataset = NULL, …)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nA feature specification created with feature_spec().\n\n\ndataset\n(Optional) A TensorFlow dataset. If NULL it will use the dataset provided when initilializing the feature_spec.\n\n\n…\n(unused)\n\n\n\n\n\n\na fitted FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ age) %>%\n  step_numeric_column(age)\n\nspec_fit <- fit(spec)\nspec_fit\n\n\n\n\nfeature_spec() to initialize the feature specification.\ndataset_use_spec() to create a tensorflow dataset prepared to modeling.\nsteps to a list of all implemented steps.\n\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/fixed_length_record_dataset.html",
    "href": "packages/tfdatasets/latest/reference/fixed_length_record_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A dataset of fixed-length records from one or more binary files.\n\n\nA dataset of fixed-length records from one or more binary files.\n\n\n\nfixed_length_record_dataset(\n  filenames,\n  record_bytes,\n  header_bytes = NULL,\n  footer_bytes = NULL,\n  buffer_size = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfilenames\nA string tensor containing one or more filenames.\n\n\nrecord_bytes\nAn integer representing the number of bytes in each record.\n\n\nheader_bytes\n(Optional) An integer scalar representing the number of bytes to skip at the start of a file.\n\n\nfooter_bytes\n(Optional) A integer scalar representing the number of bytes to ignore at the end of a file.\n\n\nbuffer_size\n(Optional) A integer scalar representing the number of bytes to buffer when reading.\n\n\n\n\n\n\nA dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/has_type.html",
    "href": "packages/tfdatasets/latest/reference/has_type.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Identify the type of the variable.\n\n\nCan only be used inside the steps specifications to find variables by type.\n\n\n\nhas_type(match = \"float32\")\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmatch\nA list of types to match.\n\n\n\n\n\n\nOther Selectors: all_nominal(), all_numeric()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/hearts.html",
    "href": "packages/tfdatasets/latest/reference/hearts.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Heart Disease Data Set\n\n\nHeart disease (angiographic disease status) dataset.\n\n\n\nhearts"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/index.html",
    "href": "packages/tfdatasets/latest/reference/index.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\ntext_line_dataset()\nA dataset comprising lines from one or more text files.\n\n\ntfrecord_dataset()\nA dataset comprising records from one or more TFRecord files.\n\n\nsql_record_spec() sql_dataset() sqlite_dataset()\nA dataset consisting of the results from a SQL query\n\n\ntensors_dataset()\nCreates a dataset with a single element, comprising the given tensors.\n\n\ntensor_slices_dataset()\nCreates a dataset whose elements are slices of the given tensors.\n\n\nsparse_tensor_slices_dataset()\nSplits each rank-N tf$SparseTensor in this dataset row-wise.\n\n\nfixed_length_record_dataset()\nA dataset of fixed-length records from one or more binary files.\n\n\nfile_list_dataset()\nA dataset of all files matching a pattern\n\n\nrange_dataset()\nCreates a dataset of a step-separated range of values.\n\n\nread_files()\nRead a dataset from a set of files\n\n\ndelim_record_spec() csv_record_spec() tsv_record_spec()\nSpecification for reading a record from a text file with delimited values\n\n\nmake_csv_dataset()\nReads CSV files into a batched dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/index.html#transforming-datasets",
    "href": "packages/tfdatasets/latest/reference/index.html#transforming-datasets",
    "title": "TensorFlow for R",
    "section": "Transforming Datasets",
    "text": "Transforming Datasets\n\n\n\nFunction(s)\nDescription\n\n\n\n\ndataset_map()\nMap a function across a dataset.\n\n\ndataset_map_and_batch()\nFused implementation of dataset_map() and dataset_batch()\n\n\ndataset_prepare()\nPrepare a dataset for analysis\n\n\ndataset_skip()\nCreates a dataset that skips count elements from this dataset\n\n\ndataset_filter()\nFilter a dataset by a predicate\n\n\ndataset_shard()\nCreates a dataset that includes only 1 / num_shards of this dataset.\n\n\ndataset_shuffle()\nRandomly shuffles the elements of this dataset.\n\n\ndataset_shuffle_and_repeat()\nShuffles and repeats a dataset returning a new permutation for each epoch.\n\n\ndataset_prefetch()\nCreates a Dataset that prefetches elements from this dataset.\n\n\ndataset_batch()\nCombines consecutive elements of this dataset into batches.\n\n\ndataset_repeat()\nRepeats a dataset count times.\n\n\ndataset_cache()\nCaches the elements in this dataset.\n\n\ndataset_take()\nCreates a dataset with at most count elements from this dataset\n\n\ndataset_flat_map()\nMaps map_func across this dataset and flattens the result.\n\n\ndataset_padded_batch()\nCombines consecutive elements of this dataset into padded batches.\n\n\ndataset_decode_delim()\nTransform a dataset with delimted text lines into a dataset with named\n\n\n\ncolumns dataset_concatenate() | Creates a dataset by concatenating given dataset with this dataset. dataset_interleave() | Maps map_func across this dataset, and interleaves the results dataset_prefetch_to_device() | A transformation that prefetches dataset values to the given device dataset_window() | Combines input elements into a dataset of windows. dataset_collect() | Collects a dataset zip_datasets() | Creates a dataset by zipping together the given datasets. sample_from_datasets() | Samples elements at random from the datasets in datasets. with_dataset() | Execute code that traverses a dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/index.html#dataset-properites",
    "href": "packages/tfdatasets/latest/reference/index.html#dataset-properites",
    "title": "TensorFlow for R",
    "section": "Dataset Properites",
    "text": "Dataset Properites\n\n\n\nFunction(s)\nDescription\n\n\n\n\noutput_types() output_shapes()\nOutput types and shapes"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/index.html#dataset-iterators",
    "href": "packages/tfdatasets/latest/reference/index.html#dataset-iterators",
    "title": "TensorFlow for R",
    "section": "Dataset Iterators",
    "text": "Dataset Iterators\n\n\n\nFunction(s)\nDescription\n\n\n\n\ninput_fn.tf_dataset()\nConstruct a tfestimators input function from a dataset\n\n\nmake_iterator_one_shot() make_iterator_initializable() make_iterator_from_structure() make_iterator_from_string_handle()\nCreates an iterator for enumerating the elements of this dataset.\n\n\niterator_get_next()\nGet next element from iterator\n\n\niterator_initializer()\nAn operation that should be run to initialize this iterator.\n\n\niterator_string_handle()\nString-valued tensor that represents this iterator\n\n\niterator_make_initializer()\nCreate an operation that can be run to initialize this iterator\n\n\nuntil_out_of_range() out_of_range_handler()\nExecute code that traverses a dataset until an out of range condition occurs\n\n\nnext_batch()\nTensor(s) for retrieving the next batch from a dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/index.html#feature-spec-api",
    "href": "packages/tfdatasets/latest/reference/index.html#feature-spec-api",
    "title": "TensorFlow for R",
    "section": "Feature Spec API",
    "text": "Feature Spec API\n\n\n\nFunction(s)\nDescription\n\n\n\n\nfeature_spec()\nCreates a feature specification.\n\n\ndense_features()\nDense Features\n\n\ndataset_use_spec()\nTransform the dataset using the provided spec.\n\n\nfit(<FeatureSpec>)\nFits a feature specification.\n\n\nscaler_min_max()\nCreates an instance of a min max scaler\n\n\nscaler_standard()\nCreates an instance of a standard scaler\n\n\ncur_info_env\nSelectors\n\n\nlayer_input_from_dataset()\nCreates a list of inputs from a dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/index.html#data",
    "href": "packages/tfdatasets/latest/reference/index.html#data",
    "title": "TensorFlow for R",
    "section": "Data",
    "text": "Data\n\n\n\nFunction(s)\nDescription\n\n\n\n\nhearts\nHeart Disease Data Set"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/input_fn.html",
    "href": "packages/tfdatasets/latest/reference/input_fn.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Construct a tfestimators input function from a dataset\n\n\nConstruct a tfestimators input function from a dataset\n\n\n\ninput_fn.tf_dataset(dataset, features, response = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nfeatures\nThe names of feature variables to be used.\n\n\nresponse\nThe name of the response variable.\n\n\n\n\n\n\nCreating an input_fn from a dataset requires that the dataset consist of a set of named output tensors (e.g. like the dataset produced by the tfrecord_dataset() or text_line_dataset() function).\n\n\n\nAn input_fn suitable for use with tfestimators train, evaluate, and predict methods"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/iterator_get_next.html",
    "href": "packages/tfdatasets/latest/reference/iterator_get_next.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Get next element from iterator\n\n\nReturns a nested list of tensors that when evaluated will yield the next element(s) in the dataset.\n\n\n\niterator_get_next(iterator, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\niterator\nAn iterator\n\n\nname\n(Optional) A name for the created operation.\n\n\n\n\n\n\nA nested list of tensors\n\n\n\nOther iterator functions: iterator_initializer(), iterator_make_initializer(), iterator_string_handle(), make-iterator"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/iterator_initializer.html",
    "href": "packages/tfdatasets/latest/reference/iterator_initializer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "An operation that should be run to initialize this iterator.\n\n\nAn operation that should be run to initialize this iterator.\n\n\n\niterator_initializer(iterator)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\niterator\nAn iterator\n\n\n\n\n\n\nOther iterator functions: iterator_get_next(), iterator_make_initializer(), iterator_string_handle(), make-iterator"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/iterator_make_initializer.html",
    "href": "packages/tfdatasets/latest/reference/iterator_make_initializer.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create an operation that can be run to initialize this iterator\n\n\nCreate an operation that can be run to initialize this iterator\n\n\n\niterator_make_initializer(iterator, dataset, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\niterator\nAn iterator\n\n\ndataset\nA dataset\n\n\nname\n(Optional) A name for the created operation.\n\n\n\n\n\n\nA tf$Operation that can be run to initialize this iterator on the given dataset.\n\n\n\nOther iterator functions: iterator_get_next(), iterator_initializer(), iterator_string_handle(), make-iterator"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/iterator_string_handle.html",
    "href": "packages/tfdatasets/latest/reference/iterator_string_handle.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "String-valued tensor that represents this iterator\n\n\nString-valued tensor that represents this iterator\n\n\n\niterator_string_handle(iterator, name = NULL)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\niterator\nAn iterator\n\n\nname\n(Optional) A name for the created operation.\n\n\n\n\n\n\nScalar tensor of type string\n\n\n\nOther iterator functions: iterator_get_next(), iterator_initializer(), iterator_make_initializer(), make-iterator"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/layer_input_from_dataset.html",
    "href": "packages/tfdatasets/latest/reference/layer_input_from_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a list of inputs from a dataset\n\n\nCreate a list ok Keras input layers that can be used together with keras::layer_dense_features().\n\n\n\nlayer_input_from_dataset(dataset)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\na TensorFlow dataset or a data.frame\n\n\n\n\n\n\na list of Keras input layers\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ age + slope) %>%\n  step_numeric_column(age, slope) %>%\n  step_bucketized_column(age, boundaries = c(10, 20, 30))\n\nspec <- fit(spec)\ndataset <- hearts %>% dataset_use_spec(spec)\n\ninput <- layer_input_from_dataset(dataset)"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/length.tf_dataset.html",
    "href": "packages/tfdatasets/latest/reference/length.tf_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Get Dataset length\n\n\nReturns the length of the dataset.\n\n\n\nlengthtf_dataset(x)\nlengthtensorflow.python.data.ops.dataset_ops.DatasetV2(x)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na tf.data.Dataset object.\n\n\n\n\n\n\nEither Inf if the dataset is infinite, NA if the dataset length is unknown, or an R numeric if it is known.\n\n\n\n\nrange_dataset(0, 42) %>% length()\n# 42\n\nrange_dataset(0, 42) %>% dataset_repeat() %>% length()\n# Inf\n\nrange_dataset(0, 42) %>% dataset_repeat() %>%\n  dataset_filter(function(x) TRUE) %>% length()\n# NA"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/make-iterator.html",
    "href": "packages/tfdatasets/latest/reference/make-iterator.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates an iterator for enumerating the elements of this dataset.\n\n\nCreates an iterator for enumerating the elements of this dataset.\n\n\n\nmake_iterator_one_shot(dataset)\n\nmake_iterator_initializable(dataset, shared_name = NULL)\n\nmake_iterator_from_structure(\n  output_types,\n  output_shapes = NULL,\n  shared_name = NULL\n)\n\nmake_iterator_from_string_handle(\n  string_handle,\n  output_types,\n  output_shapes = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\nshared_name\n(Optional) If non-empty, the returned iterator will be shared under the given name across multiple sessions that share the same devices (e.g. when using a remote server).\n\n\noutput_types\nA nested structure of tf\\(DType objects corresponding to each component of an element of this iterator. output_shapes | (Optional) A nested structure of tf\\)TensorShape objects corresponding to each component of an element of this dataset. If omitted, each component will have an unconstrainted shape.\n\n\nstring_handle\nA scalar tensor of type string that evaluates to a handle produced by the iterator_string_handle() method.\n\n\n\n\n\n\nAn Iterator over the elements of this dataset.\n\n\n\nOther iterator functions: iterator_get_next(), iterator_initializer(), iterator_make_initializer(), iterator_string_handle()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/make_csv_dataset.html",
    "href": "packages/tfdatasets/latest/reference/make_csv_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Reads CSV files into a batched dataset\n\n\nReads CSV files into a dataset, where each element is a (features, labels) list that corresponds to a batch of CSV rows. The features dictionary maps feature column names to tensors containing the corresponding feature data, and labels is a tensor containing the batch’s label data.\n\n\n\nmake_csv_dataset(\n  file_pattern,\n  batch_size,\n  column_names = NULL,\n  column_defaults = NULL,\n  label_name = NULL,\n  select_columns = NULL,\n  field_delim = \",\",\n  use_quote_delim = TRUE,\n  na_value = \"\",\n  header = TRUE,\n  num_epochs = NULL,\n  shuffle = TRUE,\n  shuffle_buffer_size = 10000,\n  shuffle_seed = NULL,\n  prefetch_buffer_size = 1,\n  num_parallel_reads = 1,\n  num_parallel_parser_calls = 2,\n  sloppy = FALSE,\n  num_rows_for_inference = 100\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfile_pattern\nList of files or glob patterns of file paths containing CSV records.\n\n\nbatch_size\nAn integer representing the number of records to combine in a single batch.\n\n\ncolumn_names\nAn optional list of strings that corresponds to the CSV columns, in order. One per column of the input record. If this is not provided, infers the column names from the first row of the records. These names will be the keys of the features dict of each dataset element.\n\n\ncolumn_defaults\nA optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (integer, numeric, or string), or a tensor with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to 0 for numeric values and \"\" for string values. If both this and select_columns are specified, these must have the same lengths, and column_defaults is assumed to be sorted in order of increasing column index.\n\n\nlabel_name\nA optional string corresponding to the label column. If provided, the data for this column is returned as a separate tensor from the features dictionary, so that the dataset complies with the format expected by a TF Estiamtors and Keras.\n\n\nselect_columns\n(Ignored if using TensorFlow version 1.8.) An optional list of integer indices or string column names, that specifies a subset of columns of CSV data to select. If column names are provided, these must correspond to names provided in column_names or inferred from the file header lines. When this argument is specified, only a subset of CSV columns will be parsed and returned, corresponding to the columns specified. Using this results in faster parsing and lower memory usage. If both this and column_defaults are specified, these must have the same lengths, and column_defaults is assumed to be sorted in order of increasing column index.\n\n\nfield_delim\nAn optional string. Defaults to \",\". Char delimiter to separate fields in a record.\n\n\nuse_quote_delim\nAn optional bool. Defaults to TRUE. If false, treats double quotation marks as regular characters inside of the string fields.\n\n\nna_value\nAdditional string to recognize as NA/NaN.\n\n\nheader\nA bool that indicates whether the first rows of provided CSV files correspond to header lines with column names, and should not be included in the data.\n\n\nnum_epochs\nAn integer specifying the number of times this dataset is repeated. If NULL, cycles through the dataset forever.\n\n\nshuffle\nA bool that indicates whether the input should be shuffled.\n\n\nshuffle_buffer_size\nBuffer size to use for shuffling. A large buffer size ensures better shuffling, but increases memory usage and startup time.\n\n\nshuffle_seed\nRandomization seed to use for shuffling.\n\n\nprefetch_buffer_size\nAn int specifying the number of feature batches to prefetch for performance improvement. Recommended value is the number of batches consumed per training step.\n\n\nnum_parallel_reads\nNumber of threads used to read CSV records from files. If >1, the results will be interleaved.\n\n\nnum_parallel_parser_calls\n(Ignored if using TensorFlow version 1.11 or later.) Number of parallel invocations of the CSV parsing function on CSV records.\n\n\nsloppy\nIf TRUE, reading performance will be improved at the cost of non-deterministic ordering. If FALSE, the order of elements produced is deterministic prior to shuffling (elements are still randomized if shuffle=TRUE. Note that if the seed is set, then order of elements after shuffling is deterministic). Defaults to FALSE.\n\n\nnum_rows_for_inference\nNumber of rows of a file to use for type inference if record_defaults is not provided. If NULL, reads all the rows of all the files. Defaults to 100.\n\n\n\n\n\n\nA dataset, where each element is a (features, labels) list that corresponds to a batch of batch_size CSV rows. The features dictionary maps feature column names to tensors containing the corresponding column data, and labels is a tensor containing the column data for the label column specified by label_name."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/next_batch.html",
    "href": "packages/tfdatasets/latest/reference/next_batch.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Tensor(s) for retrieving the next batch from a dataset\n\n\nTensor(s) for retrieving the next batch from a dataset\n\n\n\nnext_batch(dataset)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndataset\nA dataset\n\n\n\n\n\n\nTo access the underlying data within the dataset you iteratively evaluate the tensor(s) to read batches of data.\nNote that in many cases you won’t need to explicitly evaluate the tensors. Rather, you will pass the tensors to another function that will perform the evaluation (e.g. the Keras layer_input() and compile() functions).\nIf you do need to perform iteration manually by evaluating the tensors, there are a couple of possible approaches to controlling/detecting when iteration should end.\nOne approach is to create a dataset that yields batches infinitely (traversing the dataset multiple times with different batches randomly drawn). In this case you’d use another mechanism like a global step counter or detecting a learning plateau.\nAnother approach is to detect when all batches have been yielded from the dataset. When the tensor reaches the end of iteration a runtime error will occur. You can catch and ignore the error when it occurs by wrapping your iteration code in the with_dataset() function.\nSee the examples below for a demonstration of each of these methods of iteration.\n\n\n\nTensor(s) that can be evaluated to yield the next batch of training data.\n\n\n\n\n\n# iteration with 'infinite' dataset and explicit step counter\n\nlibrary(tfdatasets)\ndataset <- text_line_dataset(\"mtcars.csv\", record_spec = mtcars_spec) %>%\n  dataset_prepare(x = c(mpg, disp), y = cyl) %>%\n  dataset_shuffle(5000) %>%\n  dataset_batch(128) %>%\n  dataset_repeat() # repeat infinitely\nbatch <- next_batch(dataset)\nsteps <- 200\nfor (i in 1:steps) {\n  # use batch$x and batch$y tensors\n}\n\n# iteration that detects and ignores end of iteration error\n\nlibrary(tfdatasets)\ndataset <- text_line_dataset(\"mtcars.csv\", record_spec = mtcars_spec) %>%\n  dataset_prepare(x = c(mpg, disp), y = cyl) %>%\n  dataset_batch(128) %>%\n  dataset_repeat(10)\nbatch <- next_batch(dataset)\nwith_dataset({\n  while(TRUE) {\n    # use batch$x and batch$y tensors\n  }\n})"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/output_types.html",
    "href": "packages/tfdatasets/latest/reference/output_types.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Output types and shapes\n\n\nOutput types and shapes\n\n\n\noutput_types(object)\n\noutput_shapes(object)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nA dataset or iterator\n\n\n\n\n\n\noutput_types() returns the type of each component of an element of this object; output_shapes() returns the shape of each component of an element of this object"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/pipe.html",
    "href": "packages/tfdatasets/latest/reference/pipe.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pipe operator\n\n\nSee %>% for more details.\n\n\n\nlhs %>% rhs"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/random_integer_dataset.html",
    "href": "packages/tfdatasets/latest/reference/random_integer_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a Dataset of pseudorandom values\n\n\nCreates a Dataset of pseudorandom values\n\n\n\nrandom_integer_dataset(seed = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nseed\n(Optional) If specified, the dataset produces a deterministic sequence of values.\n\n\n\n\n\n\nThe dataset generates a sequence of uniformly distributed integer values (dtype int64)."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/range_dataset.html",
    "href": "packages/tfdatasets/latest/reference/range_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset of a step-separated range of values.\n\n\nCreates a dataset of a step-separated range of values.\n\n\n\nrange_dataset(from = 0, to = 0, by = 1, ..., dtype = tf$int64)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfrom\nRange start\n\n\nto\nRange end (exclusive)\n\n\nby\nIncrement of the sequence\n\n\n…\nignored\n\n\ndtype\nOutput dtype. (Optional, default: tf$int64)."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/read_files.html",
    "href": "packages/tfdatasets/latest/reference/read_files.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Read a dataset from a set of files\n\n\nRead files into a dataset, optionally processing them in parallel.\n\n\n\nread_files(\n  files,\n  reader,\n  ...,\n  parallel_files = 1,\n  parallel_interleave = 1,\n  num_shards = NULL,\n  shard_index = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfiles\nList of filenames or glob pattern for files (e.g. “*.csv”)\n\n\nreader\nFunction that maps a file into a dataset (e.g. text_line_dataset() or tfrecord_dataset()).\n\n\n…\nAdditional arguments to pass to reader function\n\n\nparallel_files\nAn integer, number of files to process in parallel\n\n\nparallel_interleave\nAn integer, number of consecutive records to produce from each file before cycling to another file.\n\n\nnum_shards\nAn integer representing the number of shards operating in parallel.\n\n\nshard_index\nAn integer, representing the worker index. Shared indexes are 0 based so for e.g. 8 shards valid indexes would be 0-7.\n\n\n\n\n\n\nA dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/reexports.html",
    "href": "packages/tfdatasets/latest/reference/reexports.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Objects exported from other packages\n\n\nThese objects are imported from other packages. Follow the links below to see their documentation."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/sample_from_datasets.html",
    "href": "packages/tfdatasets/latest/reference/sample_from_datasets.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Samples elements at random from the datasets in datasets.\n\n\nSamples elements at random from the datasets in datasets.\n\n\n\nsample_from_datasets(\n  datasets,\n  weights = NULL,\n  seed = NULL,\n  stop_on_empty_dataset = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndatasets\nA list ofobjects with compatible structure.\n\n\nweights\n(Optional.) A list of length(datasets) floating-point values where weights[[i]] represents the probability with which an element should be sampled from datasets[[i]], or a dataset object where each element is such a list. Defaults to a uniform distribution across datasets.\n\n\nseed\n(Optional.) An integer, representing the random seed that will be used to create the distribution.\n\n\nstop_on_empty_dataset\nIf TRUE, selection stops if it encounters an empty dataset. If FALSE, it skips empty datasets. It is recommended to set it to TRUE. Otherwise, the selected elements start off as the user intends, but may change as input datasets become empty. This can be difficult to detect since the dataset starts off looking correct. Defaults to TRUE.\n\n\n\n\n\n\nA dataset that interleaves elements from datasets at random, according to weights if provided, otherwise with uniform probability."
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/scaler.html",
    "href": "packages/tfdatasets/latest/reference/scaler.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "List of pre-made scalers\n\n\n\nscaler_standard: mean and standard deviation normalizer.\nscaler_min_max: min max normalizer\n\n\n\n\nstep_numeric_column"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/scaler_min_max.html",
    "href": "packages/tfdatasets/latest/reference/scaler_min_max.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates an instance of a min max scaler\n\n\nThis scaler will learn the min and max of the numeric variable and use this to create a normalizer_fn.\n\n\n\nscaler_min_max()\n\n\n\nscaler to a complete list of normalizers\nOther scaler: scaler_standard()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/scaler_standard.html",
    "href": "packages/tfdatasets/latest/reference/scaler_standard.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates an instance of a standard scaler\n\n\nThis scaler will learn the mean and the standard deviation and use this to create a normalizer_fn.\n\n\n\nscaler_standard()\n\n\n\nscaler to a complete list of normalizers\nOther scaler: scaler_min_max()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/selectors.html",
    "href": "packages/tfdatasets/latest/reference/selectors.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Selectors\n\n\nList of selectors that can be used to specify variables inside steps.\n\n\n\ncur_info_env"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/sparse_tensor_slices_dataset.html",
    "href": "packages/tfdatasets/latest/reference/sparse_tensor_slices_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Splits each rank-N tf$SparseTensor in this dataset row-wise.\n\n\nSplits each rank-N tf$SparseTensor in this dataset row-wise.\n\n\n\nsparse_tensor_slices_dataset(sparse_tensor)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsparse_tensor\nA tf$SparseTensor.\n\n\n\n\n\n\nA dataset of rank-(N-1) sparse tensors.\n\n\n\nOther tensor datasets: tensor_slices_dataset(), tensors_dataset()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/sql_dataset.html",
    "href": "packages/tfdatasets/latest/reference/sql_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A dataset consisting of the results from a SQL query\n\n\nA dataset consisting of the results from a SQL query\n\n\n\nsql_record_spec(names, types)\n\nsql_dataset(driver_name, data_source_name, query, record_spec)\n\nsqlite_dataset(filename, query, record_spec)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nnames\nNames of columns returned from the query\n\n\ntypes\nList of tf$DType objects (e.g. tf$int32, tf$double, tf$string) representing the types of the columns returned by the query.\n\n\ndriver_name\nString containing the database type. Currently, the only supported value is ‘sqlite’.\n\n\ndata_source_name\nString containing a connection string to connect to the database.\n\n\nquery\nString containing the SQL query to execute.\n\n\nrecord_spec\nNames and types of database columns\n\n\nfilename\nFilename for the database\n\n\n\n\n\n\nA dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_bucketized_column.html",
    "href": "packages/tfdatasets/latest/reference/step_bucketized_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates bucketized columns\n\n\nUse this step to create bucketized columns from numeric columns.\n\n\n\nstep_bucketized_column(spec, ..., boundaries)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\nboundaries\nA sorted list or tuple of floats specifying the boundaries.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nfile <- tempfile()\nwriteLines(unique(hearts$thal), file)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ age) %>%\n  step_numeric_column(age) %>%\n  step_bucketized_column(age, boundaries = c(10, 20, 30))\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_categorical_column_with_hash_bucket.html",
    "href": "packages/tfdatasets/latest/reference/step_categorical_column_with_hash_bucket.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a categorical column with hash buckets specification\n\n\nRepresents sparse feature where ids are set by hashing.\n\n\n\nstep_categorical_column_with_hash_bucket(\n  spec,\n  ...,\n  hash_bucket_size,\n  dtype = tf$string\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\nhash_bucket_size\nAn int > 1. The number of buckets.\n\n\ndtype\nThe type of features. Only string and integer types are supported.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ thal) %>%\n  step_categorical_column_with_hash_bucket(thal, hash_bucket_size = 3)\n\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_categorical_column_with_identity.html",
    "href": "packages/tfdatasets/latest/reference/step_categorical_column_with_identity.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Create a categorical column with identity\n\n\nUse this when your inputs are integers in the range [0-num_buckets).\n\n\n\nstep_categorical_column_with_identity(\n  spec,\n  ...,\n  num_buckets,\n  default_value = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\nnum_buckets\nRange of inputs and outputs is [0, num_buckets).\n\n\ndefault_value\nIf NULL, this column’s graph operations will fail for out-of-range inputs. Otherwise, this value must be in the range [0, num_buckets), and will replace inputs in that range.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\n\nhearts$thal <- as.integer(as.factor(hearts$thal)) - 1L\n\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ thal) %>%\n  step_categorical_column_with_identity(thal, num_buckets = 5)\n\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_categorical_column_with_vocabulary_file.html",
    "href": "packages/tfdatasets/latest/reference/step_categorical_column_with_vocabulary_file.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a categorical column with vocabulary file\n\n\nUse this function when the vocabulary of a categorical variable is written to a file.\n\n\n\nstep_categorical_column_with_vocabulary_file(\n  spec,\n  ...,\n  vocabulary_file,\n  vocabulary_size = NULL,\n  dtype = tf$string,\n  default_value = NULL,\n  num_oov_buckets = 0L\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\nvocabulary_file\nThe vocabulary file name.\n\n\nvocabulary_size\nNumber of the elements in the vocabulary. This must be no greater than length of vocabulary_file, if less than length, later values are ignored. If None, it is set to the length of vocabulary_file.\n\n\ndtype\nThe type of features. Only string and integer types are supported.\n\n\ndefault_value\nThe integer ID value to return for out-of-vocabulary feature values, defaults to -1. This can not be specified with a positive num_oov_buckets.\n\n\nnum_oov_buckets\nNon-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range [vocabulary_size, vocabulary_size+num_oov_buckets) based on a hash of the input value. A positive num_oov_buckets can not be specified with default_value.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nfile <- tempfile()\nwriteLines(unique(hearts$thal), file)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ thal) %>%\n  step_categorical_column_with_vocabulary_file(thal, vocabulary_file = file)\n\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_categorical_column_with_vocabulary_list.html",
    "href": "packages/tfdatasets/latest/reference/step_categorical_column_with_vocabulary_list.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a categorical column specification\n\n\nCreates a categorical column specification\n\n\n\nstep_categorical_column_with_vocabulary_list(\n  spec,\n  ...,\n  vocabulary_list = NULL,\n  dtype = NULL,\n  default_value = -1L,\n  num_oov_buckets = 0L\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\nvocabulary_list\nAn ordered iterable defining the vocabulary. Each feature is mapped to the index of its value (if present) in vocabulary_list. Must be castable to dtype. If NULL the vocabulary will be defined as all unique values in the dataset provided when fitting the specification.\n\n\ndtype\nThe type of features. Only string and integer types are supported. If NULL, it will be inferred from vocabulary_list.\n\n\ndefault_value\nThe integer ID value to return for out-of-vocabulary feature values, defaults to -1. This can not be specified with a positive num_oov_buckets.\n\n\nnum_oov_buckets\nNon-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range [lenght(vocabulary_list), length(vocabulary_list)+num_oov_buckets) based on a hash of the input value. A positive num_oov_buckets can not be specified with default_value.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ thal) %>%\n  step_categorical_column_with_vocabulary_list(thal)\n\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_crossed_column.html",
    "href": "packages/tfdatasets/latest/reference/step_crossed_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates crosses of categorical columns\n\n\nUse this step to create crosses between categorical columns.\n\n\n\nstep_crossed_column(spec, ..., hash_bucket_size, hash_key = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\nhash_bucket_size\nAn int > 1. The number of buckets.\n\n\nhash_key\n(optional) Specify the hash_key that will be used by the FingerprintCat64 function to combine the crosses fingerprints on SparseCrossOp.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nfile <- tempfile()\nwriteLines(unique(hearts$thal), file)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ age) %>%\n  step_numeric_column(age) %>%\n  step_bucketized_column(age, boundaries = c(10, 20, 30))\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_embedding_column.html",
    "href": "packages/tfdatasets/latest/reference/step_embedding_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates embeddings columns\n\n\nUse this step to create ambeddings columns from categorical columns.\n\n\n\nstep_embedding_column(\n  spec,\n  ...,\n  dimension = function(x) {\n     as.integer(x^0.25)\n },\n  combiner = \"mean\",\n  initializer = NULL,\n  ckpt_to_load_from = NULL,\n  tensor_name_in_ckpt = NULL,\n  max_norm = NULL,\n  trainable = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\ndimension\nAn integer specifying dimension of the embedding, must be > 0. Can also be a function of the size of the vocabulary.\n\n\ncombiner\nA string specifying how to reduce if there are multiple entries in a single row. Currently ‘mean’, ‘sqrtn’ and ‘sum’ are supported, with ‘mean’ the default. ‘sqrtn’ often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see tf.embedding_lookup_sparse.\n\n\ninitializer\nA variable initializer function to be used in embedding variable initialization. If not specified, defaults to tf.truncated_normal_initializer with mean 0.0 and standard deviation 1/sqrt(dimension).\n\n\nckpt_to_load_from\nString representing checkpoint name/pattern from which to restore column weights. Required if tensor_name_in_ckpt is not NULL.\n\n\ntensor_name_in_ckpt\nName of the Tensor in ckpt_to_load_from from which to restore the column weights. Required if ckpt_to_load_from is not NULL.\n\n\nmax_norm\nIf not NULL, embedding values are l2-normalized to this value.\n\n\ntrainable\nWhether or not the embedding is trainable. Default is TRUE.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nfile <- tempfile()\nwriteLines(unique(hearts$thal), file)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ thal) %>%\n  step_categorical_column_with_vocabulary_list(thal) %>%\n  step_embedding_column(thal, dimension = 3)\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_indicator_column.html",
    "href": "packages/tfdatasets/latest/reference/step_indicator_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates Indicator Columns\n\n\nUse this step to create indicator columns from categorical columns.\n\n\n\nstep_indicator_column(spec, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nfile <- tempfile()\nwriteLines(unique(hearts$thal), file)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ thal) %>%\n  step_categorical_column_with_vocabulary_list(thal) %>%\n  step_indicator_column(thal)\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_numeric_column.html",
    "href": "packages/tfdatasets/latest/reference/step_numeric_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a numeric column specification\n\n\nstep_numeric_column creates a numeric column specification. It can also be used to normalize numeric columns.\n\n\n\nstep_numeric_column(\n  spec,\n  ...,\n  shape = 1L,\n  default_value = NULL,\n  dtype = tf$float32,\n  normalizer_fn = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\nshape\nAn iterable of integers specifies the shape of the Tensor. An integer can be given which means a single dimension Tensor with given width. The Tensor representing the column will have the shape of batch_size + shape.\n\n\ndefault_value\nA single value compatible with dtype or an iterable of values compatible with dtype which the column takes on during tf.Example parsing if data is missing. A default value of NULL will cause tf.parse_example to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the default_value should be equal to the given shape.\n\n\ndtype\ndefines the type of values. Default value is tf$float32. Must be a non-quantized, real integer or floating point type.\n\n\nnormalizer_fn\nIf not NULL, a function that can be used to normalize the value of the tensor after default_value is applied for parsing. Normalizer function takes the input Tensor as its argument, and returns the output Tensor. (e.g. function(x) (x - 3.0) / 4.2). Please note that even though the most common use case of this function is normalization, it can be used for any kind of Tensorflow transformations. You can also a pre-made scaler, in this case a function will be created after fit.FeatureSpec is called on the feature specification.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ age) %>%\n  step_numeric_column(age, normalizer_fn = standard_scaler())\n\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_remove_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_remove_column.html",
    "href": "packages/tfdatasets/latest/reference/step_remove_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a step that can remove columns\n\n\nRemoves features of the feature specification.\n\n\n\nstep_remove_column(spec, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\n\nlibrary(tfdatasets)\ndata(hearts)\nhearts <- tensor_slices_dataset(hearts) %>% dataset_batch(32)\n\n# use the formula interface\nspec <- feature_spec(hearts, target ~ age) %>%\n  step_numeric_column(age, normalizer_fn = scaler_standard()) %>%\n  step_bucketized_column(age, boundaries = c(20, 50)) %>%\n  step_remove_column(age)\n\nspec_fit <- fit(spec)\nfinal_dataset <- hearts %>% dataset_use_spec(spec_fit)\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_shared_embeddings_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/step_shared_embeddings_column.html",
    "href": "packages/tfdatasets/latest/reference/step_shared_embeddings_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates shared embeddings for categorical columns\n\n\nThis is similar to step_embedding_column, except that it produces a list of embedding columns that share the same embedding weights.\n\n\n\nstep_shared_embeddings_column(\n  spec,\n  ...,\n  dimension,\n  combiner = \"mean\",\n  initializer = NULL,\n  shared_embedding_collection_name = NULL,\n  ckpt_to_load_from = NULL,\n  tensor_name_in_ckpt = NULL,\n  max_norm = NULL,\n  trainable = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspec\nA feature specification created with feature_spec().\n\n\n…\nComma separated list of variable names to apply the step. selectors can also be used.\n\n\ndimension\nAn integer specifying dimension of the embedding, must be > 0. Can also be a function of the size of the vocabulary.\n\n\ncombiner\nA string specifying how to reduce if there are multiple entries in a single row. Currently ‘mean’, ‘sqrtn’ and ‘sum’ are supported, with ‘mean’ the default. ‘sqrtn’ often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see tf.embedding_lookup_sparse.\n\n\ninitializer\nA variable initializer function to be used in embedding variable initialization. If not specified, defaults to tf.truncated_normal_initializer with mean 0.0 and standard deviation 1/sqrt(dimension).\n\n\nshared_embedding_collection_name\nOptional collective name of these columns. If not given, a reasonable name will be chosen based on the names of categorical_columns.\n\n\nckpt_to_load_from\nString representing checkpoint name/pattern from which to restore column weights. Required if tensor_name_in_ckpt is not NULL.\n\n\ntensor_name_in_ckpt\nName of the Tensor in ckpt_to_load_from from which to restore the column weights. Required if ckpt_to_load_from is not NULL.\n\n\nmax_norm\nIf not NULL, embedding values are l2-normalized to this value.\n\n\ntrainable\nWhether or not the embedding is trainable. Default is TRUE.\n\n\n\n\n\n\na FeatureSpec object.\n\n\n\nsteps for a complete list of allowed steps.\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), steps"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/steps.html",
    "href": "packages/tfdatasets/latest/reference/steps.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Steps for feature columns specification.\n\n\nList of steps that can be used to specify columns in the feature_spec interface.\n\n\n\n\nselectors for a list of selectors that can be used to specify variables.\n\nOther Feature Spec Functions: dataset_use_spec(), feature_spec(), fit.FeatureSpec(), step_bucketized_column(), step_categorical_column_with_hash_bucket(), step_categorical_column_with_identity(), step_categorical_column_with_vocabulary_file(), step_categorical_column_with_vocabulary_list(), step_crossed_column(), step_embedding_column(), step_indicator_column(), step_numeric_column(), step_remove_column(), step_shared_embeddings_column()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/tensor_slices_dataset.html",
    "href": "packages/tfdatasets/latest/reference/tensor_slices_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset whose elements are slices of the given tensors.\n\n\nCreates a dataset whose elements are slices of the given tensors.\n\n\n\ntensor_slices_dataset(tensors)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntensors\nA nested structure of tensors, each having the same size in the 0th dimension.\n\n\n\n\n\n\nA dataset.\n\n\n\nOther tensor datasets: sparse_tensor_slices_dataset(), tensors_dataset()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/tensors_dataset.html",
    "href": "packages/tfdatasets/latest/reference/tensors_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset with a single element, comprising the given tensors.\n\n\nCreates a dataset with a single element, comprising the given tensors.\n\n\n\ntensors_dataset(tensors)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntensors\nA nested structure of tensors.\n\n\n\n\n\n\nA dataset.\n\n\n\nOther tensor datasets: sparse_tensor_slices_dataset(), tensor_slices_dataset()"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/text_line_dataset.html",
    "href": "packages/tfdatasets/latest/reference/text_line_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A dataset comprising lines from one or more text files.\n\n\nA dataset comprising lines from one or more text files.\n\n\n\ntext_line_dataset(\n  filenames,\n  compression_type = NULL,\n  record_spec = NULL,\n  parallel_records = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfilenames\nString(s) specifying one or more filenames\n\n\ncompression_type\nA string, one of: NULL (no compression), \"ZLIB\", or \"GZIP\".\n\n\nrecord_spec\n(Optional) Specification used to decode delimimted text lines into records (see delim_record_spec()).\n\n\nparallel_records\n(Optional) An integer, representing the number of records to decode in parallel. If not specified, records will be processed sequentially.\n\n\n\n\n\n\nA dataset"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/tfrecord_dataset.html",
    "href": "packages/tfdatasets/latest/reference/tfrecord_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "A dataset comprising records from one or more TFRecord files.\n\n\nA dataset comprising records from one or more TFRecord files.\n\n\n\ntfrecord_dataset(\n  filenames,\n  compression_type = NULL,\n  buffer_size = NULL,\n  num_parallel_reads = NULL\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfilenames\nString(s) specifying one or more filenames\n\n\ncompression_type\nA string, one of: NULL (no compression), \"ZLIB\", or \"GZIP\".\n\n\nbuffer_size\nAn integer representing the number of bytes in the read buffer. (0 means no buffering).\n\n\nnum_parallel_reads\nAn integer representing the number of files to read in parallel. Defaults to reading files sequentially.\n\n\n\n\n\n\nIf the dataset encodes a set of TFExample instances, then they can be decoded into named records using the dataset_map() function (see example below).\n\n\n\n\n\n# Creates a dataset that reads all of the examples from two files, and extracts\n# the image and label features.\nfilenames <- c(\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\")\ndataset <- tfrecord_dataset(filenames) %>%\n  dataset_map(function(example_proto) {\n    features <- list(\n      image = tf$FixedLenFeature(shape(), tf$string, default_value = \"\"),\n      label = tf$FixedLenFeature(shape(), tf$int32, default_value = 0L)\n    )\n    tf$parse_single_example(example_proto, features)\n  })"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/until_out_of_range.html",
    "href": "packages/tfdatasets/latest/reference/until_out_of_range.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Execute code that traverses a dataset until an out of range condition occurs\n\n\nExecute code that traverses a dataset until an out of range condition occurs\n\n\n\nuntil_out_of_range(expr)\n\nout_of_range_handler(e)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nexpr\nExpression to execute (will be executed multiple times until the condition occurs)\n\n\ne\nError object\n\n\n\n\n\n\nWhen a dataset iterator reaches the end, an out of range runtime error will occur. This function will catch and ignore the error when it occurs.\n\n\n\n\nlibrary(tfdatasets)\ndataset <- text_line_dataset(\"mtcars.csv\", record_spec = mtcars_spec) %>%\n  dataset_batch(128) %>%\n  dataset_repeat(10) %>%\n  dataset_prepare(x = c(mpg, disp), y = cyl)\n\niter <- make_iterator_one_shot(dataset)\nnext_batch <- iterator_get_next(iter)\n\nuntil_out_of_range({\n  batch <- sess$run(next_batch)\n  # use batch$x and batch$y tensors\n})"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/with_dataset.html",
    "href": "packages/tfdatasets/latest/reference/with_dataset.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Execute code that traverses a dataset\n\n\nExecute code that traverses a dataset\n\n\n\nwith_dataset(expr)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nexpr\nExpression to execute\n\n\n\n\n\n\nWhen a dataset iterator reaches the end, an out of range runtime error will occur. You can catch and ignore the error when it occurs by wrapping your iteration code in a call to with_dataset() (see the example below for an illustration).\n\n\n\n\nlibrary(tfdatasets)\ndataset <- text_line_dataset(\"mtcars.csv\", record_spec = mtcars_spec) %>%\n  dataset_prepare(x = c(mpg, disp), y = cyl) %>%\n  dataset_batch(128) %>%\n  dataset_repeat(10)\n\niter <- make_iterator_one_shot(dataset)\nnext_batch <- iterator_get_next(iter)\n\nwith_dataset({\n  while(TRUE) {\n    batch <- sess$run(next_batch)\n    # use batch$x and batch$y tensors\n  }\n})"
  },
  {
    "objectID": "packages/tfdatasets/latest/reference/zip_datasets.html",
    "href": "packages/tfdatasets/latest/reference/zip_datasets.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Creates a dataset by zipping together the given datasets.\n\n\nMerges datasets together into pairs or tuples that contain an element from each dataset.\n\n\n\nzip_datasets(...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nDatasets to zip (or a single argument with a list or list of lists of datasets).\n\n\n\n\n\n\nA dataset"
  },
  {
    "objectID": "packages/index.html",
    "href": "packages/index.html",
    "title": "Reference",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "packages/tfhub/latest/news.html",
    "href": "packages/tfhub/latest/news.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "tfhub 0.8.0\n\nAdded a NEWS.md file to track changes to the package."
  },
  {
    "objectID": "packages/tfhub/latest/reference/bake.step_pretrained_text_embedding.html",
    "href": "packages/tfhub/latest/reference/bake.step_pretrained_text_embedding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Bake method for step_pretrained_text_embedding\n\n\nBake method for step_pretrained_text_embedding\n\n\n\nbake.step_pretrained_text_embedding(object, new_data, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nobject\n\n\nnew_data\nnew data to apply transformations\n\n\n…\nOne or more selector functions to choose variables."
  },
  {
    "objectID": "packages/tfhub/latest/reference/hub_image_embedding_column.html",
    "href": "packages/tfhub/latest/reference/hub_image_embedding_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Module to construct a dense 1-D representation from the pixels of images.\n\n\nModule to construct a dense 1-D representation from the pixels of images.\n\n\n\nhub_image_embedding_column(key, module_spec)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nkey\nA string or feature_column identifying the text feature.\n\n\nmodule_spec\nA string handle or a _ModuleSpec identifying the module.\n\n\n\n\n\n\nThis feature column can be used on images, represented as float32 tensors of RGB pixel data in the range [0,1]."
  },
  {
    "objectID": "packages/tfhub/latest/reference/hub_load.html",
    "href": "packages/tfhub/latest/reference/hub_load.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Hub Load\n\n\nLoads a module from a handle.\n\n\n\nhub_load(handle, tags = NULL)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nhandle\n(string) the Module handle to resolve.\n\n\ntags\nA set of strings specifying the graph variant to use, if loading from a v1 module.\n\n\n\n\n\n\nCurrently this method is fully supported only with Tensorflow 2.x and with modules created by calling export_savedmodel. The method works in both eager and graph modes.\nDepending on the type of handle used, the call may involve downloading a TensorFlow Hub module to a local cache location specified by the TFHUB_CACHE_DIR environment variable. If a copy of the module is already present in the TFHUB_CACHE_DIR, the download step is skipped.\nCurrently, three types of module handles are supported: 1) Smart URL resolvers such as tfhub.dev, e.g.: https://tfhub.dev/google/nnlm-en-dim128/1. 2) A directory on a file system supported by Tensorflow containing module files. This may include a local directory (e.g. /usr/local/mymodule) or a Google Cloud Storage bucket (gs://mymodule). 3) A URL pointing to a TGZ archive of a module, e.g. https://example.com/mymodule.tar.gz.\n\n\n\n\n\nmodel <- hub_load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')"
  },
  {
    "objectID": "packages/tfhub/latest/reference/hub_sparse_text_embedding_column.html",
    "href": "packages/tfhub/latest/reference/hub_sparse_text_embedding_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Module to construct dense representations from sparse text features.\n\n\nThe input to this feature column is a batch of multiple strings with arbitrary size, assuming the input is a SparseTensor.\n\n\n\nhub_sparse_text_embedding_column(\n  key,\n  module_spec,\n  combiner,\n  default_value,\n  trainable = FALSE\n)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nkey\nA string or feature_column identifying the text feature.\n\n\nmodule_spec\nA string handle or a _ModuleSpec identifying the module.\n\n\ncombiner\na string specifying reducing op for embeddings in the same Example. Currently, ‘mean’, ‘sqrtn’, ‘sum’ are supported. Using combiner = NULL is undefined.\n\n\ndefault_value\ndefault value for Examples where the text feature is empty. Note, it’s recommended to have default_value consistent OOV tokens, in case there was special handling of OOV in the text module. If NULL, the text feature is assumed be non-empty for each Example.\n\n\ntrainable\nWhether or not the Module is trainable. FALSE by default, meaning the pre-trained weights are frozen. This is different from the ordinary tf.feature_column.embedding_column(), but that one is intended for training from scratch.\n\n\n\n\n\n\nThis type of feature column is typically suited for modules that operate on pre-tokenized text to produce token level embeddings which are combined with the combiner into a text embedding. The combiner always treats the tokens as a bag of words rather than a sequence.\nThe output (i.e., transformed input layer) is a DenseTensor, with shape [batch_size, num_embedding_dim]."
  },
  {
    "objectID": "packages/tfhub/latest/reference/hub_text_embedding_column.html",
    "href": "packages/tfhub/latest/reference/hub_text_embedding_column.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Module to construct a dense representation from a text feature.\n\n\nThis feature column can be used on an input feature whose values are strings of arbitrary size.\n\n\n\nhub_text_embedding_column(key, module_spec, trainable = FALSE)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nkey\nA string or feature_column identifying the text feature.\n\n\nmodule_spec\nA string handle or a _ModuleSpec identifying the module.\n\n\ntrainable\nWhether or not the Module is trainable. FALSE by default, meaning the pre-trained weights are frozen. This is different from the ordinary tf.feature_column.embedding_column(), but that one is intended for training from scratch."
  },
  {
    "objectID": "packages/tfhub/latest/reference/index.html",
    "href": "packages/tfhub/latest/reference/index.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\nbake.step_pretrained_text_embedding()\nBake method for step_pretrained_text_embedding\n\n\nhub_image_embedding_column()\nModule to construct a dense 1-D representation from the pixels of images.\n\n\nhub_load()\nHub Load\n\n\nhub_sparse_text_embedding_column()\nModule to construct dense representations from sparse text features.\n\n\nhub_text_embedding_column()\nModule to construct a dense representation from a text feature.\n\n\ninstall_tfhub()\nInstall TensorFlow Hub\n\n\nlayer_hub()\nHub Layer\n\n\n%&gt;%\nPipe operator\n\n\nprep.step_pretrained_text_embedding()\nPrep method for step_pretrained_text_embedding\n\n\nstep_pretrained_text_embedding()\nPretrained text-embeddings"
  },
  {
    "objectID": "packages/tfhub/latest/reference/install_tfhub.html",
    "href": "packages/tfhub/latest/reference/install_tfhub.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Install TensorFlow Hub\n\n\nThis function is used to install the TensorFlow Hub python module.\n\n\n\ninstall_tfhub(version = \"release\", ..., restart_session = TRUE)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nversion\nversion of TensorFlow Hub to be installed.\n\n\n…\nother arguments passed to [reticulate::py_install()].\n\n\nrestart_session\nRestart R session after installing (note this will only occur within RStudio)."
  },
  {
    "objectID": "packages/tfhub/latest/reference/layer_hub.html",
    "href": "packages/tfhub/latest/reference/layer_hub.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Hub Layer\n\n\nWraps a Hub module (or a similar callable) for TF2 as a Keras Layer.\n\n\n\nlayer_hub(object, handle, trainable = FALSE, arguments = NULL, ...)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nobject\nModel or layer object\n\n\nhandle\na callable object (subject to the conventions above), or a string for which hub_load() returns such a callable. A string is required to save the Keras config of this Layer.\n\n\ntrainable\nBoolean controlling whether this layer is trainable.\n\n\narguments\noptionally, a list with additional keyword arguments passed to the callable. These must be JSON-serializable to save the Keras config of this layer.\n\n\n…\nOther arguments that are passed to the TensorFlow Hub module.\n\n\n\n\n\n\nThis layer wraps a callable object for use as a Keras layer. The callable object can be passed directly, or be specified by a string with a handle that gets passed to hub_load().\nThe callable object is expected to follow the conventions detailed below. (These are met by TF2-compatible modules loaded from TensorFlow Hub.)\nThe callable is invoked with a single positional argument set to one tensor or a list of tensors containing the inputs to the layer. If the callable accepts a training argument, a boolean is passed for it. It is TRUE if this layer is marked trainable and called for training.\nIf present, the following attributes of callable are understood to have special meanings: variables: a list of all tf.Variable objects that the callable depends on. trainable_variables: those elements of variables that are reported as trainable variables of this Keras Layer when the layer is trainable. regularization_losses: a list of callables to be added as losses of this Keras Layer when the layer is trainable. Each one must accept zero arguments and return a scalar tensor.\n\n\n\n\n\nlibrary(keras)\n\nmodel <- keras_model_sequential() %>%\n layer_hub(\n   handle = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n   input_shape = c(224, 224, 3)\n ) %>%\n layer_dense(1)"
  },
  {
    "objectID": "packages/tfhub/latest/reference/pipe.html",
    "href": "packages/tfhub/latest/reference/pipe.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pipe operator\n\n\nSee %>% for more details.\n\n\n\nlhs %>% rhs"
  },
  {
    "objectID": "packages/tfhub/latest/reference/prep.step_pretrained_text_embedding.html",
    "href": "packages/tfhub/latest/reference/prep.step_pretrained_text_embedding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Prep method for step_pretrained_text_embedding\n\n\nPrep method for step_pretrained_text_embedding\n\n\n\nprep.step_pretrained_text_embedding(x, training, info = NULL, ...)\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nobject\n\n\ntraining\nwether or not it’s training\n\n\ninfo\nvariables state\n\n\n…\nOne or more selector functions to choose variables."
  },
  {
    "objectID": "packages/tfhub/latest/reference/reexports.html",
    "href": "packages/tfhub/latest/reference/reexports.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Objects exported from other packages\n\n\nThese objects are imported from other packages. Follow the links below to see their documentation."
  },
  {
    "objectID": "packages/tfhub/latest/reference/step_pretrained_text_embedding.html",
    "href": "packages/tfhub/latest/reference/step_pretrained_text_embedding.html",
    "title": "TensorFlow for R",
    "section": "",
    "text": "Pretrained text-embeddings\n\n\nstep_pretrained_text_embedding creates a specification of a recipe step that will transform text data into its numerical transformation based on a pretrained model.\n\n\n\nstep_pretrained_text_embedding(\n  recipe,\n  ...,\n  role = \"predictor\",\n  trained = FALSE,\n  handle,\n  args = NULL,\n  skip = FALSE,\n  id = recipes::rand_id(\"pretrained_text_embedding\")\n)\n\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nrecipe\nA recipe object. The step will be added to the sequence of operations for this recipe.\n\n\n…\nOne or more selector functions to choose variables.\n\n\nrole\nRole for the created variables\n\n\ntrained\nA logical to indicate if the quantities for preprocessing have been estimated.\n\n\nhandle\nthe Module handle to resolve.\n\n\nargs\nother arguments passed to [hub_load()].\n\n\nskip\nA logical. Should the step be skipped when the recipe is baked by [recipes::bake.recipe()]? While all operations are baked when [recipes::prep.recipe()] is run, some operations may not be able to be conducted on new data (e.g. processing the outcome variable(s)). Care should be taken when using skip = TRUE as it may affect the computations for subsequent operations\n\n\nid\nA character string that is unique to this step to identify it.\n\n\n\n\n\n\n\nlibrary(tibble)\nlibrary(recipes)\ndf <- tibble(text = c('hi', \"heello\", \"goodbye\"), y = 0)\n\nrec <- recipe(y ~ text, df)\nrec <- rec %>% step_pretrained_text_embedding(\n text,\n handle = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\"\n)"
  }
]