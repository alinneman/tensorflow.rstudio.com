---
title: Advanced
---

```{r}
# Copyright 2019 The TensorFlow Authors.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
```

# TensorFlow 2 quickstart for experts

Import TensorFlow into your program. If you haven't installed TensorFlow yet, go
to the [installation guide](/install).

```{r}
library(tensorflow)
library(tfdatasets)
library(keras)
```

Load and prepare the [MNIST dataset](http://yann$lecun.com/exdb/mnist/).

```{r}
c(c(x_train, y_train), c(x_test, y_test)) %<-% keras::dataset_mnist()
x_train[] <- x_train / 255
x_test[] <-  x_test / 255 
```

Use TensorFlow datasets to batch and shuffle the dataset:

```{r}
expand_and_cast <- function(x, y) {
  list(
    tf$cast(tf$expand_dims(x, axis = 2L), tf$float32),
    y
  )
}


train_ds <- list(x_train, y_train) %>% 
  tensor_slices_dataset() %>% 
  dataset_shuffle(10000) %>% 
  dataset_batch(32)

test_ds <- tensor_slices_dataset(list(x_test, y_test)) %>% 
  dataset_batch(32)
```

Build the a model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):

```{r}
my_model <- new_model_class(
  "my_model",
  initialize = function() {
    super()$`__init__`()
    self$conv1 <- layer_conv_2d(filters = 32, kernel_size = 3, activation = 'relu')
    self$flatten <- layer_flatten()
    self$d1 <- layer_dense(units = 128, activation = 'relu')
    self$d2 <- layer_dense(units = 10)
  },
  call = function(inputs) {
    inputs %>% 
      tf$expand_dims(3L) %>% 
      self$conv1() %>% 
      self$flatten() %>% 
      self$d1() %>% 
      self$d2()
  }
)

# Create an instance of the model
model <- my_model()
```

Choose an optimizer and loss function for training: 

```{r}
loss_object <- loss_sparse_categorical_crossentropy(from_logits = TRUE)
optimizer <- optimizer_adam()
```

Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result.

```{r}
train_loss <- metric_mean(name = "train_loss")
train_accuracy <- metric_sparse_categorical_accuracy(name = "train_accuracy")

test_loss <- metric_mean(name = "test_loss")
test_accuracy <- metric_sparse_categorical_accuracy(name = "test_accuracy")
```

Use `tf$GradientTape` to train the model:

```{r}
train_step <- function(images, labels) {
  with(tf$GradientTape() %as% tape, {
    # training = TRUE is only needed if there are layers with different
    # behavior during training versus inference (e.g. Dropout).
    predictions <- model(images, training = TRUE)
    loss <- loss_object(labels, predictions)
  })
  gradients <- tape$gradient(loss, model$trainable_variables)
  optimizer$apply_gradients(zip_lists(gradients, model$trainable_variables))
  train_loss(loss)
  train_accuracy(labels, predictions)
  1
}

train <- tfautograph::autograph(function(train_ds) {
  for (batch in train_ds) {
    train_step(batch[[1]], batch[[2]])
  }
})
```

Test the model:

```{r}
test_step <- function(images, labels) {
  # training = FALSE is only needed if there are layers with different
  # behavior during training versus inference (e.g. Dropout).
  predictions <- model(images, training = FALSE)
  t_loss <- loss_object(labels, predictions)
  test_loss(t_loss)
  test_accuracy(labels, predictions)
}
test <- tfautograph::autograph(function(test_ds) {
  for (batch in test_ds) {
    test_step(batch[[1]], batch[[2]])
  }
})
```

```{r}
EPOCHS <- 1
for (epoch in seq_len(EPOCHS)) {
  # Reset the metrics at the start of the next epoch
  train_loss$reset_states()
  train_accuracy$reset_states()
  test_loss$reset_states()
  test_accuracy$reset_states()
  train(train_ds)
  test(test_ds)
  cat(sprintf('Epoch %d', epoch), "\n")
  cat(sprintf('Loss: %f', as.numeric(train_loss$result())), "\n")
  cat(sprintf('Accuracy: %f', train_accuracy$result() * 100), "\n")
  cat(sprintf('Test Loss: %f', test_loss$result()), "\n")
  cat(sprintf('Test Accuracy: %f', test_accuracy$result() * 100), "\n")
}
```

The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](/tutorials).
